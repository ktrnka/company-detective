{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified summary, Version 2!\n",
    "\n",
    "Key changes from version 1:\n",
    "- Organized by topic rather than data source\n",
    "- Technical\n",
    "    - Generate citations in a consistent format with links back to the sources\n",
    "    - Extract, organize, then abstract\n",
    "    - Heavy use of caching\n",
    "- Data sources\n",
    "    - Integrated\n",
    "        - Crunchbase\n",
    "        - Glassdoor\n",
    "        - Reddit\n",
    "        - News\n",
    "        - General search\n",
    "    - In progress\n",
    "        - Indeed job dscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import CompanyProduct, init\n",
    "\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = CompanyProduct.same(\"98point6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jinja2\n",
    "\n",
    "templates = jinja2.Environment(\n",
    "    loader=jinja2.FileSystemLoader(\"templates\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Lineage\n",
      "\n",
      "- Run at: 2024-08-23T11:49:45.227800\n",
      "- Git SHA: 8ac5171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "def git_sha():\n",
    "    return subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD']).decode().strip()\n",
    "\n",
    "def generate_lineage_markdown():\n",
    "    return f\"\"\"\n",
    "# Lineage\n",
    "\n",
    "- Run at: {datetime.now().isoformat()}\n",
    "- Git SHA: {git_sha()}\n",
    "\"\"\"\n",
    "\n",
    "print(generate_lineage_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-23 11:49:49.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m22,405 -> 21,075 chars (94% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:49:54.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36munshorten_markdown\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m1,659 -> 1,982 chars (119% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:49:54.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgeneral_search\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m22,405 -> 1,982 chars (9%) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:49:54.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgeneral_search\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mExtractive fraction: 54% \u001b[0m\n",
      "\u001b[32m2024-08-23 11:49:54.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgeneral_search\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mPercent of URLs in sources: 100% ✅\u001b[0m\n",
      "\u001b[32m2024-08-23 11:49:54.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgeneral_search\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mCitation density: 46.5% (percent of output used by URLs/link syntax) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:49:54.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgeneral_search\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mSuspicious URLs: set()\u001b[0m\n",
      "\u001b[32m2024-08-23 11:49:54.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgeneral_search\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mCache mentions: 0 ✅\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m86,983 -> 63,344 chars (73% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m28,497 -> 23,310 chars (82% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m5,165 -> 4,022 chars (78% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m3,663 -> 2,671 chars (73% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m13,770 -> 12,129 chars (88% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m4,919 -> 3,894 chars (79% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m6,786 -> 5,594 chars (82% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m69,324 -> 53,281 chars (77% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:50:13.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m110,865 -> 90,700 chars (82% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36munshorten_markdown\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m5,249 -> 7,831 chars (149% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreddit.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mReddit: Extract stage 329,972 chars -> 12,676 chars (4%)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreddit.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mReddit: Combine stage 12,676 chars -> 7,831 chars (62%)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreddit.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m361,829 -> 7,831 chars (2%) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreddit.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mExtractive fraction: 65% \u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreddit.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mPercent of URLs in sources: 100% ✅\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreddit.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mCitation density: 41.6% (percent of output used by URLs/link syntax) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreddit.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mSuspicious URLs: set()\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreddit.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mCache mentions: 2 ❌\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscrapfly_scrapers.glassdoor\u001b[0m:\u001b[36mscrape_reviews\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mscraping reviews from https://www.glassdoor.com/Reviews/Oracle-Reviews-E1737.htm\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:21.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscrapfly_scrapers.glassdoor\u001b[0m:\u001b[36mscrape_reviews\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mscraped first page of reviews of https://www.glassdoor.com/Reviews/Oracle-Reviews-E1737.htm, scraping remaining 9 pages\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:30.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscrapfly_scrapers.glassdoor\u001b[0m:\u001b[36mscrape_reviews\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mscraped 100 reviews from https://www.glassdoor.com/Reviews/Oracle-Reviews-E1737.htm in 10 pages\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:43.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mglassdoor.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1m56,911 -> 3,912 chars (7%) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:43.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mglassdoor.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mExtractive fraction: 53% \u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:43.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mglassdoor.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mPercent of URLs in sources: 100% ✅\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:43.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mglassdoor.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mCitation density: 31.0% (percent of output used by URLs/link syntax) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:43.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mglassdoor.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mSuspicious URLs: set()\u001b[0m\n",
      "\u001b[32m2024-08-23 11:51:43.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mglassdoor.summarizer\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mCache mentions: 0 ✅\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request_article: Timeout on https://blogs.oracle.com/cloud-infrastructure/post/whats-new-april-2024\n",
      "request_article: Timeout on https://blogs.oracle.com/coretec/post/oracle-database-monthly-news-december-2023-quick-links\n",
      "request_article: Timeout on https://www.costar.com/article/1367405013/oracle-expands-in-san-antonio-following-news-of-potential-headquarters-move\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-23 11:53:17.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnews.summarize\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m89,883 -> 5,179 chars (6%) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:17.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnews.summarize\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mExtractive fraction: 22% \u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:17.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnews.summarize\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mPercent of URLs in sources: 100% ✅\u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:17.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnews.summarize\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mCitation density: 21.6% (percent of output used by URLs/link syntax) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:17.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnews.summarize\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mSuspicious URLs: set()\u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:17.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnews.summarize\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mCache mentions: 0 ✅\u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:18.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m7,831 -> 5,216 chars (67% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:18.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m3,912 -> 3,083 chars (79% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:18.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m5,179 -> 4,372 chars (84% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:18.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m2,557 -> 1,641 chars (64% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:53:18.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36mshorten_markdown\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m1,982 -> 1,664 chars (84% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:54:02.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcore\u001b[0m:\u001b[36munshorten_markdown\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m9,796 -> 15,316 chars (156% of original)\u001b[0m\n",
      "\u001b[32m2024-08-23 11:54:02.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36munified_summary\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1m21,469 -> 15,316 chars (71%) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:54:02.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36munified_summary\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mExtractive fraction: 71% \u001b[0m\n",
      "\u001b[32m2024-08-23 11:54:02.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36munified_summary\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mPercent of URLs in sources: 97% ❌\u001b[0m\n",
      "\u001b[32m2024-08-23 11:54:02.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36munified_summary\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mCitation density: 51.1% (percent of output used by URLs/link syntax) \u001b[0m\n",
      "\u001b[32m2024-08-23 11:54:02.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36munified_summary\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mSuspicious URLs: {'cache://reddit/286', 'cache://reddit/600'}\u001b[0m\n",
      "\u001b[32m2024-08-23 11:54:02.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36munified_summary\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mCache mentions: 4 ❌\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to /home/keith/company-detective/output/Oracle/Oracle_20240823_115402.md\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from core import CompanyProduct, log_summary_metrics\n",
    "\n",
    "from reddit import run as process_reddit\n",
    "from glassdoor import run as process_glassdoor\n",
    "from news import run as process_news\n",
    "from crunchbase import run as process_crunchbase\n",
    "\n",
    "from core import eval_filename, nest_markdown\n",
    "from glassdoor import GlassdoorResult\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "PERSONA\n",
    "You're an expert in reviewing and analyzing news about companies and products.\n",
    "When interpreting information, you understand that all authors impart some bias and perspective according to their incentives and access to information.\n",
    "You seek to understand the authors to better interpret and debias their information by considering their background, affiliations, and potential motivations.\n",
    "\n",
    "When assessing product quality:\n",
    "- Companies typically exaggerate the positive aspects of their products and hide the negative aspects. Hence, you treat company statements about product quality with skepticism and seek corroborating evidence from independent sources.\n",
    "- Reddit tends to be polarized, often oversampling strong opinions, particularly negative ones. Therefore, you interpret feedback on Reddit by looking for patterns across multiple comments and considering the context of each comment to identify more balanced views.\n",
    "\n",
    "You review a wide range of sources to get a comprehensive view that's less susceptible to individual biases. You also consider the reliability of each source with respect to the type of information it provides. For example:\n",
    "- Crunchbase is a reliable source for information about fundraising but less so for the current number of employees.\n",
    "- News sources can be reliable but must be cross-referenced with other reports to ensure accuracy.\n",
    "\n",
    "When sharing information with others, you're careful to provide specific details and cite sources so that your readers can easily verify all information. You understand that using quotes and citations builds trust with your audience, as it demonstrates transparency and allows them to see the original context of the information. Including dates in citations is crucial because:\n",
    "- The date is a key factor in determining relevance. For example, very positive but older sentiment about a company may not indicate much about its current state.\n",
    "- Certain key details about companies and products can change drastically over time, so noting the general timeframe is crucial for accuracy. For instance, a company may have had 300 employees in 2021 but only 20 employees in 2024. Including the date provides essential context for such information.\n",
    "\n",
    "You keep facts and opinions clearly separated but share both with your audience to provide a well-rounded perspective. Your goal is to offer as detailed and balanced a view as possible, allowing your audience to make well-informed decisions. You focus on specifics, such as numbers and concrete examples, to provide clarity and support your analysis.\n",
    "\n",
    "TASK\n",
    "Carefully review all of the following information about a company and its product.\n",
    "Write a comprehensive report with citations to the original sources for reference.\n",
    "\n",
    "OUTPUT CONTENT AND FORMAT\n",
    "\n",
    "Loosely follow this template in your report. Each markdown section has tips on what information is most critical.\n",
    "\n",
    "# About {company_name}\n",
    "\n",
    "The About section should provide all the essential information about the company.\n",
    "An ideal section should at least incorporate the answers to the following questions, if available:\n",
    "- When was the company founded?\n",
    "- Approximately how many employees work at the company?\n",
    "- What products does the company produce? What services does the company offer?\n",
    "- How does the company make money? Who are their customers in general? Is it B2B, B2C? If B2B, include example customers.\n",
    "- Approximately how much revenue does the company generate annually?\n",
    "- Describe the scale of the company if possible, including the number of customers, users, or clients.\n",
    "- How are the company's products distributed or sold to users?\n",
    "- How has the company changed over time?\n",
    "\n",
    "# Key personnel\n",
    "\n",
    "Include the names and roles of any key personnel at the company. If possible, provide a brief summary of their background and experience as well as any sentiments expressed about them in the sources.\n",
    "\n",
    "# News (reverse chronological, grouped by event)\n",
    "\n",
    "# Working at {company_name}\n",
    "\n",
    "The section should include answers to the following questions and more, if available:\n",
    "- Why do people like working here?\n",
    "- Why do people dislike working here?\n",
    "- What benefits are provided?\n",
    "- How do employees feel about the leadership team?\n",
    "- Are there any concerning signs about DEI, such as a lack of diversity in certain roles or systematic issues for underrepresented groups?\n",
    "- How do employees feel about work-life balance?\n",
    "- How has the company changed over time?\n",
    "- How does employee sentiment vary by job function? Are certain roles more satisfying than others?\n",
    "\n",
    "## Positive sentiments and experiences\n",
    "\n",
    "## Negative sentiments and experiences\n",
    "\n",
    "## Neutral statements about working at {company_name}\n",
    "\n",
    "This section might include general statements about location, benefits, and other factual information that could be verified.\n",
    "\n",
    "# User reviews, sentiments, and feedback about {product_name}\n",
    "\n",
    "Please group information thematically within each section. If there's a wide date range for the information, group by year.\n",
    "\n",
    "## Positive sentiments and experiences\n",
    "\n",
    "## Negative sentiments and experiences\n",
    "\n",
    "## Neutral statements about {product_name}\n",
    "\n",
    "This section could include general, neutral statements about the product, its features, distribution, key product changes, pricing, and so on.\n",
    "\n",
    "# Bibliography\n",
    "\n",
    "The Bibliography should include a list of all the sources used to compile the summary. If there are many sources, group them by type (e.g., Reddit, Glassdoor, News, Crunchbase).\n",
    "\n",
    "# Additional reading\n",
    "\n",
    "This section should organize any additional links that the reader might find useful for further research.\n",
    "\n",
    "\n",
    "Feel free to create subheadings or additional sections as needed to capture all relevant information about the company and its product.\n",
    "Format the output as a markdown document, using markdown links for citations.\n",
    "Citations should follow the format [(Author or Title, Source, Date)](url).\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "Company: {company_name}\n",
    "Product: {product_name}\n",
    "\n",
    "Reddit sources: \n",
    "{reddit_text}\n",
    "\n",
    "Glassdoor sources:\n",
    "{glassdoor_text}\n",
    "\n",
    "News sources:\n",
    "{news_text}\n",
    "\n",
    "Crunchbase information:\n",
    "{crunchbase_text}\n",
    "\n",
    "Additional search results:\n",
    "{search_text}\n",
    "            \"\"\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "from core import URLShortener, cleanse_markdown\n",
    "from loguru import logger\n",
    "import general_search\n",
    "\n",
    "async def unified_summary(target: CompanyProduct, num_reddit_threads=2, max_glassdoor_review_pages=1, max_glassdoor_job_pages=1, max_news_articles=10, glassdoor_url=None):\n",
    "    general_search_results = general_search.search_web(target)\n",
    "    general_search_summary = general_search.summarize(target, general_search_results).content\n",
    "\n",
    "    crunchbase_markdown = await process_crunchbase(target)\n",
    "    if not crunchbase_markdown:\n",
    "        crunchbase_markdown = \"\"\n",
    "\n",
    "    reddit_result = process_reddit(target, num_threads=num_reddit_threads)\n",
    "    glassdoor_result = await process_glassdoor(target, max_review_pages=max_glassdoor_review_pages, max_job_pages=max_glassdoor_job_pages, url_override=glassdoor_url)\n",
    "    if not glassdoor_result:\n",
    "        # Hack to make the rest of the code simpler\n",
    "        glassdoor_result = GlassdoorResult.empty_result(target)\n",
    "    news_result = process_news(target, max_results=max_news_articles)\n",
    "\n",
    "    unshortened_context = \"\\n\\n\".join([\n",
    "        reddit_result.summary.output_text,\n",
    "        glassdoor_result.summary_markdown,\n",
    "        news_result.summary_markdown,\n",
    "        crunchbase_markdown,\n",
    "        general_search_summary,\n",
    "    ])\n",
    "\n",
    "    url_shortener = URLShortener()\n",
    "\n",
    "    # feed results into LLM for summarization\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    runnable = prompt | llm\n",
    "    result = runnable.invoke({\n",
    "        \"company_name\": target.company, \n",
    "        \"product_name\": target.product,\n",
    "        \"reddit_text\": url_shortener.shorten_markdown(reddit_result.summary.output_text),\n",
    "        \"glassdoor_text\": url_shortener.shorten_markdown(glassdoor_result.summary_markdown),\n",
    "        \"news_text\": url_shortener.shorten_markdown(news_result.summary_markdown),\n",
    "        \"crunchbase_text\": url_shortener.shorten_markdown(crunchbase_markdown),\n",
    "        \"search_text\": url_shortener.shorten_markdown(general_search_summary),\n",
    "        })\n",
    "    result.content = url_shortener.unshorten_markdown(cleanse_markdown(result.content))\n",
    "\n",
    "    log_summary_metrics(result.content, unshortened_context, extractive=False)\n",
    "\n",
    "\n",
    "    with open(eval_filename(target, extension=\"md\"), \"w\") as f:\n",
    "        f.write(result.content)\n",
    "\n",
    "        f.write(generate_lineage_markdown())\n",
    "\n",
    "        f.write(\"\"\"\n",
    "                \n",
    "----\n",
    "\n",
    "# INTERMEDIATE RESULTS BELOW\n",
    "Note: The report above is an aggregation of all the information below. I like to include the intermediate outputs below for debugging and verification. For instance, if the final output has a very brief section on employee sentiment, I can refer to the Glassdoor and Reddit sections below to see if it's a problem in the overall summarization or if the intermediate results were lacking.\n",
    "\"\"\")\n",
    "\n",
    "        # Write the raw Reddit summary too\n",
    "        f.write(f\"\\n----\\n# Reddit\\n{nest_markdown(reddit_result.summary.output_text, 1)}\\n\\n\")\n",
    "\n",
    "        # Write the individual Reddit threads\n",
    "        # for thread in reddit_result.threads:\n",
    "        #     f.write(f\"{reddit.fetch.submission_to_markdown(thread)}\\n\\n\")\n",
    "\n",
    "        # Write the raw Glassdoor summary too\n",
    "        f.write(f\"\\n----\\n# Glassdoor\\n{nest_markdown(glassdoor_result.summary_markdown, 1)}\\n\\n\")\n",
    "\n",
    "        # Write the individual Glassdoor reviews\n",
    "        # for review in glassdoor_result.reviews:\n",
    "        #     review_md = templates.get_template(\"glassdoor_review.md\").render(review=review)\n",
    "        #     f.write(f\"{review_md}\\n\\n\")\n",
    "\n",
    "        # Write the raw News summary too\n",
    "        f.write(f\"\\n----\\n# News\\n{nest_markdown(news_result.summary_markdown, 1)}\\n\\n\")\n",
    "\n",
    "        # Write the raw Crunchbase summary too\n",
    "        f.write(f\"\\n----\\n# Crunchbase\\n{nest_markdown(crunchbase_markdown, 1)}\\n\\n\")\n",
    "\n",
    "        # Write the raw General Search summary too\n",
    "        f.write(f\"\\n----\\n# General Search\\n{nest_markdown(general_search_summary, 1)}\\n\\n\")\n",
    "\n",
    "        print(f\"Written to {f.name}\")\n",
    "\n",
    "        return f.name\n",
    "\n",
    "import sys\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")\n",
    "\n",
    "markdown_file = await unified_summary(\n",
    "    CompanyProduct.same(\"Oracle\"), \n",
    "    num_reddit_threads=10, \n",
    "    max_glassdoor_review_pages=10, \n",
    "    max_glassdoor_job_pages=0,\n",
    "    max_news_articles=40,\n",
    "    # glassdoor_url=\"https://www.glassdoor.com/Reviews/Pomelo-Care-Reviews-E9429297.htm\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-23 11:54:02.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpublish\u001b[0m:\u001b[36mmarkdown_file_to_html\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mHTML written to /home/keith/company-detective/output/Oracle/Oracle_20240823_115402.html\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://company-detective.s3-website-us-west-2.amazonaws.com/reports/Oracle_20240823_115402.html'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from publish import markdown_file_to_html, publish_to_s3\n",
    "\n",
    "html_file = markdown_file_to_html(markdown_file)\n",
    "publish_to_s3(html_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
