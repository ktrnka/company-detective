<html>

<head>
    <meta charset="UTF-8">
    
    <title>hyperparam</title>

    <!-- materialize css dependencies -->
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <style>
        li {
            margin-bottom: 10px;
        }

        body {
            display: flex;
            min-height: 100vh;
            flex-direction: column;
        }

        main {
            flex: 1 0 auto;
        }

        footer.page-footer {
            padding-top: 0px;
        }

        h1 {
            font-size: 2.5rem;
        }

        h2 {
            font-size: 2rem;
        }

        h3 {
            font-size: 1.5rem;
        }

        h4 {
            font-size: 1.2rem;
        }

        h5 {
            font-size: 1rem;
        }

        .card-cta {
            font-weight: bold;
        }

        .card-panel {
            /* Reduce the default padding because the header tags also add padding */
            padding-top: 1px;
        }

        /* Restore the padding on the search panel though */
        #search-panel {
            padding-top: 20px;
        }
    </style>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-983SM8VQH2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-983SM8VQH2');
</script>

<body class="indigo lighten-4">

    <main>
    <div class="container">

        

<div class="row">
    <div class="col s12">
        <div class="card-panel">
        <h1>About hyperparam</h1>
<p>Hyperparam is a company focused on enhancing the data science process by providing tools that allow users to explore and curate large datasets directly in their browsers. The company addresses the challenges data scientists face in understanding and cleaning data, especially as datasets grow in scale within the AI landscape.</p>
<ul>
<li><strong>Founded</strong>: The specific founding date of Hyperparam is not provided in the available content.</li>
<li><strong>Employees</strong>: Information about the number of employees is not available.</li>
<li>
<p><strong>Products and Services</strong>:</p>
</li>
<li>
<p><strong>Hyperparam Tool</strong>: A browser-based application that allows users to interactively explore parquet files by dropping them into the tool.</p>
</li>
<li><strong>Hyparquet</strong>: A JavaScript parquet parser that facilitates efficient querying of parquet files stored in the cloud, enabling a client-side only data viewer.</li>
</ul>
<p>These products are designed to improve data quality for better model training by allowing users to load and explore datasets with billions of rows using modern data formats like Apache Parquet. The tools operate as local-first applications, meaning users can work entirely within their browser without needing complex services.</p>
<ul>
<li><strong>Business Model</strong>: Hyperparam targets a broad range of users, from mega-scale AI companies to small enterprise teams, all of whom require improved data quality to build advanced AI models. This suggests a B2B business model, although specific revenue figures are not provided.</li>
<li><strong>Distribution</strong>: The products are likely distributed online, given their browser-based nature, but specific distribution channels are not detailed.</li>
<li><strong>Company Evolution</strong>: The company is positioned as a modern data tool provider, emphasizing innovation in data science and the importance of data quality and user-friendly interfaces.</li>
</ul>
<p>Third parties and the company itself describe Hyperparam as a transformative force in data science, aiming to make data exploration more intuitive and efficient by leveraging modern technologies and AI.</p>
<h1>Key personnel</h1>
<p>Details about the leadership team or key personnel at Hyperparam are not provided in the available content.</p>
<h1>News</h1>
<p>There are no specific news articles or events related to Hyperparam provided in the available content. For more information, one might consider visiting their website or blog for updates: <a href="https://hyperparam.app/">Look At Your Data ðŸ‘€</a> and <a href="https://blog.hyperparam.app/">Hyperparam Blog</a>.</p>

        
        <hr/>
        <div class="card-cta">
            Visit the <a href="https://hyperparam.app">the company's website</a>.
        </div>
        
        </div>
    </div>
</div>

<div class="row">
    <div class="col s12">
        <div class="card-panel">
        
        No Glassdoor data found.
        
        </div>
    </div>
</div>

<div class="row">
    <div class="col s12">
        <div class="card-panel">
        <h1>Customer experience</h1>
        <h2>COMPANY Hyperparam</h2>
<h3>Positive Sentiment</h3>
<ul>
<li>"ML.NET is one of the most underrated pieces of Microsoft tech. It's amazing, we've implemented and operationalized millions of models in ML.NET who get retrained every day." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id6hm5k/">(MetiLee, Reddit, 2022-06-21)</a></li>
<li>"It works great and fast for both scenarios (IMO). I've had a few challenges but received good help on Stack Overflow, so I wouldn't hesitate to recommend ML.NET to anyone." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/iese4on/">(ThomasArdal, Reddit, 2022-07-04)</a></li>
<li>"The automl tooling that culminates in a usable model you can trivially call from code is really excellent." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id9he4v/">(chunkyks, Reddit, 2022-06-22)</a></li>
<li>"ML.NET offers a wide range of functionality, including data preprocessing, model training, and inference." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/joycd16/">(joycd16, Reddit, 2023-06-21)</a></li>
</ul>
<h3>Neutral Sentiment</h3>
<ul>
<li>"ML.NET along with the AutoML feature quite useful and easy to learn, but that is just for personal experiments." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/">(MrMantis765, Reddit, 2022-06-21)</a></li>
<li>"I would jump in but for what we need it for, it does not process very well." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id7zh8l/">(katghoti, Reddit, 2022-06-21)</a></li>
<li>"It's nice, but sometimes you just want to really want to shove an array of doubles into a thing without setting up pipelines and contexts." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id6bl0h/">(jingois, Reddit, 2022-06-21)</a></li>
<li>"Unfortunately most of my current ML work is reinforcement learning, which currently isn't even on the road map." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id9he4v/">(chunkyks, Reddit, 2022-06-22)</a></li>
</ul>
<h2>PRODUCT Hyperparam</h2>
<h3>Positive Sentiment</h3>
<ul>
<li>"You do not need to train to completion to be able to discard hyperparameter settings that will not perform well." <a href="https://www.reddit.com/r/MachineLearning/comments/xvem36/d_how_do_you_go_about_hyperparameter_tuning_when/ir0rkr8/">(neato5000, Reddit, 2022-10-04)</a></li>
<li>"In general early relative performance is a good predictor of final performance." <a href="https://www.reddit.com/r/MachineLearning/comments/xvem36/d_how_do_you_go_about_hyperparameter_tuning_when/ir0rkr8/">(neato5000, Reddit, 2022-10-04)</a></li>
<li>"Bayesian optimization may be one useful technique." <a href="https://www.reddit.com/r/MachineLearning/comments/xvem36/d_how_do_you_go_about_hyperparameter_tuning_when/ir31thx/">(One-Entertainment114, Reddit, 2022-10-04)</a></li>
</ul>
<h3>Mixed Sentiment</h3>
<ul>
<li>"Hyperparameter tuning should be a last step, not really necessary for 99% of production workloads." <a href="https://www.reddit.com/r/MachineLearning/comments/xvem36/d_how_do_you_go_about_hyperparameter_tuning_when/ir0z49w/">(caedin8, Reddit, 2022-10-04)</a></li>
<li>"Hyperparameter tuning is extremely important, but it can be done smarter." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kfzy0fj/">(Snake2k, Reddit, 2024-01-02)</a></li>
<li>"If you are working on a new architecture, Hyperparameter tuning is absolutely necessary." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kfy58s4/">(General_Service_8209, Reddit, 2024-01-02)</a></li>
<li>"Hyperparameter tuning usually has a significant impact only if you had chosen really bad values to begin with." <a href="https://www.reddit.com/r/MachineLearning/comments/vgoc1h/d_in_your_experience_whats_the_thing_that_can/id5gybp/">(HughLauriePausini, Reddit, 2022-06-21)</a></li>
</ul>
<h3>Negative Sentiment</h3>
<ul>
<li>"Hyperparameter tuning and ensembling help, but I find extra time spent here often leads to overfitting and lack of model generality." <a href="https://www.reddit.com/r/MachineLearning/comments/vgoc1h/d_in_your_experience_whats_the_thing_that_can/id39vtf/">(caedin8, Reddit, 2022-06-20)</a></li>
<li>"In my experience using tabular data for recommender systems, hyperparameter tuning and ensembling are pretty useless." <a href="https://www.reddit.com/r/MachineLearning/comments/vgoc1h/d_in_your_experience_whats_the_thing_that_can/id4a82m/">(Jorrissss, Reddit, 2022-06-20)</a></li>
<li>"From my personal experience after the initial sweep any sort of hyperparameter tuning is usually ineffective." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kfxddbr/">(Seankala, Reddit, 2024-01-02)</a></li>
<li>"To put it simply, making a model bigger and training it longer with more data will always beat parameter tuning." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kggoisj/">(kggoisj, Reddit, 2024-01-05)</a></li>
</ul>
<h3>General Observations</h3>
<ul>
<li>"Most architectural changes won't trigger any boost without the right amount and quality data, but it's a game changer when it does." <a href="https://www.reddit.com/r/MachineLearning/comments/vgoc1h/d_in_your_experience_whats_the_thing_that_can/id3fhar/">(pilooch, Reddit, 2022-06-20)</a></li>
<li>"Hyperparameter tuning does not compensate absence of poor features. Am a firm believer - strong features lead to strong models." <a href="https://www.reddit.com/r/datascience/comments/mwl2zj/do_you_often_find_hyperparam_tuning_does_very/gvj6bon/">(UnpunishedOpinion, Reddit, 2021-04-23)</a></li>
<li>"In python/sklearn, most of the time the defaults produce the best (or very close to it) performing model (F1 score), and doing a gridsearch over 6,000 combinations or whatever rarely improves anything." <a href="https://www.reddit.com/r/datascience/comments/mwl2zj/do_you_often_find_hyperparam_tuning_does_very/">(question_23, Reddit, 2021-04-23)</a></li>
<li>"I have found that having good quality data and good features gets you 95% of the way there. Hyperparameter tuning can help with the last 5%." <a href="https://www.reddit.com/r/datascience/comments/mwl2zj/do_you_often_find_hyperparam_tuning_does_very/gvkn8we/">(memcpy94, Reddit, 2021-04-23)</a></li>
</ul>

        
        <hr/>
        <div class="card-cta">
            Sources: <a href="https://www.google.com/search?q=site%3Areddit.com+%22hyperparam%22+related%3Ahyperparam.app+dataset">Search on Reddit</a>
        </div>
        
        </div>
    </div>
</div>

<div class="row">
    <div class="col s12">
        <div class="card-panel">
            <h1>General search results</h1>
            <h2>Official social media</h2>
<ul>
<li><a href="https://linkedin.com/company/hyperparam">Hyperparam on LinkedIn</a> </li>
</ul>
<h2>Job boards</h2>
<ul>
<li><a href="https://wellfound.com/jobs/3185363-senior-javascript-engineer">Senior Javascript Engineer at Hyperparam â€¢ Seattle | Wellfound</a></li>
</ul>
<h2>App stores</h2>
<ul>
<li><a href="https://hyperparam.app/">Hyperparam - Look At Your Data</a></li>
</ul>
<h2>Product reviews</h2>
<ul>
<li>No relevant product reviews found.</li>
</ul>
<h2>News articles (most recent first, grouped by event)</h2>
<ul>
<li>No significant news articles found.</li>
</ul>
<h2>Key employees (grouped by employee)</h2>
<h4>Kenny Daniel</h4>
<ul>
<li><a href="https://www.linkedin.com/in/kennydaniel">Kenny Daniel - Hyperparam | LinkedIn</a></li>
</ul>
<h2>Other pages on the company website</h2>
<ul>
<li><a href="https://blog.hyperparam.app/">Hyperparam Blog | The Missing UI for AI Data</a></li>
</ul>
<h2>Other</h2>
<ul>
<li><a href="http://proceedings.mlr.press/v80/kalimeris18a/kalimeris18a.pdf">Learning Diffusion using Hyperparameters</a></li>
<li><a href="https://aclanthology.org/2023.acl-demo.15.pdf">A Hyperparameter Optimization Toolkit for Neural Machine ...</a></li>
<li><a href="https://arxiv.org/abs/2212.08816">Improving Unsupervised Video Object Segmentation with Motion ...</a></li>
<li><a href="https://cloud.google.com/blog/products/gcp/hyperparameter-tuning-on-google-cloud-platform-is-now-faster-and-smarter">Hyperparameter tuning on Google Cloud Platform is now faster and ...</a></li>
<li><a href="https://codelabs.developers.google.com/vertex_hyperparameter_tuning">Vertex AI: Hyperparameter Tuning</a></li>
<li><a href="https://docs.mlrun.org/en/stable/hyper-params.html">Hyperparameter tuning optimization</a></li>
<li><a href="https://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf">Hyperparameter Optimization</a></li>
</ul>
        </div>
    </div>
</div>


<!-- ALL THE MODALS -->




    </div>
    </main>

    <footer class="page-footer indigo darken-4">
        <div class="footer-copyright">
            <div class="container">
                <a class="grey-text text-lighten-4" href="https://ktrnka.github.io/company-detective/">Company Detective</a> beta

                <!-- Elements on the right -->
                <span class="grey-text text-lighten-4 right">
                    <a class="grey-text text-lighten-4" href="https://airtable.com/appxVirwyt5V40t5S/pagNm9yaY2jkeoHTk/form" target="_blank">
                        <span>Add a company</span>
                        <i class="tiny material-icons">open_in_new</i>
                    </a> |
                    <a class="grey-text text-lighten-4" href="https://github.com/ktrnka/company-detective" target="_blank">
                        <span>Github</span>
                        <i class="tiny material-icons">open_in_new</i>
                    </a>
                </span>
            </div>
        </div>
    </footer>

    <!-- materialize css dependencies -->
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"
    integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>

    
<script>
    var linkToDivId = {};

    document.addEventListener('DOMContentLoaded', function() {
        var elems = document.querySelectorAll('.modal');
        var instances = M.Modal.init(elems, {});

        var links = document.getElementsByTagName('a');

        for (var i = 0; i < links.length; i++) {
            links[i].addEventListener('click', function(event) {
                var url = event.target.href;
                if (url in linkToDivId) {
                    event.preventDefault();

                    M.Modal.getInstance(document.getElementById(linkToDivId[url])).open();
                }
            });
        }
    });
</script>


</body>

</html>