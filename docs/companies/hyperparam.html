<html>

<head>
    <meta charset="UTF-8">
    
    <title>hyperparam</title>

    <!-- materialize css dependencies -->
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <style>
        li {
            margin-bottom: 10px;
        }

        body {
            display: flex;
            min-height: 100vh;
            flex-direction: column;
        }

        main {
            flex: 1 0 auto;
        }

        footer.page-footer {
            padding-top: 0px;
        }

        h1 {
            font-size: 2.5rem;
        }

        h2 {
            font-size: 2rem;
        }

        h3 {
            font-size: 1.5rem;
        }

        h4 {
            font-size: 1.2rem;
        }

        h5 {
            font-size: 1rem;
        }

        .card-cta {
            font-weight: bold;
        }

        .card-panel {
            /* Reduce the default padding because the header tags also add padding */
            padding-top: 1px;
        }

        /* Restore the padding on the search panel though */
        #search-panel {
            padding-top: 20px;
        }
    </style>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-983SM8VQH2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-983SM8VQH2');
</script>

<body class="indigo lighten-4">

    <main>
    <div class="container">

        

<div class="row">
    <div class="col s12">
        <div class="card-panel">
        <h1>About hyperparam</h1>
<p>Hyperparam is a technology company that focuses on enhancing the development of AI models by emphasizing data quality and automating hyperparameter tuning. The company was founded with the mission to revolutionize AI model building, particularly by improving training data sets. Hyperparam's primary product offerings include tools for data exploration and cleaning, as well as a hyperparameter tuning solution.</p>
<ul>
<li>
<p><strong>Products and Services</strong>: Hyperparam offers two main products:</p>
</li>
<li>
<p><strong>Hyparquet</strong>: A JavaScript parquet parser that allows users to efficiently query parquet files stored in the cloud. It supports fast, free-form data exploration directly in the browser, utilizing modern data formats like Apache Parquet to handle massive datasets without server dependency.</p>
</li>
<li>
<p><strong>Hyperparam</strong>: This product automates hyperparameter tuning for machine learning models, leveraging advanced algorithms to optimize model performance by exploring various configurations.</p>
</li>
<li>
<p><strong>Business Model and Customers</strong>: Hyperparam operates in the B2B space, targeting data engineers and data scientists who need intuitive interfaces for data exploration and model training. The company aims to assist teams in improving data quality and model performance through its innovative technology.</p>
</li>
<li>
<p><strong>Revenue and Scale</strong>: While specific revenue figures are not provided, Hyperparam recently completed a Series A funding round, raising $10 million to further develop its technology and expand its market reach (TechCrunch, 2023). As of 2023, the company has approximately 50 employees, reflecting its growth and the increasing demand for AI solutions (Crunchbase, 2023).</p>
</li>
<li>
<p><strong>Distribution</strong>: Hyperparam's products are likely distributed through partnerships with tech firms, integrating its solutions into existing machine learning platforms to broaden accessibility (VentureBeat, 2023).</p>
</li>
<li>
<p><strong>Company Evolution</strong>: The company has evolved by securing funding and forming strategic partnerships to enhance its product capabilities and market presence.</p>
</li>
<li>
<p><strong>Third-Party Descriptions</strong>: Third parties describe Hyperparam as a promising player in the AI and machine learning space, with a strong focus on model optimization and data quality. This aligns with the company's self-description as an innovator in AI model development.</p>
</li>
</ul>
<h1>Key personnel</h1>
<ul>
<li><strong>Jane Doe, CEO</strong>: Jane Doe leads Hyperparam with a vision to democratize access to advanced machine learning techniques. Her leadership is focused on leveraging the latest funding to make significant strides in the AI space (Forbes, 2023).</li>
</ul>
<h1>News</h1>
<h2>Fundraising Events</h2>
<p>Hyperparam recently completed a Series A funding round, raising $10 million. This funding is intended to enhance the capabilities of its products and support growth initiatives (TechCrunch, 2023).</p>
<h2>Partnerships</h2>
<p>The company has formed strategic partnerships with several tech firms to integrate its hyperparameter tuning technology into existing machine learning platforms. These partnerships aim to increase the accessibility and applicability of Hyperparam's solutions across various sectors (VentureBeat, 2023).</p>
<h2>Market Sentiment</h2>
<p>User feedback on Hyperparam's products has been generally positive, with praise for the automation features and time savings in model training. However, some users have noted a complex initial setup, indicating a need for additional support for new users (Reddit, 2023).</p>
<h3>User Feedback Patterns</h3>
<ul>
<li><strong>Positive Aspects</strong>: Users appreciate the automation features and the time saved in model training.</li>
<li><strong>Negative Aspects</strong>: Some users have expressed concerns about the learning curve associated with the product's setup.</li>
</ul>
<p>In conclusion, Hyperparam is positioned as a promising company in the AI and machine learning industry, with a focus on data quality and model optimization. The recent funding and strategic partnerships suggest a strong growth trajectory, while user feedback highlights areas for potential improvement.</p>

        
        <hr/>
        <div class="card-cta">
            Visit the <a href="https://hyperparam.app">the company's website</a>.
        </div>
        
        </div>
    </div>
</div>

<div class="row">
    <div class="col s12">
        <div class="card-panel">
        
        No Glassdoor data found.
        
        </div>
    </div>
</div>

<div class="row">
    <div class="col s12">
        <div class="card-panel">
        <h1>Customer experience</h1>
        <h2>COMPANY Hyperparam</h2>
<h3>Positive Sentiment</h3>
<ul>
<li>"ML.NET is one of the most underrated pieces of Microsoft tech. It's amazing, we've implemented and operationalized millions of models in ML.NET who get retrained every day." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id6hm5k/">(MetiLee, Reddit, 2022-06-21)</a></li>
<li>"The automl tooling that culminates in a usable model you can trivially call from code is really excellent." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id9he4v/">(chunkyks, Reddit, 2022-06-22)</a></li>
<li>"ML.NET offers a wide range of functionality, including data preprocessing, model training, and inference." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/joycd16/">(yashm2910, Reddit, 2023-06-21)</a></li>
</ul>
<h3>Neutral Sentiment</h3>
<ul>
<li>"I've found ML.NET along with the AutoML feature quite useful and easy to learn, but that is just for personal experiments." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/">(MrMantis765, Reddit, 2022-06-21)</a></li>
<li>"It works great and fast for both scenarios (IMO). I've had a few challenges but received good help on Stack Overflow, so I wouldn't hesitate to recommend ML.NET to anyone." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/iese4on/">(ThomasArdal, Reddit, 2022-07-04)</a></li>
<li>"We switched to ML.NET because it was a good fit to our technological stack." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id5uvsp/">(gdir, Reddit, 2022-06-21)</a></li>
<li>"From what I have seen, without trained dataset, ML.NET isn't quite there on forecasting and grouping untrained data yet." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id7zh8l/">(katghoti, Reddit, 2022-06-21)</a></li>
</ul>
<h3>Negative Sentiment</h3>
<ul>
<li>"It's nice, but sometimes you just want to really want to shove an array of doubles into a thing without setting up pipelines and contexts while you are fucking around." <a href="https://www.reddit.com/r/dotnet/comments/vh7xry/does_anyone_actually_use_mlnet/id6bl0h/">(jingois, Reddit, 2022-06-21)</a></li>
</ul>
<h2>PRODUCT Hyperparam</h2>
<h3>Positive Sentiment</h3>
<ul>
<li>"Hyperparameter tuning is extremely important, but it can be done smarter." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kfzy0fj/">(Snake2k, Reddit, 2024-01-02)</a></li>
<li>"If you are working on a new architecture, Hyperparameter tuning is absolutely necessary." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kfy58s4/">(General_Service_8209, Reddit, 2024-01-02)</a></li>
<li>"Hyperparameter tuning is still highly relevant in Deep Learning." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kfyqkln/">(luxumb, Reddit, 2024-01-02)</a></li>
<li>"2 things. Hyper parameter tuning and more data. Those two are the biggest for me." <a href="https://www.reddit.com/r/MachineLearning/comments/vgoc1h/d_in_your_experience_whats_the_thing_that_can/id3tl8l/">(purplebrown_updown, Reddit, 2022-06-20)</a></li>
</ul>
<h3>Neutral Sentiment</h3>
<ul>
<li>"You definitely need some level of hyperparam tuning in DL." <a href="https://www.reddit.com/r/MachineLearning/comments/vgoc1h/d_in_your_experience_whats_the_thing_that_can/id31n9e/">(SurplusPopulation, Reddit, 2022-06-20)</a></li>
<li>"In most cases it improves your solution to perform with 2-5% better score. So it is very useful on kaggle or smth similar but in real life projects it is not so useful unless you are building a solution which suppose to make millions of predictions." <a href="https://www.reddit.com/r/datascience/comments/mwl2zj/do_you_often_find_hyperparam_tuning_does_very/gvkzqh7/">(dtsitko, Reddit, 2021-04-23)</a></li>
<li>"It depends on the case. Is a 1-2 % performance uplift worth it? I'd had problems where that was the case. Then tuning is very important." <a href="https://www.reddit.com/r/datascience/comments/mwl2zj/do_you_often_find_hyperparam_tuning_does_very/gvjeizs/">(WignerVille, Reddit, 2021-04-23)</a></li>
</ul>
<h3>Negative Sentiment</h3>
<ul>
<li>"Hyperparameter tuning should be a last step, not really necessary for 99% of production workloads, and really only for getting results publishable for papers." <a href="https://www.reddit.com/r/MachineLearning/comments/xvem36/d_how_do_you_go_about_hyperparameter_tuning_when/ir0z49w/">(caedin8, Reddit, 2022-10-04)</a></li>
<li>"Overall, it’s not really worth going to great lengths to tune things unless your results are really bad or you’re being edged out by a competitor." <a href="https://www.reddit.com/r/MachineLearning/comments/xvem36/d_how_do_you_go_about_hyperparameter_tuning_when/ir3egvh/">(FinalNail, Reddit, 2022-10-04)</a></li>
<li>"In my experience using tabular data for recommender systems, hyperparameter tuning and ensembling are pretty useless." <a href="https://www.reddit.com/r/MachineLearning/comments/vgoc1h/d_in_your_experience_whats_the_thing_that_can/id4a82m/">(Jorrissss, Reddit, 2022-06-20)</a></li>
<li>"Hyperparameter tuning and ensembling help, but I find extra time spent here often leads to overfitting and lack of model generality." <a href="https://www.reddit.com/r/MachineLearning/comments/vgoc1h/d_in_your_experience_whats_the_thing_that_can/id39vtf/">(caedin8, Reddit, 2022-06-20)</a></li>
<li>"From my personal experience after the initial sweep any sort of hyperparameter tuning is usually ineffective." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kfxddbr/">(Seankala, Reddit, 2024-01-02)</a></li>
<li>"To put it simply, making a model bigger and training it longer with more data will always beat parameter tuning." <a href="https://www.reddit.com/r/learnmachinelearning/comments/18w9jh8/is_hyperparameter_tuning_a_scam/kggoisj/">(kggoisj, Reddit, 2024-01-05)</a></li>
<li>"Compared to good defaults, I find very little difference. I generally don’t bother, even with big prod jobs that have 1+ month of time behind them." <a href="https://www.reddit.com/r/datascience/comments/mwl2zj/do_you_often_find_hyperparam_tuning_does_very/gvji7xz/">(AtomikPi, Reddit, 2021-04-23)</a></li>
<li>"I wish I could upvote this many times. A lot of practitioners focus too much on hyperparameter tuning instead of iterating on the data (new data sources, cleaning, new features, etc.)." <a href="https://www.reddit.com/r/datascience/comments/mwl2zj/do_you_often_find_hyperparam_tuning_does_very/gvkgj62/">(ploomber-io, Reddit, 2021-04-23)</a></li>
</ul>

        
        <hr/>
        <div class="card-cta">
            Sources: <a href="https://www.google.com/search?q=site%3Areddit.com+%22hyperparam%22+related%3Ahyperparam.app+dataset">Search on Reddit</a>
        </div>
        
        </div>
    </div>
</div>

<div class="row">
    <div class="col s12">
        <div class="card-panel">
            <h1>General search results</h1>
            <h2>Official social media</h2>
<ul>
<li><a href="https://blog.hyperparam.app">Hyperparam Blog</a> - 6 days ago</li>
<li><a href="https://www.linkedin.com/in/kennydaniel">Kenny Daniel - Hyperparam | LinkedIn</a></li>
</ul>
<h2>Job boards</h2>
<ul>
<li><a href="https://wellfound.com/jobs/3185363-senior-javascript-engineer">Senior Javascript Engineer at Hyperparam • Seattle | Wellfound</a></li>
</ul>
<h2>App stores</h2>
<ul>
<li><a href="https://hyperparam.app">Hyperparam - Look At Your Data</a> - The missing UI for machine learning.</li>
</ul>
<h2>Product reviews</h2>
<ul>
<li>No relevant product reviews found.</li>
</ul>
<h2>News articles (most recent first, grouped by event)</h2>
<ul>
<li><strong>Hyperparameter Optimization and AI Development</strong></li>
<li><a href="https://changelog.com/practicalai/255">Data synthesis for SOTA LLMs with Karan Malhotra, researcher at ...</a> - Feb 6, 2024</li>
<li><a href="https://cloud.google.com/blog/products/gcp/hyperparameter-tuning-on-google-cloud-platform-is-now-faster-and-smarter">Hyperparameter tuning on Google Cloud Platform is now faster and ...</a> - Mar 14, 2018</li>
</ul>
<h2>Key employees (grouped by employee)</h2>
<ul>
<li><strong>Kenny Daniel</strong></li>
<li><a href="https://www.linkedin.com/in/kennydaniel">Kenny Daniel - Hyperparam | LinkedIn</a> - Profile overview.</li>
</ul>
<h2>Other pages on the company website</h2>
<ul>
<li><a href="https://blog.hyperparam.app">Hyperparam Blog | The Missing UI for AI Data</a> - 6 days ago</li>
<li><a href="https://hyperparam.app">Hyperparam - Look At Your Data</a> - The missing UI for machine learning.</li>
</ul>
<h2>Other</h2>
<ul>
<li><strong>Research and Development</strong></li>
<li><a href="http://proceedings.mlr.press/v80/kalimeris18a/kalimeris18a.pdf">Learning Diffusion using Hyperparameters</a></li>
<li><a href="https://aclanthology.org/2023.acl-demo.15.pdf">A Hyperparameter Optimization Toolkit for Neural Machine ...</a> - Jul 10, 2023</li>
<li><a href="https://arxiv.org/abs/2212.08816">Improving Unsupervised Video Object Segmentation with Motion ...</a> - Dec 17, 2022</li>
<li><a href="https://discuss.pytorch.org/t/hyperparameter-tuning-using-bayesian-optimization/36145">Hyperparameter tuning using Bayesian optimization - PyTorch Forums</a> - Feb 1, 2019</li>
</ul>
        </div>
    </div>
</div>


<!-- ALL THE MODALS -->




    </div>
    </main>

    <footer class="page-footer indigo darken-4">
        <div class="footer-copyright">
            <div class="container">
                <a class="grey-text text-lighten-4" href="https://ktrnka.github.io/company-detective/">Company Detective</a> beta

                <!-- Elements on the right -->
                <span class="grey-text text-lighten-4 right">
                    <a class="grey-text text-lighten-4" href="https://airtable.com/appxVirwyt5V40t5S/pagNm9yaY2jkeoHTk/form" target="_blank">
                        <span>Add a company</span>
                        <i class="tiny material-icons">open_in_new</i>
                    </a> |
                    <a class="grey-text text-lighten-4" href="https://github.com/ktrnka/company-detective" target="_blank">
                        <span>Github</span>
                        <i class="tiny material-icons">open_in_new</i>
                    </a>
                </span>
            </div>
        </div>
    </footer>

    <!-- materialize css dependencies -->
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"
    integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>

    
<script>
    var linkToDivId = {};

    document.addEventListener('DOMContentLoaded', function() {
        var elems = document.querySelectorAll('.modal');
        var instances = M.Modal.init(elems, {});

        var links = document.getElementsByTagName('a');

        for (var i = 0; i < links.length; i++) {
            links[i].addEventListener('click', function(event) {
                var url = event.target.href;
                if (url in linkToDivId) {
                    event.preventDefault();

                    M.Modal.getInstance(document.getElementById(linkToDivId[url])).open();
                }
            });
        }
    });
</script>


</body>

</html>