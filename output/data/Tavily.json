{
  "summary_markdown": "# About Tavily\n\nTavily is a technology company founded on May 12, 2024, that specializes in providing advanced search capabilities and AI tools designed to connect large language models (LLMs) to real-time web data. The company focuses on enhancing data-driven decision-making by delivering precise and reliable insights through its innovative products [(Crunchbase, 2025)](https://www.crunchbase.com/organization/tavily).\n\nTavily offers a range of services aimed at integrating AI with real-time data, including:\n\n- **Tavily Search API**: A tool for developers to integrate advanced search capabilities into their applications, providing real-time, accurate, and factual search results optimized for LLMs and AI agents [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n- **Tavily Extract API**: Allows users to extract content from specified URLs for deeper analysis.\n- **Company Researcher**: Automates multi-stage workflows for real-time company analysis, integrating search and extraction to generate comprehensive reports [(Weiss, 2024)](https://blog.tavily.com/companyresearcher/).\n- **Hybrid RAG**: Combines web sources and local databases to enhance data retrieval.\n\nTavily's products are primarily targeted at businesses looking to leverage AI for data analysis, research, and decision-making, indicating a B2B business model. The company emphasizes its commitment to providing tools that enhance productivity and efficiency across various sectors [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n\nWhile specific financial details and employee counts are not publicly disclosed, Tavily is recognized as a growing player in the AI and search technology space, with increasing interest from developers and businesses [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n\n# Key Personnel\n\nDetails about Tavily's leadership team are limited, but it is known that the team comprises AI researchers and developers passionate about improving access to accurate information. Their mission emphasizes providing unbiased and factual data to empower users and organizations [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n\n# News\n\n## Recent Developments\n\n- **JavaScript Package Release**: On October 12, 2024, Tavily announced the release of its official JavaScript package on NPM, facilitating easier integration of Tavily's capabilities into applications [(Tavily JavaScript package, 2024)](https://community.tavily.com/t/tavily-javascript-package-now-available-on-npm/172).\n\n- **Performance Improvements**: Users have reported improvements in response times, with the API now capable of delivering results in under 4 seconds for certain queries, enhancing the user experience for real-time applications [(API performance, 2024)](https://community.tavily.com/t/api-performance/115).\n\n- **New Features**: Tavily introduced a time_range argument for its API, allowing users to filter search results based on specific time frames, which is particularly useful for applications requiring up-to-date information [(Can we date bound the Tavily API, 2024)](https://community.tavily.com/t/can-we-date-bound-the-tavily-api-like-we-do-for-days-while-using-topic-news/210).\n\n## User Feedback and Market Reception\n\nFeedback from users has been generally positive, highlighting Tavily's ease of integration and the quality of search results. Some users initially noted performance issues, which the company has addressed through ongoing improvements and optimizations [(Response times are slow, 2024)](https://community.tavily.com/t/response-times-are-slow/131).\n\n# Conclusion\n\nTavily is establishing itself in the AI-driven search market with its specialized API designed for LLMs and AI agents. With recent enhancements and a focus on user feedback, Tavily is well-positioned for growth as demand for intelligent search solutions continues to rise. Prospective candidates and investors should consider Tavily's innovative approach and commitment to improving AI capabilities in data retrieval and analysis.",
  "target": [
    "Tavily",
    "Tavily",
    "tavily.com",
    null,
    false,
    false,
    null,
    [
      false,
      false
    ]
  ],
  "webpage_result": {
    "summary_markdown": "# Tavily Company Overview\n\n## Company History\nTavily is a technology company focused on providing advanced search capabilities and AI tools that connect large language models (LLMs) to real-time web data. The company aims to enhance data-driven decision-making by delivering precise and reliable insights through its innovative products.\n\n## Services\nTavily offers a range of services designed to facilitate the integration of AI with real-time data:\n\n- **Tavily Search API**: A powerful tool for developers to integrate advanced search capabilities into their applications.\n- **Tavily Extract API**: Allows users to extract content from specified URLs, providing raw information for deeper analysis.\n- **Company Researcher**: A specialized tool that automates multi-stage workflows for real-time company analysis, integrating search and extraction to generate comprehensive reports.\n- **Hybrid RAG**: Combines web sources and local databases to enhance the retrieval of relevant data.\n\n## Products\nTavily's main products include:\n\n- **Tavily Search**: Provides flexible search capabilities, allowing AI agents to retrieve contextually relevant data.\n- **Tavily Extract**: Focuses on pulling detailed information from specified sources.\n- **Company Researcher**: Automates the process of gathering and analyzing company data, ensuring accuracy and relevance.\n- **Integration with Zapier**: Enables users to automate workflows without coding, enhancing business processes with real-time data.\n\n## Customers\nTavily serves a diverse range of customers, including businesses looking to leverage AI for data analysis, research, and decision-making. The company emphasizes its commitment to providing tools that enhance productivity and efficiency in various sectors.\n\n## Leadership Team\nWhile specific details about the leadership team are not provided, Tavily's focus on innovation and customer service suggests a team of experienced professionals dedicated to advancing AI technology and its applications.\n\n## Culture\nTavily promotes a culture of collaboration and innovation, encouraging community engagement through forums and discussions. The company values respectful discourse and aims to create a supportive environment for users and developers alike.\n\n## Conclusion\nTavily stands out in the AI and data integration space by offering robust tools that connect AI agents to real-time web data, enhancing the capabilities of businesses and researchers. With a focus on precision, reliability, and user-friendly integration, Tavily is positioned as a leader in the field of AI-driven data solutions.\n\nFor more information, visit [Tavily](https://tavily.com/) or explore their [Blog](https://blog.tavily.com/) for insights and updates.",
    "page_markdowns": [
      "# [Tavily](https://tavily.com/)\n1 2 3 4 from tavily import TavilyClient tavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\") response = tavily_client.search(\"Who is Leo Messi?\") print(response)\n\n1 2 3 4 const { tavily } = require('@tavily/core'); const tvly = tavily({ apiKey: \"tvly-YOUR_API_KEY\" }); tvly.search(\"Who is Leo Messi?\") .then(results => console.log(results));",
      "# [Trust Center](https://trust.tavily.com/)\n",
      "# [Tavily](https://tavily.com/privacy)\n- Performance of, or entry into, a contract with you.\n\n-Necessary for our legitimate interests.\n\n- Respond to your requests or questions.\n\n- Manage our relationship with you, including by notifying you about changes to our terms of use or Privacy Policy.\n\n- Marketing purposes.\n\n- Deliver relevant and personalized content to you, send service messages (for example, for security purposes).\n\n- Measure or understand the effectiveness of our marketing efforts.\n\n- To use data analytics to improve our Platform, products/services, marketing, customer relationships and experiences, including by personalizing and customizing our content.\n\n- Necessary for our legitimate interests (to grow our business, to inform our marketing strategy and to maintain and secure the services).\n\n- If we have obtained your prior consent (where laws require consent for such communications).\n\nIn the event of a legal dispute between you (and/or a party on your behalf) to us (and/or a party on our behalf), we may use your data to the extent necessary in connection with handling such dispute.\n\n-Required by subpoena, law, or other legal process.\n\nNecessary to assist law enforcement officials or government enforcement agencies.\n\n-Necessary to investigate violations of or otherwise enforce our terms of use, to maintain security of the Website and prevent fraudulent or illegal activity.\n\nNecessary to protect us from legal action or claims from third parties, including you and/or other users.\n\nNecessary to protect the legal rights, personal/real property, or personal safety of our company, users, employees, and affiliates.",
      "# [Tavily API Status](https://status.tavily.com/)\n2025-02-26\n\nAccount creation outage\n\nNew account creation failing for some users\n\n2024-10-07 --> 2024-10-15\n\nRaw Content partial outage\n\nNo results returned for some queries when using the 'include_raw_content' option",
      "# [Tavily](https://tavily.com/terms)\n1. Defined Terms.\n\n\"AI Tools\" means artificial intelligence models, tools, and other technologies.\n\n\"Applications\" means one or more software applications (which may include, without limitation, large language models or other AI Tools) that you develop to interface with any Tavily APIs.\n\n\"Customer Data\" means any and all any data and information that you or Users provide to Tavily in connection with their use of the Services and includes, without limitation, Customer Input.\n\n\"Customer Input\" means any and all text, information, queries and other input submitted by you, Users, or an Application in connection with a Tavily API call.\n\n\"Output\" means the generated text, information, or other materials or output resulting from Customer Input.\n\n\"Services\" means the Tavily online search engine designed to deliver real-time results, including a Tavily web application and any associated Tavily application programming interface(s) (\"Tavily API(s)\").\n\n\"Support Services\" means Tavily's support services, if any, provided in connection with the Services.\n\n2. The Services.\n\nSubject to your continued compliance with the terms and conditions of this Agreement, Tavily will (a) provide access to the Services and (b) use commercially reasonable efforts to provide any Support Services that Tavily has agreed to provide to you. Tavily may update or modify the Services, in whole or in part, at any time in Tavily's sole discretion (each, an \"Update\") and may require you to obtain and use the most recent version of the Services. Updates may adversely affect your Applications. You are required to make any changes to your Applications that are required for integration as a result of such Update at your sole cost and expense. Your continued use of the Services following an Update constitutes your binding acceptance of the Update.\n\n3. Your Responsibilities.\n\nAccounts. You and your users (each, a \"User\") may be required to create an account (which may include a Tavily API security key) (an \"Account\") to access and use the Services. You (i) may not, and will ensure that Users do not, share Account information (including Tavily API security keys) with any third party, (ii) will keep, and ensure that all Users keep, each Account and all information (including API security keys) secure, and (iii) will only use, and will ensure that Users only use, their Account to access the Services. You are solely responsible for all activity that occurs under your Account and is solely responsible for any and all acts and omissions of Users. Any act or omission of a User will, for purposes of this Agreement, be deemed your act or omission.\n\nGeneral Use Restrictions. The Services are provided solely for Customer’s business purposes for integration with Customer Applications. Customer will not, in whole or in part: (i) modify, copy, disclose, alter, translate or create derivative works of the Services; (ii) license, sublicense, resell, distribute, lease, rent, lend, transfer, assign or otherwise dispose of the Services (provided, that integration of the Services in Customer Applications in accordance with this Agreement will not constitute a violation of this subsection); (iii) decompile, disassemble, decode, translate, or reverse engineer the Services or otherwise attempt to learn the source code, structure, algorithms, or internal ideas underlying the Services or reduce the Services by any other means to a human-perceivable form; (iv) copy, frame or mirror any part or content of the Services; (v) access the Services in order to build a competitive product or service; (vi) overburden the Services (including, without limitation, making excess Tavily API calls) or interfere with or disrupt the integrity or performance of the Services or input, upload, transmit, or otherwise provide any harmful code to or through the Services; (vii) use any data mining, robots, or similar data gathering or extraction methods; (viii) attempt to gain unauthorized access to the Services or its related systems or networks or exceed any Customer user (“User”) limitations or other restrictions set forth on the Order Form with respect to the Services (including, without limitation, restrictions with respect to Tavily API calls); (ix) disclose to any third party any performance information or analysis relating to the Services; (x) remove, alter, or obscure any proprietary notices in or on the Services; (xi) combine or integrate the Services with any software, technology, services, or materials not authorized by Tavily; (xii) design or permit any Customer Applications to disable, override, or otherwise interfere with any Tavily-implemented communications to end users, consent screens, user settings, alerts, warning, or the like; (xiii) attempt to cloak or conceal Customer’s identity or the identity of any Customer Applications when requesting authorization to use the Tavily APIs; (xiv) use the Services in connection with or to promote any products, services, or materials that constitute, promote, or are used primarily for the purpose of dealing in spyware, adware, or other malicious programs or code, counterfeit goods, items subject to U.S. embargo, unsolicited mass distribution of email (“spam”), multi-level marketing proposals, hate materials, hacking, surveillance, interception, or descrambling equipment, libelous, defamatory, obscene, pornographic, abusive, or otherwise offensive content, stolen products, and items used for theft, hazardous materials, or any illegal activities; or (xv) attempt any of the foregoing or cause or permit any individual or entity to do any of the foregoing. Customer will not assert, nor authorize, assist or encourage any third party to assert, against any Tavily or its affiliates, any patent infringement or other intellectual property rights infringement claim regarding the Services.\n\nSetup Responsibilities.You are solely responsible for obtaining and maintaining, at your expense, all of the necessary telecommunications, computer hardware, mobile devices, software, services and Internet connectivity required by you or any User to access the Services.\n\nResponsibility for Your Applications and Customer Data. You will monitor the use of your Applications for any activity that violates applicable laws, rules, and regulations or any terms and conditions of this Agreement, including any fraudulent, inappropriate, or potentially harmful behavior, and promptly restrict any offending users of your Applications from further use of such Applications. As between you and Tavily, you are solely responsible and liable for your Applications, including, without limitation, for (i) posting any privacy notices and obtaining any consents from your end users required under applicable laws, rules, and regulations for their use of your Applications and (ii) all acts and omissions of your end users in connection with your Applications and their use of any Tavily APIs, if any. Additionally, you are solely responsible for the accuracy, quality, integrity, legality, reliability, security, and appropriateness of all Customer Data (including, without limitation, Customer Input). Tavily is not responsible for performing, and is not liable for failure to perform, any back-up of any Customer Data.\n\n4. Fees.\n\nGeneral.You will pay Tavily all fees and amounts charged by Tavily for use of the Services (collectively, the \"Fees\") in accordance with this Section 4.\n\nPayment.You will pay all Fees by (i) check, (ii) bank wire transfer in immediately available funds to an account designated by Tavily, or (iii) credit or debit card via an authorized payment processor. If by credit or debit card, you authorize Tavily (or its payment processor) to charge your credit or debit card number provided to Tavily and represent and warrant that you are authorized to use and have Fees charged to that credit or debit card. Unless otherwise communicated in writing by Tavily, all payments pursuant to this Agreement: (A) are nonrefundable; (B) will be made in U.S. Dollars; and (C) are exclusive of taxes and duties, which will be paid solely by you (other than taxes based on Tavily's net income). All Fees are payable without setoff, counterclaim, deduction, recoupment, or withholding of any kind for amounts owed or purportedly owed by Tavily under this Agreement, applicable law, or otherwise. The terms of payment specified herein may be subject to Tavily's approval of your credit, and Tavily may at any time revise the specified terms of payment to require payment in advance. Tavily may assess a late charge of the lesser of 1.5% per month or the maximum rate allowed under applicable law for all late payments. You will reimburse Tavily for all costs and expenses (including reasonable attorneys' fees) incurred by Tavily in collecting any past due amounts.\n\nModification. Tavily may modify any Fees, in whole or in part, on written notice to you.\n\n5. Confidentiality.\n\nYou may acquire certain information that is the confidential, proprietary or trade secret information of Tavily or a third party (\"Confidential Information\"). Confidential Information includes without limitation: (a) any information, whether or not marked or otherwise designated as confidential, of or relating to Tavily or the Services that is not generally available to the public, including any information relating to Tavily's methods, techniques, finances, business plans, marketing plans, legal affairs, prospects, opportunities, contracts, assets or trade secrets; and (b) any information that has been made available to or obtained by Tavily by or with respect to its customers or other third parties and which Tavily is obligated to keep confidential. You: (i) will protect Confidential Information from unauthorized disclosure using at least a reasonable degree of care; (ii) will not disclose Confidential Information to any third party; and (iii) will not use the Confidential Information for any purpose other than as expressly permitted in this Agreement. After any expiration or termination of this Agreement, or at any time upon request from Tavily, you will immediately return or destroy (at Tavily's sole direction) all materials or media containing any Confidential Information, including all copies thereof, and will certify in writing to Tavily that all such Confidential Information has been returned or destroyed. You expressly acknowledge and agree that no adequate remedy exists at law for an actual or threatened breach of this Section 5 and that in such event Tavily will be entitled to seek and obtain immediate injunctive and other equitable relief, without waiving any other rights or remedies available to it.\n\n6. Customer Data.\n\nOwnership.You own and retain all right, title, and interest in and to all Customer Data, including all intellectual property rights therein. You acknowledge and agree that you (not Tavily) have control over Customer Data stored by operation of the Services.\n\nUse of Customer Data. You hereby grant Tavily and its affiliates a worldwide, royalty-free, fully paid, transferable, assignable, sublicensable (through multiple tiers), perpetual, and irrevocable license to collect, host, use, access, view, store, copy, display, create derivative works of, delete, and otherwise process Customer Data (including providing Customer Data to applicable Third-Party Service Providers (as defined below) and others) to (i) provide, support, monitor, analyze, and improve the Services and improve Tavily's other products and services, (ii) communicate with you about your Account, (iii) comply with applicable laws, including court orders, subpoenas, and requests or requirements for information made by regulatory or investigatory entities, (iv) prevent fraud or misuse of the Services, (v) perform market research, (vi) conduct product research and improvement and development of products and services by Tavily, and/or (vii) for any other lawful purpose. Tavily may expand its use of Customer Data in its discretion if not precluded by applicable laws. Tavily will not be required to transmit or provide you or any third party with Customer Data in any format except as required by applicable laws.\n\nRights in Customer Data. You represent and warrant to Tavily that you have the rights, licenses, and permissions necessary to grant the license and use rights in this Agreement and to otherwise provide Customer Data to Tavily for use by Tavily as contemplated by this Agreement and your use of the Services. You are solely responsible for the content, accuracy, integrity, quality, and legality of Customer Data and for ensuring that you have given all notices and disclosures, and obtained all consents and permissions, necessary for (i) you to use the Services (including, without limitation, to send any communications or other information or materials via the Services), (ii) your collection, use and disclosure of Customer Data, and (iii) Tavily to collect, use, and disclose Customer Data. You will not, and will ensure that third parties do not, include in Customer Data or otherwise upload, post, reproduce, or distribute any information, software, or other material protected by copyright, privacy rights, or any other intellectual property rights without first obtaining the permission of the owner of such rights.\n\n7. Intellectual Property.\n\nTavily Ownership. Subject to the rights and licenses granted to you under this Agreement, Tavily owns and will continue to own all rights, title, and interest in and to (i) the Services and Support Services, including, without limitation, any derivative work, enhancement, update, customization, modification, adaptation, alteration, upgrade, new feature, or other improvement thereof or thereto, (ii) all comments, user input, suggestions, comments, and other feedback provided by you or any User with respect to the foregoing (\"Feedback\"), and (iii) all Usage Data (as defined below). You hereby assign to Tavily all rights (including intellectual property rights), title, and interest in and to all Feedback. Except as expressly set forth in this Agreement, no express or implied license or right of any kind is granted to you regarding the foregoing, including, without limitation, any right to obtain possession of any source code, data or other technical material related to the foregoing.\n\nUsage Data. Notwithstanding anything to the contrary in this Agreement, you agree that Tavily may generate, collect, store, use, transfer, and/or disclose to third parties information gathered, prepared, computed, originated, or stored by Tavily resulting from the use or provision of the Services, including information derived from or based on Customer Data (\"Usage Data\") (i) to perform data analytics, (ii) to monitor, improve, and support the Services, (iii) to design, develop, and offer Tavily products and services, and (iv) for any other lawful purpose. Tavily owns and retains all rights to Usage Data, and no rights are granted to you, whether by implication, estoppel, waiver, or otherwise in or to any Usage Data. Tavily has no obligation to provide or make any Usage Data available to you.\n\n8. Indemnification.\n\nTo the maximum extent permitted by applicable law, you will indemnify and hold Tavily and its affiliates, and its and their officers, employees, and agents harmless against any damages, liabilities, losses, costs, or expenses (including reasonable attorneys' fees) arising from or in connection with (a) your access to or use of the Services, (b) Customer Data, and/or (c) your breach or alleged breach of this Agreement (each, an \"Indemnification Claim\"). Additionally, you will, at Tavily's sole election, defend Tavily from any Indemnification Claims. If Tavily directs you to defend an Indemnification Claim, then (i) Tavily has the right to approve the counsel you select to defend the Indemnification Claim and (ii) Tavily may also have its own counsel participate in the defense and settlement of the Indemnification Claim at your expense. Tavily may also exclusively retain control of the defense of an Indemnification Claim. You will not settle an Indemnification Claim without Tavily's written consent. 9. Disclaimers.\n\n9. Disclaimers.\n\nGeneral Disclaimers. THE SERVICES AND SUPPORT SERVICES ARE PROVIDED ON AN \"AS IS\" AND \"AS AVAILABLE\" BASIS WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, OR TITLE, AND ANY WARRANTIES ARISING OUT OF ANY COURSE OF DEALING OR USAGE OF TRADE. TAVILY DOES NOT WARRANT, AND SPECIFICALLY DISCLAIMS, THAT THE SERVICES WILL OPERATE UNINTERRUPTED, BE ERROR-FREE, OR THAT ALL DEFECTS WILL BE CORRECTED.\n\nAdditional Disclaimers Regarding Output.WITHOUT LIMITING THE FOREGOING DISCLAIMER, TAVILY MAKES NO, AND SPECIFICALLY DISCLAIMS ANY AND ALL, REPRESENTATIONS OR WARRANTIES CONCERNING THE ACCURACY, PERFORMANCE, QUALITY, RELIABILITY, SUITABILITY, OR COMPLETENESS OF ANY INFORMATION OR RESULTS OBTAINED OR DERIVED THROUGH THE USE OF THE SERVICES, INCLUDING, WITHOUT LIMITATION, ANY OUTPUT, OR THAT ANY OF THE FOREGOING WILL BE NON-INFRINGING OR OTHERWISE COMPLIANT WITH LAW OR MEET YOUR EXPECTATIONS. YOU ACKNOWLEDGE AND AGREE THAT THE OUTPUT IS AT LEAST PARTIALLY DEPENDENT ON AI TOOLS, THE USE OF WHICH MAY RESULT IN THE OUTPUT BEING INACCURATE, UNRELIABLE, INAPPROPRIATE, INFRINGING, INCOMPLETE, OR OTHERWISE UNSUITABLE OR MAY NOT MEET YOUR EXPECTATIONS. ALL OUTPUT IS PROVIDED \"AS IS,\" YOU USE ALL OUTPUT AT YOUR OWN RISK, AND YOU ARE SOLELY RESPONSIBLE FOR VETTING, EVALUATING, AND USING THE OUTPUT, INCLUDING, WITHOUT LIMITATION, ANY USE OR MODIFICATION OF CUSTOMER APPLICATIONS IN CONNECTION WITH YOUR EVALUATION AND/OR USE OF THE OUTPUT. 10. Third-Party Services.\n\n10. Third-Party Services.\n\nDefinition. Certain Services or features thereof may rely on, interoperate with, or otherwise utilize or leverage products and/or services provided by third parties (such services, \"Third-Party Services\" and the providers of such services, \"Third-Party Service Providers\").\n\nThird-Party Terms; Disclaimer.You are solely responsible and liable for complying with all terms, conditions and policies imposed by Third-Party Service Providers on Third-Party Services (\"Third-Party Terms\"). Tavily is not, and will not be deemed to be, a party to any Third-Party Terms, all of which are exclusively between you and the applicable Third-Party Service Provider(s). Tavily does not make any warranties or guarantees with respect to Third-Party Services, including the performance or continued availability of Third-Party Services and Tavily may (either itself or as required by the Third-Party Service Provider) limit or cease providing interoperation with any or all Third-Party Services (and, as a consequence, certain or all features of the Services may be limited or ceased) without entitling you to any compensation if, for example and without limitation, the Third-Party Service Provider ceases to make the Third-Party Service available for interoperation or use with the Services in a manner acceptable to Tavily. Moreover, the performance of Third-Party Services (and Third-Party Service Providers) is outside Tavily's control. TAVILY WILL NOT BE LIABLE FOR, AND TAVILY EXPRESSLY DISCLAIMS, ANY LIABILITY FOR LOSSES, COSTS, OR EXPENSES TO THE EXTENT CAUSED BY ANY THIRD-PARTY SERVICES OR THIRD-PARTY SERVICE PROVIDERS OR FOR YOUR COMPLIANCE (OR NON-COMPLIANCE) WITH ANY APPLICABLE THIRD-PARTY TERMS, EACH OF WHICH ARE YOUR EXCLUSIVE RESPONSIBILITY AND LIABILITY.\n\nAI Tools. Without limiting the foregoing, as between the parties, you are solely responsible for your use of AI Tools in connection with the Services (including, without limitation, as used by Tavily to generate Output in connection with Customer Input). You acknowledge and agree that (i) your or Tavily's use of AI Tools may involve access to Customer Inputs by Third-Party Service Providers and that such access may occur pursuant to agreements between Tavily and such Third-Party Service Providers, rather than this Agreement, (ii) such AI Tools are not under the control of Tavily and do not form part of the Services, (iii) Tavily makes no representations or warranties with respect to such AI Tools or any Customer Input or Output provided or generated in connection therewith, and (iv) you use all AI Tools (and any Customer Input or Output provided or generated in connection therewith) at your own risk. You consent and authorize Tavily to share Customer Input and Output with AI Tools to the extent required to perform the Services and acknowledges and agrees that Third-Party Service Providers may not be required to maintain the confidentiality of any Customer Input or Output and may retain certain rights to use or disclose Customer Input and Output, including to further train their algorithmic models.\n\n11. Limitation of Liability.\n\nTO THE MAXIMUM EXTENT PERMITTED UNDER APPLICABLE LAW, UNDER NO CIRCUMSTANCES WILL (A) TAVILY OR ANY OF ITS SERVICE PROVIDERS BE LIABLE TO YOU OR ANY THIRD PARTY FOR PERSONAL INJURY, PROPERTY DAMAGE, ERROR OR INTERRUPTION OF USE, LOSS, INACCURACY, OR CORRUPTION OF DATA, COVER, LOST PROFITS OR REVENUE, LOSS OF BUSINESS, OR ANY CONSEQUENTIAL, INDIRECT, SPECIAL, EXEMPLARY, PUNITIVE, OR INCIDENTAL DAMAGES, REGARDLESS OF THE FORM IN WHICH THE ACTION IS BROUGHT (INCLUDING NEGLIGENCE), ARISING OUT OF OR RELATING TO THE RELATIONSHIP BETWEEN THE PARTIES (INCLUDING THIS AGREEMENT), INCLUDING THE USE OR INABILITY TO USE THE SERVICES, WHETHER OR NOT TAVILY HAS BEEN ADVISED OF THE POSSIBILITY OF ANY SUCH DAMAGES, OR (B) TAVILY'S TOTAL LIABILITY UNDER THIS AGREEMENT, REGARDLESS OF LEGAL THEORY (INCLUDING NEGLIGENCE), EXCEED, IN THE AGGREGATE FOR ALL CLAIMS, THE FEES PAID TO TAVILY BY YOU IN THE 3-MONTH PERIOD PRECEDING THE DATE ON WHICH THE FIRST CLAIM AROSE AND ASSOCIATED WITH THE SPECIFIC SERVICES PROVIDED. MULTIPLE CLAIMS WILL NOT EXPAND THESE LIMITATIONS. THE PARTIES ACKNOWLEDGE THAT THIS SECTION 11 REFLECTS THE AGREED UPON ALLOCATION OF RISK BETWEEN THE PARTIES AND THAT NEITHER PARTY WOULD ENTER INTO THIS AGREEMENT WITHOUT THESE LIMITATIONS ON ITS LIABILITY. THIS LIMITATION ON LIABILITY WILL APPLY DESPITE THE FAILURE OF ESSENTIAL PURPOSE OF ANY LIMITED REMEDY SET FORTH IN THIS AGREEMENT.\n\n12. Term and Termination; Effect of Termination or Expiration.\n\nThis Agreement will begin on the date you accept this Agreement and will continue until (a) we terminate this Agreement upon notice to you, which we may do at any time for any reason, (b) you terminate this Agreement by cancelling your Account or otherwise terminating your use of the Services, or (c) as otherwise stated when you purchased access to the Services. Upon any termination of this Agreement, (i) your right to access and use the Services will immediately cease, (ii) you will promptly permanently erase all keys, programming instructions, tools, protocols, and other materials made available to you in connection with the Tavily APIs, (iii) you will pay Tavily all outstanding amounts due and owing, and (iv) this sentence and Sections 2, 4, and 6 through 11 will survive.\n\n13. Arbitration.\n\nPLEASE READ THIS SECTION CAREFULLY BECAUSE IT REQUIRES YOU AND TAVILY TO ARBITRATE CERTAIN DISPUTES AND CLAIMS AND LIMITS THE MANNER IN WHICH THE PARTIES CAN SEEK RELIEF FROM EACH OTHER. ARBITRATION PRECLUDES YOU AND TAVILY FROM SUING IN COURT OR HAVING A JURY TRIAL. YOU AND TAVILY AGREE THAT ARBITRATION WILL BE SOLELY ON AN INDIVIDUAL BASIS AND NOT AS A CLASS ARBITRATION, CLASS ACTION, OR ANY OTHER KIND OF REPRESENTATIVE PROCEEDING. TAVILY AND YOU ARE EACH WAIVING THE RIGHT TO TRIAL BY A JURY.\n\nFOLLOW THE INSTRUCTIONS BELOW IF YOU WISH TO OPT OUT OF THE REQUIREMENT OF ARBITRATION ON AN INDIVIDUAL BASIS. NO CLASS OR REPRESENTATIVE ACTIONS OR ARBITRATIONS ARE ALLOWED UNDER THIS ARBITRATION AGREEMENT.\n\nInformal Dispute Resolution Prior to Arbitration. For any dispute or claim that you have against Tavily, that Tavily has against you, or that you have or Tavily has arising from or relating to this Agreement, the Services, or any aspect of the relationship between you and Tavily as relates to this Agreement, the Services, including any privacy or data security claims (collectively, \"Claims,\" and each a \"Claim\"), you and Tavily agree to attempt to first resolve the Claim informally via the following process:\n\nIf you assert a Claim against Tavily, you will first contact Tavily by sending a written notice of your Claim (\"Claimant Notice\") to Tavily by certified mail addressed to 33 W 60th St, New York, NY 10023 or by email to support@tavily.com. The Claimant Notice must (a) include your name, residence address, email address, and telephone number, (b) describe the nature and basis of the Claim, and (c) set forth the specific relief sought.\n\nIf Tavily asserts a Claim against you, Tavily will first contact you by sending a written notice of Tavily’s Claim (\"Tavily Notice\"), and each of a Claimant Notice and Tavily Notice, a \"Notice\") to you via email to the primary email address associated with your account. The Tavily Notice must (a) include the name of a Tavily contact and the contact’s email address and telephone number, (b) describe the nature and basis of the Claim, and (c) set forth the specific relief sought.\n\nIf you and Tavily cannot reach an agreement to resolve the Claim within thirty (30) days after you or Tavily receives such a Notice, then either party may submit the Claim to binding arbitration as set forth below. The statute of limitations and any filing fee deadlines shall be tolled for thirty (30) days from the date that either you or Tavily first send the applicable Notice so that the parties can engage in this informal dispute-resolution process.\n\nClaims Subject to Binding Arbitration; Exceptions.Except for individual disputes that qualify for small claims court and any disputes exclusively related to the intellectual property or intellectual property rights of you or Tavily, including any disputes in which you or Tavily seek injunctive or other equitable relief for the alleged unlawful use of your or Tavily's intellectual property or other infringement of your or Tavily’s intellectual property rights (\"IP Claims\"), all Claims, whether based in contract, tort, statute, fraud, misrepresentation, or any other legal theory, including Claims that are not related to intellectual property or intellectual property rights but are jointly filed with IP Claims, that are not resolved in accordance with Section 13(a) will be resolved by a neutral arbitrator through final and binding arbitration instead of in a court by a judge or jury. Such Claims include, without limitation, disputes arising out of or relating to interpretation or application of this arbitration provision, including the enforceability, revocability, or validity of the arbitration provision or any portion of the arbitration provision. The arbitrator will have the authority to grant any remedy or relief that would otherwise be available in court.\n\nFederal Arbitration Act. This Agreement affects interstate commerce, and the enforceability of this Section 13 will be substantively and procedurally governed by the Federal Arbitration Act, 9 U.S.C. § 1, et seq. (the \"FAA\"), to the extent permitted by law. As limited by the FAA, this Agreement, and the AAA Rules (as defined below), the arbitrator will have exclusive authority to make all procedural and substantive decisions regarding any dispute and to grant any remedy that would otherwise be available in court, including the power to determine the question of arbitrability.\n\nArbitration Procedure.All Claims must be submitted to the American Arbitration Association (the \"AAA\") and will be resolved through binding arbitration before one arbitrator. The AAA administers arbitration pursuant to the due process standards set forth by the AAA and rules set forth by the AAA. The then-current version of the AAA’s Commercial Arbitration Rules and Mediation Procedures, which are available on the AAA’s website (adr.org) (the \"AAA Rules\"), as amended by this Agreement as follows, will apply to any arbitration between you and Tavily:\n\nYOU AND TAVILY AGREE THAT ANY ARBITRATION UNDER THIS AGREEMENT WILL TAKE PLACE ON AN INDIVIDUAL BASIS; CLASS ARBITRATIONS AND CLASS ACTIONS ARE NOT PERMITTED, AND YOU AND TAVILY ARE AGREEING TO GIVE UP THE ABILITY TO PARTICIPATE IN A CLASS ACTION. The arbitrator may conduct only an individual arbitration and, except as described below for the additional procedures to govern if twenty-five (25) or more similar or coordinated claims are asserted against Tavily or you by the same or coordinated counsel, may not consolidate more than one individual’s claims, preside over any type of class or representative proceeding, or preside over any proceeding involving more than one individual.\n\nAny in-person appearances will be held in Manhattan, New York.\n\nYou and Tavily agree to cooperate to seek from the arbitrator protection for any confidential, proprietary, trade secret, or otherwise sensitive information, documents, testimony, and/or other materials that might be exchanged or the subject of discovery in the arbitration. You and Tavily agree to seek such protection before any such information, documents, testimony, and/or materials are exchanged or otherwise become the subject of discovery in the arbitration.\n\nThe arbitrator's decision will follow this Agreement and will be final and binding. The arbitrator will have authority to award temporary, interim or permanent injunctive relief or relief providing for specific performance of this Agreement, but only to the extent necessary to provide relief warranted by the individual claim before the arbitrator. The award rendered by the arbitrator may be confirmed and enforced in any court having jurisdiction thereof. Notwithstanding any of the foregoing, nothing in this Agreement will preclude you from bringing issues to the attention of federal, state or local agencies and, if the law allows, they can seek relief against Tavily for you.\n\nThe AAA Supplementary Rules for Multiple Case Filings and the AAA Multiple Consumer Case Filing Fee Schedule will apply if twenty-five (25) or more similar claims are asserted against Tavily or against you by the same or coordinated counsel or are otherwise coordinated.\n\nIn addition to the application of the AAA Supplementary Rules for Multiple Case Filings and the AAA Multiple Consumer Case Filing Fee Schedule, you and Tavily understand and agree that when twenty-five (25) or more similar claims are asserted against Tavily or you by the same or coordinated counsel or are otherwise coordinated resolution of your or Tavily 's Claim might be delayed.\n\nFor such coordinated actions, you and Tavily also agree to the following coordinated bellwether process. Counsel for claimants and counsel for Tavily shall each select ten (10) cases (per side) to proceed first in individual arbitration proceedings. The remaining cases shall be deemed filed for purposes of the statute of limitations but not for the purpose of assessing AAA fees. No AAA fees shall be assessed in connection with those cases until they are selected to proceed to individual arbitration proceedings as part of a bellwether process. If the parties are unable to resolve the remaining cases after the conclusion of the initial twenty (20) proceedings, each side shall select another ten (10) cases (per side) to proceed to individual arbitration proceedings as part of a second bellwether process.\n\nA single arbitrator shall preside over each case. Only one case may be assigned to each arbitrator as part of a bellwether process unless the parties agree otherwise.\n\nThis bellwether process shall continue, consistent with the parameters identified above, until all the claims included in these coordinated filings, including your case, are adjudicated or otherwise resolved.\n\nThe statute of limitations and any filing fee deadlines shall be tolled for claims subject to this bellwether process from the time the first cases are selected for a bellwether process until the time your or Tavily's case is selected for a bellwether process, withdrawn, or otherwise resolved.\n\nA court shall have authority to enforce this paragraph and, if necessary, to enjoin the mass filing or prosecution of arbitration demands against Tavily or you.\n\nOne Year to Assert Claims.To the extent permitted by law, any Claim by you or Tavily relating in any way to this Agreement, the Services, or any aspect of the relationship between you and Tavily as relates to this Agreement or the Services, must be filed within one year after such Claim arises; otherwise, the Claim is permanently barred, which means that you and Tavily will not have the right to assert the Claim.\n\nOpting Out of Arbitration.You have the right to opt out of binding arbitration within 30 days of the date you first accepted this Agreement by providing Tavily with notice of your decision to opt-out via email at support@tavily.com or by certified mail addressed to 33 W 60th St, New York, NY 10023. In order to be effective, the opt-out notice must include your full name, mailing address, and email address. The notice must also clearly indicate your intent to opt out of binding arbitration. By opting out of binding arbitration, you are agreeing to resolve disputes in accordance with Section 14.\n\nRejection of Future Arbitration Changes. You may reject any change we make to Section 13 (except address changes) by personally signing and sending Tavily a notice within 30 days of the change via email at support@tavily.com or by certified mail addressed to 33 W 60th St, New York, NY 10023. If you do, the most recent version of Section 13 before the change you rejected will apply.\n\nSeverability.If any portion of this Section 13 is found to be unenforceable or unlawful for any reason, including but not limited to because it is found to be unconscionable: (i) the unenforceable or unlawful provision will be severed from this Agreement; (ii) severance of the unenforceable or unlawful provision will have no impact whatsoever on the remainder of this Section 13 or the parties’ ability to compel arbitration of any remaining claims on an individual basis pursuant to this Section 13; and (iii) to the extent that any claims must therefore proceed on a class, collective, consolidated, or representative basis, such claims must be litigated in a civil court of competent jurisdiction and not in arbitration. The litigation of those claims will be stayed pending the outcome of any individual claims in arbitration. Further, if any part of this Section 13 is found to prohibit an individual claim seeking public injunctive relief, that provision will have no effect to the extent such relief is allowed to be sought out of arbitration, and the remainder of this Section 13 will be enforceable.\n\nDisputes Outside the United StatesNotwithstanding any terms to the contrary in this Agreement, if you reside in any country outside of the United States, you may bring legal proceedings regarding this Agreement either by following the arbitration procedure detailed above in this Section 13 or, if given the right by applicable law, by submitting the dispute to an arbitration administrator in the jurisdiction in which you reside. To the extent any proceeding is not subject to arbitration under applicable law, you may submit the dispute to the courts of the jurisdiction in which you reside.\n\n9. Disclaimers.\n\nEntire Agreement.This Agreement constitutes the entire agreement between the parties with respect to its subject matter, and there are no agreements or understandings between the parties, express or implied, except as are expressly set forth in this Agreement.\n\nGoverning Law; Dispute Resolution. This Agreement will be governed in all respects in accordance with the laws of the State of New York, without regard to conflict of law principles that would cause the laws of any other jurisdiction to apply. Except as set forth in Section 13, you expressly agree that federal and state courts located in Manhattan, New York will have exclusive jurisdiction over any action or claim that you bring that arises out of or relating to this Agreement. You expressly consent to personal jurisdiction in any such court and hereby irrevocably waive any objection to or claim of lack of jurisdiction or forum non conveniens.\n\nAudits.Tavily may, by itself or through an independent third party, audit your use of the Services to verify (i) Fees payable and (ii) that you are otherwise compliant with the terms and conditions of this Agreement. You agree to (A) maintain complete and accurate books, logs, and other records with respect to your use of the Services and (B) provide reasonable access to your systems, books, logs, and other records for purposes of conducting these audits.\n\nMiscellaneous.This Agreement may not be modified or amended except by a writing signed by both parties. If any provision of this Agreement is found by any court to be void or otherwise unenforceable, the remainder of this Agreement will remain valid and enforceable as though such void or unenforceable provision were absent on the date of its execution. The relationship between the parties is that of independent contractors, and neither party has authority to contract for or bind the other party in any manner whatsoever. Notwithstanding any terms to the contrary in this Agreement, you consent to Tavily's use of your name and logo on Tavily's website and on Tavily's promotional and marketing related materials, identifying you as a customer of Tavily and/or describing your use of the Services. You may not assign, transfer or delegate this Agreement, nor any right or duty under this Agreement, by merger, acquisition, operation of law, or otherwise, without Tavily's prior written consent, and any attempted assignment, transfer, or delegation with such consent will be void and without effect. By using the Services, you agree (a) to receive communications (including any communications that are required to be issued in writing hereunder) electronically, including via email, (b) that any such electronically-issued communications will satisfy any legal communication requirements, including those that require notices to be in writing, (c) that, without limiting Tavily's notification rights elsewhere in this Agreement, Tavily may issue notices to the email or other address provided by you to Tavily, and (d) that such notice will be effective on delivery. Notices to Tavily, including termination notices, must be delivered to support@tavily.com or by certified mail to 33 W 60th St, New York, NY 10023. Such notice will be effective on receipt. Tavily is excused from performance of this Agreement and will not be liable for any delay in whole or in part caused by any event outside of its control. Each party has had the opportunity to review this Agreement with legal counsel, and there will be no presumption that ambiguities will be construed or interpreted against the drafter.\n\nLast updated: 9.27.24",
      "# [Tavily Blog](https://blog.tavily.com/)\nEffortless Web-Based RAG Evaluation Using Tavily and LangGraph\n\nIntroduction Every data science enthusiast knows that a vital first step to building a successful model or algorithm is having a reliable evaluation set to\n\nPrecision in AI Research: Tavily’s Company Researcher\n\nIn AI research, accuracy is critical. Outdated data? Not useful. Models generating false information? A serious issue. And if you’ve ever tried gathering insights\n\nAI Enablers: The Building Blocks of Next-Gen Enterprise Solutions\n\nIn my journey of helping enterprises deploy Large Language Model (LLM)-based applications, I’ve witnessed a transformative shift in the Software as a Service\n\nGetting Started with the Tavily Search API\n\nHow to Get Started with the Tavily Search API The Tavily Search API is a powerful tool for developers looking to integrate advanced search capabilities\n\nBuilding (and Breaking) WebLangChain\n\nImportant Links: * Hosted WebLangChain * Open-source code for WebLangChain Introduction One of the big shortcomings of LLMs is that they can only answer questions about data\n\nHow Agentic Communication will Transform the Web\n\nDetermined to illuminate the pathways of digital evolution, a visionary tech thinker unraveled his perspective during a pivotal speech: “when six billion humans are Googling,",
      "# [Tavily Community](https://community.tavily.com/)\nAPI\n\nQuestions and discussions regarding the Tavily Search API. This includes our REST API, the Tavily Online Platform and the Tavily Python Package.\n\n22\n\nDocumentation\n\nA place to discuss and suggest improvements for our Documentation and Tutorials. Please only discuss resources published by Tavily.\n\n1",
      "# [Tavily](https://tavily.com/enterprise)\nTalk to Our Team\n\nTavily provides powerful tools to connect AI agents to real-time web data. Our team is here to assist you in exploring how Tavily can enhance your AI applications.\n\nGet in touch. Our team will answer your questions and follow up with details on our custom plans and the expertise to help you drive results.",
      "# [Tavily Community](https://community.tavily.com/latest)\nPowered by Discourse, best viewed with JavaScript enabled",
      "# [Tavily Community](https://community.tavily.com/faq)\nThis is a Civilized Place for Public Discussion\n\nPlease treat this discussion forum with the same respect you would a public park. We, too, are a shared community resource — a place to share skills, knowledge and interests through ongoing conversation.\n\nThese are not hard and fast rules. They are guidelines to aid the human judgment of our community and keep this a kind, friendly place for civilized public discourse.\n\nImprove the Discussion\n\nHelp us make this a great place for discussion by always adding something positive to the discussion, however small. If you are not sure your post adds to the conversation, think over what you want to say and try again later.\n\nOne way to improve the discussion is by discovering ones that are already happening. Spend time browsing the topics here before replying or starting your own, and you’ll have a better chance of meeting others who share your interests.\n\nThe topics discussed here matter to us, and we want you to act as if they matter to you, too. Be respectful of the topics and the people discussing them, even if you disagree with some of what is being said.\n\nBe Agreeable, Even When You Disagree\n\nYou may wish to respond by disagreeing. That’s fine. But remember to criticize ideas, not people. Please avoid:\n\nName-calling\n\nAd hominem attacks\n\nResponding to a post’s tone instead of its actual content\n\nKnee-jerk contradiction\n\nInstead, provide thoughtful insights that improve the conversation.\n\nYour Participation Counts\n\nThe conversations we have here set the tone for every new arrival. Help us influence the future of this community by choosing to engage in discussions that make this forum an interesting place to be — and avoiding those that do not.\n\nDiscourse provides tools that enable the community to collectively identify the best (and worst) contributions: bookmarks, likes, flags, replies, edits, watching, muting and so forth. Use these tools to improve your own experience, and everyone else’s, too.\n\nLet’s leave our community better than we found it.\n\nIf You See a Problem, Flag It\n\nModerators have special authority; they are responsible for this forum. But so are you. With your help, moderators can be community facilitators, not just janitors or police.\n\nWhen you see bad behavior, don’t reply. Replying encourages bad behavior by acknowledging it, consumes your energy, and wastes everyone’s time. Just flag it. If enough flags accrue, action will be taken, either automatically or by moderator intervention.\n\nIn order to maintain our community, moderators reserve the right to remove any content and any user account for any reason at any time. Moderators do not preview new posts; the moderators and site operators take no responsibility for any content posted by the community.\n\nAlways Be Civil\n\nNothing sabotages a healthy conversation like rudeness:\n\nBe civil. Don’t post anything that a reasonable person would consider offensive, abusive, or hate speech.\n\nKeep it clean. Don’t post anything obscene or sexually explicit.\n\nRespect each other. Don’t harass or grief anyone, impersonate people, or expose their private information.\n\nRespect our forum. Don’t post spam or otherwise vandalize the forum.\n\nThese are not concrete terms with precise definitions — avoid even the appearance of any of these things. If you’re unsure, ask yourself how you would feel if your post was featured on the front page of a major news site.\n\nThis is a public forum, and search engines index these discussions. Keep the language, links, and images safe for family and friends.\n\nKeep It Tidy\n\nMake the effort to put things in the right place, so that we can spend more time discussing and less cleaning up. So:\n\nDon’t start a topic in the wrong category; please read the category definitions.\n\nDon’t cross-post the same thing in multiple topics.\n\nDon’t post no-content replies.\n\nDon’t divert a topic by changing it midstream.\n\nDon’t sign your posts — every post has your profile information attached to it.\n\nRather than posting “+1” or “Agreed”, use the Like button. Rather than taking an existing topic in a radically different direction, use Reply as a Linked Topic.\n\nPost Only Your Own Stuff\n\nYou may not post anything digital that belongs to someone else without permission. You may not post descriptions of, links to, or methods for stealing someone’s intellectual property (software, video, audio, images), or for breaking any other law.\n\nPowered by You",
      "# [Trust Center](https://trust.tavily.com/controls)\n",
      "# [Trust Center](https://trust.tavily.com/subprocessors)\n",
      "# [Tavily MCP Server](https://docs.tavily.com/documentation/mcp)\nThe Model Context Protocol (MCP) is an open standard that enables AI systems to interact seamlessly with various data sources and tools, facilitating secure, two-way connections.\n\nDeveloped by Anthropic, the Model Context Protocol (MCP) enables AI assistants like Claude to seamlessly integrate with Tavily’s advanced search and data extraction capabilities. This integration provides AI models with real-time access to web information, complete with sophisticated filtering options and domain-specific search features.\n\nAlthough you can launch a server on its own, it’s not particularly helpful in isolation. Instead, you should integrate it into an MCP client.",
      "# [Tavily Docs](https://docs.tavily.com/integrations/zapier)\nIntroduction\n\nNo need to write a single line of code to connect Tavily to your business processes. With Tavily’s robust search capabilities, you can pull in the latest online information into any application or workflow.\n\nSimply set up Tavily in Zapier to automate research, track real-time news, or feed relevant data into your tools of choice.\n\nHow to set up Tavily with Zapier\n\nUse cases for Tavily in Zapier\n\nWith Tavily, you can harness the power of Retrieval-Augmented Generation (RAG) to create complex workflows. Here are some examples, for inspiration:\n\nAutomated Email Generation: Use Tavily to create tailored emails based on real-time data.\n\nMeeting Preparation: Gather real-time information about meeting participants. For instance, before a client meeting, retrieve their latest news or social media updates and receive a concise summary through your preferred method, ensuring you’re well-informed.\n\nAutomated Reporting: Utilize Tavily’s online search data to generate reports. Push this information into tools like Google Sheets, Notion, or Slack to create a weekly digest of industry trends or competitor analysis, keeping your team updated effortlessly.\n\nDetailed example - company research\n\nWe can build an automated workflow that executes brief company research for newly signed-up companies and delivers the report via Slack.\n\nBest practices\n\nTo use Tavily most efficiently in your Zapier workflows, keep the following guidelines in mind when designing your automations:",
      "# [Tavily Docs](https://docs.tavily.com/documentation/quickstart)\nGet your free Tavily API key\n\nHead to the Tavily Platform and sign in (or create an account). Then, copy one of your API keys from your dashboard.\n\nGet your free API key\n\nYou get 1,000 free API Credits every month. No credit card required.\n\nInstall Tavily\n\nInstall the Tavily SDK in your language of choice.\n\nStart searching with Tavily\n\nRun your first Tavily Search in 4 lines of code. Simply replace the API key in this snippet with your own.\n\nNext steps\n\nThat’s all it takes to start using Tavily’s basic features!\n\nIf you want to learn how to implement more complex workflows in Python, check out our intermediate-level Getting Started notebook.",
      "# [SDK Reference](https://docs.tavily.com/sdk/python/reference)\nInstantiating a client\n\nTo interact with Tavily in Python, you must instatiate a client with your API key. For greater flexibility, we provide both a synchronous and an asynchronous client class.\n\nOnce you have instantiated a client, call one of our supported methods (detailed below) to access the API.\n\nSynchronous Client\n\nAsynchronous Client\n\nProxies\n\nIf you would like to specify a proxy to be used when making requests, you can do so by passing in a proxy parameter on client instantiation.\n\nProxy configuration is available in both the synchronous and asynchronous clients.\n\nAlternatively, you can specify which proxies to use by setting the TAVILY_HTTP_PROXY and TAVILY_HTTPS_PROXY variables in your environment file.\n\nTavily Search\n\nYou can access Tavily Search in Python through the client’s search function.\n\nParameters\n\nParameterTypeDescriptionDefaultquery (required)strThe query to run a search on.search_depthstrThe depth of the search. It can be \"basic\" or \"advanced\". \"advanced\" search is tailored to retrieve the most relevant sources and content snippets for your query, while \"basic\" search provides generic content snippets from each source.\"basic\"topicstrThe category of the search. Determines which agent will be used. Supported values are \"general\" and \"news\".\"general\"daysintThe number of days back from the current date to include in the results. Available only when using the \"news\" topic.3time_rangestrThe time range back from the current date. Accepted values include \"day\", \"week\", \"month\", \"year\" or shorthand values \"d\", \"w\", \"m\", \"y\".max_resultsintThe maximum number of search results to return. It must be between 0 and 20.5chunks_per_sourceintThe number of content chunks to retrieve from each source. Each chunk’s length is maximum 500 characters. It must be between 1 and 3. Available only when search_depth is advanced.3include_imagesboolInclude a list of query-related images in the response.Falseinclude_image_descriptionsboolInclude a list of query-related images and their descriptions in the response.Falseinclude_answerbool or strInclude an answer to the query generated by an LLM based on search results. A \"basic\" (or True) answer is quick but less detailed; an \"advanced\" answer is more detailed.Falseinclude_raw_contentboolInclude the cleaned and parsed HTML content of each search result.Falseinclude_domainslist[str]A list of domains to specifically include in the search results.[]exclude_domainslist[str]A list of domains to specifically exclude from the search results.[]timeoutintA timeout to be used in requests to the Tavily API.60\n\nResponse format\n\nThe response object you receive will be in the following format:\n\nKeyTypeDescriptionresultslist[Result]A list of sorted search results ranked by relevancy.querystrYour search query.response_timefloatYour search result response time.answer (optional)strThe answer to your search query, generated by an LLM based on Tavily’s search results. This is only available if include_answer is set to True.images (optional)list[str] or list[ImageResult]This is only available if include_images is set to True. A list of query-related image URLs. If include_image_descriptions is set to True, each entry will be an ImageResult.\n\nResults\n\nKeyTypeDescriptiontitlestrThe title of the search result.urlstrThe URL of the search result.contentstrThe most query-related content from the scraped URL. Tavily uses proprietary AI to extract the most relevant content based on context quality and size.scorefloatThe relevance score of the search result.raw_content (optional)strThe parsed and cleaned HTML content of the site. This is only available if include_raw_content is set to True.published_date (optional)strThe publication date of the source. This is only available if the search topic is set to \"news\".\n\nImage Results\n\nIf includeImageDescriptions is set to true, each image in the images list will be in the following ImageResult format:\n\nKeyTypeDescriptionurlstringThe URL of the image.descriptionstringAn LLM-generated description of the image.\n\nExample\n\nTavily Extract\n\nYou can access Tavily Extract in Python through the client’s extract function.\n\nParameters\n\nParameterTypeDescriptionDefaulturls (required)str or list[str]The URL (or URLs) you want to extract. If a list is provided, it must not contain more than 20 URLs.include_imagesboolInclude a list of images extracted from the URLs in the response.Falseextract_depthstrThe depth of the extraction process. You may experience higher latency with \"advanced\" extraction, but it offers a higher success rate and retrieves more data from the URL (e.g., tables, embedded content). \"basic\" extraction costs 1 API Credit per 5 successful URL extractions, while advanced extraction costs 2 API Credits per 5 successful URL extractions.\"basic\"timeoutintA timeout to be used in requests to the Tavily API.60\n\nResponse format\n\nThe response object you receive will be in the following format:\n\nKeyTypeDescriptionresultslist[SuccessfulResult]A list of extracted content.failed_resultslist[FailedResult]A list of URLs that could not be processed.response_timefloatThe search result response time.\n\nSuccessful Results\n\nEach successful result in the results list will be in the following SuccessfulResult format:\n\nKeyTypeDescriptionurlstrThe URL of the webpage.raw_contentstrThe raw content extracted.images (optional)list[str]This is only available if include_images is set to True. A list of extracted image URLs.\n\nFailed Results\n\nEach failed result in the results list will be in the following FailedResult format:\n\nKeyTypeDescriptionurlstrThe URL that failed.errorstrAn error message describing why it could not be processed.\n\nExample\n\nTavily Hybrid RAG\n\nTavily Hybrid RAG is an extension of the Tavily Search API built to retrieve relevant data from both the web and an existing database collection. This way, a RAG agent can combine web sources and locally available data to perform its tasks. Additionally, data queried from the web that is not yet in the database can optionally be inserted into it. This will allow similar searches in the future to be answered faster, without the need to query the web again.\n\nParameters\n\nThe TavilyHybridClient class is your gateway to Tavily Hybrid RAG. There are a few important parameters to keep in mind when you are instantiating a Tavily Hybrid Client.\n\nParameterTypeDescriptionDefaultapi_keystrYour Tavily API Keydb_providerstrYour database provider. Currently, only \"mongodb\" is supported.collectionstrA reference to the MongoDB collection that will be used for local search.embeddings_field (optional)strThe name of the field that stores the embeddings in the specified collection. This field MUST be the same one used in the specified index. This will also be used when inserting web search results in the database using our default function.\"embeddings\"content_field (optional)strThe name of the field that stores the text content in the specified collection. This will also be used when inserting web search results in the database using our default function.\"content\"embedding_function (optional)functionA custom embedding function (if you want to use one). The function must take in a list[str] corresponding to the list of strings to be embedded, as well as an additional string defining the type of document. It must return a list[list[float]], one embedding per input string. If no function is provided, defaults to Cohere’s Embed. Keep in mind that you shouldn’t mix different embeddings in the same database collection.ranking_function (optional)functionA custom ranking function (if you want to use one). If no function is provided, defaults to Cohere’s Rerank. It should return an ordered list[dict] where the documents are sorted by decreasing relevancy to your query. Each returned document will have two properties - content, which is a str, and score, which is a float. The function MUST accept the following parameters: query: str - This is the query you are executing. When your ranking function is called during Hybrid RAG, the query parameter of your search call (more details below) will be passed as query. documents:List[Dict]: - This is the list of documents that are returned by your Hybrid RAG call and that you want to sort. Each document will have two properties - content, which is a str, and score, which is a float. top_n: int - This is the number of results you want to return after ranking. When your ranking function is called during Hybrid RAG, the max_results value will be passed as top_n.\n\nMethods\n\nsearch(query, max_results=10, max_local=None, max_foreign=None, save_foreign=False, **kwargs)\n\nPerforms a Tavily Hybrid RAG query and returns the retrieved documents as a list[dict] where the documents are sorted by decreasing relevancy to your query. Each returned document will have three properties - content (str), score (float), and origin, which is either local or foreign.\n\nParameterTypeDescriptionDefaultquerystrThe query you want to search for.max_resultsintThe maximum number of total search results to return.10max_localintThe maximum number of local search results to return.None, which defaults to max_results.max_localintThe maximum number of local search results to return.None, which defaults to max_results.max_foreignintThe maximum number of web search results to return.None, which defaults to max_results.save_foreignUnion[bool, function]Save documents from the web search in the local database. If True is passed, our default saving function (which only saves the content str and the embedding list[float] will be used.) If False is passed, no web search result documents will be saved in the local database. If a function is passed, that function MUST take in a dict as a parameter, and return another dict. The input dict contains all properties of the returned Tavily result object. The output dict is the final document that will be inserted in the database. You are free to add to it any fields that are supported by the database, as well as remove any of the default ones. If this function returns None, the document will not be saved in the database.\n\nAdditional parameters can be provided as keyword arguments (detailed below). The keyword arguments supported by this method are: search_depth, topic, include_raw_content, include_domains,exclude_domains.\n\nSetup\n\nMongoDB setup\n\nYou will need to have a MongoDB collection with a vector search index. You can follow the MongoDB Documentation to learn how to set this up.\n\nCohere API Key\n\nBy default, embedding and ranking use the Cohere API, our recommended option. Unless you want to provide a custom embedding and ranking function, you’ll need to get an API key from Cohere and set it as an environment variable named CO_API_KEY\n\nIf you decide to stick with Cohere, please note that you’ll need to install the Cohere Python package as well:\n\nTavily Hybrid RAG Client setup\n\nOnce you are done setting up your database, you’ll need to create a MongoDB Client as well as a Tavily Hybrid RAG Client. A minimal setup would look like this:\n\nUsage\n\nOnce you create the proper clients, you can easily start searching. A few simple examples are shown below. They assume you’ve followed earlier steps. You can use most of the Tavily Search parameters with Tavily Hybrid RAG as well.\n\nSimple Tavily Hybrid RAG example\n\nThis example will look for context about Leo Messi on the web and in the local database. Here, we get 5 sources, both from our database and from the web, but we want to exclude unwanted-domain.com from our web search results:\n\nHere, we want to prioritize the number of local sources, so we will get 2 foreign (web) sources, and 5 sources from our database:\n\nNote: The sum of max_local and max_foreign can exceed max_results, but only the top max_results results will be returned.\n\nAdding retrieved data to the database\n\nIf you want to add the retrieved data to the database, you can do so by setting the save_foreign parameter to True:\n\nThis will use our default saving function, which stores the content and its embedding.\n\nExamples\n\nSample 1: Using a custom saving function\n\nYou might want to add some extra properties to documents you’re inserting or even discard some of them based on custom criteria. This can be done by passing a function to the save_foreign parameter:\n\nSample 2: Using a custom embedding function\n\nBy default, we use Cohere for our embeddings. If you want to use your own embeddings, can pass a custom embedding function to the TavilyHybridClient:\n\nSample 3: Using a custom ranking function",
      "# [Tavily Community](https://community.tavily.com/login-preferences)\nWelcome to Tavily Community\n\nThe official developer community for Tavily AI.",
      "# [Precision in AI Research: Tavily’s Company Researcher by Rotem Weiss on 2024-11-18](https://blog.tavily.com/companyresearcher/)\nIn AI research, accuracy is critical. Outdated data? Not useful. Models generating false information? A serious issue. And if you’ve ever tried gathering insights on companies with minimal online presence—or on similarly named entities—you know that many tools often fall short. That’s where Tavily’s Company Researcher comes in. This tool integrates Tavily Search and Extract, in a workflow powered by LangGraph, to deliver precise, reliable insights. Instead of just surface-level data, it generates comprehensive, current reports with in-depth detail.\n\nTavily’s Intelligent Search Layer\n\nTavily’s mission is to provide an intelligent search layer that connects large language models (LLMs) to the web, giving agents access to real-time, contextually relevant data. Tavily supports flexible search capabilities, enabling AI agents to fine-tune search strategies, retrieve raw content for analysis, or pull summaries for quick insights. Unlike static models bound to training data, Tavily’s Search and Extract endpoints combine semantic, contextual, and keyword search to deliver timely, relevant insights for data-driven decision-making.\n\nHow the Company Researcher Works\n\nThe Company Researcher automates a multi-stage workflow for real-time company analysis, integrating search and extraction with agentic behavior to generate high-quality results. Its modular and dynamic architecture allows for efficient gathering of both general context and targeted data. The use of feedback loops, combined with optional human-on-the-loop validation, ensures precise and reliable outputs. Here’s how it works:\n\nInitial Grounding with Tavily Extract: Each session begins with a user-provided company name and URL. Tavily Extract retrieves content from that site, creating a “ground truth” that anchors the search to follow. By grounding in verified data, each step operates within set accuracy boundaries, reducing hallucinations and inconsistencies.\n\nSub-Question Generation and Tavily Search: Dynamically generates specific sub-questions to guide Tavily’s search, focusing the search on high-value, relevant data instead of conducting a broad, unfocused search.\n\nAI-Driven Clustering: Retrieved documents are grouped by company, using the ground truth to verify accuracy, especially for similarly named entities. This clustering keeps only relevant sources in focus.\n\nHuman-on-the-Loop for Cluster Validation: If clustering doesn’t yield a definitive match, meaning that the correct cluster wasn't automatically identified, optional human validation can make manual adjustments, ensuring data quality.\n\nDocument Curation and Enrichment with Tavily Extract: Once a trusted cluster is identified, Tavily Extract pulls detailed data from these verified links, adding substantial depth to the research. This step enhances the precision and comprehensiveness of the final output.\n\nReport Generation and Evaluation: An LLM synthesizes the data into a structured report. If gaps are detected, new questions are generated to gather additional data, improving the report without restarting.\n\nMulti-Format Output: The final report is available in PDF or Markdown format, making it easy to share and integrate.\n\nHere is how I define the workflow IRL:\n\nKey Technical Features\n\nGrounding: The Foundation of Accuracy\n\nGrounding is core to Tavily’s Company Researcher workflow. It starts with establishing a reliable “ground truth” by using Tavily Extract on a verified company URL. This keeps the system aligned to the correct entity, especially in cases where similarly named companies exist. Creating a foundation to work from minimizes unrelated or erroneous information, improving output accuracy. Feedback loops that refer to the “ground truth” coupled with human-on-the-loop validation further reinforce this foundation, ensuring outputs are consistently relevant and curated for quality.\n\nTavily Search and Extract: Better Together for Precision\n\nTavily Extract is geared to pull raw information from specified sources. Allowing the agent to dig deep on the most important sources without the pressure of having to explore every possible lead. Tavily Search on the other hand, looks at the breadth of the web to identify the most relevant sources for your goal. By going broad it will ensure the scope of your research needs are covered. Tavily’s Company Researcher shows how you can utilize the strengths of each and have both tools work with one another to generate the results you want. In the end, only the most relevant pages are analyzed, providing accurate, contextually rich information, minimizing long context windows, and resulting in precise, actionable reports.\n\nDynamic Graph-Like Structure: Flexibility Meets Predictability\n\nThe Company Researcher uses a dynamic, graph-based structure that balances clear paths with flexibility. Traditional deterministic workflows work well for set steps but struggle in unpredictable real-world contexts. Fully dynamic workflows, like ReAct, handle unpredictability better but can lack structure and deterministic accuracy. The Company Researcher’s hybrid approach, implemented with LangGraph, maintains a clear path while adapting to real-world, real-time challenges, allowing for flexibility when data inputs vary.\n\nStructured Output: Consistency in Data\n\nStructured prompting ensures output consistency. While early LLMs could provide accurate information, their formatting was often inconsistent. I addressed this by embedding specific formatting into prompts, so each data cluster follows a set structure, making results easy to retrieve, reliable, and consistently organized.\n\nHere is an example of how it is used to define the clusters:\n\nAnd it is even simpler to call:\n\nThen, you can access each type of output because it is assigned to the cluster through the defined structure:\n\nAnd the Best Part: It’s Adaptable!\n\nTavily’s Company Researcher can be easily customized to fit a range of research needs. By making simple adjustments, you can expand its use beyond company research to tackle various data-intensive tasks, ensuring consistent and reliable results.\n\nModify Prompts: Consider tailoring the prompts used for question generation or report synthesis to better align with your specific research goals.\n\nExtend Workflow Nodes: Think about adding, removing, or altering workflow nodes to target specific types of analysis or areas of interest.\n\nCustomize Output Formats: Don’t hesitate to adjust output formats, such as using custom CSS for PDF styling, to align with your organization’s standards.\n\nGetting Started with Company Researcher:\n\nIn this section, we will walk you through the steps to download and start using Company Researcher.\n\nPrerequisites\n\nPython 3.11 or later: Python Installation Guide\n\nTavily API Key - Sign Up\n\nAnthropic API Key - Sign Up\n\nInstallation\n\nClone the Repository:\n\ngit clone https://github.com/danielleyahalom/company-researcher.git cd company-researcher\n\nCreate a Virtual Environment:\n\nTo avoid dependency conflicts, it's recommended to create and activate a virtual environment using venv:\n\npython -m venv venv source venv/bin/activate # macOS/Linux venv\\Scripts\\activate # Windows\n\nSet Up API Keys:\n\nConfigure your Anthropic and Tavily API keys as environment variables or place them in a .env file:\n\nexport TAVILY_API_KEY={Your Tavily API Key here} export ANTHROPIC_API_KEY={Your Anthropic API Key here}\n\nInstall Dependencies:\n\npip install -r requirements.txt\n\nRun the Application:\n\npython app.py\n\nOpen the App in Your Browser:\n\nhttp://localhost:5000",
      "# [Tavily Docs](https://docs.tavily.com/documentation/integrations/zapier)\nIntroduction\n\nNo need to write a single line of code to connect Tavily to your business processes. With Tavily’s robust search capabilities, you can pull in the latest online information into any application or workflow.\n\nSimply set up Tavily in Zapier to automate research, track real-time news, or feed relevant data into your tools of choice.\n\nHow to set up Tavily with Zapier\n\nUse cases for Tavily in Zapier\n\nWith Tavily, you can harness the power of Retrieval-Augmented Generation (RAG) to create complex workflows. Here are some examples, for inspiration:\n\nAutomated Email Generation: Use Tavily to create tailored emails based on real-time data.\n\nMeeting Preparation: Gather real-time information about meeting participants. For instance, before a client meeting, retrieve their latest news or social media updates and receive a concise summary through your preferred method, ensuring you’re well-informed.\n\nAutomated Reporting: Utilize Tavily’s online search data to generate reports. Push this information into tools like Google Sheets, Notion, or Slack to create a weekly digest of industry trends or competitor analysis, keeping your team updated effortlessly.\n\nDetailed example - company research\n\nWe can build an automated workflow that executes brief company research for newly signed-up companies and delivers the report via Slack.\n\nBest practices\n\nTo use Tavily most efficiently in your Zapier workflows, keep the following guidelines in mind when designing your automations:",
      "# [Tavily Docs](https://docs.tavily.com/documentation/integrations/langchain)\nWarning: The langchain_community.tools.tavily_search.tool is deprecated. While it remains functional for now, we strongly recommend migrating to the new langchain-tavily Python package which supports both Search and Extract functionality and receives continuous updates with the latest features.\n\nThe langchain-tavily Python package is the offical LangChain integration of Tavily, inlcuding both TavilySearch and TavilyExtract\n\nInstallation\n\nCredentials\n\nWe also need to set our Tavily API key. You can get an API key by visiting this site and creating an account.\n\nTavily Search\n\nHere we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily’s Search API endpoint.\n\nInstantiation\n\nThe tool accepts various parameters during instantiation:\n\nmax_results (optional, int): Maximum number of search results to return. Default is 5.\n\ntopic (optional, str): Category of the search. Can be “general”, “news”, or “finance”. Default is “general”.\n\ninclude_answer (optional, bool): Include an answer to original query in results. Default is False.\n\ninclude_raw_content (optional, bool): Include cleaned and parsed HTML of each search result. Default is False.\n\ninclude_images (optional, bool): Include a list of query related images in the response. Default is False.\n\ninclude_image_descriptions (optional, bool): Include descriptive text for each image. Default is False.\n\nsearch_depth (optional, str): Depth of the search, either “basic” or “advanced”. Default is “basic”.\n\ntime_range (optional, str): The time range back from the current date to filter results - “day”, “week”, “month”, or “year”. Default is None.\n\ninclude_domains (optional, List[str]): List of domains to specifically include. Default is None.\n\nexclude_domains (optional, List[str]): List of domains to specifically exclude. Default is None.\n\nFor a comprehensive overview of the available parameters, refer to the Tavily Search API documentation\n\nInvoke directly with args\n\nThe Tavily search tool accepts the following arguments during invocation:\n\nquery (required): A natural language search query\n\nThe following arguments can also be set during invokation : include_images, search_depth , time_range, include_domains, exclude_domains, include_images\n\nFor reliability and performance reasons, certain parameters that affect response size cannot be modified during invocation: include_answer and include_raw_content. These limitations prevent unexpected context window issues and ensure consistent results.\n\nNOTE: The optional arguments are available for agents to dynamically set, if you set a argument during instantiation and then invoke the tool with a different value, the tool will use the value you passed during invokation.\n\noutput:\n\nAgent Tool Calling\n\nWe can use our tools directly with an agent executor by binding the tool to the agent. This gives the agent the ability to dynamically set the available arguments to the Tavily search tool.\n\nIn the below example when we ask the agent to find “What is the most popular sport in the world? include only wikipedia sources” the agent will dynamically set the argments and invoke Tavily search tool : Invoking tavily_search with {'query': 'most popular sport in the world', 'include_domains': ['wikipedia.org'], 'search_depth': 'basic'}\n\nTavily Extract\n\nHere we show how to instantiate an instance of the Tavily extract tool. After instantiation we invoke the tool with a list of URLs. This tool allows you to extract content from URLs using Tavily’s Extract API endpoint.\n\nInstantiation\n\nThe tool accepts various parameters during instantiation:\n\nextract_depth (optional, str): The depth of the extraction, either “basic” or “advanced”. Default is “basic ”.\n\ninclude_images (optional, bool): Whether to include images in the extraction. Default is False.\n\nFor a comprehensive overview of the available parameters, refer to the Tavily Extract API documentation\n\nInvoke directly with args\n\nThe Tavily extract tool accepts the following arguments during invocation:\n\nurls (required): A list of URLs to extract content from.\n\nBoth extract_depth and include_images can also be set during invokation\n\nNOTE: The optional arguments are available for agents to dynamically set, if you set a argument during instantiation and then invoke the tool with a different value, the tool will use the value you passed during invokation.\n\noutput:\n\nTavily Research Agent\n\nThis example demonstrates how to build a powerful web research agent using Tavily’s search and extract Langchain tools.\n\nFeatures",
      "# [SDK Reference](https://docs.tavily.com/sdk/javascript/reference)\nInstantiating a client\n\nTo interact with Tavily in JavaScript, you must instatiate a client with your API key. Our client is asynchronous by default.\n\nOnce you have instantiated a client, call one of our supported methods (detailed below) to access the API.\n\nProxies\n\nIf you would like to specify a proxy to be used when making requests, you can do so by passing in a proxy parameter on client instantiation.\n\nProxy configuration is available in both the synchronous and asynchronous clients.\n\nAlternatively, you can specify which proxies to use by setting the TAVILY_HTTP_PROXY and TAVILY_HTTPS_PROXY variables in your environment file.\n\nTavily Search\n\nYou can access Tavily Search in JavaScript through the client’s search function.\n\nParameters\n\nParameterTypeDescriptionDefaultquery (required)stringThe query to run a search on.searchDepthstringThe depth of the search. It can be \"basic\" or \"advanced\". \"advanced\" search is tailored to retrieve the most relevant sources and content snippets for your query, while \"basic\" search provides generic content snippets from each source.\"basic\"topicstringThe category of the search. Determines which agent will be used. Supported values are \"general\" and \"news\".\"general\"daysnumberThe number of days back from the current date to include in the results. Available only when using the \"news\" topic.3timeRangestringThe time range back from the current date. Accepted values include \"day\", \"week\", \"month\", \"year\" or shorthand values \"d\", \"w\", \"m\", \"y\".maxResultsnumberThe maximum number of search results to return. It must be between 0 and 20.5chunksPerSourcenumberThe number of content chunks to retrieve from each source. Each chunk’s length is maximum 500 characters. It must be between 1 and 3. Available only when searchDepth is \"advanced\".includeImagesbooleanInclude a list of query-related images in the response.falseincludeImageDescriptionsbooleanInclude a list of query-related images and their descriptions in the response.falseincludeAnswerboolean or stringInclude an answer to the query generated by an LLM based on search results. A \"basic\" (or true) answer is quick but less detailed; an \"advanced\" answer is more detailed.falseincludeRawContentbooleanInclude the cleaned and parsed HTML content of each search result.falseincludeDomainsArray<string>A list of domains to specifically include in the search results.[]excludeDomainsArray<string>A list of domains to specifically exclude from the search results.[]timeoutnumberA timeout to be used in requests to the Tavily API.60\n\nResponse format\n\nThe response object you receive will be in the following format:\n\nKeyTypeDescriptionresultsArray<Result>A list of sorted search results ranked by relevancy.querystringYour search query.responseTimenumberYour search result response time.answer (optional)stringThe answer to your search query, generated by an LLM based on Tavily’s search results. This is only available if includeAnswer is set to true.images (optional)Array<string> or Array<ImageResult>This is only available if includeImages is set to true. A list of query-related image URLs. If includeImageDescriptions is set to true, each entry will be an ImageResult.\n\nResults\n\nEach result in the results list will be in the following Result format:\n\nKeyTypeDescriptiontitlestringThe title of the search result.urlstringThe URL of the search result.contentstringThe most query-related content from the scraped URL. Tavily uses proprietary AI to extract the most relevant content based on context quality and size.scorefloatThe relevance score of the search result.rawContent (optional)stringThe parsed and cleaned HTML content of the site. This is only available if includeRawContent is set to true.publishedDate (optional)stringThe publication date of the source. This is only available if the search topic is set to news.\n\nImage Results\n\nEach image in the images list will be in the following ImageResult format:\n\nKeyTypeDescriptionurlstrThe URL of the image.description (optional)strThis is only available if includeImageDescriptions is set to true. An LLM-generated description of the image.\n\nExample\n\nTavily Extract\n\nYou can access Tavily Extract in JavaScript through the client’s extract function.\n\nParameters\n\nParameterTypeDescriptionDefaulturls (required)Array<string>The URLs you want to extract. The list must not contain more than 20 URLs.includeImagesbooleanInclude a list of images extracted from the URLs in the response.falseextractDepthstringThe depth of the extraction process. You may experience higher latency with \"advanced\" extraction, but it offers a higher success rate and retrieves more data from the URL (e.g., tables, embedded content). \"basic\" extraction costs 1 API Credit per 5 successful URL extractions, while \"advanced\" extraction costs 2 API Credits per 5 successful URL extractions.\"basic\"timeoutnumberA timeout to be used in requests to the Tavily API.60\n\nResponse format\n\nThe response object you receive will be in the following format:\n\nKeyTypeDescriptionresultsArray<SuccessfulResult>A list of extracted content.failed_resultsArray<FailedResult>A list of URLs that could not be processed.response_timenumberThe search result response time.\n\nSuccessful Results\n\nEach successful result in the results list will be in the following SuccessfulResult format:\n\nKeyTypeDescriptionurlstringThe URL of the webpage.raw_contentstringThe raw content extracted.images (optional)Array<string>This is only available if includeImages is set to true. A list of extracted image URLs.\n\nFailed Results\n\nEach failed result in the results list will be in the following FailedResult format:\n\nKeyTypeDescriptionurlstringThe URL that failed.errorstringAn error message describing why it could not be processed.",
      "# [Tavily Docs](https://docs.tavily.com/documentation/integrations/llamaindex)\nInstall Tavily and LlamaIndex\n\nThe following dependencies are required to properly run the integration:\n\nUsage\n\nYou can use access Tavily in LlamaIndex through the TavilyToolSpec.\n\nHere is a simple use case that performs a web search with Tavily and generates an answer to the user’s search query:\n\nsearch: Search for relevant dynamic data based on a query. Returns a list of urls and their relevant content.",
      "# [API](https://community.tavily.com/c/api/8)\nPowered by Discourse, best viewed with JavaScript enabled",
      "# [Credits & Pricing](https://docs.tavily.com/documentation/api-credits)\nFree API Credits\n\nGet your free API key\n\nYou get 1,000 free API Credits every month. No credit card required.\n\nPricing Overview\n\nWe operate on a credit-based charging system. Each plan has a specific number of credits (the Researcher Plan includes 1,000 free API credits per month). Additionally, you have the option to enable Pay as you go, which allows you to be charged per credit once your plan’s credit limit is reached.\n\nPlan\n\nCredits per monthPrice per monthPrice per creditResearcher1,000Free-Project4,000$30$0.0075Bootstrap15,000$100$0.0067Startup38,000$220$0.0058Growth100,000$500$0.0050Pay as you goPer usage$0.008 / Credit$0.008EnterpriseCustomCustomCustom\n\nHead to my plan to explore our different options and manage your plan.\n\nHow API Credits Are Deducted\n\nTavily Search\n\nYour search depth determines the cost of your request.\n\nSearch depthAPI credits deductedbasic1advanced2\n\nTavily Extract\n\nThe number of successful URL extractions and your extraction depth determines the cost of your request. You never get charged if a URL extraction fails.",
      "# [Rate Limits](https://docs.tavily.com/documentation/rate-limits)\nWe offer two types of rate limits based on the environment associated with your API key.\n\nGet your API key\n\nCreate your Development or Production API keys.",
      "# [Documentation](https://community.tavily.com/c/documentation/9)\nPowered by Discourse, best viewed with JavaScript enabled",
      "# [API performance on 2024-09-04](https://community.tavily.com/t/api-performance/115)\nHello,\n\nWe are using Tavily API as a tool in our AI agent. The search API takes around 40 seconds to respond to queries, but, on retries with the same prompt, is able to come back in < 4 seconds.\n\nHere is a sample prompt - Recent Federal Reserve interest rate hikes impact on U.S. consumer spending and borrowing trends\n\nHere are the parameter we are using on the client -\n\ntavily_client.search(query, search_depth=“advanced”).\n\nIs it possible to get consistent near real time (< 4 sec) responses at all times? We are currently on bootstrap pricing mode, and we intend to move up the tier if the API satisfies our needs.\n\nThanks\n\nHi,\n\nThank you for reaching out! A response time of 40 seconds for queries is very unlikely, and I couldn’t find any record of such delays on our end. Typically, response times range between 1 to 10 seconds. You can also check the current status of the API on our status page here: https://status.tavily.com.\n\nCould you share which framework you’re using Tavily as a tool in? Perhaps that is the cause of the delays, and we’d be happy to look into it.\n\nWhile we’re unable to provide detailed technical information on how results improve over time, I can confirm that as more people research a particular topic, the results do indeed become better.\n\nLet us know if you have any more questions or feedback. We’re here to help and accommodate your needs as you continue exploring the API!\n\nThank you for your response.\n\nOur stack utilizes LangGraph, where nodes implement function calls using web search tools, including Tavily. Initially, we had set include_raw_content to True with max_results set to 10, which led to 502 errors or long runtimes. We have since disabled raw content and reduced max_results to 5, and we’re now experiencing much faster results.\n\nWe will continue to test the API, and so far, we are pleased with the results it is delivering within our stack.\n\nOn a side note, our legal team has been trying to reach you regarding enterprise pricing but hasn’t had success. Is there a specific contact we can reach out to in order to discuss your enterprise package?\n\nThanks.\n\nI’m glad to hear that you’re pleased with the results you’re obtaining using our API within your stack! Setting include_raw_content can sometimes place constraints on our system, but our team is actively working on improving performance. Things should be running more smoothly now if you need to enable it for specific cases.\n\nI apologize for the difficulties your legal team has had in reaching us. You can either fill out this form, and our team will get back to you as soon as possible, or reach out via email at support@tavily.com.\n\nThank you again for reaching out. Let us know if you have any more questions or feedback!\n\nI’ve informed our account managers, Itamar and Lee, about the situation. Lee mentioned that they’ve been trying to reach out as well, with one email sent on August 22nd and another yesterday. Lee has just sent another follow-up email. Please let us know if you haven’t received it or if there’s still an issue with getting in touch. I’d be happy to help resolve this communication gap."
    ],
    "search_results": [
      {
        "title": "Tavily",
        "link": "https://tavily.com/",
        "snippet": "Tavily Search API is a specialized search engine designed for Large Language Models (LLMs) and AI agents. It provides real-time, accurate, and unbiased ...",
        "formattedUrl": "https://tavily.com/"
      },
      {
        "title": "Trust Center - Tavily",
        "link": "https://trust.tavily.com/",
        "snippet": "Our mission is to revolutionize data access for AI agents, optimizing efficiency and innovation through a powerful search engine tailored for LLMs and RAG.",
        "formattedUrl": "https://trust.tavily.com/"
      },
      {
        "title": "AlphaAI Technologies Inc. Platform Privacy Policy",
        "link": "https://tavily.com/privacy",
        "snippet": "In order to use the Platform, you must be at least 13 years of age, or older, if otherwise required by the laws of the country you reside in. Our Platform is ...",
        "formattedUrl": "https://tavily.com/privacy"
      },
      {
        "title": "Tavily API Status",
        "link": "https://status.tavily.com/",
        "snippet": "00:22 - 00:38. No observed issues. 00:38 - 00:54. No observed issues. 00:54 - 01:10. No observed issues. 01:10 - 01:26. No observed issues. 01:26 - 01:42. No ...",
        "formattedUrl": "https://status.tavily.com/"
      },
      {
        "title": "Tavily Services Agreement",
        "link": "https://tavily.com/terms",
        "snippet": "Sep 27, 2024 ... Tavily will (a) provide access to the Services and (b) use commercially reasonable efforts to provide any Support Services that Tavily has agreed to provide to ...",
        "formattedUrl": "https://tavily.com/terms"
      },
      {
        "title": "Tavily Blog",
        "link": "https://blog.tavily.com/",
        "snippet": "Tavily is the leading search engine for AI agents, providing real-time access to data.",
        "formattedUrl": "https://blog.tavily.com/"
      },
      {
        "title": "Tavily Community",
        "link": "https://community.tavily.com/",
        "snippet": "Documentation. A place to discuss and suggest improvements for our Documentation and Tutorials. Please only discuss resources published by Tavily. 1 ...",
        "formattedUrl": "https://community.tavily.com/"
      },
      {
        "title": "Tavily",
        "link": "https://tavily.com/enterprise",
        "snippet": "Tavily is a search engine tailored for AI agents, delivering real-time, accurate results, intelligent query suggestions, and in-depth research capabilities.",
        "formattedUrl": "https://tavily.com/enterprise"
      },
      {
        "title": "Latest topics - Tavily Community",
        "link": "https://community.tavily.com/latest",
        "snippet": "How Tavily API store data related to user information, query and query response? Other Tavily Topics · advanced-question. 1, 72, January 20, 2025. Whitelist ...",
        "formattedUrl": "https://community.tavily.com/latest"
      },
      {
        "title": "FAQ - Tavily Community",
        "link": "https://community.tavily.com/faq",
        "snippet": "a shared community resource — a place to share skills, knowledge and interests through ongoing conversation. These are not hard and fast rules. They are ...",
        "formattedUrl": "https://community.tavily.com/faq"
      },
      {
        "title": "Trust Center - Tavily",
        "link": "https://trust.tavily.com/controls",
        "snippet": "Tavily prioritizes security, maintaining high standards through encryption, regular audits, and strict access controls. We adhere to global compliance standards ...",
        "formattedUrl": "https://trust.tavily.com/controls"
      },
      {
        "title": "Trust Center - Tavily",
        "link": "https://trust.tavily.com/subprocessors",
        "snippet": "Our mission is to revolutionize data access for AI agents, optimizing efficiency and innovation through a powerful search engine tailored for LLMs and RAG.",
        "formattedUrl": "https://trust.tavily.com/subprocessors"
      },
      {
        "title": "Tavily MCP Server - Tavily Docs",
        "link": "https://docs.tavily.com/documentation/mcp",
        "snippet": "​. Configuring MCP Clients · Open Cursor Settings · Navigate to Features > MCP Servers · Click on the ”+ Add New MCP Server” button · Fill out the following ...",
        "formattedUrl": "https://docs.tavily.com/documentation/mcp"
      },
      {
        "title": "Zapier - Tavily Docs",
        "link": "https://docs.tavily.com/integrations/zapier",
        "snippet": "Simply set up Tavily in Zapier to automate research, track real-time news, or feed relevant data into your tools of choice. ​. How to set ...",
        "formattedUrl": "https://docs.tavily.com/integrations/zapier"
      },
      {
        "title": "Quickstart - Tavily Docs",
        "link": "https://docs.tavily.com/documentation/quickstart",
        "snippet": "​. Get your free Tavily API key. Head to the Tavily Platform and sign in (or create an account). Then, copy one of your API keys from your dashboard.",
        "formattedUrl": "https://docs.tavily.com/documentation/quickstart"
      },
      {
        "title": "SDK Reference - Tavily Docs",
        "link": "https://docs.tavily.com/sdk/python/reference",
        "snippet": "Performs a Tavily Hybrid RAG query and returns the retrieved documents as a list[dict] where the documents are sorted by decreasing relevancy to your query.",
        "formattedUrl": "https://docs.tavily.com/sdk/python/reference"
      },
      {
        "title": "Tavily Community",
        "link": "https://community.tavily.com/login-preferences",
        "snippet": "The official developer community for Tavily AI. Home · Categories · Guidelines. Powered by Discourse, best viewed with JavaScript enabled.",
        "formattedUrl": "https://community.tavily.com/login-preferences"
      },
      {
        "title": "Precision in AI Research: Tavily's Company Researcher",
        "link": "https://blog.tavily.com/companyresearcher/",
        "snippet": "Nov 18, 2024 ... This tool integrates Tavily Search and Extract, in a workflow powered by LangGraph, to deliver precise, reliable insights.",
        "formattedUrl": "https://blog.tavily.com/companyresearcher/"
      },
      {
        "title": "Zapier - Tavily Docs",
        "link": "https://docs.tavily.com/documentation/integrations/zapier",
        "snippet": "Simply set up Tavily in Zapier to automate research, track real-time news, or feed relevant data into your tools of choice. ​. How to set ...",
        "formattedUrl": "https://docs.tavily.com/documentation/integrations/zapier"
      },
      {
        "title": "LangChain - Tavily Docs",
        "link": "https://docs.tavily.com/documentation/integrations/langchain",
        "snippet": "​. Tavily Search. Here we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After ...",
        "formattedUrl": "https://docs.tavily.com/documentation/integrations/langchain"
      },
      {
        "title": "SDK Reference - Tavily Docs",
        "link": "https://docs.tavily.com/sdk/javascript/reference",
        "snippet": "JavaScript SDK Reference. Integrate Tavily's powerful APIs natively in your JavaScript/TypeScript projects.",
        "formattedUrl": "https://docs.tavily.com/sdk/javascript/reference"
      },
      {
        "title": "LlamaIndex - Tavily Docs",
        "link": "https://docs.tavily.com/documentation/integrations/llamaindex",
        "snippet": "​. Usage. You can use access Tavily in LlamaIndex through the TavilyToolSpec . ... from llama_index.tools.tavily_research.base import TavilyToolSpec from ...",
        "formattedUrl": "https://docs.tavily.com/documentation/integrations/llamaindex"
      },
      {
        "title": "Latest API topics - Tavily Community",
        "link": "https://community.tavily.com/c/api/8",
        "snippet": "A place to discuss new features that you would like to see on Tavily in the future, or potential improvements to make our existing functionality better.",
        "formattedUrl": "https://community.tavily.com/c/api/8"
      },
      {
        "title": "Credits & Pricing - Tavily Docs",
        "link": "https://docs.tavily.com/documentation/api-credits",
        "snippet": "We operate on a credit-based charging system. Each plan has a specific number of credits (the Researcher Plan includes 1,000 free API credits per month).",
        "formattedUrl": "https://docs.tavily.com/documentation/api-credits"
      },
      {
        "title": "Rate Limits - Tavily Docs",
        "link": "https://docs.tavily.com/documentation/rate-limits",
        "snippet": "Rate Limits. Learn about Tavily's API rate limits for both development and production environments. We offer two types of rate limits based on the environment ...",
        "formattedUrl": "https://docs.tavily.com/documentation/rate-limits"
      },
      {
        "title": "Tavily Docs: Welcome",
        "link": "https://docs.tavily.com/welcome",
        "snippet": "Your journey to state-of-the-art web search starts right here. Quickstart. Start searching with Tavily in minutes · API Reference.",
        "formattedUrl": "https://docs.tavily.com/welcome"
      },
      {
        "title": "Latest Documentation topics - Tavily Community",
        "link": "https://community.tavily.com/c/documentation/9",
        "snippet": "A place to discuss and suggest improvements for our Documentation and Tutorials. Please only discuss resources published by Tavily.",
        "formattedUrl": "https://community.tavily.com/c/documentation/9"
      },
      {
        "title": "API performance - API - Tavily Community",
        "link": "https://community.tavily.com/t/api-performance/115",
        "snippet": "Sep 4, 2024 ... The search API takes around 40 seconds to respond to queries, but, on retries with the same prompt, is able to come back in < 4 seconds.",
        "formattedUrl": "https://community.tavily.com/t/api-performance/115"
      },
      {
        "title": "Python - Tavily Docs",
        "link": "https://docs.tavily.com/sdk/get-started/python",
        "snippet": "The Python SDK allows for easy interaction with the Tavily API, offering the full range of our search functionality directly from your Python programs.",
        "formattedUrl": "https://docs.tavily.com/sdk/get-started/python"
      },
      {
        "title": "JavaScript - Tavily Docs",
        "link": "https://docs.tavily.com/sdk/get-started/javascript",
        "snippet": "Introduction. Tavily's JavaScript SDK allows for easy interaction with the Tavily API, offering the full range of our search and extract functionalities ...",
        "formattedUrl": "https://docs.tavily.com/sdk/get-started/javascript"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Tavily on LinkedIn](https://www.linkedin.com/company/tavily)\n- [Tavily on X (formerly Twitter)](https://x.com/tavilyai?lang=en)\n\n# Job boards\n- No unique job board pages found.\n\n# App stores\n- No app store pages found.\n\n# Product reviews\n- No detailed product reviews found.\n\n# News articles (most recent first, grouped by event)\n- **Tavily Overview and Features**\n  - [Tavily — The API-powered Alternative to Perplexity? | by AI Rabbit](https://medium.com/codex/tavily-the-api-powered-alternative-to-perplexity-edfdc6814b39) - Feb 13, 2025\n  - [Automating Legal Compliance: The Power of Tavily and AI Agents](https://medium.com/@vikram40441/automating-legal-compliance-the-power-of-tavily-and-ai-agents-integration-2c11727273a3) - Oct 15, 2024\n  - [Tavily 2025 Company Profile: Valuation, Funding & Investors](https://pitchbook.com/profiles/company/622135-63) - Feb 22, 2025\n\n- **Partnerships and Integrations**\n  - [AI Agents in LangGraph - DeepLearning.AI](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/) - Jun 5, 2024\n  - [LLM Enhanced Web Search: The Tavily & Lang Chain](https://www.kaggle.com/code/marcinrutecki/llm-enhanced-web-search-the-tavily-lang-chain/notebook) - Apr 3, 2024\n\n# Key employees (grouped by employee)\n- **Dean Sacoransky**\n  - [Dean Sacoransky - Forward Deployed Engineer - Tavily | LinkedIn](https://ca.linkedin.com/in/dean-sacoransky-6a671119a)\n\n# Other pages on the company website\n- [Tavily Blog](https://blog.tavily.com/)\n- [Credits & Pricing - Tavily Docs](https://docs.tavily.com/documentation/api-credits)\n- [Tavily Search - Tavily Docs](https://docs.tavily.com/documentation/api-reference/endpoint/search)\n- [Tavily Services Agreement](https://tavily.com/terms)\n- [Trust Center - Tavily](https://trust.tavily.com/)\n\n# Other\n- [Tavily - Company Profile - Tracxn](https://tracxn.com/d/companies/tavily/__Zcz-EM5tIW4gjY1Ra8AeGMmlKGBLxXaBSXv2VK9IYDE) - Feb 22, 2025\n- [Tavily API Status](https://status.tavily.com/)\n- [Fetch Content and Search Results with Tavily API](https://substack.com/home/post/p-143583489?utm_campaign=post&utm_medium=web) - Apr 14, 2024\n- [Tavily - Future Tools](https://www.futuretools.io/tools/tavily)",
  "crunchbase_markdown": "# Tavily, founded 2024-05-12 [(Crunchbase, 2025)](https://www.crunchbase.com/organization/tavily)\nNone\n\n- [Website](https://tavily.com)\n- [LinkedIn](https://www.linkedin.com/company/tavily)\n- [Twitter](https://x.com/tavilyai)\n\n",
  "customer_experience_result": {
    "output_text": "# Positive Sentiment\n\n## General Praise\n- \"I like Tavily, easy to implement and super accurate retrieval. Others are ok but Tavily is just stronger imo\" [(baller_asf, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx3wtd0/)\n- \"Its great imho\" [(Naive-Home6785, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5ha95/)\n- \"tavily looks like a winner.\" [(dope-llm-engineer, Reddit, 2025-03-08)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/mgp40ug/)\n- \"Definitely give Tavily.com a try\" [(NoObject2407, Reddit, 2025-03-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/mhqeje6/)\n\n## Performance and Features\n- \"Tavily is a better choice, its QA context extraction is really good\" [(trj_flash75, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrecuk/)\n- \"My test results show that Tavily works really well; it always manages to find suitable sources.\" [(YoungMan2129, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrsbml/)\n- \"Playing with Tavily search plus langgraph. Asked it what today's top news is, which it happily retrieved and summarized so mechanically worked fine.\" [(AnomalyNexus, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/)\n- \"We use Tavily via Langchain, it works pretty well.\" [(datacog, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/llcdvc3/)\n\n# Negative Sentiment\n\n## Underperformance and Issues\n- \"I've found Tavily to underperform and decided to go with Google Search (GCP)\" [(tjger, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx429f0/)\n- \"we worked on building one of our own inhouse when we found tavily + exa weren't quite cutting it in terms of accurate, deep search (exact results to questions that may require searching through multiple pages)\" [(critiqueextension, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5afc5/)\n- \"There’s the issue with Tavily retrieving the incorrect data. In that case switch provider or find ways to tune the search results.\" [(sergeant113, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/l9949v6/)\n\n# Comparisons to Other Products\n\n## Alternatives\n- \"Consider testing out the Openperplex API. In my experience, it offers more robust features compared to Tavily and other alternatives.\" [(OkMathematician8001, Reddit, 2024-08-31)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lktp0d4/)",
    "intermediate_steps": [
      "- \"I like Tavily, easy to implement and super accurate retrieval. Others are ok but Tavily is just stronger imo\" [(baller_asf, Reddit, 2024-11-14)](cache://reddit/24)\n- \"Its great imho\" [(Naive-Home6785, Reddit, 2024-11-14)](cache://reddit/25)\n- \"I've found Tavily to underperform and decided to go with Google Search (GCP)\" [(tjger, Reddit, 2024-11-14)](cache://reddit/31)\n- \"we worked on building one of our own inhouse when we found tavily + exa weren't quite cutting it in terms of accurate, deep search (exact results to questions that may require searching through multiple pages)\" [(critiqueextension, Reddit, 2024-11-14)](cache://reddit/36)\n- \"tavily looks like a winner.\" [(dope-llm-engineer, Reddit, 2025-03-08)](cache://reddit/44)\n- \"Definitely give Tavily.com a try\" [(NoObject2407, Reddit, 2025-03-14)](cache://reddit/48)",
      "- \"Tavily is a better choice, its QA context extraction is really good\" [(trj_flash75, Reddit, 2024-09-06)](cache://reddit/62)\n- \"My test results show that Tavily works really well; it always manages to find suitable sources.\" [(YoungMan2129, Reddit, 2024-09-06)](cache://reddit/63)\n- \"Playing with Tavily search plus langgraph. Asked it what today's top news is, which it happily retrieved and summarized so mechanically worked fine.\" [(AnomalyNexus, Reddit, 2024-06-19)](cache://reddit/77)\n- \"There’s the issue with Tavily retrieving the incorrect data. In that case switch provider or find ways to tune the search results.\" [(sergeant113, Reddit, 2024-06-19)](cache://reddit/83)\n- \"We use Tavily via Langchain, it works pretty well.\" [(datacog, Reddit, 2024-09-03)](cache://reddit/117)\n- \"Consider testing out the Openperplex API. In my experience, it offers more robust features compared to Tavily and other alternatives.\" [(OkMathematician8001, Reddit, 2024-08-31)](cache://reddit/108)"
    ],
    "url_to_review": {},
    "review_markdowns": [
      "# Post ID 1gr8jnr: Which search API should I use between Tavily.com, Exa.ai and Linkup.so? Building a RAG app that needs internet access. with +17 score by [(pcamiz, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/)\nI have tried the 3 of them and Linkup seems to have a slightly different approach, with connections to premium sources while Exa seems to be a bit faster. Curious what is your preferred option out of the 3 (or if you have other solutions).\n\n[exa.ai](http://exa.ai)\n\n[linkup.so](http://linkup.so)\n\n[tavily.com](http://tavily.com)\n\n\n\n## Comment ID lx4z1sz with +4 score by [(nightman, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx4z1sz/) (in reply to ID 1gr8jnr):\nI would use Brave Search Api - it's on another (better) level of costs\n\n### Comment ID lx8cd74 with +3 score by [(334578theo, Reddit, 2024-11-15)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx8cd74/) (in reply to ID lx4z1sz):\nWe were using Exa but it got too expensive too quickly so switched to Brave and added our own filtering and it works great.\n\n#### Comment ID lxst7db with +5 score by [(yibaiveintiocho, Reddit, 2024-11-18)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lxst7db/) (in reply to ID lx8cd74):\nHey u/334578theo , cofounder of Exa here. Curious how you're using us / calculating that? We should be cheaper. Also will DM you!\n\n### Comment ID m6q1v6x with +1 score by [(No_Marionberry_5366, Reddit, 2025-01-12)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m6q1v6x/) (in reply to ID lx4z1sz):\nInterested but quite limited for deepsearch tasks right ? I would rather use [exa.ai](http://exa.ai) or [linkup.so](http://linkup.so) for that\n\n## Comment ID lx3wtd0 with +3 score by [(baller_asf, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx3wtd0/) (in reply to ID 1gr8jnr):\nI like Tavily, easy to implement and super accurate retrieval. Others are ok but Tavily is just stronger imo\n\n## Comment ID lx5ha95 with +2 score by [(Naive-Home6785, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5ha95/) (in reply to ID 1gr8jnr):\nI only know about tavily.  Its great imho\n\n## Comment ID lx8a7sk with +2 score by [(AlpineRavine, Reddit, 2024-11-15)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx8a7sk/) (in reply to ID 1gr8jnr):\nI started with Tavily, use Google search API now, but will move to Perplexity API. I think it’s the best of the three\n\n### Comment ID m6q19w2 with +1 score by [(No_Marionberry_5366, Reddit, 2025-01-12)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m6q19w2/) (in reply to ID lx8a7sk):\nReally ? interested to know more about your use cases, Perplexity is like ALWAYS wrong when I ask specific questions about companies\n\n#### Comment ID m6q5q1w with +1 score by [(AlpineRavine, Reddit, 2025-01-12)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m6q5q1w/) (in reply to ID m6q19w2):\nOne use I recently had was I wanted to create biographies of CEOs of certain companies. So I asked the pplx api 4 different questions to build a holistic picture of the person. Then used 4o-mini in downstream to combine it to single narrative. It worked really well. I would have loved if they made perplexity pro available in the API, could have tackled more complex questions as well.\n\n## Comment ID lx3y4qs with +1 score by [(No_Marionberry_5366, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx3y4qs/) (in reply to ID 1gr8jnr):\nExa strong as well. Just heard about Linkup, first uses show better relevance. Worth trying\n\n### Comment ID lx44bar with +1 score by [(pcamiz, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx44bar/) (in reply to ID lx3y4qs):\nThanks! will look into it more\n\n## Comment ID lx429f0 with +1 score by [(tjger, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx429f0/) (in reply to ID 1gr8jnr):\nI've found Tavily to underperform and decided to go with Google Search (GCP)\n\n### Comment ID lx44ipa with +2 score by [(pcamiz, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx44ipa/) (in reply to ID lx429f0):\nThanks for your reply! Do you drop the snippets of the results into your LLM context window? Asking because that's close to what i was doing with SERP API but had poor results\n\n### Comment ID m03v2ad with +1 score by [(HighOnLSTM, Reddit, 2024-12-02)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m03v2ad/) (in reply to ID lx429f0):\nWhich exact service are you using in GCP? Can you drop the official doc link by any chance? The closest I've found is - [https://programmablesearchengine.google.com/about/](https://programmablesearchengine.google.com/about/), which has super clunky documentation, and needs some significant configuration for web-search, and the results aren't even that great.\n\n#### Comment ID m08apc2 with +1 score by [(tjger, Reddit, 2024-12-03)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m08apc2/) (in reply to ID m03v2ad):\nIt is exactly that one with Google Custom Search API\n\n## Comment ID lx5afc5 with +1 score by [(critiqueextension, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5afc5/) (in reply to ID 1gr8jnr):\nwe worked on building one of our own inhouse when we found tavily + exa weren't quite cutting it in terms of accurate, deep search (exact results to questions that may require searching through multiple pages). that + the price made us build our own, and we threw it up as a service. It's absolutely not faster (yet, we're working on it) than those services if latency is your biggest concern. But its cheaper, and the reranking and chunking is also parametrically done by an agent, as opposed to the static params (that we suspect) they're using. \n\nfeel free to check it out: [https://critiquebrowser.app/en/flow-api](https://critiquebrowser.app/en/flow-api)\n\nit supports structured output parsing, so if you want in-line citation style responses, you can use the search api as is, but if you want structured output, you can specify a JSON schema and it'll return that to you. Also there's an API designer if you want tailor made specific responses to a formatted search every time.\n\n### Comment ID lx5xu78 with +1 score by [(Impressive_Log6884, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5xu78/) (in reply to ID lx5afc5):\nDoesn't building a search engine mean indexing the whole web? Or, are you wrapping GCP\n\n#### Comment ID lx665qp with +1 score by [(critiqueextension, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx665qp/) (in reply to ID lx5xu78):\nwrapping GCP,DDG,Brave,and other major content platforms individually. I don't think it precludes counting as a search engine since there still exists a mechanism performing search over a set of results. (admittedly it is using another engine hence the distinction 'agentic')\n\n## Comment ID mf85ia2 with +1 score by [(IcyRequirement4700, Reddit, 2025-02-28)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/mf85ia2/) (in reply to ID 1gr8jnr):\nProbably worth a read: [https://emergentmethods.medium.com/context-is-king-evaluating-real-time-llm-context-quality-with-ragas-a8df8e815dc9](https://emergentmethods.medium.com/context-is-king-evaluating-real-time-llm-context-quality-with-ragas-a8df8e815dc9)\n\n## Comment ID mglqd7e with +1 score by [(MattCollinsUK, Reddit, 2025-03-08)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/mglqd7e/) (in reply to ID 1gr8jnr):\nIn case it's helpful, I have a comparison here that covers Exa, Linkup, Tavily and quite a few more: [https://www.mattcollins.net/web-search-apis-for-llms](https://www.mattcollins.net/web-search-apis-for-llms)\n\n### Comment ID mgp40ug with +1 score by [(dope-llm-engineer, Reddit, 2025-03-08)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/mgp40ug/) (in reply to ID mglqd7e):\nthank you! tavily looks like a winner.\n\n### Comment ID mgpz9az with +1 score by [(notoriousFlash, Reddit, 2025-03-08)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/mgpz9az/) (in reply to ID mglqd7e):\nIs “What to Consider When Choosing a Web Search API” the end/conclusion of this article? I might be missing something or the article isn’t optimized for mobile, but outside of the pricing table I don’t see any analysis comparing the tools…\n\n## Comment ID mhpzy42 with +1 score by [(Common_Antelope_9188, Reddit, 2025-03-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/mhpzy42/) (in reply to ID 1gr8jnr):\nI am using [serper.dev](http://serper.dev) with custom filtering, i have played around with [exa.ai](http://exa.ai) in the past, in terms of features they are pretty dope however in terms of operational cost and reliability / consistency across the responses is lil less than optimal. I haven't had any chance to revisit [exa.ai](http://exa.ai) in past couple of months but I am hopeful they are aware of these issues and have released ( will release ) more stable versions.\n\n### Comment ID mhqeje6 with +1 score by [(NoObject2407, Reddit, 2025-03-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/mhqeje6/) (in reply to ID mhpzy42):\nDefinitely give Tavily.com a try\n\n## Comment ID migwtax with +1 score by [(pcamiz, Reddit, 2025-03-18)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/migwtax/) (in reply to ID 1gr8jnr):\nThanks everyone for the help here ❤️\n\nClosing the loop, I decided to go with Linkup.so. Main reason is quality of responses. It was better than exa and much better than Tavily.",
      "# Post ID 1fa73cn: Tavily vs. Exa for RAG with LangChain - Any Recommendations? with +5 score by [(YoungMan2129, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/)\nI'm starting to build a RAG workflow using LangChain, and I'm at the stage where I need to pick a search tool. I'm looking at Tavily and Exa, but I'm not sure which one would be the better choice.   \nWhat are the key difference between them?\n\n## Comment ID llrecuk with +2 score by [(trj_flash75, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrecuk/) (in reply to ID 1fa73cn):\nTavily is a better choice, its QA context extraction is really good\n\n### Comment ID llrsbml with +1 score by [(YoungMan2129, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrsbml/) (in reply to ID llrecuk):\nMy test results show that Tavily works really well; it always manages to find suitable sources. However, I'm not quite clear on how it actually accomplishes this.\n\n## Comment ID llrtt5d with +1 score by [(ravediamond000, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrtt5d/) (in reply to ID 1fa73cn):\nBe careful with search engine tool as it can really gives you bad data, even more in case that is very domain specific oriented.\n\n### Comment ID llt3hqn with +1 score by [(YoungMan2129, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llt3hqn/) (in reply to ID llrtt5d):\nThanks for the reminder😀\n\n## Comment ID lmunexh with +1 score by [(OkMathematician8001, Reddit, 2024-09-13)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/lmunexh/) (in reply to ID 1fa73cn):\nthe best Ai web search tool is openperplex (api.openperplex.com) you can try it for free. citations, sources , pro mode, 40+ locations and more.  \n[openperplex.com](http://openperplex.com)\n\n### Comment ID lmvvngy with +1 score by [(YoungMan2129, Reddit, 2024-09-13)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/lmvvngy/) (in reply to ID lmunexh):\nIs that still open source now?\n\n#### Comment ID lmx1kqh with +1 score by [(OkMathematician8001, Reddit, 2024-09-13)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/lmx1kqh/) (in reply to ID lmvvngy):\nYes it is opensource, you can host the search backend yourself or you can use the api\n\n## Comment ID lx40pyq with +1 score by [(pcamiz, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/lx40pyq/) (in reply to ID 1fa73cn):\nReopening this one. Anyone with recent experience using Tavily.com vs. Exa.ai vs. Linkup.so? I am trying them out for my RAG app that needs to access internet content. Which one do you recommend?\n\n### Comment ID m026ne7 with +1 score by [(comeoncomon, Reddit, 2024-12-02)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/m026ne7/) (in reply to ID lx40pyq):\nLinkup has done the job for me for sales enablement and research use case - accuracy has been superior and I don't mind a bit more latency",
      "# Post ID 1cc1dyq: How are you guys doing internet search? with +13 score by [(OfficeSalamander, Reddit, 2024-04-24)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/)\nI am trying to use internet-search enabled bots, and I was wondering how you guys were doing it - I see that Serpdev and Tavily have Langchain integration - which of these two do you guys like? Or do you roll your own?\n\n## Comment ID l15grm7 with +3 score by [(sergeant113, Reddit, 2024-04-25)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l15grm7/) (in reply to ID 1cc1dyq):\nMy experience is that determining what to search is half the battle here. I’ve built a search-enabled chatbot using my own Searx server and wikipedia, and the good results are very dependent on the complexity of the user’s question. \n\nMy plan to improve this setup is to build a dedicated research Agent that will process the question into a research problem with various information requirements. Then a search agent will attempt to collect the information for the research agent. Finally a executive summary and report is compiled for me.\n\nOf course, there will have to be a mechanism to determine which question get this full-flow treatment, and which only require a direct search query.\n\n### Comment ID lfyqwup with +1 score by [(baggsy_, Reddit, 2024-08-01)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lfyqwup/) (in reply to ID l15grm7):\n>My plan to improve this setup is to build a dedicated research Agent that will process the question into a research problem with various information requirements. Then a search agent will attempt to collect the information for the research agent. Finally a executive summary and report is compiled for me.\n\nu/sergeant113, did you have much success here? I definitely need to work on the \"knowing what to Google\"  problem (as opposed to the SERP APIs or scraping), and have been thinking of leveraging agents to help me.\n\n### Comment ID lrrl537 with +1 score by [(Traditional_Art_6943, Reddit, 2024-10-13)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lrrl537/) (in reply to ID l15grm7):\nAre you still developing an agent, I too am building a Searx powered search, scrape and summarizing agent. I will be very glad to discuss on the same\n\n#### Comment ID lrrmdyy with +1 score by [(sergeant113, Reddit, 2024-10-13)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lrrmdyy/) (in reply to ID lrrl537):\nIt’s pending for now. The search & summarize part has been done. I’m still working on the query planning. Some potential leads, but I havent had the time to do some extensive development. Happy to discuss though.\n\n## Comment ID l15ftxa with +2 score by [(suavestallion, Reddit, 2024-04-25)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l15ftxa/) (in reply to ID 1cc1dyq):\nI'm using google cse. Easy peasy. And scrapers\n\n### Comment ID l1663eb with +2 score by [(Such_Advantage_6949, Reddit, 2024-04-25)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1663eb/) (in reply to ID l15ftxa):\nWhat you mean by google cse, i tried to find if there is google api to do search but couldnt find any\n\n#### Comment ID l1c9zun with +1 score by [(Jdonavan, Reddit, 2024-04-26)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1c9zun/) (in reply to ID l1663eb):\nThen you didn't even use google in your search.\n\n## Comment ID l12p9xw with +1 score by [(Familyinalicante, Reddit, 2024-04-24)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l12p9xw/) (in reply to ID 1cc1dyq):\nThere's planty of solutions. You need to be more specific. There's also many tutorials on internet for this.\n\n### Comment ID l1302uk with +3 score by [(OfficeSalamander, Reddit, 2024-04-24)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1302uk/) (in reply to ID l12p9xw):\nA tutorial doesn’t really help me - I know how to write the integrations easily enough - I’ve already tested Tavily and Serpdev for my use case, and I’m contemplating just writing my own search code (would allow me to get the granularity of the search results I want perhaps), but I wanted people’s opinions about what they liked or found useful for search integration for LLMs.\n\nI’m not sure what more specificity you want me to provide but if you want to know what I’m trying to do - I want to search current news, mostly. That’s my main use-case. Specifically for agent bots like CrewAI\n\n#### Comment ID l1bix96 with +1 score by [(Familyinalicante, Reddit, 2024-04-26)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1bix96/) (in reply to ID l1302uk):\nDuckduckGo tool is not what you're looking for?\n\n#### Comment ID lrrl9dp with +1 score by [(Traditional_Art_6943, Reddit, 2024-10-13)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lrrl9dp/) (in reply to ID l1302uk):\nAre you still working on this agent\n\n## Comment ID l12vvx7 with +1 score by [(Skylight_Chaser, Reddit, 2024-04-24)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l12vvx7/) (in reply to ID 1cc1dyq):\nperplexity is cool atm\n\n## Comment ID l17saa9 with +1 score by [(None, Reddit, 2024-04-25)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l17saa9/) (in reply to ID 1cc1dyq):\nBrave search api works good and easy to implement\n\n## Comment ID l1c82p4 with +1 score by [(suavestallion, Reddit, 2024-04-26)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1c82p4/) (in reply to ID 1cc1dyq):\nUse a custom google search engine, plus the Google tool in langchain. Just search the langchain documentation. Don't use serpapi\n\n### Comment ID l1clae0 with +2 score by [(OfficeSalamander, Reddit, 2024-04-26)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1clae0/) (in reply to ID l1c82p4):\nYeah that’s pretty much where I am now. I was wondering why people were paying for these services rather than just using normal Google search APIs, and figured there must be a reason, which is why I came here. But honestly, looking at the results, it looks pretty damn similar to just baseline Google search results, and that API is free, so I’m not sure why people are using these other APIs\n\n#### Comment ID lpezy5r with +1 score by [(valueinvesting_io, Reddit, 2024-09-28)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lpezy5r/) (in reply to ID l1clae0):\nis there a limit to the number of Google search APIs you can request?\n\n### Comment ID lk7472p with +1 score by [(Altruistic_Box8467, Reddit, 2024-08-27)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lk7472p/) (in reply to ID l1c82p4):\nWhy not serpapi? Because it scrapes google which is not allowed by google?\n\n#### Comment ID lk8q3ff with +2 score by [(suavestallion, Reddit, 2024-08-27)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lk8q3ff/) (in reply to ID lk7472p):\nI just like it better. I don't care about rules\n\n## Comment ID lktp0d4 with +1 score by [(OkMathematician8001, Reddit, 2024-08-31)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lktp0d4/) (in reply to ID 1cc1dyq):\nConsider testing out the Openperplex API. In my experience, it offers more robust features compared to Tavily and other alternatives. Some standout capabilities include multi-language support, location-based services, and flexible answer formats (HTML, Markdown, or plain text). You can explore these features at no cost with their free trial option.\n\nhttps://preview.redd.it/z2cqkqa1xzld1.png?width=2514&format=png&auto=webp&s=9bb3a1f3c52c26b89b0704fcefab69b14ccda4f8\n\n  \n[https://api.openperplex.com](https://api.openperplex.com)",
      "# Post ID 1auucox: Agent that uses a vector store retriever and a websearch retriever ( tavily or google search ) as tools for RAG with +4 score by [(None, Reddit, 2024-02-19)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/)\nHello everyone , i'm currently stuck on making an agent that uses two different retrievers as tools through create\\_retriever\\_tool and initialize\\_agent. However , im either getting stuck in a loop , getting wrong results or just exceeding context limit.\n\nIm wondering if there is someone has done something like this with local models or any documentation on this subject. \n\nTIA\n\n&#x200B;\n\n## Comment ID l5e58f0 with +1 score by [(Mohamed_SickitLearn, Reddit, 2024-05-23)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/l5e58f0/) (in reply to ID 1auucox):\nsimple RAG systems won't allow you unofortuantely to build such complex idea. you will need to implement something Self-RAG. check this example [https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph\\_self\\_rag.ipynb](https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag.ipynb)   \nyou might find also videos explaining Self RAG and Addaptive RAG.\n\n## Comment ID kr6mcxp with +1 score by [(eduardopy, Reddit, 2024-02-19)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/kr6mcxp/) (in reply to ID 1auucox):\nYou would need to share what you are doing to get helped.\n\n## Comment ID krcj5xw with +1 score by [(IlEstLaPapi, Reddit, 2024-02-20)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/krcj5xw/) (in reply to ID 1auucox):\nI think you need a planner to decide which tool to use and a feedback loop to adapt.  Or you need to define a priority order if your usecase makes it obvious.\n\n## Comment ID krdsnaj with +1 score by [(mehul_gupta1997, Reddit, 2024-02-21)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/krdsnaj/) (in reply to ID 1auucox):\nWas facing the same issue, then used chains as tools. Working fine now : https://youtu.be/cBpdiQ3gljM?si=QZY61sIU0SE3UhGS",
      "# Post ID 1d3upmf: Would you use this instead of Perplexity? with +3 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/)\nI'm building a General purpose AI Copilot (Bind AI) with ability to switch between GPT-4o, Claude 3 Opus, Command R and a few other models, it carries over the chat history when you switch models. We just added \"Web Search\", similar to Perplexity it can research the web and provide a summarized answer. You can generate code and execute the code (simple stuff which does not require multiple files to execute)\n\nI wanted get feedback from this community, as you guys use multiple tools along with Perplexity:\n\n1. Would you find this useful, in addition *or* as a replacement to Perplexity, Phind, MS Copilot or similar?\n2. If not, why not, what could make this more useful?\n\nIf you're interested to know the inner workings, we're using a prompt template + Langchain Agents/Tools which interacts with the web. We experimented with quite a few APIs for search retrieval (Bing search, Brave, Google search via SERPapi, Tavily). It is fairly easy to get something working, however, it does require implementing agentic workflows and tool routing to get better responses, esp. for cases where you don't actually need to search the web (recent models such as GPT-4o do fairly well without internet search). We also noticed that, better models do better job synthesizing the information from search results, we compared 4o, Command R, Haiku, Mixtral, GPT 3.5. (I might write a blog post on this, I had posted a comment on a sub-reddit recently). We're not yet integrated with Mistral Codestral which just came out today.\n\n**Edit**: Removed the links, since I got the feedback I was looking for.\n\nIf you're curious, you can google for \"Bind AI\" and find the link.\n\n## Comment ID l6a9pdx with +7 score by [(fluffy_muser, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6a9pdx/) (in reply to ID 1d3upmf):\nAre you applying Sun Zu wisdom: “Keep your friends close; keep your enemies closer.” by posting it here? 😂\n\n### Comment ID l6ac03b with +2 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6ac03b/) (in reply to ID l6a9pdx):\nHaha. This subreddit is a good touchstone to test out my hypothesis :)\nIf it is positive here then maybe it's something useful\n\n## Comment ID l6ajs1n with +3 score by [(nightman, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6ajs1n/) (in reply to ID 1d3upmf):\nThank you for the explanation. But to get the answer you have to explain what you will provide on top of what is Perplexity providing. If it's just a clone, with same functionality (and possibly worst accuracy and hallucinations as you sometimes skip search) - why should we use it?\n\n### Comment ID l6am36x with +3 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6am36x/) (in reply to ID l6ajs1n):\nThe primary purpose of Bind AI is to create a general purpose AI system which can automate boring or repetitive tasks and \"do the tasks for you\".\n\nThere are several such tasks and several tools for the job right now. We're focusing on \"work\" related tasks and not really general/leisure web search (eg shopping).\nThere are a lot of vertical AI applications for different purposes (eg Jasper/Writer for Marketing, Github Copilot for code, Perplexity for Search, Microsoft copilot for general things, custom built AI assistants), in reality it's not that complex to build a single system that can do all or atleast most of it\n\nBelow is the functionality we plan to provide so that everything can be done via a single platform rather than multiple tools:\n- Select the most advanced and latest AI models in a single place\n- Ability to search the web to create deeply researched content/articles/documents\n- Connected to specialized datasets (eg sec financial data) to get much deeper insights.\n- In-built Code Canvas to generate, edit AI-generated code, execute/test it.\n- In-built document canvas to act on the AI-generated data (rather than copy pasting snippets to google docs).\n- Integrate your data (GitHub, Google drive, Upload etc) to generate content/code based on your information\n- Push AI generated data out directly (github, salesforce etc)\n- Automate sequential tasks via agents, by connecting your APIs or applications (eg grab data from salesforce and push it to Marketo)\n\nPersona wise, we're targeting folks looking to do technical tasks, and not really general consumers.\n\nThe question does arise, why do we need web search in Bind AI? Because, it's table stakes. Why provide outdated information? It doesn't really make sense to have someone use 2-3 different AI tools to do overlapping tasks.\n\ntl;dr: Perplexity is looking to be a google-killer, we're looking to reimagine how work is done with AI.\n\n#### Comment ID l6amy50 with +2 score by [(nightman, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6amy50/) (in reply to ID l6am36x):\nThank for the explanation\n\n## Comment ID l6b3bim with +2 score by [(InappropriateCanuck, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6b3bim/) (in reply to ID 1d3upmf):\nSure, if it's better I'll use that one instead.\n\nI just trialed it with a complex design query (database design semantics about cursors, composite indexes, b-trees in various SQL databases) and it failed pretty royally to organize its thoughts with sequential searches like Perplexity does tbh. \n\nUnsure what model this uses behind the scenes as I can't choose it for my query. Which to me is an automatic lose.\n\nEdit: I actually can't get the Web Search going.\n\n### Comment ID l6b5syf with +2 score by [(defection_, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6b5syf/) (in reply to ID l6b3bim):\nI'll agree with this. I've been increasingly disappointed with Perplexity and their way of going about things, so I'd be more than open to leaving. However, after an initial test for my uses, there's still going to be a fair bit of work that needs to be done to surpass Perplexity's capabilities.\n\n#### Comment ID l6bnamk with +1 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6bnamk/) (in reply to ID l6b5syf):\nIf you don't mind sharing, could you list your key use cases. Is it general search, code generation?\n\n### Comment ID l6bmrnx with +2 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6bmrnx/) (in reply to ID l6b3bim):\nThis is good, real, eye opening feedback (also because I just woke up and checked this as the first thing).\nRight now, it's using a GPT-4o model, and we're only playing with a prompt+tool.\nTo select a model, [this](https://copilot.getbind.co/chat/code-generation?model=all) link will take you there(It requires a trial signup, had to put a paywall as Opus is pretty expensive and we're bootstrapping)\n\ntbh, it will do simple things right now. \nWe havent released an agentic planner yet for code generation or search, which is what pplx pro search does. It's taking about a minute to plan and breakdown things, and we're optimizing it to respond much faster.\nIf you're open to sharing your actual query over dm, i'd like to see how we could improve the system to deal with those.\n\nIt will be a bit of a catchup for us, we've raised $0 vs $100M raised by perplexity. I have been bootstrapping with a small team, inspired by how zapier built its business.\n\nThat said, reddit is a great place to be humbled, but also a great place to learn real hard feedback. So thank you for this!\n\n## Comment ID l6fz460 with +1 score by [(crazy_canuck, Reddit, 2024-05-31)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6fz460/) (in reply to ID 1d3upmf):\nI’m a consultant working with SMBs, there are quite a number of enterprise features I’d like to bring to my clients. Are you interested in building enterprise features?\n\n### Comment ID l6hbj4x with +1 score by [(datacog, Reddit, 2024-05-31)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6hbj4x/) (in reply to ID l6fz460):\nDefinitely. Let me DM you.\n\n## Comment ID l6ly6zv with +1 score by [(TomHale, Reddit, 2024-06-01)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6ly6zv/) (in reply to ID 1d3upmf):\nI tried the F1 example.  I want to be able to click through and verify, but I cannot.\n\n### Comment ID l6mvcpv with +1 score by [(datacog, Reddit, 2024-06-01)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6mvcpv/) (in reply to ID l6ly6zv):\nYou mean, you want to click on the source link and verify but it's not working?",
      "# Post ID 1fkzfu5: Looking for recommendations to build a search application with +3 score by [(atlas-golden, Reddit, 2024-09-20)](https://www.reddit.com/r/LangChain/comments/1fkzfu5/looking_for_recommendations_to_build_a_search/)\nHi everyone, I believe this use-case/problem has been around for some time but since I am pretty new to the whole LLM world, I am still unsure what's the best way to develop such applications. \n\nWhat I'm trying to develop is an application that can take in a question (written in natural language) from the user, conduct a search over the internet (and perhaps internal local storages and databases), and come up with the list of top 5-10 results that are the most relevant to the user's query. \n\nWith these results, the application summarises them and answers the original question in natural language, with citations from the search result (something like what Perplexity is doing). \n\nThe \"special\" thing about this application is that it is built for a small circle of network (a high net-worth group of users in a niche industry) so the answers have to be super relevant to the industry as well as their professions. \n\nCurrently, the plan I have is Tavily, LangGraph, and MongoDB.\n\n1. With the user's query, conduct a Tavily search to get at least 50 results.\n2. Develop a context (just paragraphs of context) and do some rankings with the list of found results.\n3. With the 5-10 top-ranked results, conduct some certain summarization with an agent and show the final answer on the app.\n\nIt sounds insanely simple and I am sure this is a popular topic/use-case and the community has come up with more successfuly/sophisticated solutions. Can everyone advise?\n\nAny ideas, knowledge sharing or advice is most welcome! Thank you!\n\n## Comment ID lnzry7h with +1 score by [(Synyster328, Reddit, 2024-09-20)](https://www.reddit.com/r/LangChain/comments/1fkzfu5/looking_for_recommendations_to_build_a_search/lnzry7h/) (in reply to ID 1fkzfu5):\nAh, the billion dollar question - What results are relevant?\n\n### Comment ID lo2ep3a with +2 score by [(atlas-golden, Reddit, 2024-09-20)](https://www.reddit.com/r/LangChain/comments/1fkzfu5/looking_for_recommendations_to_build_a_search/lo2ep3a/) (in reply to ID lnzry7h):\n😅 exactly - not only relevant, but relevant based on a context. I'm feeling pretty stuck here\n\n## Comment ID lnzxwp8 with +1 score by [(kingksingh, Reddit, 2024-09-20)](https://www.reddit.com/r/LangChain/comments/1fkzfu5/looking_for_recommendations_to_build_a_search/lnzxwp8/) (in reply to ID 1fkzfu5):\n(I am on a journey to build something similar)\nOne of the most important things that needs attention is \"how to restrict user questions to a specific domain, of course one can use prompt engineering to handle most of the queries like 'do not answer anything other than xxyy domain queries' but this is not enough. Because on perplexity user can ask anything, the one that you plan to build is specific to an industry, so system must not answer questions other than its domain\"\n\n## Comment ID lo05pzq with +1 score by [(DeadPukka, Reddit, 2024-09-20)](https://www.reddit.com/r/LangChain/comments/1fkzfu5/looking_for_recommendations_to_build_a_search/lo05pzq/) (in reply to ID 1fkzfu5):\nThis a great use case.  I put together an example of our platform would handle it, without needing agents.\n\n[https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit\\_2024\\_09\\_08\\_Web\\_Search\\_to\\_RAG.ipynb](https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_09_08_Web_Search_to_RAG.ipynb)\n\nWe could also generate summaries of each web page, if needed; just not shown in this example.\n\n### Comment ID lo3bb6a with +2 score by [(atlas-golden, Reddit, 2024-09-20)](https://www.reddit.com/r/LangChain/comments/1fkzfu5/looking_for_recommendations_to_build_a_search/lo3bb6a/) (in reply to ID lo05pzq):\nThank you. I'm gonna go and study it!\n\n## Comment ID lobbfch with +1 score by [(regentwells, Reddit, 2024-09-22)](https://www.reddit.com/r/LangChain/comments/1fkzfu5/looking_for_recommendations_to_build_a_search/lobbfch/) (in reply to ID 1fkzfu5):\nQdrant excels at neural search and it works really well with LangChain.   \nAs of version 1.10, there are many advanced options to conduct search: regular semantic search, sparse, hybrid, recommendations, context and exploration.   \n[https://qdrant.tech/blog/qdrant-1.10.x/](https://qdrant.tech/blog/qdrant-1.10.x/)",
      "# Post ID 1dj5mhi: Live data for agents with +3 score by [(AnomalyNexus, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/)\nPlaying with Tavily search plus langgraph. Asked it what todays top news is, which it happily retrieved and summarized so mechanically worked fine. Only problem is something is off with the news:\n\n>A volcano in Japan spewing ash and rock 200 meters into the sky\n\n...that's November 2023. Same for the rest of the articles, so clearly an older index. Which is fair, can't expect a search provider to be entirely live, but still a problem.\n\nSo couple of questions on this:\n\n* Has anyone had luck using searxng to get more current info?\n* How would you split this out in tooling? Give it one search engine for general and then a 2nd tool for news and say a third for weather etc? Stock market? Currencies? Seems like an approach that would get out of hand pretty fast and just confuse the LLM.\n* More generally - what sources for have you had luck with to make your agents more...worldly & current? Provders, techniques, whatever\n\nThanks\n\n## Comment ID l98xbq7 with +8 score by [(Danidre, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/l98xbq7/) (in reply to ID 1dj5mhi):\nSomewhere along those lines, you gotta specify what \"today\" means. Whether you pass that in through the template, or provide a tool to get the current date. I wouldn't doubt that it searched for articles that included the word \"today\" and got those from 2023.\n\nOf course, all this is speculation.\n\n### Comment ID l9a4gzl with +2 score by [(AnomalyNexus, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/l9a4gzl/) (in reply to ID l98xbq7):\nTried it with a date, and it does change things though not necessarily for the better. Now it's returning a [TV broadcast schedule](https://www.bbc.co.uk/programmes/m0020g1f). Irrelevant, but more live.\n\n...so I guess your theory is mostly right\n\n## Comment ID l98ymwd with +2 score by [(Shakakai, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/l98ymwd/) (in reply to ID 1dj5mhi):\nHave you tried the perplexity API? It’ll give very recent results.\n\n### Comment ID l9a4ibf with +2 score by [(AnomalyNexus, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/l9a4ibf/) (in reply to ID l98ymwd):\n> perplexity API\n\nDidn't realize they had one. Will take a look. Thanks\n\n## Comment ID l9949v6 with +2 score by [(sergeant113, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/l9949v6/) (in reply to ID 1dj5mhi):\nThere’s the issue with Tavily retrieving the incorrect data. In that case switch provider or find ways to tune the search results.\n\nAnd then, there’s the issue with the LLM not being selective in its reporting. If so, try adding some metadata info to your context.\n“””\nToday: Wednesday June 18th 2024\nLocation: San Francisco, California\nMain currency: USD $\n“””\n\nAsk it to only extract\n\n## Comment ID l9a7g7y with +1 score by [(nightman, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/l9a7g7y/) (in reply to ID 1dj5mhi):\nIMHO you have to preprocess question before sending to  Tavily, e.g.:\n* remove today from question\n* filter search results only by specific dates\n\n## Comment ID l9b0u6o with +1 score by [(Jdonavan, Reddit, 2024-06-19)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/l9b0u6o/) (in reply to ID 1dj5mhi):\nI created an RSS tool for my agents to grab news.\n\n## Comment ID lmunx7i with +1 score by [(OkMathematician8001, Reddit, 2024-09-13)](https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/lmunx7i/) (in reply to ID 1dj5mhi):\nthe best AI web search tool is openperplex ( [api.openperplex.com](http://api.openperplex.com) ) you can try it for free. citations, sources , pro mode, 40+ locations and more.  \n[openperplex.com](http://openperplex.com/)",
      "# Post ID 1il8235: What AI Agent Tools Are You Missing? with +5 score by [(0xhbam, Reddit, 2025-02-09)](https://www.reddit.com/r/LangChain/comments/1il8235/what_ai_agent_tools_are_you_missing/)\nHey everyone,\n\nIf you’ve been building AI agents, you’ve probably encountered gaps where existing tools just don’t cut it—either they don’t exist, aren’t flexible enough, or you’ve had to build them from scratch.\n\nCurious to hear from the community:\n\n1. **What AI agent tools do you feel are missing or not good enough?** \n2. **What functionalities do you always end up coding yourself?** \n3. **Are there any tools you wish existed as plug-and-play components?**\n\nFor example, **Firecrawl, Tavily Search, and Browserbase** are among the powerful agent tools I’ve found particularly useful.\n\nWould love to hear what tools you’ve built from scratch or what gaps you’ve encountered! \n\nDrop your thoughts below. 🚀\n\n\n\n## Comment ID mbso2lc with +3 score by [(EmiyaBoi, Reddit, 2025-02-09)](https://www.reddit.com/r/LangChain/comments/1il8235/what_ai_agent_tools_are_you_missing/mbso2lc/) (in reply to ID 1il8235):\nIf you are looking for startup ideas. I doubt you'll find any that won't become irrelevant in a couple years. Companies like crewai just end up releasing any tool anyone starts thinking about.\n\nI mean look at Tavily. It was impressive an year back. Now? I can build a better tavily like tool way too quickly with absolutely free or far cheaper apis, libraries or tools by crewai.\n\nIn an year the hype discussion will move away from Agents and agentic workflows will just become another technique in the tool belt like RAG.\n\n## Comment ID mbu0ht2 with +2 score by [(raisinbrain, Reddit, 2025-02-09)](https://www.reddit.com/r/LangChain/comments/1il8235/what_ai_agent_tools_are_you_missing/mbu0ht2/) (in reply to ID 1il8235):\nA slack-like chat environment, but targeted primarily against agents, exposes an mcp server and full embedding search of chat logs. Slack and discord of course exist but are set up for mostly human users with each bot as a separate “app”. I’m sure both will include more features What I want is a lightweight, self hostable environment primarily for agents to show up like any other user.\n\n### Comment ID mc2w3h7 with +1 score by [(0xhbam, Reddit, 2025-02-10)](https://www.reddit.com/r/LangChain/comments/1il8235/what_ai_agent_tools_are_you_missing/mc2w3h7/) (in reply to ID mbu0ht2):\nThat sounds interesting! Is it similar to a collaborative Slack for agents and humans, where they can interact within a shared workspace and execute tasks by accessing with external tools?\n\n## Comment ID mc1d1cl with +2 score by [(producttapas, Reddit, 2025-02-10)](https://www.reddit.com/r/LangChain/comments/1il8235/what_ai_agent_tools_are_you_missing/mc1d1cl/) (in reply to ID 1il8235):\nAs someone deep in the AI agent space, I've felt that pain! One tool I always end up coding is a better context management system. Existing solutions often fall short in handling complex, multi-turn conversations while maintaining coherent context.\n\nI've also wished for a more intuitive way to debug AI agent workflows. Something that visualizes the decision-making process and allows for easy tweaking of parameters on the fly.\n\nOn the plug-and-play front, a robust error handling and recovery system would be a game-changer. It's something I've had to build from scratch too many times.\n\nThese challenges inspired me to create Product Tapas, a newsletter that dives into these AI tool gaps and emerging solutions. It's been eye-opening to see how others are tackling similar issues.",
      "# Post ID 1fl8jco: Building Your First CrewAI Tool: Tavily Search Walkthrough with +1 score by [(zinyando, Reddit, 2024-09-20)](https://www.reddit.com/r/LLMDevs/comments/1fl8jco/building_your_first_crewai_tool_tavily_search/)\n\n\n## Comment ID lo3d5ug with +1 score by [(OkMathematician8001, Reddit, 2024-09-20)](https://www.reddit.com/r/LLMDevs/comments/1fl8jco/building_your_first_crewai_tool_tavily_search/lo3d5ug/) (in reply to ID 1fl8jco):\nCrewAI must integrate the Openperplex API, much better than tavily api\n\n### Comment ID lo3e00f with +1 score by [(zinyando, Reddit, 2024-09-20)](https://www.reddit.com/r/LLMDevs/comments/1fl8jco/building_your_first_crewai_tool_tavily_search/lo3e00f/) (in reply to ID lo3d5ug):\nThe concepts are the same though, you can integrate Openperplexity yourself if you really want it for your AI agents workflows",
      "# Post ID 1f80h36: Alternatives with API web browsing capabilities with +4 score by [(metrohs, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/)\nWorking on a project that required web browsing, but as we all know, this is not something currently supported by openAI’s api’s. Surveying the crowd to see if anyone has a unique solution or knows of an off the shelf model with web browsing. TIA\n\n## Comment ID llb7g3w with +3 score by [(None, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/llb7g3w/) (in reply to ID 1f80h36):\n[removed]\n\n### Comment ID llbgfx6 with +2 score by [(__nickerbocker__, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/llbgfx6/) (in reply to ID llb7g3w):\nThat's only on the assistants API, and Search != Browsing. While it can read some pages in limited scenarios, it will fail a lot or outright hallucinate. OP probably needs something like skyvern.\n\n## Comment ID llckci5 with +2 score by [(geepytee, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/llckci5/) (in reply to ID 1f80h36):\nOut of curiosity, why do you want this as an API? \n\nI previously built usedouble.com which was a sales enrichment tool that searches Google and opens the top results, and parses the information with GPT-4 and returns it to you (can still try it for free, we haven't touched this since last year)\n\nBasically what we built is the API you're looking for, it's just that we didn't expose the API to the public or offer it in any way. We just use it to power our GUI. \n\nIf many want this, maybe we should open source it for everyone to use with their own keys (it did require OpenAI + SerpAPI + Proxies, which is a lot of keys)\n\n### Comment ID llcoqfz with +1 score by [(metrohs, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/llcoqfz/) (in reply to ID llckci5):\nWithout saying too much - our chatbot needs to have the ability to search the web in a variety of cases to obtain the most up-to-date information. While, hypothetically, the latest information that 4o is trained on would be decently accurate (50-60?), the industry that my program is directed at will demand much better accuracy.\n\n## Comment ID llbjpgg with +1 score by [(Confident-Ant-8972, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/llbjpgg/) (in reply to ID 1f80h36):\nPerplexity\n\n### Comment ID llcdvc3 with +2 score by [(datacog, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/llcdvc3/) (in reply to ID llbjpgg):\nIt doesn't offer a search api afaik.\n\n#### Comment ID lld1o16 with +1 score by [(Confident-Ant-8972, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/lld1o16/) (in reply to ID llcdvc3):\nHuh, I remember reading those API docs\n\n#### Comment ID lldmrcg with +1 score by [(TI1l1I1M, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/lldmrcg/) (in reply to ID llcdvc3):\nEvery api call uses web sources for perplexity. Getting links to the sources is another ordeal however\n\n## Comment ID llcdluw with +1 score by [(datacog, Reddit, 2024-09-03)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/llcdluw/) (in reply to ID 1f80h36):\nYou can try Tavily, Brave search APIs. We use Tavily via Langchain, it works pretty well.\n\n## Comment ID lnconm4 with +1 score by [(Nedomas, Reddit, 2024-09-16)](https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/lnconm4/) (in reply to ID 1f80h36):\nTheres a few services, i personally used firecrawl and multion, but theres more."
    ],
    "sources": {
      "steam_url": null,
      "steam_reviews": null,
      "google_play_url": null,
      "google_play_reviews": null,
      "apple_store_url": null,
      "apple_reviews": null,
      "reddit_urls": [
        "https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/",
        "https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/",
        "https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/",
        "https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/",
        "https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/",
        "https://www.reddit.com/r/LangChain/comments/1fkzfu5/looking_for_recommendations_to_build_a_search/",
        "https://www.reddit.com/r/LangChain/comments/1dj5mhi/live_data_for_agents/",
        "https://www.reddit.com/r/LangChain/comments/1il8235/what_ai_agent_tools_are_you_missing/",
        "https://www.reddit.com/r/LLMDevs/comments/1fl8jco/building_your_first_crewai_tool_tavily_search/",
        "https://www.reddit.com/r/ChatGPTCoding/comments/1f80h36/alternatives_with_api_web_browsing_capabilities/"
      ],
      "reddit_search_url": "https://www.google.com/search?q=site%3Areddit.com+%22Tavily%22+related%3Atavily.com+"
    }
  },
  "glassdoor_result": null,
  "news_result": [
    [
      "Tavily",
      "Tavily",
      "tavily.com",
      null,
      false,
      false,
      null,
      [
        false,
        false
      ]
    ],
    [
      {
        "title": "Tavily",
        "link": "https://tavily.com/",
        "snippet": "Oct 23, 2024 ... Tavily is a search engine tailored for AI agents, delivering real-time, accurate results, intelligent query suggestions, and in-depth research capabilities.",
        "formattedUrl": "https://tavily.com/"
      },
      {
        "title": "Tavily Search - Tavily Docs",
        "link": "https://docs.tavily.com/documentation/api-reference/endpoint/search",
        "snippet": "Mar 18, 2025 ... Bearer authentication header in the form Bearer <token>, where <token> is your Tavily API key (e.g., Bearer tvly-YOUR_API_KEY). Body. application/json.",
        "formattedUrl": "https://docs.tavily.com/documentation/api-reference/endpoint/search"
      },
      {
        "title": "Can we date bound the Tavily API like we do for days while using ...",
        "link": "https://community.tavily.com/t/can-we-date-bound-the-tavily-api-like-we-do-for-days-while-using-topic-news/210",
        "snippet": "Nov 13, 2024 ... We are using Tavily in a company research use case and “news” has the date filter but the news results typically don't pick up announcements on company blogs ...",
        "formattedUrl": "https://community.tavily.com/t/can-we-date...the-tavily...news/210"
      },
      {
        "title": "Zapier - Tavily Docs",
        "link": "https://docs.tavily.com/integrations/zapier",
        "snippet": "Feb 5, 2025 ... Simply set up Tavily in Zapier to automate research, track real-time news, or feed relevant data into your tools of choice.",
        "formattedUrl": "https://docs.tavily.com/integrations/zapier"
      },
      {
        "title": "Response times are slow - Other Tavily Topics - Tavily Community",
        "link": "https://community.tavily.com/t/response-times-are-slow/131",
        "snippet": "Sep 10, 2024 ... Hello Team We see that Tavily is taking a minimum of 4 seconds to reply even when we have set max of 3 responses to be retried.",
        "formattedUrl": "https://community.tavily.com/t/response-times-are-slow/131"
      },
      {
        "title": "Precision in AI Research: Tavily's Company Researcher",
        "link": "https://blog.tavily.com/companyresearcher/",
        "snippet": "Nov 18, 2024 ... This tool integrates Tavily Search and Extract, in a workflow powered by LangGraph, to deliver precise, reliable insights.",
        "formattedUrl": "https://blog.tavily.com/companyresearcher/"
      },
      {
        "title": "Tavily JavaScript package now available on NPM - Announcements ...",
        "link": "https://community.tavily.com/t/tavily-javascript-package-now-available-on-npm/172",
        "snippet": "Oct 12, 2024 ... Good news! We're excited to announce the release of the official Tavily JavaScript package on NPM! Check it out here! Get started now by running npm i ...",
        "formattedUrl": "https://community.tavily.com/t/tavily-javascript-package-now...on.../172"
      },
      {
        "title": "tavily-ai/tavily-python: A python wrapper for Tavily search API - GitHub",
        "link": "https://github.com/tavily-ai/tavily-python",
        "snippet": "Aug 29, 2024 ... Performs a Tavily Search query and returns a str of content and sources within the provided token limit. It's useful for getting only related content from ...",
        "formattedUrl": "https://github.com/tavily-ai/tavily-python"
      },
      {
        "title": "API performance - API - Tavily Community",
        "link": "https://community.tavily.com/t/api-performance/115",
        "snippet": "Sep 4, 2024 ... Hello, We are using Tavily API as a tool in our AI agent. The search API takes around 40 seconds to respond to queries, but, on retries with the same prompt ...",
        "formattedUrl": "https://community.tavily.com/t/api-performance/115"
      },
      {
        "title": "Effortless Web-Based RAG Evaluation Using Tavily and LangGraph",
        "link": "https://blog.tavily.com/effortless-web-based-rag-evaluation-using-tavily-and-langgraph/",
        "snippet": "Jan 20, 2025 ... max_results=5 # Limits results to the top 5 most relevant sources. ) Key Parameters of Tavily Search: topic=\"news\" : Narrows the search to news-related content, ...",
        "formattedUrl": "https://blog.tavily.com/effortless-web-based-rag-evaluation-using-tavily-an..."
      },
      {
        "title": "tavily-ai/tavily-mcp - GitHub",
        "link": "https://github.com/tavily-ai/tavily-mcp",
        "snippet": "Jan 27, 2025 ... It is better to explicitly request to use the tools by describing what you want to do (e.g., \"User tavily-search to search the web for the latest news on AI\").",
        "formattedUrl": "https://github.com/tavily-ai/tavily-mcp"
      },
      {
        "title": "Tavily Search | 🦜️ LangChain",
        "link": "https://python.langchain.com/docs/integrations/tools/tavily_search/",
        "snippet": "Mar 20, 2025 ... Tavily's Search API is a search engine built specifically for AI agents ... include_images (optional, bool): Include a list of query related images in the ...",
        "formattedUrl": "https://python.langchain.com/docs/integrations/tools/tavily_search/"
      },
      {
        "title": "LLM Enhanced Web Search: The Tavily & Lang Chain",
        "link": "https://www.kaggle.com/code/marcinrutecki/llm-enhanced-web-search-the-tavily-lang-chain/notebook",
        "snippet": "Apr 3, 2024 ... Tavily is a search API, specifically designed for AI agents and tailored for RAG purposes. Tavily's primary objective is to provide factual and reliable ...",
        "formattedUrl": "https://www.kaggle.com/code/marcinrutecki/llm...web...tavily.../notebook"
      },
      {
        "title": "Tavily — The API-powered Alternative to Perplexity? | by AI Rabbit ...",
        "link": "https://medium.com/codex/tavily-the-api-powered-alternative-to-perplexity-edfdc6814b39",
        "snippet": "Feb 13, 2025 ... So what is Tavily about? · Limiting the sources to use (e.g. only sources you trust, like Reuters, news.anthropic.com, etc.) · Limiting publishing dates (e.g. ...",
        "formattedUrl": "https://medium.com/.../tavily-the-api-powered-alternative-to-perplexity-edf..."
      },
      {
        "title": "Tavily",
        "link": "https://www.crunchbase.com/organization/tavily/org_similarity_overview",
        "snippet": "Sep 23, 2024 ... +2 more. Choosito! search and learn turns the web into a leveled library of educational resources. Tavily and Choosito share similar descriptions and employee ...",
        "formattedUrl": "https://www.crunchbase.com/organization/tavily/org_similarity_overview"
      },
      {
        "title": "Tavily Search MCP Agent | Glama",
        "link": "https://glama.ai/mcp/servers/@arben-adm/tavily-mcp-search",
        "snippet": "Jan 8, 2025 ... This MCP server performs multi-topic searches in business, news, finance, and politics using the Tavily API, providing high-quality sources and intelligent ...",
        "formattedUrl": "https://glama.ai/mcp/servers/@arben-adm/tavily-mcp-search"
      },
      {
        "title": "Common Tools - PydanticAI",
        "link": "https://ai.pydantic.dev/common-tools/",
        "snippet": "Feb 27, 2025 ... Tavily is a paid service, but they have free credits to explore their ... data) \"\"\" Here are some of the top recent news articles related to GenAI: 1.",
        "formattedUrl": "https://ai.pydantic.dev/common-tools/"
      },
      {
        "title": "Get Started with Tavily in Python - Colab",
        "link": "https://colab.research.google.com/drive/1dWGtS3u4ocCLebuaa8Ivz7BkZ_40IgH1",
        "snippet": "Feb 6, 2025 ... ... Tavily, and build a RAG-powered daily news digest app using our main services - Tavily Search and Tavily Extract. You will first be building a simple ...",
        "formattedUrl": "https://colab.research.google.com/.../1dWGtS3u4ocCLebuaa8Ivz7BkZ_40I..."
      },
      {
        "title": "Purpose of agentic search - Travily - AI Agents in LangGraph ...",
        "link": "https://community.deeplearning.ai/t/purpose-of-agentic-search-travily/645163",
        "snippet": "Jun 11, 2024 ... ... similar pattern that is explained in the lesson 2 and 3. Maybe Openai is using an own 'homemade' tool, with a similar purpose of Tavily. For weather ...",
        "formattedUrl": "https://community.deeplearning.ai/t/purpose-of-agentic-search.../645163"
      },
      {
        "title": "AI Agents in LangGraph - DeepLearning.AI",
        "link": "https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/",
        "snippet": "Jun 5, 2024 ... Build agentic AI workflows using LangChain's LangGraph and Tavily's agentic search. Learn directly from LangChain and Tavily founders.",
        "formattedUrl": "https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/"
      }
    ],
    [
      "# [Tavily](https://tavily.com/)\n1 2 3 4 from tavily import TavilyClient tavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\") response = tavily_client.search(\"Who is Leo Messi?\") print(response)\n\n1 2 3 4 const { tavily } = require('@tavily/core'); const tvly = tavily({ apiKey: \"tvly-YOUR_API_KEY\" }); tvly.search(\"Who is Leo Messi?\") .then(results => console.log(results));",
      "# [Tavily Search](https://docs.tavily.com/documentation/api-reference/endpoint/search)\n{ \"query\": \"Who is Leo Messi?\", \"answer\": \"Lionel Messi, born in 1987, is an Argentine footballer widely regarded as one of the greatest players of his generation. He spent the majority of his career playing for FC Barcelona, where he won numerous domestic league titles and UEFA Champions League titles. Messi is known for his exceptional dribbling skills, vision, and goal-scoring ability. He has won multiple FIFA Ballon d'Or awards, numerous La Liga titles with Barcelona, and holds the record for most goals scored in a calendar year. In 2014, he led Argentina to the World Cup final, and in 2015, he helped Barcelona capture another treble. Despite turning 36 in June, Messi remains highly influential in the sport.\", \"images\": [], \"results\": [ { \"title\": \"Lionel Messi Facts | Britannica\", \"url\": \"https://www.britannica.com/facts/Lionel-Messi\", \"content\": \"Lionel Messi, an Argentine footballer, is widely regarded as one of the greatest football players of his generation. Born in 1987, Messi spent the majority of his career playing for Barcelona, where he won numerous domestic league titles and UEFA Champions League titles. Messi is known for his exceptional dribbling skills, vision, and goal\", \"score\": 0.81025416, \"raw_content\": null } ], \"response_time\": \"1.67\" }",
      "# [Can we date bound the Tavily API like we do for days while using topic=\"news\"? by acalder.gc on 2024-11-13](https://community.tavily.com/t/can-we-date-bound-the-tavily-api-like-we-do-for-days-while-using-topic-news/210)\nAs in the question, I am looking to date bound the search API to return results from a particular range, and days doesn’t have that level of control over my workflow.\n\nWould really appreciate help on this.\n\nHi,\n\nThank you for reaching out! That does sound like a very useful feature. However, currently, our API does not support date-bound filtering for the topic=“news” queries. You can filter by “days,” but there’s no direct way to specify a custom date range at the moment.\n\nWe appreciate your feedback and will consider this for future updates!\n\nBest,\n\nMay\n\n+1 to this question. I am building an AI financial agent and it would be very helpful to date-bound the filtering at the API level, especially for things like sentiment analysis.\n\nConcrete example: I have a backtester that calls the API repeatedly over a date range (e.g. Jan 2023 and March 2023). I would like to get the news sentiment between that date range only for my AI agent to do sentiment anlaysis.\n\nThis feature would be huge.\n\nJust adding that I would also love to see the “date” filter on the general search. We are using Tavily in a company research use case and “news” has the date filter but the news results typically don’t pick up announcements on company blogs and return low-relevancy results from mainstream news sites instead.\n\nHey all! we’ve added a time_range argument that allows you to specify a time range, going back from the current date, to include in the search results. Accepted values include \"day\", \"week\", \"month\", \"year\", or their shorthand versions: \"d\", \"w\", \"m\", \"y\". The default is None, which will not filter search results by time range.\n\nNote that time_range argument is available for both the “general” and “news” topics, while the days argument is exclusive to topic=\"news\" and allows you to specify an exact number of days from the current date to include in the results.\n\nWe hope this is useful! Let us know if you have any questions or feedback.\n\n@maitar Clarifying question: is the new feature just a day/week/etc back from the current date? Attributing a date to the results would also be a feature to consider…if I were searching for news for the last quarter or by quarter, I could do. “year” search and group the results by time period if I knew when each result was published.",
      "# [Tavily Docs](https://docs.tavily.com/integrations/zapier)\nIntroduction\n\nNo need to write a single line of code to connect Tavily to your business processes. With Tavily’s robust search capabilities, you can pull in the latest online information into any application or workflow.\n\nSimply set up Tavily in Zapier to automate research, track real-time news, or feed relevant data into your tools of choice.\n\nHow to set up Tavily with Zapier\n\nUse cases for Tavily in Zapier\n\nWith Tavily, you can harness the power of Retrieval-Augmented Generation (RAG) to create complex workflows. Here are some examples, for inspiration:\n\nAutomated Email Generation: Use Tavily to create tailored emails based on real-time data.\n\nMeeting Preparation: Gather real-time information about meeting participants. For instance, before a client meeting, retrieve their latest news or social media updates and receive a concise summary through your preferred method, ensuring you’re well-informed.\n\nAutomated Reporting: Utilize Tavily’s online search data to generate reports. Push this information into tools like Google Sheets, Notion, or Slack to create a weekly digest of industry trends or competitor analysis, keeping your team updated effortlessly.\n\nDetailed example - company research\n\nWe can build an automated workflow that executes brief company research for newly signed-up companies and delivers the report via Slack.\n\nBest practices\n\nTo use Tavily most efficiently in your Zapier workflows, keep the following guidelines in mind when designing your automations:",
      "# [Response times are slow on 2024-09-10](https://community.tavily.com/t/response-times-are-slow/131)\nHello Team\n\nWe see that Tavily is taking a minimum of 4 seconds to reply even when we have set max of 3 responses to be retried.\n\nIs this in the expected lines? What can we do to get the responses within a second?\n\nFYI, as of now we are using a Free plan for our POC and if its successful, would consider switching to an enterprise plan.\n\nHey there,\n\nThank you for your feedback. A ~3-second response time can occur due to a few factors beyond the number of documents retrieved. For instance, fetching raw content, images, or targeting specific domains can add a bit of time. The complexity of the queries you’re running also plays a part.\n\nWhen querying responses with topic=\"news\", you can expect shorter response times, so you might want to experiment with that if news queries are relevant to your needs.\n\nWe’re more than happy to work with you to optimize your setup and meet your needs as you continue exploring the API. Feel free to reach out here or privately at support@tavily.com",
      "# [Precision in AI Research: Tavily’s Company Researcher by Rotem Weiss on 2024-11-18](https://blog.tavily.com/companyresearcher/)\nIn AI research, accuracy is critical. Outdated data? Not useful. Models generating false information? A serious issue. And if you’ve ever tried gathering insights on companies with minimal online presence—or on similarly named entities—you know that many tools often fall short. That’s where Tavily’s Company Researcher comes in. This tool integrates Tavily Search and Extract, in a workflow powered by LangGraph, to deliver precise, reliable insights. Instead of just surface-level data, it generates comprehensive, current reports with in-depth detail.\n\nTavily’s Intelligent Search Layer\n\nTavily’s mission is to provide an intelligent search layer that connects large language models (LLMs) to the web, giving agents access to real-time, contextually relevant data. Tavily supports flexible search capabilities, enabling AI agents to fine-tune search strategies, retrieve raw content for analysis, or pull summaries for quick insights. Unlike static models bound to training data, Tavily’s Search and Extract endpoints combine semantic, contextual, and keyword search to deliver timely, relevant insights for data-driven decision-making.\n\nHow the Company Researcher Works\n\nThe Company Researcher automates a multi-stage workflow for real-time company analysis, integrating search and extraction with agentic behavior to generate high-quality results. Its modular and dynamic architecture allows for efficient gathering of both general context and targeted data. The use of feedback loops, combined with optional human-on-the-loop validation, ensures precise and reliable outputs. Here’s how it works:\n\nInitial Grounding with Tavily Extract: Each session begins with a user-provided company name and URL. Tavily Extract retrieves content from that site, creating a “ground truth” that anchors the search to follow. By grounding in verified data, each step operates within set accuracy boundaries, reducing hallucinations and inconsistencies.\n\nSub-Question Generation and Tavily Search: Dynamically generates specific sub-questions to guide Tavily’s search, focusing the search on high-value, relevant data instead of conducting a broad, unfocused search.\n\nAI-Driven Clustering: Retrieved documents are grouped by company, using the ground truth to verify accuracy, especially for similarly named entities. This clustering keeps only relevant sources in focus.\n\nHuman-on-the-Loop for Cluster Validation: If clustering doesn’t yield a definitive match, meaning that the correct cluster wasn't automatically identified, optional human validation can make manual adjustments, ensuring data quality.\n\nDocument Curation and Enrichment with Tavily Extract: Once a trusted cluster is identified, Tavily Extract pulls detailed data from these verified links, adding substantial depth to the research. This step enhances the precision and comprehensiveness of the final output.\n\nReport Generation and Evaluation: An LLM synthesizes the data into a structured report. If gaps are detected, new questions are generated to gather additional data, improving the report without restarting.\n\nMulti-Format Output: The final report is available in PDF or Markdown format, making it easy to share and integrate.\n\nHere is how I define the workflow IRL:\n\nKey Technical Features\n\nGrounding: The Foundation of Accuracy\n\nGrounding is core to Tavily’s Company Researcher workflow. It starts with establishing a reliable “ground truth” by using Tavily Extract on a verified company URL. This keeps the system aligned to the correct entity, especially in cases where similarly named companies exist. Creating a foundation to work from minimizes unrelated or erroneous information, improving output accuracy. Feedback loops that refer to the “ground truth” coupled with human-on-the-loop validation further reinforce this foundation, ensuring outputs are consistently relevant and curated for quality.\n\nTavily Search and Extract: Better Together for Precision\n\nTavily Extract is geared to pull raw information from specified sources. Allowing the agent to dig deep on the most important sources without the pressure of having to explore every possible lead. Tavily Search on the other hand, looks at the breadth of the web to identify the most relevant sources for your goal. By going broad it will ensure the scope of your research needs are covered. Tavily’s Company Researcher shows how you can utilize the strengths of each and have both tools work with one another to generate the results you want. In the end, only the most relevant pages are analyzed, providing accurate, contextually rich information, minimizing long context windows, and resulting in precise, actionable reports.\n\nDynamic Graph-Like Structure: Flexibility Meets Predictability\n\nThe Company Researcher uses a dynamic, graph-based structure that balances clear paths with flexibility. Traditional deterministic workflows work well for set steps but struggle in unpredictable real-world contexts. Fully dynamic workflows, like ReAct, handle unpredictability better but can lack structure and deterministic accuracy. The Company Researcher’s hybrid approach, implemented with LangGraph, maintains a clear path while adapting to real-world, real-time challenges, allowing for flexibility when data inputs vary.\n\nStructured Output: Consistency in Data\n\nStructured prompting ensures output consistency. While early LLMs could provide accurate information, their formatting was often inconsistent. I addressed this by embedding specific formatting into prompts, so each data cluster follows a set structure, making results easy to retrieve, reliable, and consistently organized.\n\nHere is an example of how it is used to define the clusters:\n\nAnd it is even simpler to call:\n\nThen, you can access each type of output because it is assigned to the cluster through the defined structure:\n\nAnd the Best Part: It’s Adaptable!\n\nTavily’s Company Researcher can be easily customized to fit a range of research needs. By making simple adjustments, you can expand its use beyond company research to tackle various data-intensive tasks, ensuring consistent and reliable results.\n\nModify Prompts: Consider tailoring the prompts used for question generation or report synthesis to better align with your specific research goals.\n\nExtend Workflow Nodes: Think about adding, removing, or altering workflow nodes to target specific types of analysis or areas of interest.\n\nCustomize Output Formats: Don’t hesitate to adjust output formats, such as using custom CSS for PDF styling, to align with your organization’s standards.\n\nGetting Started with Company Researcher:\n\nIn this section, we will walk you through the steps to download and start using Company Researcher.\n\nPrerequisites\n\nPython 3.11 or later: Python Installation Guide\n\nTavily API Key - Sign Up\n\nAnthropic API Key - Sign Up\n\nInstallation\n\nClone the Repository:\n\ngit clone https://github.com/danielleyahalom/company-researcher.git cd company-researcher\n\nCreate a Virtual Environment:\n\nTo avoid dependency conflicts, it's recommended to create and activate a virtual environment using venv:\n\npython -m venv venv source venv/bin/activate # macOS/Linux venv\\Scripts\\activate # Windows\n\nSet Up API Keys:\n\nConfigure your Anthropic and Tavily API keys as environment variables or place them in a .env file:\n\nexport TAVILY_API_KEY={Your Tavily API Key here} export ANTHROPIC_API_KEY={Your Anthropic API Key here}\n\nInstall Dependencies:\n\npip install -r requirements.txt\n\nRun the Application:\n\npython app.py\n\nOpen the App in Your Browser:\n\nhttp://localhost:5000",
      "# [Tavily JavaScript package now available on NPM on 2024-10-12](https://community.tavily.com/t/tavily-javascript-package-now-available-on-npm/172)\nGood news!\n\nWe’re excited to announce the release of the official Tavily JavaScript package on NPM! Check it out here!\n\nGet started now by running npm i @tavily/core in your JavaScript project!\n\nPlease note that the package is still in Beta. If you encounter any bugs, or have any suggestions, please contact us!\n\nWhat’s new?\n\nUsing Tavily in your JavaScript app has never been easier. Head to our documentation to get started. It only takes three lines of code!\n\nWhat’s changing?\n\nOur JavaScript package provides a clean, simple way to interact with our API. The days of manually constructing and sending HTTP requests are over!\n\nAny questions?",
      "# [python: A python wrapper for Tavily search API by tavily-ai](https://github.com/tavily-ai/tavily-python)\n{ \"results\": [ { \"url\": \"https://en.wikipedia.org/wiki/Artificial_intelligence\", \"raw_content\": \"Contents\\nArtificial intelligence\\nArtificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is a field of study in computer science that develops and studies intelligent machines. \\\"AI\\\" may also refer to the machines themselves.\\nAI technology is widely used throughout industry, government and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), and competing at the highest level in strategy games (such as chess and Go).[1]\\nArtificial intelligence was founded as an academic discipline in 1956.[2] The field went through multiple cycles of optimism[3][4] followed by disappointment and loss of funding,[5][6] but after 2012, when deep learning surpassed all previous AI techniques,[7] there was a vast increase in funding and interest.\\nThe various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals.[8]\\nTo solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience and many other fields.[9]\\nGoals\\nThe general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\\nReasoning, problem-solving\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[10] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[11]\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \\\"combinatorial explosion\\\": they became exponentially slower as the problems grew larger.[12]\\nEven humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[13]\\nAccurate and efficient reasoning is an unsolved problem.\\nKnowledge representation\\nKnowledge representation and knowledge engineering[14] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[15] scene interpretation,[16] clinical decision support,[17] knowledge discovery (mining \\\"interesting\\\" and actionable inferences from large databases),[18] and other areas.[19]\\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[20] Knowledge bases need to represent things such as:\\nobjects, properties, categories and relations between objects;\\n[21]\\nsituations, events, states and time;[22]\\ncauses and effects;[23]\\nknowledge about knowledge (what we know about what other people know);[24]\\ndefault reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[25] and many other aspects and domains of knowledge.\\nAmong the most difficult problems in KR are: the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[26] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \\\"facts\\\" or \\\"statements\\\" that they could express verbally).[13]\\nKnowledge acquisition is the difficult problem of obtaining knowledge for AI applications.[c] Modern AI gathers knowledge by \\\"scraping\\\" the internet (including Wikipedia). The knowledge itself was collected by the volunteers and professionals who published the information (who may or may not have agreed to provide their work to AI companies).[29] This \\\"crowd sourced\\\" technique does not guarantee that the knowledge is correct or reliable. The knowledge of Large Language Models (such as ChatGPT) is highly unreliable -- it generates misinformation and falsehoods (known as \\\"hallucinations\\\"). Providing accurate knowledge for these modern AI applications is an unsolved problem.\\nPlanning and decision making\\nAn \\\"agent\\\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][30]\\nIn automated planning, the agent has a specific goal.[31] In automated decision making, the agent has preferences – there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision making agent assigns a number to each situation (called the \\\"utility\\\") that measures how much the agent prefers it. For each possible action, it can calculate the \\\"expected utility\\\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[32]\\nIn classical planning, the agent knows exactly what the effect of any action will be.[33]\\nIn most real-world problems, however, the agent may not be certain about the situation they are in (it is \\\"unknown\\\" or \\\"unobservable\\\") and it may not know for certain what will happen after each possible action (it is not \\\"deterministic\\\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[34]\\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning) or the agent can seek information to improve its preferences.[35]\\nInformation value theory can be used to weigh the value of exploratory or experimental actions.[36]\\nThe space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain what the outcome will be.\\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g. by iteration), be heuristic, or it can be learned.[37]\\nGame theory describes rational behavior of multiple interacting agents, and is used in AI programs that make decisions that involve other agents.[38]\\nLearning\\nMachine learning is the study of programs that can improve their performance on a given task automatically.[39]\\nIt has been a part of AI from the beginning.[e]\\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[42]\\nSupervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[43]\\nIn reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \\\"good\\\".[44]\\nTransfer learning is when the knowledge gained from one problem is applied to a new problem.[45] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[46]\\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[47]\\nNatural language processing\\nNatural language processing (NLP)[48] allows programs to read, write and communicate in human languages such as English.\\nSpecific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[49]\\nEarly work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation[f]\\nunless restricted to small domains called \\\"micro-worlds\\\" (due to the common sense knowledge problem[26]).\\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[50] transformers (a deep learning architecture using an attention mechanism),[51] and others.[52] In 2019, generative pre-trained transformer (or \\\"GPT\\\") language models began to generate coherent text,[53][54] and by 2023 these models were able to get human-level scores on the bar exam, SAT, GRE, and many other real-world applications.[55]\\nPerception\\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[56]\\nThe field includes speech recognition,[57]\\nimage classification,[58]\\nfacial recognition, object recognition,[59]\\nand robotic perception.[60]\\nSocial intelligence\\nAffective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process or simulate human feeling, emotion and mood.[62]\\nFor example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\\nHowever, this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are.[63] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.[64]\\nGeneral intelligence\\nA machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.[8]\\nTools\\nAI research uses a wide variety of tools to accomplish the goals above.[b]\\nSearch and optimization\\nAI can solve many problems by intelligently searching through many possible solutions.[65] There are two very different kinds of search used in AI: state space search and local search.\\nState space search searches through a tree of possible states to try to find a goal state.[66]\\nFor example, Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[67]\\nSimple exhaustive searches[68]\\nare rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.[12]\\n\\\"Heuristics\\\" or \\\"rules of thumb\\\" can help to prioritize choices that are more likely to reach a goal.[69]\\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and counter-moves, looking for a winning position.[70]\\nLocal search uses mathematical optimization to find a numeric solution to a problem. It begins with some form of a guess and then refines the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. This process is called stochastic gradient descent.[71]\\nEvolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses).[72]\\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[73]\\nNeural networks and statistical classifiers (discussed below), also use a form of local search, where the \\\"landscape\\\" to be searched is formed by learning.\\nLogic\\nFormal Logic is used for reasoning and knowledge representation.[74]\\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \\\"and\\\", \\\"or\\\", \\\"not\\\" and \\\"implies\\\")[75]\\nand predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \\\"Every X is a Y\\\" and \\\"There are some Xs that are Ys\\\").[76]\\nLogical inference (or deduction) is the process of proving a new statement (conclusion) from other statements that are already known to be true (the premises).[77]\\nA logical knowledge base also handles queries and assertions as a special case of inference.[78]\\nAn inference rule describes what is a valid step in a proof. The most general inference rule is resolution.[79]\\nInference can be reduced to performing a search to find a path that leads from premises to conclusions, where each step is the application of an inference rule.[80]\\nInference performed this way is intractable except for short proofs in restricted domains. No efficient, powerful and general method has been discovered.[81]\\nFuzzy logic assigns a \\\"degree of truth\\\" between 0 and 1 and handles uncertainty and probabilistic situations.[82]\\nNon-monotonic logics are designed to handle default reasoning.[25]\\nOther specialized versions of logic have been developed to describe many complex domains (see knowledge representation above).\\nProbabilistic methods for uncertain reasoning\\nMany problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[83]\\nBayesian networks[84]\\nare a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm),[g][86]\\nlearning (using the expectation-maximization algorithm),[h][88]\\nplanning (using decision networks)[89]\\nand perception (using dynamic Bayesian networks).[90]\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[90]\\nPrecise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[91]\\nand information value theory.[92]\\nThese tools include models such as Markov decision processes,\\n[93]\\ndynamic decision networks,[90]\\ngame theory and mechanism design.[94]\\nClassifiers and statistical learning methods\\nThe simplest AI applications can be divided into two types: classifiers (e.g. \\\"if shiny then diamond\\\"), on one hand, and controllers (e.g. \\\"if diamond then pick up\\\"), on the other hand. Classifiers[95]\\nare functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \\\"observation\\\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[43]\\nThere are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm.[96] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[97]\\nThe naive Bayes classifier is reportedly the \\\"most widely used learner\\\"[98] at Google, due in part to its scalability.[99]\\nNeural networks are also used as classifiers.[100]\\nArtificial neural networks\\nArtificial neural networks[100] were inspired by the design of the human brain: a simple \\\"neuron\\\" N accepts input from other neurons, each of which, when activated (or \\\"fired\\\"), casts a weighted \\\"vote\\\" for or against whether neuron N should itself activate. In practice, the input \\\"neurons\\\" are a list of numbers, the \\\"weights\\\" are a matrix, the next layer is the dot product (i.e., several weighted sums) scaled by an increasing function, such as the logistic function. \\\"The resemblance to real neural cells and structures is superficial\\\", according to Russell and Norvig.[101][i]\\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.[102]\\nNeural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.[103]\\nIn feedforward neural networks the signal passes in only one direction.[104]\\nRecurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.[105]\\nPerceptrons[106]\\nuse only a single layer of neurons, deep learning[107] uses multiple layers.\\nConvolutional neural networks strengthen the connection between neurons that are \\\"close\\\" to each other – this is especially important in image processing, where a local set of neurons must identify an \\\"edge\\\" before the network can identify an object.[108]\\nDeep learning\\nDeep learning[107]\\nuses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.[110]\\nDeep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, image classification[111]\\nand others. The reason that deep learning performs so well in so many applications is not known as of 2023.[112]\\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[j]\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[k]\\nSpecialized hardware and software\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.[121]\\nHistorically, specialized languages, such as Lisp, Prolog, and others, had been used.\\nApplications\\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search),\\ntargeting online advertisements,[122]\\nrecommendation systems (offered by Netflix, YouTube or Amazon),\\ndriving internet traffic,[123][124]\\ntargeted advertising (AdSense, Facebook),\\nvirtual assistants (such as Siri or Alexa),[125]\\nautonomous vehicles (including drones,\\nADAS and self-driving cars),\\nautomatic language translation (Microsoft Translator, Google Translate),\\nfacial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and\\nimage labeling (used by Facebook, Apple's iPhoto and TikTok).\\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported they had incorporated \\\"AI\\\" in some offerings or processes.[126]\\nA few examples are energy storage,[127]\\nmedical diagnosis,\\nmilitary logistics,\\napplications that predict the result of judicial decisions,[128]\\nforeign policy,[129]\\nor supply chain management.\\nGame playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[130] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[131]\\nIn March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps.[132] Then it defeated Ke Jie in 2017, who at the time continuously held the world No. 1 ranking for two years.[133][134][135] Other programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus[l] and Cepheus.[137] DeepMind in the 2010s developed a \\\"generalized artificial intelligence\\\" that could learn many diverse Atari games on its own.[138]\\nIn the early 2020s, generative AI gained widespread prominence. ChatGPT, based on GPT-3, and other large language models, were tried by 14% of Americans adults.[139] The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion[140][141]\\nsparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat,[142]\\nthe fictional arrest of Donald Trump,[143]\\nand a hoax of an attack on the Pentagon,[144]\\nas well as the usage in professional creative arts.[145][146]\\nAlphaFold 2 (2020) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[147]\\nEthics\\nAI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \\\"solve intelligence, and then use that to solve everything else\\\".[148] However, as the use of AI has become widespread, several unintended consequences and risks have been identified.[149]\\nAnyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning.[150]\\nRisks and harm\\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\\nTechnology companies collect a wide range of data from their users, including online activity, geolocation data, video and audio.[151]\\nFor example, in order to build speech recognition algorithms, Amazon others have recorded millions of private conversations and allowed temps to listen to and transcribe some of them.[152]\\nOpinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.[153]\\nAI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.[154]\\nSince 2016, some privacy experts, such as Cynthia Dwork, began to view privacy in terms of fairness -- Brian Christian wrote that experts have pivoted \\\"from the question of 'what they know' to the question of 'what they're doing with it'.\\\".[155]\\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under a rationale of \\\"fair use\\\". Experts disagree about how well, and under what circumstances, this rationale will hold up in courts of law; relevant factors may include \\\"the purpose and character of the use of the copyrighted work\\\" and \\\"the effect upon the potential market for the copyrighted work\\\".[156] In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[157][158]\\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[159] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[160] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem.\\nIn 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films or human writing.\\nIt is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda.[161] AI pioneer Geoffrey Hinton expressed concern about AI enabling \\\"authoritarian leaders to manipulate their electorates\\\" on a large scale, among other risks.[162]\\nMachine learning applications will be biased if they learn from biased data.[163]\\nThe developers may not be aware that the bias exists.[164]\\nBias can be introduced by the way training data is selected and by the way a model is deployed.[165][163] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[166]\\nFairness in machine learning is the study of how to prevent the harm caused by algorithmic bias. It has become serious area of academic study within AI. Researchers have discovered it is not always possible to define \\\"fairness\\\" in a way that satisfies all stakeholders.[167]\\nOn June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \\\"gorillas\\\" because they were black. The system was trained on a dataset that contained very few images of black people,[168] a problem called \\\"sample size disparity\\\".[169] Google \\\"fixed\\\" this problem by preventing the system from labelling anything as a \\\"gorilla\\\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.[170]\\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist.\\nIn 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different -- the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[171] In 2017, several researchers[m] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[173]\\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \\\"race\\\" or \\\"gender\\\"). The feature will correlate with other features (like \\\"address\\\", \\\"shopping history\\\" or \\\"first name\\\"), and the program will make the same decisions based on these features as it would on \\\"race\\\" or \\\"gender\\\".[174]\\nMoritz Hardt said \\\"the most robust fact in this research area is that fairness through blindness doesn't work.\\\"[175]\\nCriticism of COMPAS highlighted a deeper problem with the misuse of AI. Machine learning models are designed to make \\\"predictions\\\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. Unfortunately, if an application then uses these predictions as recommendations, some of these \\\"recommendations\\\" will likely be racist.[176] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is necessarily descriptive and not proscriptive.[n]\\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[169]\\nAt its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022) the Association for Computing Machinery, in Seoul, South Korea, presented and published findings recommending that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.[178]\\nMost modern AI applications can not explain how they have reached a decision.[179] The large amount of relationships between inputs and outputs in deep neural networks and resulting complexity makes it difficult for even an expert to explain how they produced their outputs, making them a black box.[180]\\nThere have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, Justin Ko and Roberto Novoa developed a system that could identify skin diseases better than medical professionals, however it classified any image with a ruler as \\\"cancerous\\\", because pictures of malignancies typically include a ruler to show the scale.[181] A more dangerous example was discovered by Rich Caruana in 2015: a machine learning system that accurately predicted risk of death classified a patient that was over 65, asthma and difficulty breathing as \\\"low risk\\\". Further research showed that in high-risk cases like this, the hospital would allocate more resources and save the patient's life, decreasing the risk measured by the program.[182] Mistakes like these become obvious when we know how the program has reached a decision. Without an explanation, these problems may not not be discovered until after they have caused harm.\\nA second issue is that people who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are required to clearly and completely explain the reasoning behind any decision they make.[183] Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists.[o] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.[184]\\nDARPA established the XAI (\\\"Explainable Artificial Intelligence\\\") program in 2014 to try and solve these problems.[185]\\nThere are several potential solutions to the transparency problem. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.[186] Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network have learned and produce output that can suggest what the network is learning.[187] Supersparse linear integer models use learning to identify the most important features, rather than the classification. Simple addition of these features can then make the classification (i.e. learning is used to create a scoring system classifier, which is transparent).[188]\\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.[p] By 2015, over fifty countries were reported to be researching battlefield robots.[190] These weapons are considered especially dangerous for several reasons: if they kill an innocent person it is not clear who should be held accountable, it is unlikely they will reliably choose targets, and, if produced at scale, they are potentially weapons of mass destruction.[191] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.[192]\\nAI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes and generative AI aid in producing misinformation; advanced AI can make authoritarian centralized decision making more competitive with liberal and decentralized systems such as markets.[193]\\nTerrorists, criminals and rogue states can use weaponized AI such as advanced digital warfare and lethal autonomous weapons.\\nMachine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.[194]\\nFrom the early days of the development of artificial intelligence there have been arguments, for example those put forward by Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.[195]\\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.[196]\\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \\\"we're in uncharted territory\\\" with AI.[197] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[198] Risk estimates vary; for example, in the 2010s Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \\\"high risk\\\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \\\"high risk\\\".[q][200] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology (rather than social policy) creates unemployment (as opposed to redundancies).[196]\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \\\"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\\\" is \\\"worth taking seriously\\\".[201] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[202]\\nIn April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.[203][204]\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as the physicist Stephen Hawking puts it, \\\"spell the end of the human race\\\".[205] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \\\"self-awareness\\\" (or \\\"sentience\\\" or \\\"consciousness\\\") and becomes a malevolent character.[r] These sci-fi scenarios are misleading in several ways.\\nFirst, AI does not require human-like \\\"sentience\\\" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager).[207] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \\\"you can't fetch the coffee if you're dead.\\\"[208] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \\\"fundamentally on our side\\\".[209]\\nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[210]\\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[211] Personalities such as Stephen Hawking, Bill Gates, Elon Musk have expressed concern about existential risk from AI.[212]\\nIn the early 2010's, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[213]\\nHowever, after 2016, the study of current and future risks and possible solutions became a serious area of research.[214]\\nAI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI and in 2023 many leading AI experts issued the joint statement that \\\"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\\\".[215]\\nEthical machines and alignment\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[216]\\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[217]\\nThe field of machine ethics is also called computational morality,[217]\\nand was founded at an AAAI symposium in 2005.[218]\\nOther approaches include Wendell Wallach's \\\"artificial moral agents\\\"[219]\\nand Stuart J. Russell's three principles for developing provably beneficial machines.[220]\\nRegulation\\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.[221]\\nThe regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[222] According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.[223][224]\\nBetween 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[225]\\nMost EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, US and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[225]\\nThe Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[225] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[226]\\nIn 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.[227]\\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \\\"products and services using AI have more benefits than drawbacks\\\".[223] A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.[228]\\nIn a 2023 Fox News poll, 35% of Americans thought it \\\"very important\\\", and an additional 41% thought it \\\"somewhat important\\\", for the federal government to regulate AI, versus 13% responding \\\"not very important\\\" and 8% responding \\\"not at all important\\\".[229][230]\\nIn November 2023, a global AI safety summit was held in Bletchley Park to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.[231]\\nHistory\\nThe study of mechanical or \\\"formal\\\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \\\"0\\\" and \\\"1\\\", could simulate both mathematical deduction and formal reasoning, which is known as the Church–Turing thesis.[232] This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \\\"electronic brain\\\".[s][234] The first paper later recognized as \\\"AI\\\" was McCullouch and Pitts design for Turing-complete \\\"artificial neurons\\\" in 1943.[235]\\nThe field of AI research was founded at a workshop at Dartmouth College in 1956.[t][2] The attendees became the leaders of AI research in the 1960s.[u] They and their students produced programs that the press described as \\\"astonishing\\\":[v] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[w][3]\\nBy the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense[239] and laboratories had been established around the world.[240] Herbert Simon predicted, \\\"machines will be capable, within twenty years, of doing any work a man can do\\\".[241] Marvin Minsky agreed, writing, \\\"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\\\".[242]\\nThey had, however, underestimated the difficulty of the problem.[x] Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[244] and ongoing pressure from the US Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks approach would never be useful for solving real-world tasks, thus discrediting the approach altogether.[245] The \\\"AI winter\\\", a period when obtaining funding for AI projects was difficult, followed.[5]\\nIn the early 1980s, AI research was revived by the commercial success of expert systems,[246] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[4] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[6]\\nMany researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition.[247] A number of researchers began to look into \\\"sub-symbolic\\\" approaches.[248] Robotics researchers, such as Rodney Brooks, rejected \\\"representation\\\" in general and focussed directly on engineering machines that move and survive.[y]. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[83][253] But the most important development was the revival of \\\"connectionism\\\", including neural network research, by Geoffrey Hinton and others.[254] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[255]\\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \\\"narrow\\\" and \\\"formal\\\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[256]\\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \\\"artificial intelligence\\\".[257]\\nSeveral academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \\\"AGI\\\"), which had several well-funded institutions by the 2010s.[8]\\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[7]\\nFor many specific tasks, other methods were abandoned.[z]\\nDeep learning's success was based on both hardware improvements (faster computers,[259] graphics processing units, cloud computing[260])\\nand access to large amounts of data[261] (including curated datasets,[260] such as ImageNet).\\nDeep learning's success led to an enormous increase in interest and funding in AI.[aa]\\nThe amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019,[225]\\nand WIPO reported that AI was the most prolific emerging technology in terms of the number of patent applications and granted patents[262]\\nAccording to 'AI Impacts', about $50 billion annually was invested in \\\"AI\\\" around 2022 in the US alone and about 20% of new US Computer Science PhD graduates have specialized in \\\"AI\\\";[263]\\nabout 800,000 \\\"AI\\\"-related US job openings existed in 2022.[264]\\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[214]\\nPhilosophy\\nDefining artificial intelligence\\nAlan Turing wrote in 1950 \\\"I propose to consider the question 'can machines think'?\\\"[265]\\nHe advised changing the question from whether a machine \\\"thinks\\\", to \\\"whether or not it is possible for machinery to show intelligent behaviour\\\".[265]\\nHe devised the Turing test, which measures the ability of a machine to simulate human conversation.[266] Since we can only observe the behavior of the machine, it does not matter if it is \\\"actually\\\" thinking or literally has a \\\"mind\\\". Turing notes that we can not determine these things about other people[ab] but \\\"it is usual to have a polite convention that everyone thinks\\\"[267]\\nRussell and Norvig agree with Turing that AI must be defined in terms of \\\"acting\\\" and not \\\"thinking\\\".[268] However, they are critical that the test compares machines to people. \\\"Aeronautical engineering texts,\\\" they wrote, \\\"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\\\"[269] AI founder John McCarthy agreed, writing that \\\"Artificial intelligence is not, by definition, simulation of human intelligence\\\".[270]\\nMcCarthy defines intelligence as \\\"the computational part of the ability to achieve goals in the world.\\\"[271] Another AI founder, Marvin Minsky similarly defines it as \\\"the ability to solve hard problems\\\".[272] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \\\"intelligence\\\" of the machine—and no other philosophical discussion is required, or may not even be possible.\\nAnother definition has been adopted by Google,[273] a major practitioner in the field of AI.\\nThis definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\\nEvaluating approaches to AI\\nNo established unifying theory or paradigm has guided AI research for most of its history.[ac] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \\\"artificial intelligence\\\" to mean \\\"machine learning with neural networks\\\"). This approach is mostly sub-symbolic, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.\\nSymbolic AI (or \\\"GOFAI\\\")[275] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \\\"intelligent\\\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \\\"A physical symbol system has the necessary and sufficient means of general intelligent action.\\\"[276]\\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \\\"intelligent\\\" tasks were easy for AI, but low level \\\"instinctive\\\" tasks were extremely difficult.[277]\\nPhilosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \\\"feel\\\" for the situation, rather than explicit symbolic knowledge.[278]\\nAlthough his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree.[ad][13]\\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[280][281] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\\n\\\"Neats\\\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \\\"Scruffies\\\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 70s and 80s,[282]\\nbut eventually was seen as irrelevant. Modern AI has elements of both.\\nFinding a provably correct or optimal solution is intractable for many important problems.[12] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 80s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.[283][284]\\nGeneral intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\\nMachine consciousness, sentience and mind\\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \\\"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\\\"[285] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\nDavid Chalmers identified two problems in understanding the mind, which he named the \\\"hard\\\" and \\\"easy\\\" problems of consciousness.[286] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). Human information processing is easy to explain, however, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[287]\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[288]\\nPhilosopher John Searle characterized this position as \\\"strong AI\\\": \\\"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\\\"[ae]\\nSearle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[292]\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights.[293]\\nAny hypothetical robot rights would lie on a spectrum with animal rights and human rights.[294]\\nThis issue has been considered in fiction for centuries,[295]\\nand is now being considered by, for example, California's Institute for the Future; however, critics argue that the discussion is premature.[296]\\nFuture\\nSuperintelligence and the singularity\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[284]\\nIf research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \\\"intelligence explosion\\\" and Vernor Vinge called a \\\"singularity\\\".[297]\\nHowever, technologies can't improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[298]\\nTranshumanism\\nRobot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.[299]\\nEdward Fredkin argues that \\\"artificial intelligence is the next stage in evolution\\\", an idea first proposed by Samuel Butler's \\\"Darwin among the Machines\\\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.[300]\\nIn fiction\\nThought-capable artificial beings have appeared as storytelling devices since antiquity,[301]\\nand have been a persistent theme in science fiction.[302]\\nA common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[303]\\nIsaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \\\"Multivac\\\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics;[304]\\nwhile almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[305]\\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[306]\\nSee also\\nExplanatory notes\\nReferences\\nAI textbooks\\nThe two most widely used textbooks in 2023. (See the Open Syllabus).\\nThese were the four the most widely used AI textbooks in 2008:\\nLater editions.\\nHistory of AI\\nOther sources\\nFurther reading\\nExternal links\", \"images\": [\"https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-en.svg\"] }, { \"url\": \"https://www.britannica.com/science/autumn-season\", \"raw_content\": \"Autumn | Definition, Characteristics, & Facts | Britannica\\n\\nSearch Britannica Click here to search\\n\\nSearch Britannica Click here to search\\nSubscribe Now\\nSubscribe\\nLogin\\n\\nHome\\nHistory & Society\\nScience & Tech\\nBiographies\\nAnimals & Nature\\nGeography & Travel\\nArts & Culture\\n\\nMoney\\n\\n\\nGames & Quizzes\\n\\nVideos\\nOn This Day\\nOne Good Fact\\nDictionary\\nNew Articles\\n\\nHistory & Society\\n\\nLifestyles & Social Issues\\nPhilosophy & Religion\\nPolitics, Law & Government\\nWorld History\\n\\nScience & Tech\\n\\nHealth & Medicine\\nScience\\nTechnology\\n\\nBiographies\\n\\nBrowse Biographies\\n\\nAnimals & Nature\\n\\nBirds, Reptiles & Other Vertebrates\\nBugs, Mollusks & Other Invertebrates\\nEnvironment\\nFossils & Geologic Time\\nMammals\\nPlants\\n\\nGeography & Travel\\n\\nGeography & Travel\\n\\nArts & Culture\\n\\nEntertainment & Pop Culture\\nLiterature\\nSports & Recreation\\n\\nVisual Arts\\n\\n\\nCompanions\\n\\nDemystified\\nImage Galleries\\nInfographics\\nLists\\nPodcasts\\nSpotlight\\nSummaries\\nThe Forum\\nTop Questions\\n\\n#WTFact\\n\\n\\n100 Women\\n\\nBritannica Kids\\nSaving Earth\\nSpace Next 50\\nStudent Center\\n\\nAsk the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture Money Videos\\nautumn\\nTable of Contents\\nIntroduction References & Edit History Quick Facts & Related Topics\\nImages & Videos\\n \\nRelated Questions\\n\\nWhat does Earth look like?\\n\\nRead Next\\n\\nWhy Do Leaves Change Colors in the Fall?\\n\\n22 Questions About Time and Timekeeping Answered\\n\\nWhy Do Leaves Fall in Autumn?\\n\\nThe Perils of an Early Spring\\n\\nFirst Day of Fall\\nDiscover\\n\\n7 Scary Surgical Instruments, Then and Now\\n\\nWhere Does the Name Europe Come From?\\n\\nCruel and Unusual Punishments: 15 Types of Torture\\n\\nWhat’s the Difference Between Hispanic and Latino?\\n\\nAll 119 References in “We Didn’t Start the Fire,” Explained\\n\\nWhy Is a Baker’s Dozen 13?\\n\\n10 Famous Artworks by Leonardo da Vinci\\nContents\\nScience Earth Science, Geologic Time & Fossils Earth Sciences\\nautumn\\nseason\\nActions\\nCite\\n_verified_Cite\\nWhile every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions.\\nSelect Citation Style\\nCopy Citation\\nShare\\nShare\\nShare to social media\\nFacebook X\\nURL\\nhttps://www.britannica.com/science/autumn-season\\nGive Feedback\\nExternal Websites\\nFeedback\\nCorrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login).\\nFeedback Type \\nYour Feedback Submit Feedback\\nThank you for your feedback\\nOur editors will review what you’ve submitted and determine whether to revise the article.\\nExternal Websites\\n\\nLiveScience - Autumn: The Cooling-Off Season\\n\\nBritannica Websites\\nArticles from Britannica Encyclopedias for elementary and high school students.\\n\\nautumn - Children's Encyclopedia (Ages 8-11)\\nautumn - Student Encyclopedia (Ages 11 and up)\\n\\nPrint Cite\\n_verified_Cite\\nWhile every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions.\\nSelect Citation Style\\nCopy Citation\\nShare\\nShare\\nShare to social media\\nFacebook X\\nURL\\nhttps://www.britannica.com/science/autumn-season\\nFeedback\\nExternal Websites\\nFeedback\\nCorrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login).\\nFeedback Type \\nYour Feedback Submit Feedback\\nThank you for your feedback\\nOur editors will review what you’ve submitted and determine whether to revise the article.\\nExternal Websites\\n\\nLiveScience - Autumn: The Cooling-Off Season\\n\\nBritannica Websites\\nArticles from Britannica Encyclopedias for elementary and high school students.\\n\\nautumn - Children's Encyclopedia (Ages 8-11)\\nautumn - Student Encyclopedia (Ages 11 and up)\\n\\nAlso known as: fall\\nWritten and fact-checked by\\nThe Editors of Encyclopaedia Britannica Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree. They write new content and verify and edit content received from contributors.\\nThe Editors of Encyclopaedia Britannica\\nLast Updated: Aug 29, 2024 • Article History\\nTable of Contents\\n\\nautumn\\nSee all media\\nRelated Topics:\\ncalendar\\nharvest\\nyear\\nIndian summer\\nautumnal equinox\\n(Show more)\\nSee all related content →\\nRecent News\\nAug. 29, 2024, 4:45 PM ET (AP)\\nFall is bringing fantasy (and romantasy), literary fiction, politics and Taylor-ed book offerings\\nautumn, season of the year between summer and winter during which temperatures gradually decrease. It is often called fall in the United States because leaves fall from the trees at that time. Autumn is usually defined in the Northern Hemisphere as the period between the autumnal equinox (day and night equal in length), September 22 or 23, and the winter solstice (year’s shortest day), December 21 or 22; and in the Southern Hemisphere as the period between March 20 or 21 and June 21 or 22. The autumn temperature transition between summer heat and winter cold occurs only in middle and high latitudes; in equatorial regions, temperatures generally vary little during the year. In the polar regions autumn is very short. For physical causes of the seasons, see season.\\n\\nWhat causes the seasons?In many parts of the world, weather cycles through the four seasons like clockwork: spring, summer, autumn, and winter.(more)\\nSee all videos for this article\\n\\nWhy do some trees lose their leaves in autumn?Learn why leaves of deciduous trees change colour in autumn.(more)\\nSee all videos for this article\\nThe concept of autumn in European languages is connected with the harvesting of crops; in many cultures autumn, like the other seasons, has been marked by rites and festivals revolving around the season’s importance in food production. Animals gather food in autumn in preparation for the coming winter, and those with fur often grow thicker coats. Many birds migrate toward the Equator to escape the falling temperatures. A common autumn phenomenon in the central and eastern United States and in Europe is Indian summer, a period of unseasonably warm weather that sometimes occurs in late October or November.\\nThe Editors of Encyclopaedia BritannicaThis article was most recently revised and updated by Meg Matthias.\", \"images\": [\"https://cdn.britannica.com/mendel/eb-logo/MendelNewThistleLogo.png\", \"https://cdn.britannica.com/mendel/eb-logo/MendelNewThistleLogo.png\", \"https://cdn.britannica.com/88/137188-004-A05832DA/Boston-Public-Garden.jpg\", \"https://cdn.britannica.com/62/247262-138-1891B9BE/what-causes-seasons.jpg?w=400&h=225&c=crop\", \"https://cdn.britannica.com/23/179623-138-8D7F3C16/leaves-trees-colour.jpg?w=400&h=225&c=crop\", \"https://cdn.britannica.com/01/144901-004-07156D4A/Great-Smoky-Mountains-National-Park-Tennessee.jpg\", \"https://cdn.britannica.com/45/158545-004-A787D7AA/autumn-foliage-North-Cascades-National-Park-Washington.jpg\", \"https://cdn.britannica.com/62/180762-138-850D2106/journey-New-England-2013.jpg?w=400&h=225&c=crop\", \"https://cdn.britannica.com/28/180828-138-C9C052FB/video-Otago-New-Zealand-South-Island.jpg?w=400&h=225&c=crop\", \"https://cdn.britannica.com/88/137188-050-8C779D64/Boston-Public-Garden.jpg?w=400&h=300&c=crop\"], }, { \"url\": \"https://docs.tavily.com/docs/welcome\", \"raw_content\": \"Introduction\\nHey there! 👋\\nWe're a team of AI researchers and developers who are passionate about helping you build the next generation of AI assistants.\\nOur mission is to empower individuals and organizations with accurate, unbiased, and factual information.\\nTavily Search API​\\nBuilding an AI agent that leverages realtime online information is not a simple task. Scraping doesn't scale and requires expertise to refine, current search engine APIs don't provide explicit information to queries but simply potential related articles (which are not always related), and are not very customziable for AI agent needs. This is why we're excited to introduce the first search engine for AI agents - Tavily Search API.\\nTavily Search API is a search engine optimized for LLMs, aimed at efficient, quick and persistent search results. Unlike other search APIs such as Serp or Google, Tavily focuses on optimizing search for AI developers and autonomous AI agents. We take care of all the burden of searching, scraping, filtering and extracting the most relevant information from online sources. All in a single API call! \\nTo try the API in action, you can now use our hosted version on our API Playground.\\nIf you're an AI developer looking to integrate your application with our API, or seek increased API limits, please reach out!\\nWhy choose the Tavily Search API?​\\nHow does the Search API work?​\\nCurrent search APIs such as Google, Serp and Bing retrieve search results based on user query. However, the results are sometimes irrelevant to the goal of the search, and return simple site URLs and snippets of content which are not always relevant. Because of this, any developer would need to then scrape the sites to extract relevant content, filter irrelevant information, optimize the content to fit LLM context limits, and more. This task is a burden and requires a lot of time and effort to complete. The Tavily Search API takes care of all of this for you in a single API call.\\nTavily Search API aggregates up to 20 sites per a single API call, and uses proprietary AI to score, filter and rank the top most relevant sources and content to your task, query or goal.\\nIn addition, Tavily allows developers to add custom fields such as context and limit response tokens to enable the optimal search experience for LLMs.\\nTavily can also help your AI agent make better decisions by including a short answer for cross-agent communication.\\nRemember: With LLM hallucinations, it's crucial to optimize for RAG with the right context and information.\\nGetting started​\\n🙋‍♂️ Got questions? Stumbled upon an issue? Or simply intrigued? Don't hesitate! Our support team is always on standby, eager to assist. Join us, dive deep, and redefine your search experience! Contact us!\\nGPT Researcher​\\nIn this digital age, quickly accessing relevant and trustworthy information is more crucial than ever. However, we've learned that none of today's search engines provide a suitable tool that provides factual, explicit and objective answers without the need to continuously click and explore multiple sites for a given research task. \\nThis is why we've built the trending open source GPT Researcher. GPT Researcher is an autonomous agent that takes care of the tedious task of research for you, by scraping, filtering and aggregating over 20+ web sources per a single research task. \\nTo learn more about GPT Researcher, check out the documentation page.\\n\", \"images\": [\"https://docs.tavily.com/img/tavily.png\", \"https://docs.tavily.com/img/tavily-dark.png\"] } ], \"failed_results\": [ ], \"response_time\": 0.02 }",
      "# [API performance on 2024-09-04](https://community.tavily.com/t/api-performance/115)\nHello,\n\nWe are using Tavily API as a tool in our AI agent. The search API takes around 40 seconds to respond to queries, but, on retries with the same prompt, is able to come back in < 4 seconds.\n\nHere is a sample prompt - Recent Federal Reserve interest rate hikes impact on U.S. consumer spending and borrowing trends\n\nHere are the parameter we are using on the client -\n\ntavily_client.search(query, search_depth=“advanced”).\n\nIs it possible to get consistent near real time (< 4 sec) responses at all times? We are currently on bootstrap pricing mode, and we intend to move up the tier if the API satisfies our needs.\n\nThanks\n\nHi,\n\nThank you for reaching out! A response time of 40 seconds for queries is very unlikely, and I couldn’t find any record of such delays on our end. Typically, response times range between 1 to 10 seconds. You can also check the current status of the API on our status page here: https://status.tavily.com.\n\nCould you share which framework you’re using Tavily as a tool in? Perhaps that is the cause of the delays, and we’d be happy to look into it.\n\nWhile we’re unable to provide detailed technical information on how results improve over time, I can confirm that as more people research a particular topic, the results do indeed become better.\n\nLet us know if you have any more questions or feedback. We’re here to help and accommodate your needs as you continue exploring the API!\n\nThank you for your response.\n\nOur stack utilizes LangGraph, where nodes implement function calls using web search tools, including Tavily. Initially, we had set include_raw_content to True with max_results set to 10, which led to 502 errors or long runtimes. We have since disabled raw content and reduced max_results to 5, and we’re now experiencing much faster results.\n\nWe will continue to test the API, and so far, we are pleased with the results it is delivering within our stack.\n\nOn a side note, our legal team has been trying to reach you regarding enterprise pricing but hasn’t had success. Is there a specific contact we can reach out to in order to discuss your enterprise package?\n\nThanks.\n\nI’m glad to hear that you’re pleased with the results you’re obtaining using our API within your stack! Setting include_raw_content can sometimes place constraints on our system, but our team is actively working on improving performance. Things should be running more smoothly now if you need to enable it for specific cases.\n\nI apologize for the difficulties your legal team has had in reaching us. You can either fill out this form, and our team will get back to you as soon as possible, or reach out via email at support@tavily.com.\n\nThank you again for reaching out. Let us know if you have any more questions or feedback!\n\nI’ve informed our account managers, Itamar and Lee, about the situation. Lee mentioned that they’ve been trying to reach out as well, with one email sent on August 22nd and another yesterday. Lee has just sent another follow-up email. Please let us know if you haven’t received it or if there’s still an issue with getting in touch. I’d be happy to help resolve this communication gap.",
      "# [Effortless Web-Based RAG Evaluation Using Tavily and LangGraph by Eyal Ben Barouch on 2025-01-20](https://blog.tavily.com/effortless-web-based-rag-evaluation-using-tavily-and-langgraph/)\nIntroduction\n\nEvery data science enthusiast knows that a vital first step to building a successful model or algorithm is having a reliable evaluation set to aspire to. In the rapidly evolving landscape of Retrieval-Augmented Generation (RAG) and AI-driven search systems, the importance of high-quality eval datasets is crucial.\n\nIn this article, we introduce an agentic workflow designed to generate subject-specific dynamic evaluation datasets, enabling precise validation of web search augmented agents' performance.\n\nKnown RAG evaluation datasets, such as HotPotQA, CRAG, and MultiHop-RAG, have been pivotal in benchmarking and fine-tuning models. However, these datasets primarily focus on evaluating performance with static, pre-defined document sets. As a result, they fall short when it comes to evaluating web-based RAG systems, where data is dynamic, contextual, and ever-changing.\n\nThis gap presents a significant challenge: how do we effectively test and refine RAG systems designed for real-world web search scenarios? Enter the Real-Time Dataset Generator for RAG Evals — an agentic tool leveraging Tavily’s Search Layer and LangGraph framework to create diverse, relevant, and dynamic datasets tailored specifically for web based RAG agents.\n\nWhat is the Real-Time Dataset Generator?\n\nIf you’ve ever built an AI agent, you already know that evaluating it is just as challenging as creating it. When it comes to research agents or tailoring an agent for a specific subject, the process can become even more daunting. Why? Because it’s often a tedious, manual process — one that involves crafting domain-specific queries, curating relevant data, and ensuring the results align with the agent’s objectives. This approach is not only time-consuming but also prone to inconsistencies.\n\nAt its core, the Real-Time Dataset Generator is an agent designed to create datasets for evaluating other agents, automating the tedious processes of query generation, web data collection, and filtering. This enables developers and researchers to focus on building smarter, more capable agents.\n\nThe Generator offers a powerful solution for evaluating how effectively LLM based agents handle fact-based, up-to-date questions in time-sensitive domains such as news-focused agents delivering real-time updates, sports agents providing accurate game statistics, financial agents analyzing market trends, and more. By generating dynamic datasets aligned with current events, this tool ensures agents can be rigorously tested and refined for precise and relevant responses.\n\nHow it works?\n\nStep 1: Input\n\nThe workflow begins with user-provided inputs:\n\ninput = {num_qa: \"number of questions and answers\", QA_subject: \"subject of the Q&A\", save_to_langsmith: \"save locally or to Langsmith\"}\n\nStep 2: Domain Specific Search Query Generation\n\nIf a subject is provided (e.g., “NBA Basketball”), the system generates a set of search queries using this prompt:\n\nQA_QUERIES_SYSTEM_PROMPT = \"\"\" **Objective:** Produce {num_queries} clear, effective, and varied queries to gather the most relevant and recent information about the input subject. **Guidelines:** 1. Ensure clarity, specificity, and relevance to the subject. 2. Prioritize fresh and comprehensive results. \"\"\"\n\nThis ensures queries are tailored to gather high-quality, recent, and subject-specific information.\n\nStep 3: Web Search with Tavily\n\nThis step guarantees that the dataset reflects current and relevant information, particularly for web search RAG evaluation, where up-to-date data is crucial.This is the heart of the RAG Dataset Generator, transforming queries into actionable, high-quality data that forms the foundation of the evaluation set.\n\nquery_with_date = f\"{query} {datetime.now().strftime('%m-%Y')}\" tavily_response = await self.tavily_client.search( query=query_with_date, topic=\"news\", # Focuses search on recent news articles. days=3, # Searches content from the past 3 days. max_results=5 # Limits results to the top 5 most relevant sources. )\n\nKey Parameters of Tavily Search:\n\ntopic=\"news\":\n\nNarrows the search to news-related content, targeting fresh and reliable sources.\n\ndays=3:\n\nSearches for content published within the last three days, keeping the dataset relevant for real-world evaluation scenarios.\n\nmax_results=5:\n\nRetrieves up to five highly relevant results per query, avoiding information overload while maintaining quality.\n\nStep 4: Q&A Pair Generation\n\nFor each website returned by Tavily, the system generates question-answer pair using a map-reduce paradigm to ensure efficient processing across multiple sources. This step is implemented using LangGraph’s Send API.\n\ndef map_qa(state): # Map Function return [Send(\"generate_qa\", {\"page_content\": result.get('content', '')}) for url,result in state.search_results.items()]\n\n# nodes/generate_qa.py from web_search_benchmark_generator.prompts import QA_GENERATION_SYSTEM_PROMPT,QA_GENERATION_USER_PROMPT from langchain_core.messages import HumanMessage, SystemMessage from pydantic import BaseModel,Field from typing import List, Dict from web_search_benchmark_generator.state import QAState class QA(BaseModel): question: str = Field( ..., description=\"A question generated from the content.\" ) answer: str = Field( ..., description=\"The corresponding answer to the question.\" ) class QAList(BaseModel): qa_list: List[QA] = Field( ..., description=\"A list of QA pairs, each containing a question and its corresponding answer.\" ) class QAGenerator: def __init__(self,cfg,utils): self.model = cfg.LLM self.cfg = cfg self.default_system_prompt = QA_GENERATION_SYSTEM_PROMPT self.default_user_prompt = QA_GENERATION_USER_PROMPT self.utils = utils async def run(self, state: QAState): \"\"\" Generate 10 question-and-answer pairs based on the given page content. Args: state (QAState): The state containing the page content. Returns: List[Dict[str, str]]: A list of dictionaries containing question-answer pairs. \"\"\" msgs = \"🤔 Running QA Generator\" if self.cfg.DEBUG: print(msgs) page_content = state['page_content'] # Create system and user messages for the model system_message = SystemMessage(content=self.default_system_prompt) user_message = HumanMessage( content=self.default_user_prompt.format(page_content=page_content) ) messages = [system_message, user_message] try: response = await self.model.with_structured_output(QAList).ainvoke(messages) return {\"q_and_as\":response.qa_list} except Exception as e: # Handle and log errors msgs += f\"Error in QA Generator: {e}\" if self.cfg.DEBUG: print(msgs) raise ValueError(f\"Failed to generate QA pairs: {e}\")\n\nStep 5: Save the Evaluation Set\n\nFinally, the generated dataset is saved either locally or to Langsmith, based on the input configuration.\n\n# Create the dataset dataset = self.client.create_dataset( dataset_name=dataset_name, description=self.description, ) # Prepare inputs and outputs for bulk creation inputs = [{\"question\": qa.question} for qa in qa_list] outputs = [{\"expected_answer\": qa.answer} for qa in qa_list] # Save the examples self.client.create_examples( inputs=inputs, outputs=outputs, dataset_id=dataset.id, ) return {\"output_message\": f\"Dataset '{dataset_name}' saved in langsmith, You can access the dataset via the URL {dataset.url}.\"}\n\nOutput\n\nThe result is a well-structured, subject-specific evaluation dataset, ready for use in advanced evaluation methods like LLM-as-a-Judge.\n\nEvaluation of the Dataset Using LLM-as-a-Judge\n\nOnce the dataset is generated, its quality and relevance can be assessed using the LLM-as-a-Judge approach. This involves leveraging large language models to evaluate the accuracy, coherence, and completeness of the generated question-answer pairs. The LLM acts as an unbiased evaluator, scoring the answers based on alignment with expected outcomes or factual correctness. This method provides a scalable, automated way to validate datasets, ensuring they meet high standards for RAG system evaluation.\n\nAn LLM-as-a-judge prompt example:\n\nllm_judge_prompt = \"\"\" You are an unbiased evaluator tasked with assessing whether the generated answer aligns with the expected answer based on the provided question. Evaluate the generated answer's accuracy, coherence, and completeness compared to the expected answer. Provide a score from 1 to 10 for each criterion, followed by a brief explanation. Question: {question} Expected Answer: {expected_answer} Generated Answer: {generated_answer} Evaluation: - Accuracy: [Score: 1-10] - [Does the generated answer align with the expected answer?] - Coherence: [Score: 1-10] - [Is the generated answer clearly written and logically presented?] - Completeness: [Score: 1-10] - [Does the generated answer fully address the question as intended by the expected answer?] - Overall Feedback: [Your observations and suggestions for improvement] \"\"\"\n\nGetting Started with the Dataset Generator",
      "# [ai/tavily by tavily-ai](https://github.com/tavily-ai/tavily-mcp)\n🔌 Compatible with Cline, Cursor, Claude Desktop, and any other MCP Clients!\n\nTavily MCP is also compatible with any MCP client\n\n📚 tutorial on combining Tavily MCP with Neo4j MCP server!\n\n📚 tutorial Integrating Tavily MCP with Cline in VS Code ( Demo + Example Use-Cases)\n\nThe Model Context Protocol (MCP) is an open standard that enables AI systems to interact seamlessly with various data sources and tools, facilitating secure, two-way connections.\n\nDeveloped by Anthropic, the Model Context Protocol (MCP) enables AI assistants like Claude to seamlessly integrate with Tavily's advanced search and data extraction capabilities. This integration provides AI models with real-time access to web information, complete with sophisticated filtering options and domain-specific search features.\n\nThe Tavily MCP server provides:\n\nSeamless interaction with the tavily-search and tavily-extract tools\n\nReal-time web search capabilities through the tavily-search tool\n\nIntelligent data extraction from web pages via the tavily-extract tool\n\nBefore you begin, ensure you have:\n\nTavily API key\n\nIf you don't have a Tavily API key, you can sign up for a free account here\n\nClaude Desktop or Cursor\n\nNode.js (v20 or higher)\n\nYou can verify your Node.js installation by running:\n\nnode --version\n\nGit installed (only needed if using Git installation method)\n\nOn macOS: brew install git\n\nOn Linux:\n\nDebian/Ubuntu: sudo apt install git\n\nRedHat/CentOS: sudo yum install git\n\nOn Windows: Download Git for Windows\n\nnpx -y tavily-mcp@0.1.4\n\nTo install Tavily MCP Server for Claude Desktop automatically via Smithery:\n\nnpx -y @smithery/cli install @tavily-ai/tavily-mcp --client claude\n\nAlthough you can launch a server on its own, it's not particularly helpful in isolation. Instead, you should integrate it into an MCP client. Below is an example of how to configure the Claude Desktop app to work with the tavily-mcp server.\n\nThis repository will explain how to configure both Cursor and Claude Desktop to work with the tavily-mcp server.\n\nThe easiest way to set up the Tavily MCP server in Cline is through the marketplace with a single click:\n\nOpen Cline in VS Code\n\nClick on the Cline icon in the sidebar\n\nNavigate to the \"MCP Servers\" tab ( 4 squares )\n\nSearch \"Tavily\" and click \"install\"\n\nWhen prompted, enter your Tavily API key\n\nAlternatively, you can manually set up the Tavily MCP server in Cline:\n\nOpen the Cline MCP settings file:\n\nFor macOS:\n\n# Using Visual Studio Code code ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json # Or using TextEdit open -e ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n\nFor Windows:\n\ncode %APPDATA%\\Code\\User\\globalStorage\\saoudrizwan.claude-dev\\settings\\cline_mcp_settings.json\n\nAdd the Tavily server configuration to the file:\n\nReplace your-api-key-here with your actual Tavily API key.\n\n{ \"mcpServers\": { \"tavily-mcp\": { \"command\": \"npx\", \"args\": [\"-y\", \"tavily-mcp@0.1.4\"], \"env\": { \"TAVILY_API_KEY\": \"your-api-key-here\" }, \"disabled\": false, \"autoApprove\": [] } } }\n\nSave the file and restart Cline if it's already running.\n\nWhen using Cline, you'll now have access to the Tavily MCP tools. You can ask Cline to use the tavily-search and tavily-extract tools directly in your conversations.\n\nNote: Requires Cursor version 0.45.6 or higher\n\nTo set up the Tavily MCP server in Cursor:\n\nOpen Cursor Settings\n\nNavigate to Features > MCP Servers\n\nClick on the \"+ Add New MCP Server\" button\n\nFill out the following information:\n\nName: Enter a nickname for the server (e.g., \"tavily-mcp\")\n\nType: Select \"command\" as the type\n\nCommand: Enter the command to run the server:\n\nenv TAVILY_API_KEY=your-api-key npx -y tavily-mcp@0.1.4\n\nImportant: Replace your-api-key with your Tavily API key. You can get one at app.tavily.com/home\n\nAfter adding the server, it should appear in the list of MCP servers. You may need to manually press the refresh button in the top right corner of the MCP server to populate the tool list.\n\nThe Composer Agent will automatically use the Tavily MCP tools when relevant to your queries. It is better to explicitly request to use the tools by describing what you want to do (e.g., \"User tavily-search to search the web for the latest news on AI\"). On mac press command + L to open the chat, select the composer option at the top of the screen, beside the submit button select agent and submit the query when ready.\n\nReplace your-api-key-here with your actual Tavily API key.\n\nClone the repository:\n\nInstall dependencies:\n\nnpm install\n\nBuild the project:\n\nnpm run build\n\nFollow the configuration steps outlined in the Configuring the Claude Desktop app section above, using the below JSON configuration.\n\nReplace your-api-key-here with your actual Tavily API key and /path/to/tavily-mcp with the actual path where you cloned the repository on your system.\n\nOnce the installation is complete, and the Claude desktop app is configured, you must completely close and re-open the Claude desktop app to see the tavily-mcp server. You should see a hammer icon in the bottom left of the app, indicating available MCP tools, you can click on the hammer icon to see more detial on the tavily-search and tavily-extract tools.\n\nNow claude will have complete access to the tavily-mcp server, including the tavily-search and tavily-extract tools. If you insert the below examples into the Claude desktop app, you should see the tavily-mcp server tools in action.\n\nGeneral Web Search:\n\nNews Search:\n\nDomain-Specific Search:\n\nExtract Article Content:\n\nYou can also combine the tavily-search and tavily-extract tools to perform more complex tasks.\n\nServer Not Found\n\nVerify the npm installation by running npm --verison\n\nCheck Claude Desktop configuration syntax by running code ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n\nEnsure Node.js is properly installed by running node --version\n\nNPX related issues\n\nIf you encounter errors related to npx, you may need to use the full path to the npx executable instead.\n\nYou can find this path by running which npx in your terminal, then replace the \"command\": \"npx\" line with \"command\": \"/full/path/to/npx\" in your configuration.\n\nAPI Key Issues\n\nConfirm your Tavily API key is valid\n\nCheck the API key is correctly set in the config\n\nVerify no spaces or quotes around the API key",
      "# [Tavily Search](https://python.langchain.com/docs/integrations/tools/tavily_search/)\nTavily's Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\n\nClassPackageSerializableJS supportPackage latestTavilySearchlangchain-tavily✅❌\n\nReturns artifactNative asyncReturn dataPricing❌✅title, URL, content snippet, raw_content, answer, images1,000 free searches / month\n\nThe integration lives in the langchain-tavily package.\n\nWe also need to set our Tavily API key. You can get an API key by visiting this site and creating an account.\n\nHere we show how to instantiate an instance of the Tavily search tool. The tool accepts various parameters to customize the search. After instantiation we invoke the tool with a simple query. This tool allows you to complete search queries using Tavily's Search API endpoint.\n\nInstantiation The tool accepts various parameters during instantiation:\n\nmax_results (optional, int): Maximum number of search results to return. Default is 5.\n\ntopic (optional, str): Category of the search. Can be \"general\", \"news\", or \"finance\". Default is \"general\".\n\ninclude_answer (optional, bool): Include an answer to original query in results. Default is False.\n\ninclude_raw_content (optional, bool): Include cleaned and parsed HTML of each search result. Default is False.\n\ninclude_images (optional, bool): Include a list of query related images in the response. Default is False.\n\ninclude_image_descriptions (optional, bool): Include descriptive text for each image. Default is False.\n\nsearch_depth (optional, str): Depth of the search, either \"basic\" or \"advanced\". Default is \"basic\".\n\ntime_range (optional, str): The time range back from the current date to filter results - \"day\", \"week\", \"month\", or \"year\". Default is None.\n\ninclude_domains (optional, List[str]): List of domains to specifically include. Default is None.\n\nexclude_domains (optional, List[str]): List of domains to specifically exclude. Default is None.\n\nFor a comprehensive overview of the available parameters, refer to the Tavily Search API documentation\n\nThe Tavily search tool accepts the following arguments during invocation:\n\nquery (required): A natural language search query\n\nThe following arguments can also be set during invocation : include_images, search_depth , time_range, include_domains, exclude_domains, include_images\n\nFor reliability and performance reasons, certain parameters that affect response size cannot be modified during invocation: include_answer and include_raw_content. These limitations prevent unexpected context window issues and ensure consistent results.\n\nNOTE: The optional arguments are available for agents to dynamically set, if you set an argument during instantiation and then invoke the tool with a different value, the tool will use the value you passed during invocation.\n\nWe can also invoke the tool with a model-generated ToolCall, in which case a ToolMessage will be returned:\n\nWe can use our tools directly with an agent executor by binding the tool to the agent. This gives the agent the ability to dynamically set the available arguments to the Tavily search tool.\n\nIn the below example when we ask the agent to find \"What nation hosted the Euro 2024? Include only wikipedia sources.\" the agent will dynamically set the argments and invoke Tavily search tool : Invoking tavily_search with {'query': 'Euro 2024 host nation', 'include_domains': ['wikipedia.org']\n\nWe will need to install langgraph:\n\nFor detailed documentation of all Tavily Search API features and configurations head to the API reference: https://docs.tavily.com/documentation/api-reference/endpoint/search",
      "# [LLM Enhanced Web Search: The Tavily & Lang Chain by marcinrutecki on 2024-04-03](https://www.kaggle.com/code/marcinrutecki/llm-enhanced-web-search-the-tavily-lang-chain/notebook)\n",
      "# [Tavily — The API-powered Alternative to Perplexity? by AI Rabbit, medium.com on 2025-02-13](https://medium.com/codex/tavily-the-api-powered-alternative-to-perplexity-edfdc6814b39)\nPerplexity is yet another fascinating innovation in the AI space, and it has been around for a while now. It has managed to establish itself as a real and imho better alternative to Google (even Google AI) by offering more control over the search itself (like choosing the model, the depth of the AI search, and so on).\n\nHowever, Perplexity is more focused on the user interface and experience (UI/UX). When it comes to integrating with other tools — such as workflows on make.com or n8n, agents, or chatbots — you typically need an API. Although Perplexity does have an API, it is mainly for AI LLM inference.\n\nIn its simplest form, the API should simply answer questions using internet search and AI.\n\nAnd here is where Tavily steps in. If you haven’t heard of them, they’re the driving force behind the open source research gpt.\n\nWith GPT Researcher, you can do exactly what you would expect: AI-powered research using facts from the internet or even on-premise documents, powered by LLMs. It has become incredibly powerful. It’s worth taking a look at.\n\nSo what is Tavily about?\n\nIn simple terms, Tavily is a search service (like Serper or serpapi) with one big advantage: it is built from the ground up for LLM search. Put plainly, you can just ask a question and it can search the internet for you, then answer that specific question. Best of all, it’s entirely accessible via an API.\n\nHere’s an example scenario you can try in the playground:\n\nLet’s say you don’t have time to follow all the news, and you just want a summary from the last week.\n\nYou could simply do something like:\n\nwhat are the latest news form the us administration? summarize in 500 words.\n\nYou can simply ask the question and:\n\n…ask it to provide an answer (not just the search results).\n\nThen select the days back, for example from the last week.",
      "# [Tavily Search MCP Agent](https://glama.ai/mcp/servers/@arben-adm/tavily-mcp-search)\n🔍 My Tavily Search MCP Agent\n\nI've created a powerful Model Context Protocol (MCP) Server powered by the Tavily API. With this, you can get high-quality, reliable information from business, news, finance, and politics - all through a robust and developer-friendly interface.\n\n🌟 Why I Built Tavily Search MCP\n\nIn today's fast-paced digital landscape, I recognized the need for quick access to precise information. I needed a web search tool that works with my sequential thinking MCP server. That's why I developed Tavily Search MCP, which excels with:\n\n⚡️ Lightning-fast async search responses\n\n🛡️ Built-in fault tolerance with automatic retries\n\n🎯 Clean, markdown-formatted results\n\n🔍 Smart content snippets\n\n🛠️ Comprehensive error handling\n\n🖼️ Optional image results\n\n📰 Specialized news search\n\n🚀 Quick Start\n\nInstalling via Smithery\n\nTo install Tavily Search for Claude Desktop automatically via Smithery:\n\nnpx -y @smithery/cli install mcp-tavily-search --client claude\n\nInstalling Manually\n\nHere's how you can get up and running with my project in minutes:\n\n# 1. Create environment uv venv && .venv\\Scripts\\activate # Windows # OR uv venv && source .venv/bin/activate # Unix/MacOS # 2. Install dependencies uv pip install -e . # 3. Set up configuration echo TAVILY_API_KEY=your-key-here > .env # 4. Start server cd mcp_tavily_search && uv run server.py\n\n💡 Core Features\n\n⚡️ Performance & Reliability\n\nI've implemented asynchronous request handling\n\nBuilt-in error handling and automatic retries\n\nConfigurable request timeouts\n\nComprehensive logging system\n\n🎯 Search Configuration\n\nI've made the search depth configurable (basic/advanced)\n\nAdjustable result limits (1-20 results)\n\nClean markdown-formatted output\n\nSnippet previews with source URLs\n\nOptional image results\n\nSpecialized news search topic\n\n🛡️ Error Handling\n\nAPI authentication validation\n\nRate limit detection\n\nNetwork error recovery\n\nRequest timeout management\n\n🛠️ Developer Integration\n\nPrerequisites\n\nPython 3.11 or higher\n\nUV Package Manager (Installation Guide)\n\nTavily API key (Get one here)\n\nClaude Desktop Setup\n\nI've optimized the Claude Desktop experience with this configuration:\n\n{ \"mcpServers\": { \"tavily-search\": { \"command\": \"uv\", \"args\": [ \"--directory\", \"/path/to/mcp-tavily-search/mcp_tavily_search\", \"run\", \"server.py\" ], \"env\": { \"TAVILY_API_KEY\": \"YOUR-API-KEY\" } } } }\n\n📁 Configuration paths:\n\nWindows: %APPDATA%\\Claude\\claude_desktop_config.json\n\nUnix/MacOS: ~/.config/Claude/claude_desktop_config.json\n\nProject Architecture\n\nI've designed a clean, modular structure to make development a breeze:\n\nmcp-tavily-search/ ├── mcp_tavily_search/ # Core package │ ├── server.py # Server implementation │ ├── client.py # Tavily API client │ ├── test_server.py # Server tests │ ├── test_client.py # Client tests │ └── __init__.py # Package initialization ├── .env # Environment configuration ├── README.md # Documentation └── pyproject.toml # Project configuration\n\nKey Components\n\nServer (server.py)\n\nI've implemented the MCP protocol\n\nRequest handling and routing\n\nError recovery and health monitoring\n\nClient (client.py)\n\nTavily API integration\n\nRetry mechanism with exponential backoff\n\nResult formatting and processing\n\nError handling and logging\n\nTests (test_server.py and test_client.py)\n\nComprehensive unit tests for both server and client\n\nEnsures reliability and correctness of the implementation\n\nUsage Examples\n\nHere are some examples of how to use the enhanced search capabilities I've implemented:\n\nBasic search:\n\n{ \"name\": \"search\", \"arguments\": { \"query\": \"Latest news on artificial intelligence\" } }\n\nAdvanced search with images:\n\n{ \"name\": \"search\", \"arguments\": { \"query\": \"Elon Musk SpaceX achievements\", \"search_depth\": \"advanced\", \"include_images\": true, \"max_results\": 10 } }\n\nNews-specific search:\n\n{ \"name\": \"search\", \"arguments\": { \"query\": \"Climate change impact on agriculture\", \"topic\": \"news\", \"max_results\": 5 } }\n\nSearch with raw content:\n\n{ \"name\": \"search\", \"arguments\": { \"query\": \"Python programming best practices\", \"include_raw_content\": true, \"max_results\": 3 } }\n\nTroubleshooting Guide\n\nConnection Issues\n\nIf things don't work as expected, follow these steps I've outlined:\n\nVerify your configuration paths\n\nCheck the Claude Desktop logs:\n\n# Windows type %APPDATA%\\Claude\\logs\\latest.log # Unix/MacOS cat ~/.config/Claude/logs/latest.log\n\nTest the server manually using the quick start commands\n\nAPI Troubleshooting\n\nIf you're experiencing API issues:\n\nValidate your API key permissions\n\nCheck your network connection\n\nMonitor the API response in the server logs\n\nRunning Tests\n\nTo run the unit tests for this project, follow these steps:\n\nInstall the development dependencies:\n\nuv pip install -e \".[dev]\"\n\nRun the tests using pytest:\n\npytest mcp_tavily_search\n\nThis will run all the tests in the mcp_tavily_search directory, including both test_client.py and test_server.py.\n\nCommunity and Support\n\nI encourage you to report issues and contribute on GitHub\n\nShare your implementations and improvements\n\nJoin our discussions and help others\n\nSecurity and Best Practices\n\nSecurity is paramount in my implementation. The server includes:\n\nSecure API key handling through environment variables\n\nAutomatic request timeout management\n\nComprehensive error tracking and logging\n\nLicense\n\nI've licensed this project under MIT. See the LICENSE file for details.\n\nAcknowledgments\n\nI'd like to give special thanks to:",
      "# [Common Tools](https://ai.pydantic.dev/common-tools/)\nPydanticAI ships with native tools that can be used to enhance your agent's capabilities.\n\nDuckDuckGo Search Tool\n\nThe DuckDuckGo search tool allows you to search the web for information. It is built on top of the DuckDuckGo API.\n\nInstallation\n\nTo use duckduckgo_search_tool, you need to install pydantic-ai-slim with the duckduckgo optional group:\n\nUsage\n\nHere's an example of how you can use the DuckDuckGo search tool with an agent:\n\nTavily Search Tool\n\nInfo\n\nTavily is a paid service, but they have free credits to explore their product.\n\nYou need to sign up for an account and get an API key to use the Tavily search tool.\n\nThe Tavily search tool allows you to search the web for information. It is built on top of the Tavily API.\n\nInstallation\n\nTo use tavily_search_tool, you need to install pydantic-ai-slim with the tavily optional group:\n\nUsage\n\nHere's an example of how you can use the Tavily search tool with an agent:",
      "# [Google Colab](https://colab.research.google.com/drive/1dWGtS3u4ocCLebuaa8Ivz7BkZ_40IgH1)\n",
      "# [Purpose of agentic search - Travily on 2024-06-11](https://community.deeplearning.ai/t/purpose-of-agentic-search-travily/645163)\nHello Vdurga. Large Language Models does not come with the behavior you saw in OpenAI ChatGPT. What you are seeing in ChatGPT is a similar pattern that is explained in the lesson 2 and 3. Maybe Openai is using an own ‘homemade’ tool, with a similar purpose of Tavily.\n\nFor weather scenario of the examples in lesson 2 and 3, ChatGPT already have available tools, but regarding scenarios where there is no tool, lesson 2 and 3 gives an example about how to solve these cases.\n\nI’m not sure.\n\nI think the purpose of using Agentic Search is that it uses specialized tools such as Tavily, to provide curated search results, relevant to each step of our agentic workflow where web search is required.\n\nIn the case example of “Lesson 2: LangGraph components” a promp asking about the weather is used. This is simple enough that a chatGPT prompt like the one you shared would be enough to solve the problem. However Agentic Search can be integrated into a more complex multi-step process where the list of URLs returned by Tavily is used to feed other parts of the application that together create an application with extensive capabilities beyond what an LLM model alone has.\n\nIn other words, I think the purpose of Agentic search may be to provide curated relevant links to each process step of our agentic workflow where that information is needed.\n\nWhy to use this new tool, Tavily, to do that curated search instead of the gpt model?. I’m not sure. I think perhaps because when we connect though OpenAI’s API to the the gpt-4o model, what we get is access only to the model, and not to the tools that the chatGPT interface uses in combination with the model, to connect with the internet and provide current information.",
      "# [AI Agents in LangGraph on 2024-06-02](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/)\nLangChain, a popular open source framework for building LLM applications, recently introduced LangGraph. This extension allows developers to create highly controllable agents.\n\nIn this course you will learn to build an agent from scratch using Python and an LLM, and then you will rebuild it using LangGraph, learning about its components and how to combine them to build flow-based applications.\n\nAdditionally, you will learn about agentic search, which returns multiple answers in an agent-friendly format, enhancing the agent’s built-in knowledge. This course will show you how to use agentic search in your applications to provide better data for agents to enhance their output.\n\nIn detail:\n\nBuild an agent from scratch, and understand the division of tasks between the LLM and the code around the LLM.\n\nImplement the agent you built using LangGraph.\n\nLearn how agentic search retrieves multiple answers in a predictable format, unlike traditional search engines that return links.\n\nImplement persistence in agents, enabling state management across multiple threads, conversation switching, and the ability to reload previous states.\n\nIncorporate human-in-the-loop into agent systems.\n\nDevelop an agent for essay writing, replicating the workflow of a researcher working on this task.\n\nStart building more controllable agents using LangGraph!"
    ],
    "# Tavily Company and Product Report\n\n## Company Overview\n\nTavily is an innovative technology company focused on providing advanced search capabilities tailored for AI applications. Their primary offering is the Tavily Search API, which is designed to deliver real-time, accurate, and factual search results optimized for large language models (LLMs) and AI agents. Tavily aims to simplify the process of integrating web search into AI workflows, allowing developers to access relevant information without the complexities of traditional search engines [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n\n### Key Features and Offerings\n\n- **Tavily Search API**: This API aggregates data from multiple sources, scoring and filtering results to provide the most relevant content in a single call. It is particularly beneficial for AI developers who require precise and contextual information for their applications [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n  \n- **Company Researcher Tool**: This tool integrates Tavily's search and extraction capabilities to automate the process of gathering detailed insights about companies. It utilizes a multi-stage workflow that includes grounding in verified data, sub-question generation, and AI-driven clustering to ensure accuracy and relevance [(Weiss, 2024)](https://blog.tavily.com/companyresearcher/).\n\n- **Integration with Zapier**: Tavily can be easily integrated into various business processes through Zapier, allowing for automated workflows that can generate reports, prepare meeting information, and more [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n\n## Recent Developments\n\n- **JavaScript Package Release**: On October 12, 2024, Tavily announced the release of its official JavaScript package on NPM, making it easier for developers to integrate Tavily's capabilities into their applications [(Tavily JavaScript package, 2024)](https://community.tavily.com/t/tavily-javascript-package-now-available-on-npm/172).\n\n- **Performance Improvements**: Users have reported improvements in response times, with the API now capable of delivering results in under 4 seconds for certain queries, enhancing the user experience for real-time applications [(API performance, 2024)](https://community.tavily.com/t/api-performance/115).\n\n- **New Features**: Tavily has introduced a time_range argument for its API, allowing users to filter search results based on specific time frames, which is particularly useful for applications requiring up-to-date information [(Can we date bound the Tavily API, 2024)](https://community.tavily.com/t/can-we-date-bound-the-tavily-api-like-we-do-for-days-while-using-topic-news/210).\n\n## Company Scale and Financials\n\nWhile specific financial details and employee counts are not publicly disclosed, Tavily is positioned as a growing player in the AI and search technology space, with increasing interest from developers and businesses looking to leverage AI for enhanced data retrieval and analysis. The company has been actively engaging with users to refine its offerings and expand its capabilities [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n\n## Executive Insights\n\nTavily's leadership team comprises AI researchers and developers passionate about improving access to accurate information. Their mission emphasizes the importance of providing unbiased and factual data to empower users and organizations [(Tavily Docs, 2024)](https://docs.tavily.com/integrations/zapier).\n\n## User Feedback and Market Reception\n\nFeedback from users has been generally positive, highlighting Tavily's ease of integration and the quality of search results. However, some users have noted initial performance issues, which the company has addressed through ongoing improvements and optimizations [(Response times are slow, 2024)](https://community.tavily.com/t/response-times-are-slow/131).\n\n## Conclusion\n\nTavily is carving out a niche in the AI-driven search market with its specialized API designed for LLMs and AI agents. With recent enhancements and a focus on user feedback, Tavily is well-positioned for growth as demand for intelligent search solutions continues to rise. Prospective candidates and investors should consider Tavily's innovative approach and commitment to improving AI capabilities in data retrieval and analysis."
  ],
  "lineage": {
    "run_at": "2025-03-28T23:46:51.831607",
    "git_sha": "9e00c41"
  }
}