{
  "summary_markdown": "# About Tavily\n\nTavily is a technology company founded on May 12, 2024, that specializes in providing advanced AI tools and services, particularly in the realm of real-time data access and search capabilities for AI applications [(Crunchbase, 2025)](https://www.crunchbase.com/organization/tavily). The company focuses on bridging the gap between large language models (LLMs) and real-time web data, enhancing the capabilities of AI agents. Tavily's offerings are primarily B2B, targeting AI developers, researchers, and enterprises looking to integrate advanced AI capabilities into their applications.\n\n## Products and Services\n\n- **Tavily Search API**: A search engine optimized for LLMs, providing efficient and persistent search results tailored for AI developers and autonomous agents. It aggregates data from multiple sources in a single API call, filtering and ranking content for relevance [(Minh Le Duc, Medium, 2024-07-29)](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e).\n\n- **GPT Researcher**: An open-source autonomous research agent that automates the process of gathering and synthesizing information from the web. It is designed to produce detailed, factual, and unbiased research reports by scraping and aggregating data from various online sources [(Rotem Weiss, Tavily Blog, 2024-11-18)](https://blog.tavily.com/companyresearcher/).\n\n- **Custom Solutions**: Tavily provides tailored solutions for enterprises looking to enhance their AI applications with real-time data capabilities.\n\n## Revenue and Distribution\n\nWhile specific revenue figures are not provided, Tavily generates income through its API services and custom solutions for enterprises. The company's products are distributed primarily through digital channels, allowing developers and organizations to integrate Tavily's tools into their existing systems.\n\n## Company Evolution\n\nTavily has quickly positioned itself as a leader in AI-optimized search engines, focusing on real-time data access and integration with AI applications. The company emphasizes community engagement and continuous improvement, reflecting a proactive approach to product development [(Tavily Community, 2024-09-10)](https://community.tavily.com/t/response-times-are-slow/131).\n\n# Key Personnel\n\nSpecific details about Tavily's leadership team are not provided in the available sources. However, the company is led by a group of AI researchers and developers passionate about advancing AI technology and its applications. The overall sentiment from the company’s communications emphasizes a commitment to improving user experience and providing high-quality, reliable data for AI applications.\n\n# News\n\n## Product Developments\n\n- **New Features**: On July 30, 2024, Tavily introduced an \"invoices\" tab on its dashboard, allowing users to view and download their invoices directly, a feature that was highly requested by users [(Tavily Community, 2024-07-30)](https://community.tavily.com/t/invoices-now-available-on-the-tavily-dashboard/58).\n\n## Community Engagement\n\n- **User Feedback**: Tavily has been actively engaging with its user community, addressing feedback regarding response times and optimizing the API for better performance. Users have reported response times averaging around three seconds, which can vary based on query complexity [(Tavily Community, 2024-09-10)](https://community.tavily.com/t/response-times-are-slow/131).\n\n## Market Position\n\nTavily is positioned as a leader in the niche of AI-optimized search engines, catering specifically to developers and organizations that require accurate and timely information for their AI applications. The company is leveraging the growing demand for AI solutions across various industries, which is expected to continue expanding in the coming years [(Minh Le Duc, Medium, 2024-07-29)](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e).\n\n# Conclusion\n\nTavily is a forward-thinking company making significant strides in the AI and search technology space. With its specialized search API and commitment to providing accurate, real-time information, Tavily is well-positioned to meet the evolving needs of AI developers and organizations. The recent enhancements to its product offerings and active engagement with the user community further solidify its reputation as a reliable partner in the AI landscape. For prospective candidates and investors, Tavily represents a promising opportunity in a rapidly growing market, driven by innovation and a strong focus on user needs.",
  "target": [
    "Tavily",
    "Tavily",
    "tavily.com",
    null,
    false,
    false
  ],
  "webpage_result": {
    "summary_markdown": "# Tavily Company Overview\n\n## Company History\nTavily is a technology company focused on providing advanced AI tools and services, particularly in the realm of real-time data access and search capabilities for AI applications. The company aims to bridge the gap between large language models (LLMs) and real-time web data, enhancing the capabilities of AI agents.\n\n## Services\nTavily offers a range of services designed to optimize the integration of AI with real-time data:\n\n- **Tavily Search API**: A search engine optimized for LLMs, providing efficient and persistent search results tailored for AI developers and autonomous agents. It aggregates data from multiple sources in a single API call, filtering and ranking content for relevance.\n  \n- **GPT Researcher**: An open-source autonomous research agent that automates the process of gathering and synthesizing information from the web. It is designed to produce detailed, factual, and unbiased research reports by scraping and aggregating data from various online sources.\n\n- **Custom Solutions**: Tavily provides tailored solutions for enterprises looking to enhance their AI applications with real-time data capabilities.\n\n## Products\n- **Tavily Search API**: Focused on delivering relevant search results for AI applications, it allows developers to customize search parameters and manage domain-specific queries.\n  \n- **GPT Researcher**: This tool automates research tasks, generating comprehensive reports by leveraging multiple web sources and LLMs for summarization and analysis.\n\n## Customers\nTavily serves a diverse clientele, including AI developers, researchers, and enterprises looking to integrate advanced AI capabilities into their applications. The company emphasizes collaboration with its users to refine and enhance its offerings.\n\n## Leadership Team\nWhile specific details about the leadership team are not provided, Tavily is led by a group of AI researchers and developers passionate about advancing AI technology and its applications.\n\n## Culture\nTavily promotes a culture of innovation and collaboration, encouraging community engagement through forums and discussions. The company values feedback from its users to continuously improve its products and services.\n\n## Community Engagement\nTavily fosters a community for developers and users to share knowledge, ask questions, and discuss improvements related to its products. This includes forums for API discussions, documentation suggestions, and general community interactions.\n\n## Conclusion\nTavily is positioned as a leader in providing AI tools that connect LLMs with real-time web data, enhancing the capabilities of AI applications through innovative products like the Tavily Search API and GPT Researcher. The company is committed to continuous improvement and community engagement, ensuring that its offerings meet the evolving needs of its users.\n\nFor more information, visit [Tavily](https://tavily.com/) and explore their [documentation](https://docs.tavily.com/).",
    "page_markdowns": [
      "# [Tavily](https://tavily.com/)\n1 2 3 4 from tavily import TavilyClient tavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\") response = tavily_client.search(\"Who is Leo Messi?\") print(response)\n\n1 2 3 4 const { tavily } = require('@tavily/core'); const tvly = tavily({ apiKey: \"tvly-YOUR_API_KEY\" }); tvly.search(\"Who is Leo Messi?\") .then(results => console.log(results));",
      "# [Trust Center](https://trust.tavily.com/)\n",
      "# [Tavily](https://tavily.com/privacy)\n- Performance of, or entry into, a contract with you.\n\n-Necessary for our legitimate interests.\n\n- Respond to your requests or questions.\n\n- Manage our relationship with you, including by notifying you about changes to our terms of use or Privacy Policy.\n\n- Marketing purposes.\n\n- Deliver relevant and personalized content to you, send service messages (for example, for security purposes).\n\n- Measure or understand the effectiveness of our marketing efforts.\n\n- To use data analytics to improve our Platform, products/services, marketing, customer relationships and experiences, including by personalizing and customizing our content.\n\n- Necessary for our legitimate interests (to grow our business, to inform our marketing strategy and to maintain and secure the services).\n\n- If we have obtained your prior consent (where laws require consent for such communications).\n\nIn the event of a legal dispute between you (and/or a party on your behalf) to us (and/or a party on our behalf), we may use your data to the extent necessary in connection with handling such dispute.\n\n-Required by subpoena, law, or other legal process.\n\nNecessary to assist law enforcement officials or government enforcement agencies.\n\n-Necessary to investigate violations of or otherwise enforce our terms of use, to maintain security of the Website and prevent fraudulent or illegal activity.\n\nNecessary to protect us from legal action or claims from third parties, including you and/or other users.\n\nNecessary to protect the legal rights, personal/real property, or personal safety of our company, users, employees, and affiliates.",
      "# [Tavily](https://tavily.com/terms)\n1. Defined Terms.\n\n\"AI Tools\" means artificial intelligence models, tools, and other technologies.\n\n\"Applications\" means one or more software applications (which may include, without limitation, large language models or other AI Tools) that you develop to interface with any Tavily APIs.\n\n\"Customer Data\" means any and all any data and information that you or Users provide to Tavily in connection with their use of the Services and includes, without limitation, Customer Input.\n\n\"Customer Input\" means any and all text, information, queries and other input submitted by you, Users, or an Application in connection with a Tavily API call.\n\n\"Output\" means the generated text, information, or other materials or output resulting from Customer Input.\n\n\"Services\" means the Tavily online search engine designed to deliver real-time results, including a Tavily web application and any associated Tavily application programming interface(s) (\"Tavily API(s)\").\n\n\"Support Services\" means Tavily's support services, if any, provided in connection with the Services.\n\n2. The Services.\n\nSubject to your continued compliance with the terms and conditions of this Agreement, Tavily will (a) provide access to the Services and (b) use commercially reasonable efforts to provide any Support Services that Tavily has agreed to provide to you. Tavily may update or modify the Services, in whole or in part, at any time in Tavily's sole discretion (each, an \"Update\") and may require you to obtain and use the most recent version of the Services. Updates may adversely affect your Applications. You are required to make any changes to your Applications that are required for integration as a result of such Update at your sole cost and expense. Your continued use of the Services following an Update constitutes your binding acceptance of the Update.\n\n3. Your Responsibilities.\n\nAccounts. You and your users (each, a \"User\") may be required to create an account (which may include a Tavily API security key) (an \"Account\") to access and use the Services. You (i) may not, and will ensure that Users do not, share Account information (including Tavily API security keys) with any third party, (ii) will keep, and ensure that all Users keep, each Account and all information (including API security keys) secure, and (iii) will only use, and will ensure that Users only use, their Account to access the Services. You are solely responsible for all activity that occurs under your Account and is solely responsible for any and all acts and omissions of Users. Any act or omission of a User will, for purposes of this Agreement, be deemed your act or omission.\n\nGeneral Use Restrictions. The Services are provided solely for Customer’s business purposes for integration with Customer Applications. Customer will not, in whole or in part: (i) modify, copy, disclose, alter, translate or create derivative works of the Services; (ii) license, sublicense, resell, distribute, lease, rent, lend, transfer, assign or otherwise dispose of the Services (provided, that integration of the Services in Customer Applications in accordance with this Agreement will not constitute a violation of this subsection); (iii) decompile, disassemble, decode, translate, or reverse engineer the Services or otherwise attempt to learn the source code, structure, algorithms, or internal ideas underlying the Services or reduce the Services by any other means to a human-perceivable form; (iv) copy, frame or mirror any part or content of the Services; (v) access the Services in order to build a competitive product or service; (vi) overburden the Services (including, without limitation, making excess Tavily API calls) or interfere with or disrupt the integrity or performance of the Services or input, upload, transmit, or otherwise provide any harmful code to or through the Services; (vii) use any data mining, robots, or similar data gathering or extraction methods; (viii) attempt to gain unauthorized access to the Services or its related systems or networks or exceed any Customer user (“User”) limitations or other restrictions set forth on the Order Form with respect to the Services (including, without limitation, restrictions with respect to Tavily API calls); (ix) disclose to any third party any performance information or analysis relating to the Services; (x) remove, alter, or obscure any proprietary notices in or on the Services; (xi) combine or integrate the Services with any software, technology, services, or materials not authorized by Tavily; (xii) design or permit any Customer Applications to disable, override, or otherwise interfere with any Tavily-implemented communications to end users, consent screens, user settings, alerts, warning, or the like; (xiii) attempt to cloak or conceal Customer’s identity or the identity of any Customer Applications when requesting authorization to use the Tavily APIs; (xiv) use the Services in connection with or to promote any products, services, or materials that constitute, promote, or are used primarily for the purpose of dealing in spyware, adware, or other malicious programs or code, counterfeit goods, items subject to U.S. embargo, unsolicited mass distribution of email (“spam”), multi-level marketing proposals, hate materials, hacking, surveillance, interception, or descrambling equipment, libelous, defamatory, obscene, pornographic, abusive, or otherwise offensive content, stolen products, and items used for theft, hazardous materials, or any illegal activities; or (xv) attempt any of the foregoing or cause or permit any individual or entity to do any of the foregoing. Customer will not assert, nor authorize, assist or encourage any third party to assert, against any Tavily or its affiliates, any patent infringement or other intellectual property rights infringement claim regarding the Services.\n\nSetup Responsibilities.You are solely responsible for obtaining and maintaining, at your expense, all of the necessary telecommunications, computer hardware, mobile devices, software, services and Internet connectivity required by you or any User to access the Services.\n\nResponsibility for Your Applications and Customer Data. You will monitor the use of your Applications for any activity that violates applicable laws, rules, and regulations or any terms and conditions of this Agreement, including any fraudulent, inappropriate, or potentially harmful behavior, and promptly restrict any offending users of your Applications from further use of such Applications. As between you and Tavily, you are solely responsible and liable for your Applications, including, without limitation, for (i) posting any privacy notices and obtaining any consents from your end users required under applicable laws, rules, and regulations for their use of your Applications and (ii) all acts and omissions of your end users in connection with your Applications and their use of any Tavily APIs, if any. Additionally, you are solely responsible for the accuracy, quality, integrity, legality, reliability, security, and appropriateness of all Customer Data (including, without limitation, Customer Input). Tavily is not responsible for performing, and is not liable for failure to perform, any back-up of any Customer Data.\n\n4. Fees.\n\nGeneral.You will pay Tavily all fees and amounts charged by Tavily for use of the Services (collectively, the \"Fees\") in accordance with this Section 4.\n\nPayment.You will pay all Fees by (i) check, (ii) bank wire transfer in immediately available funds to an account designated by Tavily, or (iii) credit or debit card via an authorized payment processor. If by credit or debit card, you authorize Tavily (or its payment processor) to charge your credit or debit card number provided to Tavily and represent and warrant that you are authorized to use and have Fees charged to that credit or debit card. Unless otherwise communicated in writing by Tavily, all payments pursuant to this Agreement: (A) are nonrefundable; (B) will be made in U.S. Dollars; and (C) are exclusive of taxes and duties, which will be paid solely by you (other than taxes based on Tavily's net income). All Fees are payable without setoff, counterclaim, deduction, recoupment, or withholding of any kind for amounts owed or purportedly owed by Tavily under this Agreement, applicable law, or otherwise. The terms of payment specified herein may be subject to Tavily's approval of your credit, and Tavily may at any time revise the specified terms of payment to require payment in advance. Tavily may assess a late charge of the lesser of 1.5% per month or the maximum rate allowed under applicable law for all late payments. You will reimburse Tavily for all costs and expenses (including reasonable attorneys' fees) incurred by Tavily in collecting any past due amounts.\n\nModification. Tavily may modify any Fees, in whole or in part, on written notice to you.\n\n5. Confidentiality.\n\nYou may acquire certain information that is the confidential, proprietary or trade secret information of Tavily or a third party (\"Confidential Information\"). Confidential Information includes without limitation: (a) any information, whether or not marked or otherwise designated as confidential, of or relating to Tavily or the Services that is not generally available to the public, including any information relating to Tavily's methods, techniques, finances, business plans, marketing plans, legal affairs, prospects, opportunities, contracts, assets or trade secrets; and (b) any information that has been made available to or obtained by Tavily by or with respect to its customers or other third parties and which Tavily is obligated to keep confidential. You: (i) will protect Confidential Information from unauthorized disclosure using at least a reasonable degree of care; (ii) will not disclose Confidential Information to any third party; and (iii) will not use the Confidential Information for any purpose other than as expressly permitted in this Agreement. After any expiration or termination of this Agreement, or at any time upon request from Tavily, you will immediately return or destroy (at Tavily's sole direction) all materials or media containing any Confidential Information, including all copies thereof, and will certify in writing to Tavily that all such Confidential Information has been returned or destroyed. You expressly acknowledge and agree that no adequate remedy exists at law for an actual or threatened breach of this Section 5 and that in such event Tavily will be entitled to seek and obtain immediate injunctive and other equitable relief, without waiving any other rights or remedies available to it.\n\n6. Customer Data.\n\nOwnership.You own and retain all right, title, and interest in and to all Customer Data, including all intellectual property rights therein. You acknowledge and agree that you (not Tavily) have control over Customer Data stored by operation of the Services.\n\nUse of Customer Data. You hereby grant Tavily and its affiliates a worldwide, royalty-free, fully paid, transferable, assignable, sublicensable (through multiple tiers), perpetual, and irrevocable license to collect, host, use, access, view, store, copy, display, create derivative works of, delete, and otherwise process Customer Data (including providing Customer Data to applicable Third-Party Service Providers (as defined below) and others) to (i) provide, support, monitor, analyze, and improve the Services and improve Tavily's other products and services, (ii) communicate with you about your Account, (iii) comply with applicable laws, including court orders, subpoenas, and requests or requirements for information made by regulatory or investigatory entities, (iv) prevent fraud or misuse of the Services, (v) perform market research, (vi) conduct product research and improvement and development of products and services by Tavily, and/or (vii) for any other lawful purpose. Tavily may expand its use of Customer Data in its discretion if not precluded by applicable laws. Tavily will not be required to transmit or provide you or any third party with Customer Data in any format except as required by applicable laws.\n\nRights in Customer Data. You represent and warrant to Tavily that you have the rights, licenses, and permissions necessary to grant the license and use rights in this Agreement and to otherwise provide Customer Data to Tavily for use by Tavily as contemplated by this Agreement and your use of the Services. You are solely responsible for the content, accuracy, integrity, quality, and legality of Customer Data and for ensuring that you have given all notices and disclosures, and obtained all consents and permissions, necessary for (i) you to use the Services (including, without limitation, to send any communications or other information or materials via the Services), (ii) your collection, use and disclosure of Customer Data, and (iii) Tavily to collect, use, and disclose Customer Data. You will not, and will ensure that third parties do not, include in Customer Data or otherwise upload, post, reproduce, or distribute any information, software, or other material protected by copyright, privacy rights, or any other intellectual property rights without first obtaining the permission of the owner of such rights.\n\n7. Intellectual Property.\n\nTavily Ownership. Subject to the rights and licenses granted to you under this Agreement, Tavily owns and will continue to own all rights, title, and interest in and to (i) the Services and Support Services, including, without limitation, any derivative work, enhancement, update, customization, modification, adaptation, alteration, upgrade, new feature, or other improvement thereof or thereto, (ii) all comments, user input, suggestions, comments, and other feedback provided by you or any User with respect to the foregoing (\"Feedback\"), and (iii) all Usage Data (as defined below). You hereby assign to Tavily all rights (including intellectual property rights), title, and interest in and to all Feedback. Except as expressly set forth in this Agreement, no express or implied license or right of any kind is granted to you regarding the foregoing, including, without limitation, any right to obtain possession of any source code, data or other technical material related to the foregoing.\n\nUsage Data. Notwithstanding anything to the contrary in this Agreement, you agree that Tavily may generate, collect, store, use, transfer, and/or disclose to third parties information gathered, prepared, computed, originated, or stored by Tavily resulting from the use or provision of the Services, including information derived from or based on Customer Data (\"Usage Data\") (i) to perform data analytics, (ii) to monitor, improve, and support the Services, (iii) to design, develop, and offer Tavily products and services, and (iv) for any other lawful purpose. Tavily owns and retains all rights to Usage Data, and no rights are granted to you, whether by implication, estoppel, waiver, or otherwise in or to any Usage Data. Tavily has no obligation to provide or make any Usage Data available to you.\n\n8. Indemnification.\n\nTo the maximum extent permitted by applicable law, you will indemnify and hold Tavily and its affiliates, and its and their officers, employees, and agents harmless against any damages, liabilities, losses, costs, or expenses (including reasonable attorneys' fees) arising from or in connection with (a) your access to or use of the Services, (b) Customer Data, and/or (c) your breach or alleged breach of this Agreement (each, an \"Indemnification Claim\"). Additionally, you will, at Tavily's sole election, defend Tavily from any Indemnification Claims. If Tavily directs you to defend an Indemnification Claim, then (i) Tavily has the right to approve the counsel you select to defend the Indemnification Claim and (ii) Tavily may also have its own counsel participate in the defense and settlement of the Indemnification Claim at your expense. Tavily may also exclusively retain control of the defense of an Indemnification Claim. You will not settle an Indemnification Claim without Tavily's written consent. 9. Disclaimers.\n\n9. Disclaimers.\n\nGeneral Disclaimers. THE SERVICES AND SUPPORT SERVICES ARE PROVIDED ON AN \"AS IS\" AND \"AS AVAILABLE\" BASIS WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, OR TITLE, AND ANY WARRANTIES ARISING OUT OF ANY COURSE OF DEALING OR USAGE OF TRADE. TAVILY DOES NOT WARRANT, AND SPECIFICALLY DISCLAIMS, THAT THE SERVICES WILL OPERATE UNINTERRUPTED, BE ERROR-FREE, OR THAT ALL DEFECTS WILL BE CORRECTED.\n\nAdditional Disclaimers Regarding Output.WITHOUT LIMITING THE FOREGOING DISCLAIMER, TAVILY MAKES NO, AND SPECIFICALLY DISCLAIMS ANY AND ALL, REPRESENTATIONS OR WARRANTIES CONCERNING THE ACCURACY, PERFORMANCE, QUALITY, RELIABILITY, SUITABILITY, OR COMPLETENESS OF ANY INFORMATION OR RESULTS OBTAINED OR DERIVED THROUGH THE USE OF THE SERVICES, INCLUDING, WITHOUT LIMITATION, ANY OUTPUT, OR THAT ANY OF THE FOREGOING WILL BE NON-INFRINGING OR OTHERWISE COMPLIANT WITH LAW OR MEET YOUR EXPECTATIONS. YOU ACKNOWLEDGE AND AGREE THAT THE OUTPUT IS AT LEAST PARTIALLY DEPENDENT ON AI TOOLS, THE USE OF WHICH MAY RESULT IN THE OUTPUT BEING INACCURATE, UNRELIABLE, INAPPROPRIATE, INFRINGING, INCOMPLETE, OR OTHERWISE UNSUITABLE OR MAY NOT MEET YOUR EXPECTATIONS. ALL OUTPUT IS PROVIDED \"AS IS,\" YOU USE ALL OUTPUT AT YOUR OWN RISK, AND YOU ARE SOLELY RESPONSIBLE FOR VETTING, EVALUATING, AND USING THE OUTPUT, INCLUDING, WITHOUT LIMITATION, ANY USE OR MODIFICATION OF CUSTOMER APPLICATIONS IN CONNECTION WITH YOUR EVALUATION AND/OR USE OF THE OUTPUT. 10. Third-Party Services.\n\n10. Third-Party Services.\n\nDefinition. Certain Services or features thereof may rely on, interoperate with, or otherwise utilize or leverage products and/or services provided by third parties (such services, \"Third-Party Services\" and the providers of such services, \"Third-Party Service Providers\").\n\nThird-Party Terms; Disclaimer.You are solely responsible and liable for complying with all terms, conditions and policies imposed by Third-Party Service Providers on Third-Party Services (\"Third-Party Terms\"). Tavily is not, and will not be deemed to be, a party to any Third-Party Terms, all of which are exclusively between you and the applicable Third-Party Service Provider(s). Tavily does not make any warranties or guarantees with respect to Third-Party Services, including the performance or continued availability of Third-Party Services and Tavily may (either itself or as required by the Third-Party Service Provider) limit or cease providing interoperation with any or all Third-Party Services (and, as a consequence, certain or all features of the Services may be limited or ceased) without entitling you to any compensation if, for example and without limitation, the Third-Party Service Provider ceases to make the Third-Party Service available for interoperation or use with the Services in a manner acceptable to Tavily. Moreover, the performance of Third-Party Services (and Third-Party Service Providers) is outside Tavily's control. TAVILY WILL NOT BE LIABLE FOR, AND TAVILY EXPRESSLY DISCLAIMS, ANY LIABILITY FOR LOSSES, COSTS, OR EXPENSES TO THE EXTENT CAUSED BY ANY THIRD-PARTY SERVICES OR THIRD-PARTY SERVICE PROVIDERS OR FOR YOUR COMPLIANCE (OR NON-COMPLIANCE) WITH ANY APPLICABLE THIRD-PARTY TERMS, EACH OF WHICH ARE YOUR EXCLUSIVE RESPONSIBILITY AND LIABILITY.\n\nAI Tools. Without limiting the foregoing, as between the parties, you are solely responsible for your use of AI Tools in connection with the Services (including, without limitation, as used by Tavily to generate Output in connection with Customer Input). You acknowledge and agree that (i) your or Tavily's use of AI Tools may involve access to Customer Inputs by Third-Party Service Providers and that such access may occur pursuant to agreements between Tavily and such Third-Party Service Providers, rather than this Agreement, (ii) such AI Tools are not under the control of Tavily and do not form part of the Services, (iii) Tavily makes no representations or warranties with respect to such AI Tools or any Customer Input or Output provided or generated in connection therewith, and (iv) you use all AI Tools (and any Customer Input or Output provided or generated in connection therewith) at your own risk. You consent and authorize Tavily to share Customer Input and Output with AI Tools to the extent required to perform the Services and acknowledges and agrees that Third-Party Service Providers may not be required to maintain the confidentiality of any Customer Input or Output and may retain certain rights to use or disclose Customer Input and Output, including to further train their algorithmic models.\n\n11. Limitation of Liability.\n\nTO THE MAXIMUM EXTENT PERMITTED UNDER APPLICABLE LAW, UNDER NO CIRCUMSTANCES WILL (A) TAVILY OR ANY OF ITS SERVICE PROVIDERS BE LIABLE TO YOU OR ANY THIRD PARTY FOR PERSONAL INJURY, PROPERTY DAMAGE, ERROR OR INTERRUPTION OF USE, LOSS, INACCURACY, OR CORRUPTION OF DATA, COVER, LOST PROFITS OR REVENUE, LOSS OF BUSINESS, OR ANY CONSEQUENTIAL, INDIRECT, SPECIAL, EXEMPLARY, PUNITIVE, OR INCIDENTAL DAMAGES, REGARDLESS OF THE FORM IN WHICH THE ACTION IS BROUGHT (INCLUDING NEGLIGENCE), ARISING OUT OF OR RELATING TO THE RELATIONSHIP BETWEEN THE PARTIES (INCLUDING THIS AGREEMENT), INCLUDING THE USE OR INABILITY TO USE THE SERVICES, WHETHER OR NOT TAVILY HAS BEEN ADVISED OF THE POSSIBILITY OF ANY SUCH DAMAGES, OR (B) TAVILY'S TOTAL LIABILITY UNDER THIS AGREEMENT, REGARDLESS OF LEGAL THEORY (INCLUDING NEGLIGENCE), EXCEED, IN THE AGGREGATE FOR ALL CLAIMS, THE FEES PAID TO TAVILY BY YOU IN THE 3-MONTH PERIOD PRECEDING THE DATE ON WHICH THE FIRST CLAIM AROSE AND ASSOCIATED WITH THE SPECIFIC SERVICES PROVIDED. MULTIPLE CLAIMS WILL NOT EXPAND THESE LIMITATIONS. THE PARTIES ACKNOWLEDGE THAT THIS SECTION 11 REFLECTS THE AGREED UPON ALLOCATION OF RISK BETWEEN THE PARTIES AND THAT NEITHER PARTY WOULD ENTER INTO THIS AGREEMENT WITHOUT THESE LIMITATIONS ON ITS LIABILITY. THIS LIMITATION ON LIABILITY WILL APPLY DESPITE THE FAILURE OF ESSENTIAL PURPOSE OF ANY LIMITED REMEDY SET FORTH IN THIS AGREEMENT.\n\n12. Term and Termination; Effect of Termination or Expiration.\n\nThis Agreement will begin on the date you accept this Agreement and will continue until (a) we terminate this Agreement upon notice to you, which we may do at any time for any reason, (b) you terminate this Agreement by cancelling your Account or otherwise terminating your use of the Services, or (c) as otherwise stated when you purchased access to the Services. Upon any termination of this Agreement, (i) your right to access and use the Services will immediately cease, (ii) you will promptly permanently erase all keys, programming instructions, tools, protocols, and other materials made available to you in connection with the Tavily APIs, (iii) you will pay Tavily all outstanding amounts due and owing, and (iv) this sentence and Sections 2, 4, and 6 through 11 will survive.\n\n13. Arbitration.\n\nPLEASE READ THIS SECTION CAREFULLY BECAUSE IT REQUIRES YOU AND TAVILY TO ARBITRATE CERTAIN DISPUTES AND CLAIMS AND LIMITS THE MANNER IN WHICH THE PARTIES CAN SEEK RELIEF FROM EACH OTHER. ARBITRATION PRECLUDES YOU AND TAVILY FROM SUING IN COURT OR HAVING A JURY TRIAL. YOU AND TAVILY AGREE THAT ARBITRATION WILL BE SOLELY ON AN INDIVIDUAL BASIS AND NOT AS A CLASS ARBITRATION, CLASS ACTION, OR ANY OTHER KIND OF REPRESENTATIVE PROCEEDING. TAVILY AND YOU ARE EACH WAIVING THE RIGHT TO TRIAL BY A JURY.\n\nFOLLOW THE INSTRUCTIONS BELOW IF YOU WISH TO OPT OUT OF THE REQUIREMENT OF ARBITRATION ON AN INDIVIDUAL BASIS. NO CLASS OR REPRESENTATIVE ACTIONS OR ARBITRATIONS ARE ALLOWED UNDER THIS ARBITRATION AGREEMENT.\n\nInformal Dispute Resolution Prior to Arbitration. For any dispute or claim that you have against Tavily, that Tavily has against you, or that you have or Tavily has arising from or relating to this Agreement, the Services, or any aspect of the relationship between you and Tavily as relates to this Agreement, the Services, including any privacy or data security claims (collectively, \"Claims,\" and each a \"Claim\"), you and Tavily agree to attempt to first resolve the Claim informally via the following process:\n\nIf you assert a Claim against Tavily, you will first contact Tavily by sending a written notice of your Claim (\"Claimant Notice\") to Tavily by certified mail addressed to 33 W 60th St, New York, NY 10023 or by email to support@tavily.com. The Claimant Notice must (a) include your name, residence address, email address, and telephone number, (b) describe the nature and basis of the Claim, and (c) set forth the specific relief sought.\n\nIf Tavily asserts a Claim against you, Tavily will first contact you by sending a written notice of Tavily’s Claim (\"Tavily Notice\"), and each of a Claimant Notice and Tavily Notice, a \"Notice\") to you via email to the primary email address associated with your account. The Tavily Notice must (a) include the name of a Tavily contact and the contact’s email address and telephone number, (b) describe the nature and basis of the Claim, and (c) set forth the specific relief sought.\n\nIf you and Tavily cannot reach an agreement to resolve the Claim within thirty (30) days after you or Tavily receives such a Notice, then either party may submit the Claim to binding arbitration as set forth below. The statute of limitations and any filing fee deadlines shall be tolled for thirty (30) days from the date that either you or Tavily first send the applicable Notice so that the parties can engage in this informal dispute-resolution process.\n\nClaims Subject to Binding Arbitration; Exceptions.Except for individual disputes that qualify for small claims court and any disputes exclusively related to the intellectual property or intellectual property rights of you or Tavily, including any disputes in which you or Tavily seek injunctive or other equitable relief for the alleged unlawful use of your or Tavily's intellectual property or other infringement of your or Tavily’s intellectual property rights (\"IP Claims\"), all Claims, whether based in contract, tort, statute, fraud, misrepresentation, or any other legal theory, including Claims that are not related to intellectual property or intellectual property rights but are jointly filed with IP Claims, that are not resolved in accordance with Section 13(a) will be resolved by a neutral arbitrator through final and binding arbitration instead of in a court by a judge or jury. Such Claims include, without limitation, disputes arising out of or relating to interpretation or application of this arbitration provision, including the enforceability, revocability, or validity of the arbitration provision or any portion of the arbitration provision. The arbitrator will have the authority to grant any remedy or relief that would otherwise be available in court.\n\nFederal Arbitration Act. This Agreement affects interstate commerce, and the enforceability of this Section 13 will be substantively and procedurally governed by the Federal Arbitration Act, 9 U.S.C. § 1, et seq. (the \"FAA\"), to the extent permitted by law. As limited by the FAA, this Agreement, and the AAA Rules (as defined below), the arbitrator will have exclusive authority to make all procedural and substantive decisions regarding any dispute and to grant any remedy that would otherwise be available in court, including the power to determine the question of arbitrability.\n\nArbitration Procedure.All Claims must be submitted to the American Arbitration Association (the \"AAA\") and will be resolved through binding arbitration before one arbitrator. The AAA administers arbitration pursuant to the due process standards set forth by the AAA and rules set forth by the AAA. The then-current version of the AAA’s Commercial Arbitration Rules and Mediation Procedures, which are available on the AAA’s website (adr.org) (the \"AAA Rules\"), as amended by this Agreement as follows, will apply to any arbitration between you and Tavily:\n\nYOU AND TAVILY AGREE THAT ANY ARBITRATION UNDER THIS AGREEMENT WILL TAKE PLACE ON AN INDIVIDUAL BASIS; CLASS ARBITRATIONS AND CLASS ACTIONS ARE NOT PERMITTED, AND YOU AND TAVILY ARE AGREEING TO GIVE UP THE ABILITY TO PARTICIPATE IN A CLASS ACTION. The arbitrator may conduct only an individual arbitration and, except as described below for the additional procedures to govern if twenty-five (25) or more similar or coordinated claims are asserted against Tavily or you by the same or coordinated counsel, may not consolidate more than one individual’s claims, preside over any type of class or representative proceeding, or preside over any proceeding involving more than one individual.\n\nAny in-person appearances will be held in Manhattan, New York.\n\nYou and Tavily agree to cooperate to seek from the arbitrator protection for any confidential, proprietary, trade secret, or otherwise sensitive information, documents, testimony, and/or other materials that might be exchanged or the subject of discovery in the arbitration. You and Tavily agree to seek such protection before any such information, documents, testimony, and/or materials are exchanged or otherwise become the subject of discovery in the arbitration.\n\nThe arbitrator's decision will follow this Agreement and will be final and binding. The arbitrator will have authority to award temporary, interim or permanent injunctive relief or relief providing for specific performance of this Agreement, but only to the extent necessary to provide relief warranted by the individual claim before the arbitrator. The award rendered by the arbitrator may be confirmed and enforced in any court having jurisdiction thereof. Notwithstanding any of the foregoing, nothing in this Agreement will preclude you from bringing issues to the attention of federal, state or local agencies and, if the law allows, they can seek relief against Tavily for you.\n\nThe AAA Supplementary Rules for Multiple Case Filings and the AAA Multiple Consumer Case Filing Fee Schedule will apply if twenty-five (25) or more similar claims are asserted against Tavily or against you by the same or coordinated counsel or are otherwise coordinated.\n\nIn addition to the application of the AAA Supplementary Rules for Multiple Case Filings and the AAA Multiple Consumer Case Filing Fee Schedule, you and Tavily understand and agree that when twenty-five (25) or more similar claims are asserted against Tavily or you by the same or coordinated counsel or are otherwise coordinated resolution of your or Tavily 's Claim might be delayed.\n\nFor such coordinated actions, you and Tavily also agree to the following coordinated bellwether process. Counsel for claimants and counsel for Tavily shall each select ten (10) cases (per side) to proceed first in individual arbitration proceedings. The remaining cases shall be deemed filed for purposes of the statute of limitations but not for the purpose of assessing AAA fees. No AAA fees shall be assessed in connection with those cases until they are selected to proceed to individual arbitration proceedings as part of a bellwether process. If the parties are unable to resolve the remaining cases after the conclusion of the initial twenty (20) proceedings, each side shall select another ten (10) cases (per side) to proceed to individual arbitration proceedings as part of a second bellwether process.\n\nA single arbitrator shall preside over each case. Only one case may be assigned to each arbitrator as part of a bellwether process unless the parties agree otherwise.\n\nThis bellwether process shall continue, consistent with the parameters identified above, until all the claims included in these coordinated filings, including your case, are adjudicated or otherwise resolved.\n\nThe statute of limitations and any filing fee deadlines shall be tolled for claims subject to this bellwether process from the time the first cases are selected for a bellwether process until the time your or Tavily's case is selected for a bellwether process, withdrawn, or otherwise resolved.\n\nA court shall have authority to enforce this paragraph and, if necessary, to enjoin the mass filing or prosecution of arbitration demands against Tavily or you.\n\nOne Year to Assert Claims.To the extent permitted by law, any Claim by you or Tavily relating in any way to this Agreement, the Services, or any aspect of the relationship between you and Tavily as relates to this Agreement or the Services, must be filed within one year after such Claim arises; otherwise, the Claim is permanently barred, which means that you and Tavily will not have the right to assert the Claim.\n\nOpting Out of Arbitration.You have the right to opt out of binding arbitration within 30 days of the date you first accepted this Agreement by providing Tavily with notice of your decision to opt-out via email at support@tavily.com or by certified mail addressed to 33 W 60th St, New York, NY 10023. In order to be effective, the opt-out notice must include your full name, mailing address, and email address. The notice must also clearly indicate your intent to opt out of binding arbitration. By opting out of binding arbitration, you are agreeing to resolve disputes in accordance with Section 14.\n\nRejection of Future Arbitration Changes. You may reject any change we make to Section 13 (except address changes) by personally signing and sending Tavily a notice within 30 days of the change via email at support@tavily.com or by certified mail addressed to 33 W 60th St, New York, NY 10023. If you do, the most recent version of Section 13 before the change you rejected will apply.\n\nSeverability.If any portion of this Section 13 is found to be unenforceable or unlawful for any reason, including but not limited to because it is found to be unconscionable: (i) the unenforceable or unlawful provision will be severed from this Agreement; (ii) severance of the unenforceable or unlawful provision will have no impact whatsoever on the remainder of this Section 13 or the parties’ ability to compel arbitration of any remaining claims on an individual basis pursuant to this Section 13; and (iii) to the extent that any claims must therefore proceed on a class, collective, consolidated, or representative basis, such claims must be litigated in a civil court of competent jurisdiction and not in arbitration. The litigation of those claims will be stayed pending the outcome of any individual claims in arbitration. Further, if any part of this Section 13 is found to prohibit an individual claim seeking public injunctive relief, that provision will have no effect to the extent such relief is allowed to be sought out of arbitration, and the remainder of this Section 13 will be enforceable.\n\nDisputes Outside the United StatesNotwithstanding any terms to the contrary in this Agreement, if you reside in any country outside of the United States, you may bring legal proceedings regarding this Agreement either by following the arbitration procedure detailed above in this Section 13 or, if given the right by applicable law, by submitting the dispute to an arbitration administrator in the jurisdiction in which you reside. To the extent any proceeding is not subject to arbitration under applicable law, you may submit the dispute to the courts of the jurisdiction in which you reside.\n\n9. Disclaimers.\n\nEntire Agreement.This Agreement constitutes the entire agreement between the parties with respect to its subject matter, and there are no agreements or understandings between the parties, express or implied, except as are expressly set forth in this Agreement.\n\nGoverning Law; Dispute Resolution. This Agreement will be governed in all respects in accordance with the laws of the State of New York, without regard to conflict of law principles that would cause the laws of any other jurisdiction to apply. Except as set forth in Section 13, you expressly agree that federal and state courts located in Manhattan, New York will have exclusive jurisdiction over any action or claim that you bring that arises out of or relating to this Agreement. You expressly consent to personal jurisdiction in any such court and hereby irrevocably waive any objection to or claim of lack of jurisdiction or forum non conveniens.\n\nAudits.Tavily may, by itself or through an independent third party, audit your use of the Services to verify (i) Fees payable and (ii) that you are otherwise compliant with the terms and conditions of this Agreement. You agree to (A) maintain complete and accurate books, logs, and other records with respect to your use of the Services and (B) provide reasonable access to your systems, books, logs, and other records for purposes of conducting these audits.\n\nMiscellaneous.This Agreement may not be modified or amended except by a writing signed by both parties. If any provision of this Agreement is found by any court to be void or otherwise unenforceable, the remainder of this Agreement will remain valid and enforceable as though such void or unenforceable provision were absent on the date of its execution. The relationship between the parties is that of independent contractors, and neither party has authority to contract for or bind the other party in any manner whatsoever. Notwithstanding any terms to the contrary in this Agreement, you consent to Tavily's use of your name and logo on Tavily's website and on Tavily's promotional and marketing related materials, identifying you as a customer of Tavily and/or describing your use of the Services. You may not assign, transfer or delegate this Agreement, nor any right or duty under this Agreement, by merger, acquisition, operation of law, or otherwise, without Tavily's prior written consent, and any attempted assignment, transfer, or delegation with such consent will be void and without effect. By using the Services, you agree (a) to receive communications (including any communications that are required to be issued in writing hereunder) electronically, including via email, (b) that any such electronically-issued communications will satisfy any legal communication requirements, including those that require notices to be in writing, (c) that, without limiting Tavily's notification rights elsewhere in this Agreement, Tavily may issue notices to the email or other address provided by you to Tavily, and (d) that such notice will be effective on delivery. Notices to Tavily, including termination notices, must be delivered to support@tavily.com or by certified mail to 33 W 60th St, New York, NY 10023. Such notice will be effective on receipt. Tavily is excused from performance of this Agreement and will not be liable for any delay in whole or in part caused by any event outside of its control. Each party has had the opportunity to review this Agreement with legal counsel, and there will be no presumption that ambiguities will be construed or interpreted against the drafter.\n\nLast updated: 9.27.24",
      "# [Tavily Blog](https://blog.tavily.com/)\nEffortless Web-Based RAG Evaluation Using Tavily and LangGraph\n\nIntroduction Every data science enthusiast knows that a vital first step to building a successful model or algorithm is having a reliable evaluation set to",
      "# [Tavily Documentation](https://docs.tavily.com/)\nTavily Search API\n\nTavily Search API is a search engine optimized for LLMs, optimized for a factual, efficient, and persistent search experience\n\nExamples and Demos\n\nCheck out Tavily API in action across multiple frameworks and use cases",
      "# [Tavily Community](https://community.tavily.com/)\nAPI\n\nQuestions and discussions regarding the Tavily Search API. This includes our REST API, the Tavily Online Platform and the Tavily Python Package.\n\n18\n\nDocumentation\n\nA place to discuss and suggest improvements for our Documentation and Tutorials. Please only discuss resources published by Tavily.\n\n1",
      "# [Tavily](https://tavily.com/enterprise)\nTalk to Our Team\n\nTavily provides powerful tools to connect AI agents to real-time web data. Our team is here to assist you in exploring how Tavily can enhance your AI applications.\n\nGet in touch. Our team will answer your questions and follow up with details on our custom plans and the expertise to help you drive results.",
      "# [Tavily Community](https://community.tavily.com/faq)\nThis is a Civilized Place for Public Discussion\n\nPlease treat this discussion forum with the same respect you would a public park. We, too, are a shared community resource — a place to share skills, knowledge and interests through ongoing conversation.\n\nThese are not hard and fast rules. They are guidelines to aid the human judgment of our community and keep this a kind, friendly place for civilized public discourse.\n\nImprove the Discussion\n\nHelp us make this a great place for discussion by always adding something positive to the discussion, however small. If you are not sure your post adds to the conversation, think over what you want to say and try again later.\n\nOne way to improve the discussion is by discovering ones that are already happening. Spend time browsing the topics here before replying or starting your own, and you’ll have a better chance of meeting others who share your interests.\n\nThe topics discussed here matter to us, and we want you to act as if they matter to you, too. Be respectful of the topics and the people discussing them, even if you disagree with some of what is being said.\n\nBe Agreeable, Even When You Disagree\n\nYou may wish to respond by disagreeing. That’s fine. But remember to criticize ideas, not people. Please avoid:\n\nName-calling\n\nAd hominem attacks\n\nResponding to a post’s tone instead of its actual content\n\nKnee-jerk contradiction\n\nInstead, provide thoughtful insights that improve the conversation.\n\nYour Participation Counts\n\nThe conversations we have here set the tone for every new arrival. Help us influence the future of this community by choosing to engage in discussions that make this forum an interesting place to be — and avoiding those that do not.\n\nDiscourse provides tools that enable the community to collectively identify the best (and worst) contributions: bookmarks, likes, flags, replies, edits, watching, muting and so forth. Use these tools to improve your own experience, and everyone else’s, too.\n\nLet’s leave our community better than we found it.\n\nIf You See a Problem, Flag It\n\nModerators have special authority; they are responsible for this forum. But so are you. With your help, moderators can be community facilitators, not just janitors or police.\n\nWhen you see bad behavior, don’t reply. Replying encourages bad behavior by acknowledging it, consumes your energy, and wastes everyone’s time. Just flag it. If enough flags accrue, action will be taken, either automatically or by moderator intervention.\n\nIn order to maintain our community, moderators reserve the right to remove any content and any user account for any reason at any time. Moderators do not preview new posts; the moderators and site operators take no responsibility for any content posted by the community.\n\nAlways Be Civil\n\nNothing sabotages a healthy conversation like rudeness:\n\nBe civil. Don’t post anything that a reasonable person would consider offensive, abusive, or hate speech.\n\nKeep it clean. Don’t post anything obscene or sexually explicit.\n\nRespect each other. Don’t harass or grief anyone, impersonate people, or expose their private information.\n\nRespect our forum. Don’t post spam or otherwise vandalize the forum.\n\nThese are not concrete terms with precise definitions — avoid even the appearance of any of these things. If you’re unsure, ask yourself how you would feel if your post was featured on the front page of a major news site.\n\nThis is a public forum, and search engines index these discussions. Keep the language, links, and images safe for family and friends.\n\nKeep It Tidy\n\nMake the effort to put things in the right place, so that we can spend more time discussing and less cleaning up. So:\n\nDon’t start a topic in the wrong category; please read the category definitions.\n\nDon’t cross-post the same thing in multiple topics.\n\nDon’t post no-content replies.\n\nDon’t divert a topic by changing it midstream.\n\nDon’t sign your posts — every post has your profile information attached to it.\n\nRather than posting “+1” or “Agreed”, use the Like button. Rather than taking an existing topic in a radically different direction, use Reply as a Linked Topic.\n\nPost Only Your Own Stuff\n\nYou may not post anything digital that belongs to someone else without permission. You may not post descriptions of, links to, or methods for stealing someone’s intellectual property (software, video, audio, images), or for breaking any other law.\n\nPowered by You",
      "# [Tavily Community](https://community.tavily.com/latest)\nPowered by Discourse, best viewed with JavaScript enabled",
      "# [Frequently Asked Questions](https://docs.tavily.com/docs/faq)\nIt really depends on what you're aiming for.\n\nIf you're looking to connect your AI application to the internet with our tailored API, check out the Python or REST API documentation. You can also check out demos and examples for inspiration here.\n\nIf you're looking to build and deploy our open source autonomous research agent GPT Researcher, please see GPT Researcher documentation.\n\nWe do our best to ensure that the information we provide is factual and accurate. We do this by using multiple sources, and by using proprietary AI to score and rank the most relevant and accurate information. We also use proprietary AI to filter out irrelevant information and sources.\n\nLastly, by using RAG and other techniques, we ensure that the information is relevant to the context of the research task, leading to more accurate generative AI content and reduced hallucinations.\n\nTavily search API is a search engine optimized for LLMs, aimed at efficient, quick and persistent search results. Unlike other search APIs such as Serp or Google, Tavily focuses on optimizing search for AI developers and autonomous AI agents. We take care of all the burden in searching, scraping, filtering and extracting the most relevant information from online sources. All in a single API call!\n\nThe search API can also be used to return answers to questions (for use cases such as multi-agent frameworks like autogen) and can complete comprehensive research tasks in seconds. Moreover, Tavily leverages proprietary news, weather, and other internal data sources to complement online information.\n\nTo try the API in action, you can now use our hosted version here or on our API Playground.\n\nCurrent search APIs such as Google, Serp and Bing retrieve search results based on user query. However, the results are sometimes irrelevant to the goal of the search, and return simple site URLs and snippets of content which are not always relevant. Because of this, any developer would need to then scrape the sites for relevant content, filter irrelevant information, optimize the content to fit LLM context limits, and more. This tasks is a burden and requires skills to get right.\n\nTavily Search API aggregates up to 20 sites per a single API call, and uses AI to score, filter and rank the top most relevant sources and content to your task, query or goal. In addition, Tavily allows developers to add custom fields such as context and limit response tokens to enable the optimal search experience for LLMs. Lastly, Tavily indexes and ranks search results based on factors such as trusted sources, content quality, and more. This allows for a more accurate and relevant search experience for AI agents.\n\nRemember: With LLM hallucinations, it's crucial to optimize for RAG with the right context and information.\n\nTavily is free to use for up to 1,000 API calls per month. Check out our pricing page to see our other pricing plans.\n\nWe're constantly working on improving our products and services. We're currently working on improving our search API together with design partners, and adding more data sources to our search engine.\n\nFeel free to contact us if you have any further questions or suggestions!\n\nGPT Researcher is a popular open source autonomous research agent that takes care of the tedious task of research for you, by scraping, filtering and aggregating up to 20 web sources per a single research task.\n\nGPT Researcher is built with best practices for leveraging LLMs (prompt engineering, RAG, chains, embeddings, etc), and is optimized for quick and efficient research. It is also fully customizable and can be tailored to your specific needs.\n\nTo learn more about GPT Researcher, check out the documentation page.\n\nA research task using GPT Researcher costs around $0.01 per a single run (for GPT-4 usage). We're constantly optimizing LLM calls to reduce costs and improve performance.",
      "# [Tavily Community](https://community.tavily.com/login-preferences)\nWelcome to Tavily Community\n\nThe official developer community for Tavily AI.",
      "# [Precision in AI Research: Tavily’s Company Researcher by Rotem Weiss on 2024-11-18](https://blog.tavily.com/companyresearcher/)\nIn AI research, accuracy is critical. Outdated data? Not useful. Models generating false information? A serious issue. And if you’ve ever tried gathering insights on companies with minimal online presence—or on similarly named entities—you know that many tools often fall short. That’s where Tavily’s Company Researcher comes in. This tool integrates Tavily Search and Extract, in a workflow powered by LangGraph, to deliver precise, reliable insights. Instead of just surface-level data, it generates comprehensive, current reports with in-depth detail.\n\nTavily’s Intelligent Search Layer\n\nTavily’s mission is to provide an intelligent search layer that connects large language models (LLMs) to the web, giving agents access to real-time, contextually relevant data. Tavily supports flexible search capabilities, enabling AI agents to fine-tune search strategies, retrieve raw content for analysis, or pull summaries for quick insights. Unlike static models bound to training data, Tavily’s Search and Extract endpoints combine semantic, contextual, and keyword search to deliver timely, relevant insights for data-driven decision-making.\n\nHow the Company Researcher Works\n\nThe Company Researcher automates a multi-stage workflow for real-time company analysis, integrating search and extraction with agentic behavior to generate high-quality results. Its modular and dynamic architecture allows for efficient gathering of both general context and targeted data. The use of feedback loops, combined with optional human-on-the-loop validation, ensures precise and reliable outputs. Here’s how it works:\n\nInitial Grounding with Tavily Extract: Each session begins with a user-provided company name and URL. Tavily Extract retrieves content from that site, creating a “ground truth” that anchors the search to follow. By grounding in verified data, each step operates within set accuracy boundaries, reducing hallucinations and inconsistencies.\n\nSub-Question Generation and Tavily Search: Dynamically generates specific sub-questions to guide Tavily’s search, focusing the search on high-value, relevant data instead of conducting a broad, unfocused search.\n\nAI-Driven Clustering: Retrieved documents are grouped by company, using the ground truth to verify accuracy, especially for similarly named entities. This clustering keeps only relevant sources in focus.\n\nHuman-on-the-Loop for Cluster Validation: If clustering doesn’t yield a definitive match, meaning that the correct cluster wasn't automatically identified, optional human validation can make manual adjustments, ensuring data quality.\n\nDocument Curation and Enrichment with Tavily Extract: Once a trusted cluster is identified, Tavily Extract pulls detailed data from these verified links, adding substantial depth to the research. This step enhances the precision and comprehensiveness of the final output.\n\nReport Generation and Evaluation: An LLM synthesizes the data into a structured report. If gaps are detected, new questions are generated to gather additional data, improving the report without restarting.\n\nMulti-Format Output: The final report is available in PDF or Markdown format, making it easy to share and integrate.\n\nHere is how I define the workflow IRL:\n\nKey Technical Features\n\nGrounding: The Foundation of Accuracy\n\nGrounding is core to Tavily’s Company Researcher workflow. It starts with establishing a reliable “ground truth” by using Tavily Extract on a verified company URL. This keeps the system aligned to the correct entity, especially in cases where similarly named companies exist. Creating a foundation to work from minimizes unrelated or erroneous information, improving output accuracy. Feedback loops that refer to the “ground truth” coupled with human-on-the-loop validation further reinforce this foundation, ensuring outputs are consistently relevant and curated for quality.\n\nTavily Search and Extract: Better Together for Precision\n\nTavily Extract is geared to pull raw information from specified sources. Allowing the agent to dig deep on the most important sources without the pressure of having to explore every possible lead. Tavily Search on the other hand, looks at the breadth of the web to identify the most relevant sources for your goal. By going broad it will ensure the scope of your research needs are covered. Tavily’s Company Researcher shows how you can utilize the strengths of each and have both tools work with one another to generate the results you want. In the end, only the most relevant pages are analyzed, providing accurate, contextually rich information, minimizing long context windows, and resulting in precise, actionable reports.\n\nDynamic Graph-Like Structure: Flexibility Meets Predictability\n\nThe Company Researcher uses a dynamic, graph-based structure that balances clear paths with flexibility. Traditional deterministic workflows work well for set steps but struggle in unpredictable real-world contexts. Fully dynamic workflows, like ReAct, handle unpredictability better but can lack structure and deterministic accuracy. The Company Researcher’s hybrid approach, implemented with LangGraph, maintains a clear path while adapting to real-world, real-time challenges, allowing for flexibility when data inputs vary.\n\nStructured Output: Consistency in Data\n\nStructured prompting ensures output consistency. While early LLMs could provide accurate information, their formatting was often inconsistent. I addressed this by embedding specific formatting into prompts, so each data cluster follows a set structure, making results easy to retrieve, reliable, and consistently organized.\n\nHere is an example of how it is used to define the clusters:\n\nAnd it is even simpler to call:\n\nThen, you can access each type of output because it is assigned to the cluster through the defined structure:\n\nAnd the Best Part: It’s Adaptable!\n\nTavily’s Company Researcher can be easily customized to fit a range of research needs. By making simple adjustments, you can expand its use beyond company research to tackle various data-intensive tasks, ensuring consistent and reliable results.\n\nModify Prompts: Consider tailoring the prompts used for question generation or report synthesis to better align with your specific research goals.\n\nExtend Workflow Nodes: Think about adding, removing, or altering workflow nodes to target specific types of analysis or areas of interest.\n\nCustomize Output Formats: Don’t hesitate to adjust output formats, such as using custom CSS for PDF styling, to align with your organization’s standards.\n\nGetting Started with Company Researcher:\n\nIn this section, we will walk you through the steps to download and start using Company Researcher.\n\nPrerequisites\n\nPython 3.11 or later: Python Installation Guide\n\nTavily API Key - Sign Up\n\nAnthropic API Key - Sign Up\n\nInstallation\n\nClone the Repository:\n\ngit clone https://github.com/danielleyahalom/company-researcher.git cd company-researcher\n\nCreate a Virtual Environment:\n\nTo avoid dependency conflicts, it's recommended to create and activate a virtual environment using venv:\n\npython -m venv venv source venv/bin/activate # macOS/Linux venv\\Scripts\\activate # Windows\n\nSet Up API Keys:\n\nConfigure your Anthropic and Tavily API keys as environment variables or place them in a .env file:\n\nexport TAVILY_API_KEY={Your Tavily API Key here} export ANTHROPIC_API_KEY={Your Anthropic API Key here}\n\nInstall Dependencies:\n\npip install -r requirements.txt\n\nRun the Application:\n\npython app.py\n\nOpen the App in Your Browser:\n\nhttp://localhost:5000",
      "# [Langchain](https://docs.tavily.com/docs/integrations/langchain)\n> Entering new AgentExecutor chain...\n\nInvoking: `tavily_search_results_json` with `{'query': 'latest burning man floods news'}`\n\n[{'url': 'https://www.cbsnews.com/news/flooding-burning-man-shelter-in-place/', 'content': 'Watch CBS News\\nNevada flooding forces Burning Man attendees to shelter in place\\nUpdated on:\\nSeptember 2, 2023 / 10:04 PM EDT\\n/ CBS/AP\\nThousands of Burning Man attendees trudged in sloppy mud on Saturday — many barefoot or wearing plastic bags on their feet — as flooding from storms swept through the Nevada desert, forcing organizers to close vehicular access to the counterculture festival. Vehicular gates will be closed for the remainder of the event, which began on Aug. 27 and was scheduled to end on Monday, according to the U.S. Bureau of Land Management, which oversees the Black Rock Desert where the festival is being held. \"\\nDue to recent rainfall, the Bureau of Land Management and the Pershing County Sheriff\\'s Office officials have closed the entrance to Burning Man for the remainder of the event. Superstar DJ and music producer Diplo shared a video to social media Saturday afternoon that showed several people riding on the back of a truck leaving the festival, one of whom appeared to be comedian Chris Rock.\\n Mike Jed, a festivalgoer, and fellow campers made a bucket toilet so people didn\\'t have to trudge as often through the mud to reach the portable toilets.\\n'}, {'url': 'https://www.npr.org/2023/09/03/1197497458/the-latest-on-the-burning-man-flooding', 'content': \"There are also reports that at least one person has died at the counterculture festival about a hundred miles north of Reno, Nev. Earlier this afternoon, I caught up with NPR's Claudia Peschiutta, who's at her first burn, and she told me it's muddy where she is, but that she and her camp family have been making the best of things.\\n National\\nThe latest on the Burning Man flooding\\nClaudia Peschiutta\\nAuthorities are investigating a death at the Burning Man festival in the Nevada desert after tens of thousands of people are stuck in camps because of rain.\\n SCOTT DETROW, HOST:\\nKnee-deep mud, warnings to conserve food and water, orders to shelter in place - this is all at Burning Man 2023 after torrential rains turned the Black Rock Desert into miles and miles of mud. I mean, mostly what I've seen from my personal experience is just any sort of need that you have, somebody, whether friend or neighbor or stranger, will jump in to help you out in some way. And I should mention that desert Wi-Fi is doing the best as it can as we talk to you, dropping in and out.\"}, {'url': 'https://www.nbcnews.com/news/us-news/live-blog/live-updates-burning-man-flooding-keeps-thousands-stranded-nevada-site-rcna103193', 'content': \"Profile\\nSections\\ntv\\nFeatured\\nMore From NBC\\nFollow NBC News\\nnews Alerts\\nThere are no new alerts at this time\\nBurning Man flooding keeps thousands stranded at Nevada site as authorities investigate 1 death\\nBurning Man attendees struggling to get home\\n70,000+ stuck at Burning Man: When will they be able to get out?\\n Thousands still stranded at Burning Man after torrential rain\\nBurning Man revelers unfazed by deluge and deep mud\\nReuters\\nThousands of Burning Man attendees partied hard on Sunday despite downpours that turned the Nevada desert where the annual arts and music festival takes place into a sea of sticky mud and led officials to order the multitudes to shelter in place.\\n Neal Katyal warns hiking in the mud\\ncan be 'worse than walking on ice'\\nDoha Madani\\nNeal Katyal, the former acting U.S. solicitor general, is among the Burning Man attendees who decided to take the risk and hike out of the festival grounds.\\n Videos posted to his Instagram story show Diplo walking through mud before, he says, he hitchhiked to Gerlach and Reno to make a flight to Washington, D.C.\\n“I just got done DJ’ing for three hours, after walking f---ing for four hours out of the desert and taking a flight, mud still on my face,” he said in a video posted to his Instagram story last night.\\n Burning Man memes are swamping social media\\nAngela Yang\\nAs heavy rain turns Burning Man 2023 into a muddy mess, a deluge of unsympathetic jokes has swamped the internet outside Black Rock City, the temporary location built annually for the nine-day festival in the remote desert of Nevada.\\n\"}, {'url': 'https://www.cnn.com/us/live-news/nevada-desert-burning-man-weather-rain-09-03-23/index.html', 'content': 'The festival’s 2023 theme is “Animalia,” which the Burning Man website explains, “will celebrate the animal world and our place in it — animals real and imagined, mythic and remembered — and explore the curious mental constructs that allow us to believe that imagined animals are real, real animals are imagined, and that somehow, despite all evidence to the contrary, mankind is somehow not part of the animal kingdom.”\\n Thousands stranded at Burning Man festival after heavy rains\\nBy Maureen Chowdhury, Steve Almasy and Matt Meyer, CNN\\nWhat we\\'re covering\\nPresident Biden has been briefed on the situation at Burning Man festival\\nFrom CNN\\'s Betsy Klein\\nPresident Joe Biden was briefed Sunday on the situation at the Burning Man festival in Black Rock Desert, Nevada, according to a White House official.\\n View Katyal\\'s post below:\\nSome of the 70,000 people stranded at Burning Man are walking out of the site, sheriff\\'s office says\\nFrom CNN\\'s Melissa Alonso\\nThere are currently \"a little over 70,000\" people stranded at the Burning Man festival in Nevada due to the mud and flooding, Pershing County Sheriff’s Sgt. Burning Man organizers working to provide cell service and medical resources as attendees shelter in place\\nFrom CNN\\'s Nouran Salahieh\\xa0and\\xa0Emma Tucker\\nBurning Man organizers say they are placing mobile cell trailers around the battered festival grounds, configuring their Wi-Fi system for public access, and sending buses to nearby Gerlach, Nevada, to pick up people who might have walked out of the desert and ferry them to Reno.\\n Festivalgoers are managing to have a good time despite being stuck in the mud, attendee says\\nDawne Looney, a Burning Man festival attendee, says people are making the best of the situation despite the heavy rain and mud stranding an estimated 70,000 of them in the desert.\\n'}, {'url': 'https://abcnews.go.com/US/burning-man-flooding-happened-stranded-festivalgoers/story?id=102908331', 'content': '\"\\nTop Stories\\nMacy\\'s Thanksgiving Day Parade temporarily halted by pro-Palestinian protesters\\nGuns N\\' Roses singer Axl Rose accused of alleged 1989 sexual assault by former model\\nFBI: Rainbow Bridge crash, explosion not connected to terrorism\\nToxic chemical spill from Kentucky train derailment forces residents to flee homes\\nHezbollah fires rockets at north Israel after an airstrike kills 5 of the group\\'s senior fighters\\nABC News Live\\n24/7 coverage of breaking news and live events ABC News\\nVideo\\nLive\\nShows\\nElection 2024\\n538\\nStream on\\nBurning Man flooding: What happened to stranded festivalgoers?\\n In response to the unusual weather, event organizers shut down traffic in or out of what is called Black Rock City -- where the festival is held in the desert -- including the local airport.\\n MORE: These US regions will experience scorching temperatures for the remainder of Labor Day weekend\\nOn Sunday, mobile cell trailers to boost cell service and charging stations were placed around the festival grounds amid the recovery efforts, according to organizers.\\n This is typically the driest time of the year for the desert, and it does not take much rain to make the desert floor a mud bath.\\n'}]The latest Burning Man festival, held in Nevada's Black Rock Desert, was hit by severe flooding due to storms, forcing thousands of attendees to shelter in place as the normally dry desert was turned into a muddy landscape. The vehicular gates were closed for the remainder of the event, a decision taken by the U.S. Bureau of Land Management and the Pershing County Sheriff's Office. There were reports of one death at the festival and authorities are investigating the incident. Despite the harsh conditions, festival attendees were seen making the best of the situation.\n\nThe festival, which began on August 27, 2023, and was supposed to end on September 4, 2023, saw over 70,000 attendees stuck due to the flooding. To aid attendees, festival organizers provided mobile cell trailers to boost cell service and charging stations around the festival grounds. They also worked on providing medical resources and public Wi-Fi access.\n\nNotably, many attendees, including celebrities like DJ Diplo, were seen leaving the festival by hitchhiking or walking through the mud. The floods led to a flurry of social media activity, including both messages of support and unsympathetic jokes. The President, Joe Biden, was also briefed on the situation at the festival.\n\n> Finished chain.",
      "# [API](https://community.tavily.com/c/api/8)\nPowered by Discourse, best viewed with JavaScript enabled",
      "# [Tavily on 2023-11-12](https://docs.tavily.com/blog)\nOpenAI has done it again with a groundbreaking DevDay showcasing some of the latest improvements to the OpenAI suite of tools, products and services. One major release was the new Assistants API that makes it easier for developers to build their own assistive AI apps that have goals and can call models and tools.\n\nAfter AutoGPT was published, we immediately took it for a spin. The first use case that came to mind was autonomous online research. Forming objective conclusions for manual research tasks can take time, sometimes weeks, to find the right resources and information. Seeing how well AutoGPT created tasks and executed them got me thinking about the great potential of using AI to conduct comprehensive research and what it meant for the future of online research.",
      "# [LlamaIndex](https://docs.tavily.com/docs/integrations/llamaindex)\nThis tool has a more extensive example usage documented in a Jupyter notebook here\n\nTo get started, install the required library:\n\nHere's an example usage of the TavilyToolSpec:\n\nsearch: Search for relevant dynamic data based on a query. Returns a list of urls and their relevant content.",
      "# [Announcements](https://community.tavily.com/c/announcements/6)\nPowered by Discourse, best viewed with JavaScript enabled",
      "# [Other Tavily Topics](https://community.tavily.com/c/other/4)\nPowered by Discourse, best viewed with JavaScript enabled",
      "# [API performance on 2024-09-04](https://community.tavily.com/t/api-performance/115)\nHello,\n\nWe are using Tavily API as a tool in our AI agent. The search API takes around 40 seconds to respond to queries, but, on retries with the same prompt, is able to come back in < 4 seconds.\n\nHere is a sample prompt - Recent Federal Reserve interest rate hikes impact on U.S. consumer spending and borrowing trends\n\nHere are the parameter we are using on the client -\n\ntavily_client.search(query, search_depth=“advanced”).\n\nIs it possible to get consistent near real time (< 4 sec) responses at all times? We are currently on bootstrap pricing mode, and we intend to move up the tier if the API satisfies our needs.\n\nThanks\n\nHi,\n\nThank you for reaching out! A response time of 40 seconds for queries is very unlikely, and I couldn’t find any record of such delays on our end. Typically, response times range between 1 to 10 seconds. You can also check the current status of the API on our status page here: https://status.tavily.com.\n\nCould you share which framework you’re using Tavily as a tool in? Perhaps that is the cause of the delays, and we’d be happy to look into it.\n\nWhile we’re unable to provide detailed technical information on how results improve over time, I can confirm that as more people research a particular topic, the results do indeed become better.\n\nLet us know if you have any more questions or feedback. We’re here to help and accommodate your needs as you continue exploring the API!\n\nThank you for your response.\n\nOur stack utilizes LangGraph, where nodes implement function calls using web search tools, including Tavily. Initially, we had set include_raw_content to True with max_results set to 10, which led to 502 errors or long runtimes. We have since disabled raw content and reduced max_results to 5, and we’re now experiencing much faster results.\n\nWe will continue to test the API, and so far, we are pleased with the results it is delivering within our stack.\n\nOn a side note, our legal team has been trying to reach you regarding enterprise pricing but hasn’t had success. Is there a specific contact we can reach out to in order to discuss your enterprise package?\n\nThanks.\n\nI’m glad to hear that you’re pleased with the results you’re obtaining using our API within your stack! Setting include_raw_content can sometimes place constraints on our system, but our team is actively working on improving performance. Things should be running more smoothly now if you need to enable it for specific cases.\n\nI apologize for the difficulties your legal team has had in reaching us. You can either fill out this form, and our team will get back to you as soon as possible, or reach out via email at support@tavily.com.\n\nThank you again for reaching out. Let us know if you have any more questions or feedback!\n\nI’ve informed our account managers, Itamar and Lee, about the situation. Lee mentioned that they’ve been trying to reach out as well, with one email sent on August 22nd and another yesterday. Lee has just sent another follow-up email. Please let us know if you haven’t received it or if there’s still an issue with getting in touch. I’d be happy to help resolve this communication gap.",
      "# [Customization](https://docs.tavily.com/docs/gpt-researcher/config)\nThe config.py enables you to customize GPT Researcher to your specific needs and preferences.\n\nThanks to our amazing community and contributions, GPT Researcher supports multiple LLMs and Retrievers. In addition, GPT Researcher can be tailored to various report formats (such as APA), word count, research iterations depth, etc.\n\nGPT Researcher defaults to our recommended suite of integrations: OpenAI for LLM calls and Tavily API for retrieving realtime online information.\n\nAs seen below, OpenAI still stands as the superior LLM. We assume it will stay this way for some time, and that prices will only continue to decrease, while performance and speed increase over time.\n\nIt may not come as a surprise that our default search engine is Tavily. We're aimed at building our search engine to tailor the exact needs of searching and aggregating for the most factual and unbiased information for research tasks. We highly recommend using it with GPT Researcher, and more generally with LLM applications that are built with RAG. To learn more about our search API see here\n\nHere is an example of the default config.py file found in /gpt_researcher/config/:\n\nPlease note that you can also include your own external JSON file by adding the path in the config_file param.\n\nTo learn more about additional LLM support you can check out the Langchain Adapter and Langchain supported LLMs documentation. Simply pass different provider names in the llm_provider config param.\n\nYou can also change the search engine by modifying the retriever param to others such as duckduckgo, googleAPI, googleSerp, searx and more.\n\nPlease note that you might need to sign up and obtain an API key for any of the other supported retrievers and LLM providers.",
      "# [Introduction](https://docs.tavily.com/docs/gpt-researcher/introduction)\nGPT Researcher is an autonomous agent designed for comprehensive online research on a variety of tasks.\n\nThe agent can produce detailed, factual and unbiased research reports, with customization options for focusing on relevant resources, outlines, and lessons. Inspired by the recent Plan-and-Solve and RAG papers, GPT Researcher addresses issues of speed, determinism and reliability, offering a more stable performance and increased speed through parallelized agent work, as opposed to synchronous operations.\n\nTo form objective conclusions for manual research tasks can take time, sometimes weeks to find the right resources and information.\n\nCurrent LLMs are trained on past and outdated information, with heavy risks of hallucinations, making them almost irrelevant for research tasks.\n\nSolutions that enable web search (such as ChatGPT + Web Plugin), only consider limited resources and content that in some cases result in superficial conclusions or biased answers.\n\nUsing only a selection of resources can create bias in determining the right conclusions for research questions or tasks.\n\nThe main idea is to run \"planner\" and \"execution\" agents, whereas the planner generates questions to research, and the execution agents seek the most related information based on each generated research question. Finally, the planner filters and aggregates all related information and creates a research report.\n\nThe agents leverage both gpt3.5-turbo and gpt-4-turbo (128K context) to complete a research task. We optimize for costs using each only when necessary. The average research task takes around 3 minutes to complete, and costs ~$0.1.\n\nMore specifically:\n\nCreate a domain specific agent based on research query or task.\n\nGenerate a set of research questions that together form an objective opinion on any given task.\n\nFor each research question, trigger a crawler agent that scrapes online resources for information relevant to the given task.\n\nFor each scraped resources, summarize based on relevant information and keep track of its sources.\n\nFinally, filter and aggregate all summarized sources and generate a final research report.\n\nHow it Works\n\nHow to Install\n\nLive Demo\n\nHomepage\n\n📝 Generate research, outlines, resources and lessons reports\n\n📜 Can generate long and detailed research reports (over 2K words)\n\n🌐 Aggregates over 20 web sources per research to form objective and factual conclusions\n\n🖥️ Includes an easy-to-use web interface (HTML/CSS/JS)\n\n🔍 Scrapes web sources with javascript support\n\n📂 Keeps track and context of visited and used web sources\n\n📄 Export research reports to PDF, Word and more...\n\nThis project, GPT Researcher, is an experimental application and is provided \"as-is\" without any warranty, express or implied. We are sharing codes for academic purposes under the MIT license. Nothing herein is academic advice, and NOT a recommendation to use in academic or research papers.\n\nOur view on unbiased research claims:\n\nThe whole point of our scraping system is to reduce incorrect fact. How? The more sites we scrape the less chances of incorrect data. We are scraping 20 per research, the chances that they are all wrong is extremely low.\n\nWe do not aim to eliminate biases; we aim to reduce it as much as possible. We are here as a community to figure out the most effective human/llm interactions.\n\nIn research, people also tend towards biases as most have already opinions on the topics they research about. This tool scrapes many opinions and will evenly explain diverse views that a biased person would never have read.",
      "# [How we built GPT Researcher by Assaf Elovic, github.com on 2023-09-22](https://docs.tavily.com/blog/building-gpt-researcher)\nAfter AutoGPT was published, we immediately took it for a spin. The first use case that came to mind was autonomous online research. Forming objective conclusions for manual research tasks can take time, sometimes weeks, to find the right resources and information. Seeing how well AutoGPT created tasks and executed them got me thinking about the great potential of using AI to conduct comprehensive research and what it meant for the future of online research.\n\nBut the problem with AutoGPT was that it usually ran into never-ending loops, required human interference for almost every step, constantly lost track of its progress, and almost never actually completed the task.\n\nNonetheless, the information and context gathered during the research task were lost (such as keeping track of sources), and sometimes hallucinated.\n\nThe passion for leveraging AI for online research and the limitations I found put me on a mission to try and solve it while sharing my work with the world. This is when I created GPT Researcher — an open source autonomous agent for online comprehensive research.\n\nIn this article, we will share the steps that guided me toward the proposed solution.\n\nThe first step in solving these issues was to seek a more deterministic solution that could ultimately guarantee completing any research task within a fixed time frame, without human interference.\n\nThis is when we stumbled upon the recent paper Plan and Solve. The paper aims to provide a better solution for the challenges stated above. The idea is quite simple and consists of two components: first, devising a plan to divide the entire task into smaller subtasks and then carrying out the subtasks according to the plan.\n\nAs it relates to research, first create an outline of questions to research related to the task, and then deterministically execute an agent for every outline item. This approach eliminates the uncertainty in task completion by breaking the agent steps into a deterministic finite set of tasks. Once all tasks are completed, the agent concludes the research.\n\nFollowing this strategy has improved the reliability of completing research tasks to 100%. Now the challenge is, how to improve quality and speed?\n\nThe biggest challenge with LLMs is the lack of factuality and unbiased responses caused by hallucinations and out-of-date training sets (GPT is currently trained on datasets from 2021). But the irony is that for research tasks, it is crucial to optimize for these exact two criteria: factuality and bias.\n\nTo tackle this challenges, we assumed the following:\n\nLaw of large numbers — More content will lead to less biased results. Especially if gathered properly.\n\nLeveraging LLMs for the summarization of factual information can significantly improve the overall better factuality of results.\n\nAfter experimenting with LLMs for quite some time, we can say that the areas where foundation models excel are in the summarization and rewriting of given content. So, in theory, if LLMs only review given content and summarize and rewrite it, potentially it would reduce hallucinations significantly.\n\nIn addition, assuming the given content is unbiased, or at least holds opinions and information from all sides of a topic, the rewritten result would also be unbiased. So how can content be unbiased? The law of large numbers. In other words, if enough sites that hold relevant information are scraped, the possibility of biased information reduces greatly. So the idea would be to scrape just enough sites together to form an objective opinion on any topic.\n\nGreat! Sounds like, for now, we have an idea for how to create both deterministic, factual, and unbiased results. But what about the speed problem?\n\nAnother issue with AutoGPT is that it works synchronously. The main idea of it is to create a list of tasks and then execute them one by one. So if, let’s say, a research task requires visiting 20 sites, and each site takes around one minute to scrape and summarize, the overall research task would take a minimum of +20 minutes. That’s assuming it ever stops. But what if we could parallelize agent work?\n\nBy levering Python libraries such as asyncio, the agent tasks have been optimized to work in parallel, thus significantly reducing the time to research.\n\nIn the example above, we trigger scraping for all URLs in parallel, and only once all is done, continue with the task. Based on many tests, an average research task takes around three minutes (!!). That’s 85% faster than AutoGPT.\n\nFinally, after aggregating as much information as possible about a given research task, the challenge is to write a comprehensive report about it.\n\nAfter experimenting with several OpenAI models and even open source, I’ve concluded that the best results are currently achieved with GPT-4. The task is straightforward — provide GPT-4 as context with all the aggregated information, and ask it to write a detailed report about it given the original research task.\n\nThe prompt is as follows:\n\nThe results are quite impressive, with some minor hallucinations in very few samples, but it’s fair to assume that as GPT improves over time, results will only get better.\n\nNow that we’ve reviewed the necessary steps of GPT Researcher, let’s break down the final architecture, as shown below:\n\nMore specifically:\n\nGenerate an outline of research questions that form an objective opinion on any given task.\n\nFor each research question, trigger a crawler agent that scrapes online resources for information relevant to the given task.\n\nFor each scraped resource, keep track, filter, and summarize only if it includes relevant information.\n\nFinally, aggregate all summarized sources and generate a final research report.\n\nThe future of online research automation is heading toward a major disruption. As AI continues to improve, it is only a matter of time before AI agents can perform comprehensive research tasks for any of our day-to-day needs. AI research can disrupt areas of finance, legal, academia, health, and retail, reducing our time for each research by 95% while optimizing for factual and unbiased reports within an influx and overload of ever-growing online information.\n\nImagine if an AI can eventually understand and analyze any form of online content — videos, images, graphs, tables, reviews, text, audio. And imagine if it could support and analyze hundreds of thousands of words of aggregated information within a single prompt. Even imagine that AI can eventually improve in reasoning and analysis, making it much more suitable for reaching new and innovative research conclusions. And that it can do all that in minutes, if not seconds.",
      "# [How to build an OpenAI Assistant with Internet access by Assaf Elovic, github.com on 2023-11-12](https://docs.tavily.com/blog/building-openai-assistant)\nOpenAI has done it again with a groundbreaking DevDay showcasing some of the latest improvements to the OpenAI suite of tools, products and services. One major release was the new Assistants API that makes it easier for developers to build their own assistive AI apps that have goals and can call models and tools.\n\nThe new Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling. Although you might expect the Retrieval tool to support online information retrieval (such as search APIs or as ChatGPT plugins), it only supports raw data for now such as text or CSV files.\n\nThis blog will demonstrate how to leverage the latest Assistants API with online information using the function calling tool.\n\nTo skip the tutorial below, feel free to check out the full Github Gist here.\n\nAt a high level, a typical integration of the Assistants API has the following steps:\n\nCreate an Assistant in the API by defining its custom instructions and picking a model. If helpful, enable tools like Code Interpreter, Retrieval, and Function calling.\n\nCreate a Thread when a user starts a conversation.\n\nAdd Messages to the Thread as the user ask questions.\n\nRun the Assistant on the Thread to trigger responses. This automatically calls the relevant tools.\n\nAs you can see below, an Assistant object includes Threads for storing and handling conversation sessions between the assistant and users, and Run for invocation of an Assistant on a Thread.\n\nLet’s go ahead and implement these steps one by one! For the example, we will build a finance GPT that can provide insights about financial questions. We will use the OpenAI Python SDK v1.2 and Tavily Search API.\n\nFirst things first, let’s define the assistant’s instructions:\n\nNext, let’s finalize step 1 and create an assistant using the latest GPT-4 Turbo model (128K context), and the call function using the Tavily web search API:\n\nStep 2+3 are quite straight forward, we’ll initiate a new thread and update it with a user message:\n\nFinally, we’ll run the assistant on the thread to trigger the function call and get the response:\n\nSo far so good! But this is where it gets a bit messy. Unlike with the regular GPT APIs, the Assistants API doesn’t return a synchronous response, but returns a status. This allows for asynchronous operations across assistants, but requires more overhead for fetching statuses and dealing with each manually.\n\nTo manage this status lifecycle, let’s build a function that can be reused and handles waiting for various statuses (such as ‘requires_action’):\n\nThis function will sleep as long as the run has not been finalized such as in cases where it’s completed or requires an action from a function call.\n\nWe’re almost there! Lastly, let’s take care of when the assistant wants to call the web search API:\n\nAs seen above, if the assistant has reasoned that a function call should trigger, we extract the given required function params and pass back to the runnable thread. We catch this status and call our functions as seen below:\n\nThat’s it! We now have a working OpenAI Assistant that can be used to answer financial questions using real time online information. Below is the full runnable code:\n\nThe assistant can be further customized and improved using additional retrieval information, OpenAI’s coding interpreter and more. Also, you can go ahead and add more function tools to make the assistant even smarter.\n\nFeel free to drop a comment below if you have any further questions!",
      "# [Multi Agent Frameworks](https://docs.tavily.com/docs/gpt-researcher/agent_frameworks)\nWe are strong advocates for the future of AI agents, envisioning a world where autonomous agents communicate and collaborate as a cohesive team to undertake and complete complex tasks.\n\nWe hold the belief that research is a pivotal element in successfully tackling these complex tasks, ensuring superior outcomes.\n\nConsider the scenario of developing a coding agent responsible for coding tasks using the latest API documentation and best practices. It would be wise to integrate an agent specializing in research to curate the most recent and relevant documentation, before crafting a technical design that would subsequently be handed off to the coding assistant tasked with generating the code. This approach is applicable across various sectors, including finance, business analysis, healthcare, marketing, and legal, among others.\n\nOne multi-agent framework that we're excited about is LangGraph, built by the team at Langchain. LangGraph is a Python library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation.\n\nWhat's great about LangGraph is that it follows a DAG architecture, enabling each specialized agent to communicate with one another, and subsequently trigger actions among other agents within the graph.\n\nWe've added an example for leveraging GPT Researcher with LangGraph which can be found in /multi_agents.\n\nThe example demonstrates a generic use case for an editorial agent team that works together to complete a research report on a given task.\n\nThe research team is made up of 7 AI agents:\n\nChief Editor - Oversees the research process and manages the team. This is the \"master\" agent that coordinates the other agents using Langgraph.\n\nResearcher (gpt-researcher) - A specialized autonomous agent that conducts in depth research on a given topic.\n\nEditor - Responsible for planning the research outline and structure.\n\nReviewer - Validates the correctness of the research results given a set of criteria.\n\nRevisor - Revises the research results based on the feedback from the reviewer.\n\nWriter - Responsible for compiling and writing the final report.\n\nPublisher - Responsible for publishing the final report in various formats.\n\nGenerally, the process is based on the following stages:\n\nPlanning stage\n\nData collection and analysis\n\nWriting and submission\n\nReview and revision\n\nPublication\n\nMore specifically (as seen in the architecture diagram) the process is as follows:\n\nBrowser (gpt-researcher) - Browses the internet for initial research based on the given research task.\n\nEditor - Plans the report outline and structure based on the initial research.\n\nFor each outline topic (in parallel):\n\nResearcher (gpt-researcher) - Runs an in depth research on the subtopics and writes a draft.\n\nReviewer - Validates the correctness of the draft given a set of criteria and provides feedback.\n\nRevisor - Revises the draft until it is satisfactory based on the reviewer feedback.\n\nWriter - Compiles and writes the final report including an introduction, conclusion and references section from the given research findings.\n\nPublisher - Publishes the final report to multi formats such as PDF, Docx, Markdown, etc.\n\nInstall required packages:\n\npip install -r requirements.txt\n\nRun the application:\n\npython main.py",
      "# [Troubleshooting](https://docs.tavily.com/docs/gpt-researcher/troubleshooting)\nWe're constantly working to provide a more stable version. If you're running into any issues, please first check out the resolved issues or ask us via our Discord community.\n\nThis relates to not having permission to use gpt-4 yet. Based on OpenAI, it will be widely available for all by end of July.\n\nThe issue relates to the library WeasyPrint (which is used to generate PDFs from the research report). Please follow this guide to resolve it: https://doc.courtbouillon.org/weasyprint/stable/first_steps.html\n\nOr you can install this package manually\n\nIn case of MacOS you can install this lib using brew install glib gobject-introspection\n\nIn case of Linux you can install this lib using sudo apt install libglib2.0-dev\n\ncannot load library 'pango'\n\nIn case of MacOS you can install this lib using brew install pango\n\nIn case of Linux you can install this lib using sudo apt install libpango-1.0-0\n\nWorkaround for Mac M chip users\n\nIf the above solutions don't work, you can try the following:\n\nInstall a fresh version of Python 3.11 pointed to brew: brew install python@3.11\n\nInstall the required libraries: brew install pango glib gobject-introspection\n\nInstall the required GPT Researcher Python packages: pip3.11 install -r requirements.txt\n\nRun the app with Python 3.11 (using brew): python3.11 -m uvicorn main:app --reload\n\nError processing the url\n\nWe're using Selenium for site scraping. Some sites fail to be scraped. In these cases, restart and try running again.\n\nChrome version issues\n\nMany users have an issue with their chromedriver because the latest chrome browser version doesn't have a compatible chrome driver yet.\n\nTo downgrade your Chrome web browser using slimjet, follow these steps. First, visit the website and scroll down to find the list of available older Chrome versions. Choose the version you wish to install making sure it's compatible with your operating system. Once you've selected the desired version, click on the corresponding link to download the installer. Before proceeding with the installation, it's crucial to uninstall your current version of Chrome to avoid conflicts.\n\nIt's important to check if the version you downgrade to, has a chromedriver available in the official chrome driver website",
      "# [Agent Example](https://docs.tavily.com/docs/gpt-researcher/example)\nIf you're interested in using GPT Researcher as a standalone agent, you can easily import it into any existing Python project. Below, is an example of calling the agent to generate a research report:\n\nYou can further enhance this example to use the returned report as context for generating valuable content such as news article, marketing content, email templates, newsletters, etc.\n\nYou can also use GPT Researcher to gather information about code documentation, business analysis, financial information and more. All of which can be used to complete much more complex tasks that require factual and high quality realtime information.",
      "# [Introduction](https://docs.tavily.com/docs/welcome)\nHey there! 👋\n\nWe're a team of AI researchers and developers who are passionate about helping you build the next generation of AI assistants. Our mission is to empower individuals and organizations with accurate, unbiased, and factual information.\n\nBuilding an AI agent that leverages realtime online information is not a simple task. Scraping doesn't scale and requires expertise to refine, current search engine APIs don't provide explicit information to queries but simply potential related articles (which are not always related), and are not very customziable for AI agent needs. This is why we're excited to introduce the first search engine for AI agents - Tavily Search API.\n\nTavily Search API is a search engine optimized for LLMs, aimed at efficient, quick and persistent search results. Unlike other search APIs such as Serp or Google, Tavily focuses on optimizing search for AI developers and autonomous AI agents. We take care of all the burden of searching, scraping, filtering and extracting the most relevant information from online sources. All in a single API call!\n\nTo try the API in action, you can now use our hosted version on our API Playground.\n\nIf you're an AI developer looking to integrate your application with our API, or seek increased API limits, please reach out!\n\nPurpose-Built: Tailored just for LLM Agents, we ensure the search results are optimized for RAG. We take care of all the burden in searching, scraping, filtering and extracting information from online sources. All in a single API call! Simply pass the returned search results as context to your LLM.\n\nVersatility: Beyond just fetching results, Tavily Search API offers precision. With customizable search depths, domain management, and parsing HTML content controls, you're in the driver's seat.\n\nPerformance: Committed to speed and efficiency, our API guarantees real-time and trusted information. Our team works hard to improve Tavily's performance over time.\n\nIntegration-friendly: We appreciate the essence of adaptability. That's why integrating our API with your existing setup is a breeze. You can choose our Python library or a simple API call or any of our supported partners such as Langchain and LLamaIndex.\n\nTransparent & Informative: Our detailed documentation ensures you're never left in the dark. From setup basics to nuanced features, we've got you covered.\n\nCurrent search APIs such as Google, Serp and Bing retrieve search results based on user query. However, the results are sometimes irrelevant to the goal of the search, and return simple site URLs and snippets of content which are not always relevant. Because of this, any developer would need to then scrape the sites to extract relevant content, filter irrelevant information, optimize the content to fit LLM context limits, and more. This task is a burden and requires a lot of time and effort to complete. The Tavily Search API takes care of all of this for you in a single API call.\n\nTavily Search API aggregates up to 20 sites per a single API call, and uses proprietary AI to score, filter and rank the top most relevant sources and content to your task, query or goal. In addition, Tavily allows developers to add custom fields such as context and limit response tokens to enable the optimal search experience for LLMs.\n\nTavily can also help your AI agent make better decisions by including a short answer for cross-agent communication.\n\nRemember: With LLM hallucinations, it's crucial to optimize for RAG with the right context and information.\n\nSign Up: Begin by signing up on our platform.\n\nObtain Your API Key: Once registered, we will generate a Tavily API Key for you. You will also be able to generate additional keys.\n\nTest Drive in the API Playground: Before diving in, familiarize yourself by testing out endpoints in our interactive API playground.\n\nExplore & Learn: Dive into our Python SDK or REST API documentation to get familiar with the various features. The documentation offers a comprehensive rundown of functionalities, supplemented with practical sample inputs and outputs.\n\nSample Use: Check out our Python examples page to see some code snippets showing you what you can accomplish with Tavily in only a few lines of code. Want a real-world application? Check out our Research Assistant — a prime example that showcases how the API can optimize your AI content generation with factual and unbiased results.\n\nStay up to date: Join our Community to get latest updates on our continuous improvements and development\n\n🙋‍♂️ Got questions? Stumbled upon an issue? Or simply intrigued? Don't hesitate! Our support team is always on standby, eager to assist. Join us, dive deep, and redefine your search experience! Contact us!\n\nIn this digital age, quickly accessing relevant and trustworthy information is more crucial than ever. However, we've learned that none of today's search engines provide a suitable tool that provides factual, explicit and objective answers without the need to continuously click and explore multiple sites for a given research task.\n\nThis is why we've built the trending open source GPT Researcher. GPT Researcher is an autonomous agent that takes care of the tedious task of research for you, by scraping, filtering and aggregating over 20+ web sources per a single research task.",
      "# [Roadmap](https://docs.tavily.com/docs/gpt-researcher/roadmap)\nWe're constantly working on additional features and improvements to our products and services. We're also working on new products and services to help you build better AI applications using GPT Researcher.\n\nOur vision is to build the #1 autonomous research agent for AI developers and researchers, and we're excited to have you join us on this journey!\n\nThe roadmap is prioritized based on the following goals: Performance, Quality, Modularity and Conversational flexibility. The roadmap is public and can be found here."
    ],
    "search_results": [
      {
        "title": "Tavily",
        "link": "https://tavily.com/",
        "snippet": "Tavily is a search engine tailored for AI agents, delivering real-time, accurate results, intelligent query suggestions, and in-depth research capabilities.",
        "formattedUrl": "https://tavily.com/"
      },
      {
        "title": "Trust Center - Tavily",
        "link": "https://trust.tavily.com/",
        "snippet": "Our mission is to revolutionize data access for AI agents, optimizing efficiency and innovation through a powerful search engine tailored for LLMs and RAG.",
        "formattedUrl": "https://trust.tavily.com/"
      },
      {
        "title": "AlphaAI Technologies Inc. Platform Privacy Policy",
        "link": "https://tavily.com/privacy",
        "snippet": "Tavily is a search engine tailored for AI agents, delivering real-time, accurate results, intelligent query suggestions, and in-depth research capabilities.",
        "formattedUrl": "https://tavily.com/privacy"
      },
      {
        "title": "Tavily API Status",
        "link": "https://status.tavily.com/",
        "snippet": "22:15 - 22:31. No observed issues. 22:31 - 22:47. No observed issues. 22:47 - 23:03. No observed issues. 23:03 - 23:19. No observed issues. 23:19 - 23:35. No ...",
        "formattedUrl": "https://status.tavily.com/"
      },
      {
        "title": "Tavily Services Agreement",
        "link": "https://tavily.com/terms",
        "snippet": "Sep 27, 2024 ... Tavily will (a) provide access to the Services and (b) use commercially reasonable efforts to provide any Support Services that Tavily has agreed to provide to ...",
        "formattedUrl": "https://tavily.com/terms"
      },
      {
        "title": "Tavily Blog",
        "link": "https://blog.tavily.com/",
        "snippet": "Tavily is the leading search engine for AI agents, providing real-time access to data.",
        "formattedUrl": "https://blog.tavily.com/"
      },
      {
        "title": "Tavily Documentation | Tavily",
        "link": "https://docs.tavily.com/",
        "snippet": "Tavily is the leading search engine optimized for AI agents - powered by LLMs.",
        "formattedUrl": "https://docs.tavily.com/"
      },
      {
        "title": "Tavily Community",
        "link": "https://community.tavily.com/",
        "snippet": "The official developer community for Tavily AI.",
        "formattedUrl": "https://community.tavily.com/"
      },
      {
        "title": "Tavily",
        "link": "https://tavily.com/enterprise",
        "snippet": "Tavily is a search engine tailored for AI agents, delivering real-time, accurate results, intelligent query suggestions, and in-depth research capabilities.",
        "formattedUrl": "https://tavily.com/enterprise"
      },
      {
        "title": "FAQ - Tavily Community",
        "link": "https://community.tavily.com/faq",
        "snippet": "a shared community resource — a place to share skills, knowledge and interests through ongoing conversation. These are not hard and fast rules. They are ...",
        "formattedUrl": "https://community.tavily.com/faq"
      },
      {
        "title": "Latest topics - Tavily Community",
        "link": "https://community.tavily.com/latest",
        "snippet": "The official developer community for Tavily AI.",
        "formattedUrl": "https://community.tavily.com/latest"
      },
      {
        "title": "Frequently Asked Questions | Tavily",
        "link": "https://docs.tavily.com/docs/faq",
        "snippet": "Tavily search API is a search engine optimized for LLMs, aimed at efficient, quick and persistent search results. Unlike other search APIs such as Serp or ...",
        "formattedUrl": "https://docs.tavily.com/docs/faq"
      },
      {
        "title": "Tavily Community",
        "link": "https://community.tavily.com/login-preferences",
        "snippet": "The official developer community for Tavily AI.",
        "formattedUrl": "https://community.tavily.com/login-preferences"
      },
      {
        "title": "Precision in AI Research: Tavily's Company Researcher",
        "link": "https://blog.tavily.com/companyresearcher/",
        "snippet": "Nov 18, 2024 ... This tool integrates Tavily Search and Extract, in a workflow powered by LangGraph, to deliver precise, reliable insights.",
        "formattedUrl": "https://blog.tavily.com/companyresearcher/"
      },
      {
        "title": "Langchain | Tavily",
        "link": "https://docs.tavily.com/docs/integrations/langchain",
        "snippet": "We're excited to partner with Langchain as their recommended search tool! See the Langchain blog for more details. Tavily API can now empower your Langchain ...",
        "formattedUrl": "https://docs.tavily.com/docs/integrations/langchain"
      },
      {
        "title": "Latest API topics - Tavily Community",
        "link": "https://community.tavily.com/c/api/8",
        "snippet": "Questions and discussions regarding the Tavily Search API. This includes our REST API, the Tavily Online Platform and the Tavily Python Package.",
        "formattedUrl": "https://community.tavily.com/c/api/8"
      },
      {
        "title": "Blog | Tavily",
        "link": "https://docs.tavily.com/blog",
        "snippet": "Nov 12, 2023 ... How we built GPT Researcher ... After AutoGPT was published, we immediately took it for a spin. The first use case that came to mind was ...",
        "formattedUrl": "https://docs.tavily.com/blog"
      },
      {
        "title": "LlamaIndex | Tavily",
        "link": "https://docs.tavily.com/docs/integrations/llamaindex",
        "snippet": "This tool has a more extensive example usage documented in a Jupyter notebook here.",
        "formattedUrl": "https://docs.tavily.com/docs/integrations/llamaindex"
      },
      {
        "title": "Latest Announcements topics - Tavily Community",
        "link": "https://community.tavily.com/c/announcements/6",
        "snippet": "0, 41, July 5, 2024. Tavily JavaScript package now available on NPM · new-feature , tavily-js. 0, 90, October 12, 2024. Python package version 0.4.0.",
        "formattedUrl": "https://community.tavily.com/c/announcements/6"
      },
      {
        "title": "Latest Other Tavily Topics topics - Tavily Community",
        "link": "https://community.tavily.com/c/other/4",
        "snippet": "1, 26, November 13, 2024. How to Automate Multi-Page Scraping for eCommerce Sites Using Tavily API? feature-request , advanced-question.",
        "formattedUrl": "https://community.tavily.com/c/other/4"
      },
      {
        "title": "API performance - API - Tavily Community",
        "link": "https://community.tavily.com/t/api-performance/115",
        "snippet": "Sep 4, 2024 ... The search API takes around 40 seconds to respond to queries, but, on retries with the same prompt, is able to come back in < 4 seconds.",
        "formattedUrl": "https://community.tavily.com/t/api-performance/115"
      },
      {
        "title": "Customization | Tavily",
        "link": "https://docs.tavily.com/docs/gpt-researcher/config",
        "snippet": "The config.py enables you to customize GPT Researcher to your specific needs and preferences.",
        "formattedUrl": "https://docs.tavily.com/docs/gpt-researcher/config"
      },
      {
        "title": "Introduction | Tavily",
        "link": "https://docs.tavily.com/docs/gpt-researcher/introduction",
        "snippet": "GPT Researcher is an autonomous agent designed for comprehensive online research on a variety of tasks.",
        "formattedUrl": "https://docs.tavily.com/docs/gpt-researcher/introduction"
      },
      {
        "title": "How we built GPT Researcher | Tavily",
        "link": "https://docs.tavily.com/blog/building-gpt-researcher",
        "snippet": "Sep 22, 2023 ... An open source autonomous agent for online comprehensive research. In this article, we will share the steps that guided me toward the proposed solution.",
        "formattedUrl": "https://docs.tavily.com/blog/building-gpt-researcher"
      },
      {
        "title": "How to build an OpenAI Assistant with Internet access | Tavily",
        "link": "https://docs.tavily.com/blog/building-openai-assistant",
        "snippet": "Nov 12, 2023 ... This blog will demonstrate how to leverage the latest Assistants API with online information using the function calling tool.",
        "formattedUrl": "https://docs.tavily.com/blog/building-openai-assistant"
      },
      {
        "title": "Multi Agent Frameworks | Tavily",
        "link": "https://docs.tavily.com/docs/gpt-researcher/agent_frameworks",
        "snippet": "We are strong advocates for the future of AI agents, envisioning a world where autonomous agents communicate and collaborate as a cohesive team to undertake ...",
        "formattedUrl": "https://docs.tavily.com/docs/gpt-researcher/agent_frameworks"
      },
      {
        "title": "Troubleshooting | Tavily",
        "link": "https://docs.tavily.com/docs/gpt-researcher/troubleshooting",
        "snippet": "If you're running into any issues, please first check out the resolved issues or ask us via our Discord community.",
        "formattedUrl": "https://docs.tavily.com/docs/gpt-researcher/troubleshooting"
      },
      {
        "title": "Agent Example | Tavily",
        "link": "https://docs.tavily.com/docs/gpt-researcher/example",
        "snippet": "If you're interested in using GPT Researcher as a standalone agent, you can easily import it into any existing Python project. Below, is an example of ...",
        "formattedUrl": "https://docs.tavily.com/docs/gpt-researcher/example"
      },
      {
        "title": "Introduction | Tavily",
        "link": "https://docs.tavily.com/docs/welcome",
        "snippet": "Tavily Search API is a search engine optimized for LLMs, aimed at efficient, quick and persistent search results. Unlike other search APIs such as Serp or ...",
        "formattedUrl": "https://docs.tavily.com/docs/welcome"
      },
      {
        "title": "Roadmap | Tavily",
        "link": "https://docs.tavily.com/docs/gpt-researcher/roadmap",
        "snippet": "We're constantly working on additional features and improvements to our products and services. We're also working on new products and services to help you ...",
        "formattedUrl": "https://docs.tavily.com/docs/gpt-researcher/roadmap"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Tavily | LinkedIn](https://www.linkedin.com/company/tavily)\n- [tavily (@tavilyai) / X](https://x.com/tavilyai?lang=en)\n\n# Job boards\n- None found.\n\n# App stores\n- None found.\n\n# Product reviews\n- None found.\n\n# News articles (most recent first, grouped by event)\n- **Tavily Search API Developments**\n  - [Effortless Web-Based RAG Evaluation Using Tavily and LangGraph](https://blog.tavily.com/effortless-web-based-rag-evaluation-using-tavily-and-langgraph/) - Jan 20, 2025\n  - [Building an Event-Planner Agent using Tavily, Lang-graph, and ...](https://blog.gopenai.com/building-an-event-planner-agent-using-tavily-lang-graph-and-openai-1597553fb3d1) - Jun 9, 2024\n  - [Automating Legal Compliance: The Power of Tavily and AI Agents ...](https://medium.com/@vikram40441/automating-legal-compliance-the-power-of-tavily-and-ai-agents-integration-2c11727273a3) - Oct 15, 2024\n  - [Boost Your RAG Performance with Tavily Search API | by Minh Le ...](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e) - Jul 29, 2024\n\n# Key employees (grouped by employee)\n- None found.\n\n# Other pages on the company website\n- [Tavily Blog](https://blog.tavily.com/)\n- [Tavily Documentation | Tavily](https://docs.tavily.com/)\n- [Frequently Asked Questions | Tavily](https://docs.tavily.com/docs/faq)\n- [Trust Center - Tavily](https://trust.tavily.com/)\n- [Tavily Services Agreement](https://tavily.com/terms)\n\n# Other\n- [Tavily - Company Profile - Tracxn](https://tracxn.com/d/companies/tavily/__Zcz-EM5tIW4gjY1Ra8AeGMmlKGBLxXaBSXv2VK9IYDE) - Dec 22, 2024\n- [Tavily AI - Your AI mate for rapid insights and comprehensive ...](https://eliteai.tools/tool/tavily-ai)\n- [Tavily - Future Tools](https://www.futuretools.io/tools/tavily)\n- [Tavily: Enhancing AI Capabilities with a Powerful Search API for ...](https://www.stormfors.com/platforms/tavily)",
  "crunchbase_markdown": "# Tavily, founded 2024-05-12 [(Crunchbase, 2025)](https://www.crunchbase.com/organization/tavily)\nNone\n\n- [Website](https://tavily.com)\n- [LinkedIn](https://www.linkedin.com/company/tavily)\n- [Twitter](https://x.com/tavilyai)\n\n",
  "customer_experience_result": {
    "output_text": "# Positive Sentiment\n\n## Product Performance\n- \"Tavily is a better choice, its QA context extraction is really good\" [(trj_flash75, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrecuk/)\n- \"My test results show that Tavily works really well; it always manages to find suitable sources.\" [(YoungMan2129, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrsbml/)\n- \"Tavily has a search api that allows you to search something and get snippets and links\" [(matteogeniaccio, Reddit, 2024-05-15)](https://www.reddit.com/r/LocalLLaMA/comments/1csidgc/how_to_scrape_websitepages_and_form_dataset/l45g7u6/)\n- \"We use Tavily.com to automate research and information sourcing for writing articles in werd.ai and that's sufficient for the purpose.\" [(WerdAI, Reddit, 2025-01-20)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8982nk/)\n- \"Tavily itself let's you specify the max number of results retrieved, so you're not just limited to 10!\" [(WerdAI, Reddit, 2025-01-20)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8982nk/)\n- \"I like Tavily, easy to implement and super accurate retrieval. Others are ok but Tavily is just stronger imo\" [(baller_asf, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx3wtd0/)\n- \"Its great imho\" [(Naive-Home6785, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5ha95/)\n\n# Mixed Sentiment\n\n## Product Comparison\n- \"I use Google PSE to extract top ranking links, then Tavily to extract content from these links\" [(LilFingaz, Reddit, 2025-01-21)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8a7umv/)\n\n# Negative Sentiment\n\n## Product Performance\n- \"I've found Tavily to underperform and decided to go with Google Search (GCP)\" [(tjger, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx429f0/)\n- \"we worked on building one of our own inhouse when we found tavily + exa weren't quite cutting it in terms of accurate, deep search (exact results to questions that may require searching through multiple pages)\" [(critiqueextension, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5afc5/)",
    "intermediate_steps": [
      "- \"Tavily is a better choice, its QA context extraction is really good\" [(trj_flash75, Reddit, 2024-09-06)](cache://reddit/10)\n- \"My test results show that Tavily works really well; it always manages to find suitable sources.\" [(YoungMan2129, Reddit, 2024-09-06)](cache://reddit/11)\n- \"Tavily has a search api that allows you to search something and get snippets and links\" [(matteogeniaccio, Reddit, 2024-05-15)](cache://reddit/57)\n- \"We use Tavily.com to automate research and information sourcing for writing articles in werd.ai and that's sufficient for the purpose.\" [(WerdAI, Reddit, 2025-01-20)](cache://reddit/68)\n- \"Tavily itself let's you specify the max number of results retrieved, so you're not just limited to 10!\" [(WerdAI, Reddit, 2025-01-20)](cache://reddit/68)\n- \"I use Google PSE to extract top ranking links, then Tavily to extract content from these links\" [(LilFingaz, Reddit, 2025-01-21)](cache://reddit/70)",
      "- \"I like Tavily, easy to implement and super accurate retrieval. Others are ok but Tavily is just stronger imo\" [(baller_asf, Reddit, 2024-11-14)](cache://reddit/107)\n- \"Its great imho\" [(Naive-Home6785, Reddit, 2024-11-14)](cache://reddit/108)\n- \"I've found Tavily to underperform and decided to go with Google Search (GCP)\" [(tjger, Reddit, 2024-11-14)](cache://reddit/114)\n- \"we worked on building one of our own inhouse when we found tavily + exa weren't quite cutting it in terms of accurate, deep search (exact results to questions that may require searching through multiple pages)\" [(critiqueextension, Reddit, 2024-11-14)](cache://reddit/119)"
    ],
    "url_to_review": {},
    "review_markdowns": [
      "# Post ID 1gr8jnr: Which search API should I use between Tavily.com, Exa.ai and Linkup.so? Building a RAG app that needs internet access. with +16 score by [(pcamiz, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/)\nI have tried the 3 of them and Linkup seems to have a slightly different approach, with connections to premium sources while Exa seems to be a bit faster. Curious what is your preferred option out of the 3 (or if you have other solutions).\n\n[exa.ai](http://exa.ai)\n\n[linkup.so](http://linkup.so)\n\n[tavily.com](http://tavily.com)\n\n\n\n## Comment ID lx4z1sz with +5 score by [(nightman, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx4z1sz/) (in reply to ID 1gr8jnr):\nI would use Brave Search Api - it's on another (better) level of costs\n\n### Comment ID lx8cd74 with +3 score by [(334578theo, Reddit, 2024-11-15)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx8cd74/) (in reply to ID lx4z1sz):\nWe were using Exa but it got too expensive too quickly so switched to Brave and added our own filtering and it works great.\n\n#### Comment ID lxst7db with +2 score by [(yibaiveintiocho, Reddit, 2024-11-18)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lxst7db/) (in reply to ID lx8cd74):\nHey u/334578theo , cofounder of Exa here. Curious how you're using us / calculating that? We should be cheaper. Also will DM you!\n\n### Comment ID m6q1v6x with +1 score by [(No_Marionberry_5366, Reddit, 2025-01-12)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m6q1v6x/) (in reply to ID lx4z1sz):\nInterested but quite limited for deepsearch tasks right ? I would rather use [exa.ai](http://exa.ai) or [linkup.so](http://linkup.so) for that\n\n## Comment ID lx3wtd0 with +3 score by [(baller_asf, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx3wtd0/) (in reply to ID 1gr8jnr):\nI like Tavily, easy to implement and super accurate retrieval. Others are ok but Tavily is just stronger imo\n\n## Comment ID lx5ha95 with +2 score by [(Naive-Home6785, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5ha95/) (in reply to ID 1gr8jnr):\nI only know about tavily.  Its great imho\n\n## Comment ID lx8a7sk with +2 score by [(AlpineRavine, Reddit, 2024-11-15)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx8a7sk/) (in reply to ID 1gr8jnr):\nI started with Tavily, use Google search API now, but will move to Perplexity API. I think it’s the best of the three\n\n### Comment ID m6q19w2 with +1 score by [(No_Marionberry_5366, Reddit, 2025-01-12)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m6q19w2/) (in reply to ID lx8a7sk):\nReally ? interested to know more about your use cases, Perplexity is like ALWAYS wrong when I ask specific questions about companies\n\n#### Comment ID m6q5q1w with +1 score by [(AlpineRavine, Reddit, 2025-01-12)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m6q5q1w/) (in reply to ID m6q19w2):\nOne use I recently had was I wanted to create biographies of CEOs of certain companies. So I asked the pplx api 4 different questions to build a holistic picture of the person. Then used 4o-mini in downstream to combine it to single narrative. It worked really well. I would have loved if they made perplexity pro available in the API, could have tackled more complex questions as well.\n\n## Comment ID lx3y4qs with +1 score by [(None, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx3y4qs/) (in reply to ID 1gr8jnr):\n[removed]\n\n### Comment ID lx44bar with +1 score by [(pcamiz, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx44bar/) (in reply to ID lx3y4qs):\nThanks! will look into it more\n\n## Comment ID lx429f0 with +1 score by [(tjger, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx429f0/) (in reply to ID 1gr8jnr):\nI've found Tavily to underperform and decided to go with Google Search (GCP)\n\n### Comment ID lx44ipa with +2 score by [(pcamiz, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx44ipa/) (in reply to ID lx429f0):\nThanks for your reply! Do you drop the snippets of the results into your LLM context window? Asking because that's close to what i was doing with SERP API but had poor results\n\n### Comment ID m03v2ad with +1 score by [(HighOnLSTM, Reddit, 2024-12-02)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m03v2ad/) (in reply to ID lx429f0):\nWhich exact service are you using in GCP? Can you drop the official doc link by any chance? The closest I've found is - [https://programmablesearchengine.google.com/about/](https://programmablesearchengine.google.com/about/), which has super clunky documentation, and needs some significant configuration for web-search, and the results aren't even that great.\n\n#### Comment ID m08apc2 with +1 score by [(tjger, Reddit, 2024-12-03)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/m08apc2/) (in reply to ID m03v2ad):\nIt is exactly that one with Google Custom Search API\n\n## Comment ID lx5afc5 with +1 score by [(critiqueextension, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5afc5/) (in reply to ID 1gr8jnr):\nwe worked on building one of our own inhouse when we found tavily + exa weren't quite cutting it in terms of accurate, deep search (exact results to questions that may require searching through multiple pages). that + the price made us build our own, and we threw it up as a service. It's absolutely not faster (yet, we're working on it) than those services if latency is your biggest concern. But its cheaper, and the reranking and chunking is also parametrically done by an agent, as opposed to the static params (that we suspect) they're using. \n\nfeel free to check it out: [https://critiquebrowser.app/en/flow-api](https://critiquebrowser.app/en/flow-api)\n\nit supports structured output parsing, so if you want in-line citation style responses, you can use the search api as is, but if you want structured output, you can specify a JSON schema and it'll return that to you. Also there's an API designer if you want tailor made specific responses to a formatted search every time.\n\n### Comment ID lx5xu78 with +1 score by [(Impressive_Log6884, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx5xu78/) (in reply to ID lx5afc5):\nDoesn't building a search engine mean indexing the whole web? Or, are you wrapping GCP\n\n#### Comment ID lx665qp with +1 score by [(critiqueextension, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/lx665qp/) (in reply to ID lx5xu78):\nwrapping GCP,DDG,Brave,and other major content platforms individually. I don't think it precludes counting as a search engine since there still exists a mechanism performing search over a set of results. (admittedly it is using another engine hence the distinction 'agentic')",
      "# Post ID 1fa73cn: Tavily vs. Exa for RAG with LangChain - Any Recommendations? with +5 score by [(YoungMan2129, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/)\nI'm starting to build a RAG workflow using LangChain, and I'm at the stage where I need to pick a search tool. I'm looking at Tavily and Exa, but I'm not sure which one would be the better choice.   \nWhat are the key difference between them?\n\n## Comment ID llrecuk with +2 score by [(trj_flash75, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrecuk/) (in reply to ID 1fa73cn):\nTavily is a better choice, its QA context extraction is really good\n\n### Comment ID llrsbml with +1 score by [(YoungMan2129, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrsbml/) (in reply to ID llrecuk):\nMy test results show that Tavily works really well; it always manages to find suitable sources. However, I'm not quite clear on how it actually accomplishes this.\n\n## Comment ID llrtt5d with +1 score by [(ravediamond000, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llrtt5d/) (in reply to ID 1fa73cn):\nBe careful with search engine tool as it can really gives you bad data, even more in case that is very domain specific oriented.\n\n### Comment ID llt3hqn with +1 score by [(YoungMan2129, Reddit, 2024-09-06)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/llt3hqn/) (in reply to ID llrtt5d):\nThanks for the reminder😀\n\n## Comment ID lmunexh with +1 score by [(OkMathematician8001, Reddit, 2024-09-13)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/lmunexh/) (in reply to ID 1fa73cn):\nthe best Ai web search tool is openperplex (api.openperplex.com) you can try it for free. citations, sources , pro mode, 40+ locations and more.  \n[openperplex.com](http://openperplex.com)\n\n### Comment ID lmvvngy with +1 score by [(YoungMan2129, Reddit, 2024-09-13)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/lmvvngy/) (in reply to ID lmunexh):\nIs that still open source now?\n\n#### Comment ID lmx1kqh with +1 score by [(OkMathematician8001, Reddit, 2024-09-13)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/lmx1kqh/) (in reply to ID lmvvngy):\nYes it is opensource, you can host the search backend yourself or you can use the api\n\n## Comment ID lx40pyq with +1 score by [(pcamiz, Reddit, 2024-11-14)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/lx40pyq/) (in reply to ID 1fa73cn):\nReopening this one. Anyone with recent experience using Tavily.com vs. Exa.ai vs. Linkup.so? I am trying them out for my RAG app that needs to access internet content. Which one do you recommend?\n\n### Comment ID m026ne7 with +1 score by [(comeoncomon, Reddit, 2024-12-02)](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/m026ne7/) (in reply to ID lx40pyq):\nLinkup has done the job for me for sales enablement and research use case - accuracy has been superior and I don't mind a bit more latency",
      "# Post ID 1cc1dyq: How are you guys doing internet search? with +14 score by [(OfficeSalamander, Reddit, 2024-04-24)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/)\nI am trying to use internet-search enabled bots, and I was wondering how you guys were doing it - I see that Serpdev and Tavily have Langchain integration - which of these two do you guys like? Or do you roll your own?\n\n## Comment ID l15grm7 with +3 score by [(sergeant113, Reddit, 2024-04-25)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l15grm7/) (in reply to ID 1cc1dyq):\nMy experience is that determining what to search is half the battle here. I’ve built a search-enabled chatbot using my own Searx server and wikipedia, and the good results are very dependent on the complexity of the user’s question. \n\nMy plan to improve this setup is to build a dedicated research Agent that will process the question into a research problem with various information requirements. Then a search agent will attempt to collect the information for the research agent. Finally a executive summary and report is compiled for me.\n\nOf course, there will have to be a mechanism to determine which question get this full-flow treatment, and which only require a direct search query.\n\n### Comment ID lfyqwup with +1 score by [(baggsy_, Reddit, 2024-08-01)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lfyqwup/) (in reply to ID l15grm7):\n>My plan to improve this setup is to build a dedicated research Agent that will process the question into a research problem with various information requirements. Then a search agent will attempt to collect the information for the research agent. Finally a executive summary and report is compiled for me.\n\nu/sergeant113, did you have much success here? I definitely need to work on the \"knowing what to Google\"  problem (as opposed to the SERP APIs or scraping), and have been thinking of leveraging agents to help me.\n\n### Comment ID lrrl537 with +1 score by [(Traditional_Art_6943, Reddit, 2024-10-13)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lrrl537/) (in reply to ID l15grm7):\nAre you still developing an agent, I too am building a Searx powered search, scrape and summarizing agent. I will be very glad to discuss on the same\n\n#### Comment ID lrrmdyy with +1 score by [(sergeant113, Reddit, 2024-10-13)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lrrmdyy/) (in reply to ID lrrl537):\nIt’s pending for now. The search & summarize part has been done. I’m still working on the query planning. Some potential leads, but I havent had the time to do some extensive development. Happy to discuss though.\n\n## Comment ID l15ftxa with +2 score by [(suavestallion, Reddit, 2024-04-25)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l15ftxa/) (in reply to ID 1cc1dyq):\nI'm using google cse. Easy peasy. And scrapers\n\n### Comment ID l1663eb with +2 score by [(Such_Advantage_6949, Reddit, 2024-04-25)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1663eb/) (in reply to ID l15ftxa):\nWhat you mean by google cse, i tried to find if there is google api to do search but couldnt find any\n\n#### Comment ID l1c9zun with +1 score by [(Jdonavan, Reddit, 2024-04-26)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1c9zun/) (in reply to ID l1663eb):\nThen you didn't even use google in your search.\n\n## Comment ID l12p9xw with +1 score by [(Familyinalicante, Reddit, 2024-04-24)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l12p9xw/) (in reply to ID 1cc1dyq):\nThere's planty of solutions. You need to be more specific. There's also many tutorials on internet for this.\n\n### Comment ID l1302uk with +2 score by [(OfficeSalamander, Reddit, 2024-04-24)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1302uk/) (in reply to ID l12p9xw):\nA tutorial doesn’t really help me - I know how to write the integrations easily enough - I’ve already tested Tavily and Serpdev for my use case, and I’m contemplating just writing my own search code (would allow me to get the granularity of the search results I want perhaps), but I wanted people’s opinions about what they liked or found useful for search integration for LLMs.\n\nI’m not sure what more specificity you want me to provide but if you want to know what I’m trying to do - I want to search current news, mostly. That’s my main use-case. Specifically for agent bots like CrewAI\n\n#### Comment ID l1bix96 with +1 score by [(Familyinalicante, Reddit, 2024-04-26)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1bix96/) (in reply to ID l1302uk):\nDuckduckGo tool is not what you're looking for?\n\n#### Comment ID lrrl9dp with +1 score by [(Traditional_Art_6943, Reddit, 2024-10-13)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lrrl9dp/) (in reply to ID l1302uk):\nAre you still working on this agent\n\n## Comment ID l12vvx7 with +1 score by [(Skylight_Chaser, Reddit, 2024-04-24)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l12vvx7/) (in reply to ID 1cc1dyq):\nperplexity is cool atm\n\n## Comment ID l17saa9 with +1 score by [(None, Reddit, 2024-04-25)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l17saa9/) (in reply to ID 1cc1dyq):\nBrave search api works good and easy to implement\n\n## Comment ID l1c82p4 with +1 score by [(suavestallion, Reddit, 2024-04-26)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1c82p4/) (in reply to ID 1cc1dyq):\nUse a custom google search engine, plus the Google tool in langchain. Just search the langchain documentation. Don't use serpapi\n\n### Comment ID l1clae0 with +2 score by [(OfficeSalamander, Reddit, 2024-04-26)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/l1clae0/) (in reply to ID l1c82p4):\nYeah that’s pretty much where I am now. I was wondering why people were paying for these services rather than just using normal Google search APIs, and figured there must be a reason, which is why I came here. But honestly, looking at the results, it looks pretty damn similar to just baseline Google search results, and that API is free, so I’m not sure why people are using these other APIs\n\n#### Comment ID lpezy5r with +1 score by [(valueinvesting_io, Reddit, 2024-09-28)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lpezy5r/) (in reply to ID l1clae0):\nis there a limit to the number of Google search APIs you can request?\n\n### Comment ID lk7472p with +1 score by [(Altruistic_Box8467, Reddit, 2024-08-27)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lk7472p/) (in reply to ID l1c82p4):\nWhy not serpapi? Because it scrapes google which is not allowed by google?\n\n#### Comment ID lk8q3ff with +1 score by [(suavestallion, Reddit, 2024-08-27)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lk8q3ff/) (in reply to ID lk7472p):\nI just like it better. I don't care about rules\n\n## Comment ID lktp0d4 with +1 score by [(OkMathematician8001, Reddit, 2024-08-31)](https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/lktp0d4/) (in reply to ID 1cc1dyq):\nConsider testing out the Openperplex API. In my experience, it offers more robust features compared to Tavily and other alternatives. Some standout capabilities include multi-language support, location-based services, and flexible answer formats (HTML, Markdown, or plain text). You can explore these features at no cost with their free trial option.\n\nhttps://preview.redd.it/z2cqkqa1xzld1.png?width=2514&format=png&auto=webp&s=9bb3a1f3c52c26b89b0704fcefab69b14ccda4f8\n\n  \n[https://api.openperplex.com](https://api.openperplex.com)",
      "# Post ID 1auucox: Agent that uses a vector store retriever and a websearch retriever ( tavily or google search ) as tools for RAG with +6 score by [(None, Reddit, 2024-02-19)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/)\nHello everyone , i'm currently stuck on making an agent that uses two different retrievers as tools through create\\_retriever\\_tool and initialize\\_agent. However , im either getting stuck in a loop , getting wrong results or just exceeding context limit.\n\nIm wondering if there is someone has done something like this with local models or any documentation on this subject. \n\nTIA\n\n&#x200B;\n\n## Comment ID l5e58f0 with +1 score by [(Mohamed_SickitLearn, Reddit, 2024-05-23)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/l5e58f0/) (in reply to ID 1auucox):\nsimple RAG systems won't allow you unofortuantely to build such complex idea. you will need to implement something Self-RAG. check this example [https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph\\_self\\_rag.ipynb](https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag.ipynb)   \nyou might find also videos explaining Self RAG and Addaptive RAG.\n\n## Comment ID kr6mcxp with +1 score by [(eduardopy, Reddit, 2024-02-19)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/kr6mcxp/) (in reply to ID 1auucox):\nYou would need to share what you are doing to get helped.\n\n## Comment ID krcj5xw with +1 score by [(IlEstLaPapi, Reddit, 2024-02-20)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/krcj5xw/) (in reply to ID 1auucox):\nI think you need a planner to decide which tool to use and a feedback loop to adapt.  Or you need to define a priority order if your usecase makes it obvious.\n\n## Comment ID krdsnaj with +1 score by [(mehul_gupta1997, Reddit, 2024-02-21)](https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/krdsnaj/) (in reply to ID 1auucox):\nWas facing the same issue, then used chains as tools. Working fine now : https://youtu.be/cBpdiQ3gljM?si=QZY61sIU0SE3UhGS",
      "# Post ID 1d3upmf: Would you use this instead of Perplexity? with +2 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/)\nI'm building a General purpose AI Copilot (Bind AI) with ability to switch between GPT-4o, Claude 3 Opus, Command R and a few other models, it carries over the chat history when you switch models. We just added \"Web Search\", similar to Perplexity it can research the web and provide a summarized answer. You can generate code and execute the code (simple stuff which does not require multiple files to execute)\n\nI wanted get feedback from this community, as you guys use multiple tools along with Perplexity:\n\n1. Would you find this useful, in addition *or* as a replacement to Perplexity, Phind, MS Copilot or similar?\n2. If not, why not, what could make this more useful?\n\nIf you're interested to know the inner workings, we're using a prompt template + Langchain Agents/Tools which interacts with the web. We experimented with quite a few APIs for search retrieval (Bing search, Brave, Google search via SERPapi, Tavily). It is fairly easy to get something working, however, it does require implementing agentic workflows and tool routing to get better responses, esp. for cases where you don't actually need to search the web (recent models such as GPT-4o do fairly well without internet search). We also noticed that, better models do better job synthesizing the information from search results, we compared 4o, Command R, Haiku, Mixtral, GPT 3.5. (I might write a blog post on this, I had posted a comment on a sub-reddit recently). We're not yet integrated with Mistral Codestral which just came out today.\n\n**Edit**: Removed the links, since I got the feedback I was looking for.\n\nIf you're curious, you can google for \"Bind AI\" and find the link.\n\n## Comment ID l6a9pdx with +6 score by [(fluffy_muser, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6a9pdx/) (in reply to ID 1d3upmf):\nAre you applying Sun Zu wisdom: “Keep your friends close; keep your enemies closer.” by posting it here? 😂\n\n### Comment ID l6ac03b with +2 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6ac03b/) (in reply to ID l6a9pdx):\nHaha. This subreddit is a good touchstone to test out my hypothesis :)\nIf it is positive here then maybe it's something useful\n\n## Comment ID l6ajs1n with +3 score by [(nightman, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6ajs1n/) (in reply to ID 1d3upmf):\nThank you for the explanation. But to get the answer you have to explain what you will provide on top of what is Perplexity providing. If it's just a clone, with same functionality (and possibly worst accuracy and hallucinations as you sometimes skip search) - why should we use it?\n\n### Comment ID l6am36x with +3 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6am36x/) (in reply to ID l6ajs1n):\nThe primary purpose of Bind AI is to create a general purpose AI system which can automate boring or repetitive tasks and \"do the tasks for you\".\n\nThere are several such tasks and several tools for the job right now. We're focusing on \"work\" related tasks and not really general/leisure web search (eg shopping).\nThere are a lot of vertical AI applications for different purposes (eg Jasper/Writer for Marketing, Github Copilot for code, Perplexity for Search, Microsoft copilot for general things, custom built AI assistants), in reality it's not that complex to build a single system that can do all or atleast most of it\n\nBelow is the functionality we plan to provide so that everything can be done via a single platform rather than multiple tools:\n- Select the most advanced and latest AI models in a single place\n- Ability to search the web to create deeply researched content/articles/documents\n- Connected to specialized datasets (eg sec financial data) to get much deeper insights.\n- In-built Code Canvas to generate, edit AI-generated code, execute/test it.\n- In-built document canvas to act on the AI-generated data (rather than copy pasting snippets to google docs).\n- Integrate your data (GitHub, Google drive, Upload etc) to generate content/code based on your information\n- Push AI generated data out directly (github, salesforce etc)\n- Automate sequential tasks via agents, by connecting your APIs or applications (eg grab data from salesforce and push it to Marketo)\n\nPersona wise, we're targeting folks looking to do technical tasks, and not really general consumers.\n\nThe question does arise, why do we need web search in Bind AI? Because, it's table stakes. Why provide outdated information? It doesn't really make sense to have someone use 2-3 different AI tools to do overlapping tasks.\n\ntl;dr: Perplexity is looking to be a google-killer, we're looking to reimagine how work is done with AI.\n\n#### Comment ID l6amy50 with +2 score by [(nightman, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6amy50/) (in reply to ID l6am36x):\nThank for the explanation\n\n## Comment ID l6b3bim with +2 score by [(InappropriateCanuck, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6b3bim/) (in reply to ID 1d3upmf):\nSure, if it's better I'll use that one instead.\n\nI just trialed it with a complex design query (database design semantics about cursors, composite indexes, b-trees in various SQL databases) and it failed pretty royally to organize its thoughts with sequential searches like Perplexity does tbh. \n\nUnsure what model this uses behind the scenes as I can't choose it for my query. Which to me is an automatic lose.\n\nEdit: I actually can't get the Web Search going.\n\n### Comment ID l6b5syf with +2 score by [(defection_, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6b5syf/) (in reply to ID l6b3bim):\nI'll agree with this. I've been increasingly disappointed with Perplexity and their way of going about things, so I'd be more than open to leaving. However, after an initial test for my uses, there's still going to be a fair bit of work that needs to be done to surpass Perplexity's capabilities.\n\n#### Comment ID l6bnamk with +1 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6bnamk/) (in reply to ID l6b5syf):\nIf you don't mind sharing, could you list your key use cases. Is it general search, code generation?\n\n### Comment ID l6bmrnx with +2 score by [(datacog, Reddit, 2024-05-30)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6bmrnx/) (in reply to ID l6b3bim):\nThis is good, real, eye opening feedback (also because I just woke up and checked this as the first thing).\nRight now, it's using a GPT-4o model, and we're only playing with a prompt+tool.\nTo select a model, [this](https://copilot.getbind.co/chat/code-generation?model=all) link will take you there(It requires a trial signup, had to put a paywall as Opus is pretty expensive and we're bootstrapping)\n\ntbh, it will do simple things right now. \nWe havent released an agentic planner yet for code generation or search, which is what pplx pro search does. It's taking about a minute to plan and breakdown things, and we're optimizing it to respond much faster.\nIf you're open to sharing your actual query over dm, i'd like to see how we could improve the system to deal with those.\n\nIt will be a bit of a catchup for us, we've raised $0 vs $100M raised by perplexity. I have been bootstrapping with a small team, inspired by how zapier built its business.\n\nThat said, reddit is a great place to be humbled, but also a great place to learn real hard feedback. So thank you for this!\n\n## Comment ID l6fz460 with +1 score by [(crazy_canuck, Reddit, 2024-05-31)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6fz460/) (in reply to ID 1d3upmf):\nI’m a consultant working with SMBs, there are quite a number of enterprise features I’d like to bring to my clients. Are you interested in building enterprise features?\n\n### Comment ID l6hbj4x with +1 score by [(datacog, Reddit, 2024-05-31)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6hbj4x/) (in reply to ID l6fz460):\nDefinitely. Let me DM you.\n\n## Comment ID l6ly6zv with +1 score by [(TomHale, Reddit, 2024-06-01)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6ly6zv/) (in reply to ID 1d3upmf):\nI tried the F1 example.  I want to be able to click through and verify, but I cannot.\n\n### Comment ID l6mvcpv with +1 score by [(datacog, Reddit, 2024-06-01)](https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/l6mvcpv/) (in reply to ID l6ly6zv):\nYou mean, you want to click on the source link and verify but it's not working?",
      "# Post ID 1goq6b5: A Personal NotebookLM and Perplexity-like AI Assistant with privacy. with +18 score by [(Uiqueblhats, Reddit, 2024-11-11)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/)\nHi everyone for the last month or two I have been trying to build a hybrid of NotebookLM and Perplexity with better integration with browsers as well.\n\nSo here is my little attempt to make something.\n\nhttps://reddit.com/link/1goq6b5/video/ybcb9nard90e1/player\n\nSurfSense :\n\nWhile tools like NotebookLM and Perplexity are impressive and highly effective for conducting research on any topic, imagine having both at your disposal with complete privacy control. That's exactly what SurfSense offers. With SurfSense, you can create your own knowledge base for research, similar to NotebookLM, or easily research the web just like Perplexity. SurfSense also includes an effective cross-browser extension to directly save dynamic content bookmarks, such as social media chats, calendar invites, important emails, tutorials, recipes, and more to your SurfSense knowledge base. Now, you’ll never forget anything and can easily research everything.\n\nBugs are to be expected but I hope you guys give it a go.\n\nGitHub Link: [https://github.com/MODSetter/SurfSense](https://github.com/MODSetter/SurfSense)\n\n## Comment ID lwkxhxm with +2 score by [(rageagainistjg, Reddit, 2024-11-11)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwkxhxm/) (in reply to ID 1goq6b5):\nHey there! Quick question for you. I’m not totally clear on how this tool works, so I’d love a bit of clarification. Let’s say I have a website or a blog, and it’s packed with links, tutorials, and documentation about a product—let’s use Microsoft Excel as an example. So if I just put in the link to the blog’s homepage, would your tool search through everything on that blog? And then, when I ask it a question, it would refer to the blog’s content to help solve the problem? Is that how it works?\n\n### Comment ID lwmn3x7 with +1 score by [(Uiqueblhats, Reddit, 2024-11-11)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwmn3x7/) (in reply to ID lwkxhxm):\nHi my tool helps you to easily save data (bookmarks or files) to your RAG system and it have access to search engine api's. It can help you research faster over your data or from web.\n\n#### Comment ID lwmoc8j with +1 score by [(rageagainistjg, Reddit, 2024-11-11)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwmoc8j/) (in reply to ID lwmn3x7):\nThanks! Just want to clarify two things:\n\n1. If I input a website URL, does your tool automatically scan all pages within that site?\n\n2. Once saved, can it then use that site’s content to answer my specific questions?\n\nTrying to understand exactly how it works with website content.”​​​​​​\n\n## Comment ID lwozje6 with +2 score by [(youmeiknow, Reddit, 2024-11-12)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwozje6/) (in reply to ID 1goq6b5):\nThanks for this. I have few questions, can you help me to understand\n\n1. Being self host - does it need api keys of perpelxicy (I turn perplexity subscription)?\n2. What LLms the tool is using?\n\n### Comment ID lwp00bt with +1 score by [(Uiqueblhats, Reddit, 2024-11-12)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwp00bt/) (in reply to ID lwozje6):\n1. No it doesn't use Perplexity API. It uses gpt-researcher (It supports multiple search engines API) internally with few of my modifications for my usecase.\n\n2.gpt-4o-mini in video. I suggest qwen for local setups\n\n## Comment ID lwlrwev with +1 score by [(mountainhighmushroom, Reddit, 2024-11-11)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwlrwev/) (in reply to ID 1goq6b5):\nI tried creating an account but got an error. Seems sweet though\n\n### Comment ID lwmo6zb with +2 score by [(Uiqueblhats, Reddit, 2024-11-11)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwmo6zb/) (in reply to ID lwlrwev):\nOnline website is just for showcase atm. You need to self host it for now :)\n\n## Comment ID lwo9f7x with +1 score by [(cleverusernametry, Reddit, 2024-11-12)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwo9f7x/) (in reply to ID 1goq6b5):\nAny example spaces I can check out? 90% of open source knock offs are really poor in actual usage\n\n### Comment ID lwof93m with +1 score by [(Uiqueblhats, Reddit, 2024-11-12)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwof93m/) (in reply to ID lwo9f7x):\nI will be honest its slower compared to NotebookLM & Perplexity but responses are of same quality and dare I say it's better imo.\n\n#### Comment ID lwvskkt with +1 score by [(cleverusernametry, Reddit, 2024-11-13)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwvskkt/) (in reply to ID lwof93m):\nCan you share an example space?\n\n## Comment ID lwryjqw with +1 score by [(zono5000000, Reddit, 2024-11-12)](https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/lwryjqw/) (in reply to ID 1goq6b5):\nGetting a google captcha error saying unauthorized even tho i created my google recaptcha v2 keys. I posted more details on the github.",
      "# Post ID 1ctcncj: Farfalle: Open-source Perplexity with +57 score by [(rashadphil, Reddit, 2024-05-16)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/)\n\n\n## Comment ID l4aw0do with +17 score by [(rashadphil, Reddit, 2024-05-16)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4aw0do/) (in reply to ID 1ctcncj):\nHey all! I built an open-source AI-powered answer engine called Farfalle. It’s a a self-hostable alternative to Perplexity. It features a generative UI built from scratch with streaming events from the backend.\n\nCheck out a live demo here: [farfalle.dev](https://www.farfalle.dev/).\n\n**Open-source**: The code is fully open-source on Github ([git.new/farfalle](https://git.new/farfalle))\n\nThe repository includes instructions on how to run the project locally, along with one-click deploy buttons for Vercel and Render.\n\n🛠️ Tech Stack\n\n* **Frontend**: Next.js\n* **Backend**: FastAPI (Python)\n* **Search** **API**: Tavily\n* **Logging**: Logfire\n* **Rate Limiting**: Redis\n* **Components**: Shadcn\n* **Providers / LLMs**: Groq/LLama3-70B, OpenAI/GPT4-o\n\nI’d love to hear any feedback!\n\n### Comment ID l4ygoq5 with +2 score by [(beren0073, Reddit, 2024-05-21)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4ygoq5/) (in reply to ID l4aw0do):\nI've been playing around with it and like it. There is some inconsistency with how different models will format responses. I've also noticed that often the sources will take you to an aggregation page with numerous stories, not the one you thought you were going to read, but that may be more of a Tavily issue.\n\nDocker \"just works\" for me, nice job.\n\nGetting \"Model at capacity\" errors frequently when running the local LLMs on an Nvidia 4090. Might need to wait a little longer?\n\nStruggles with \"only use articles published today\" but I've seen similar issues with Perplexity, too.\n\n### Comment ID la1pw61 with +1 score by [(xeneks, Reddit, 2024-06-24)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/la1pw61/) (in reply to ID l4aw0do):\num.. grok worked :) I guess you paid for my single test query?\n\n## Comment ID l4c5h55 with +4 score by [(LarDark, Reddit, 2024-05-16)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4c5h55/) (in reply to ID 1ctcncj):\nLocal models and i'm in!\n\nIt looks neat tho! nice UI haha\n\n### Comment ID l4ieamq with +3 score by [(rashadphil, Reddit, 2024-05-17)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4ieamq/) (in reply to ID l4c5h55):\nJust added local model support! Check it out here: [https://github.com/rashadphz/farfalle/](https://github.com/rashadphz/farfalle/)\n\n## Comment ID l4eow3r with +2 score by [(SemaiSemai, Reddit, 2024-05-17)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4eow3r/) (in reply to ID 1ctcncj):\nWhy name it like that?\n\n### Comment ID l4epaiq with +5 score by [(rashadphil, Reddit, 2024-05-17)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4epaiq/) (in reply to ID l4eow3r):\nit's my favorite pasta shape\n\n#### Comment ID l4eprl4 with +2 score by [(SemaiSemai, Reddit, 2024-05-17)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4eprl4/) (in reply to ID l4epaiq):\nWhat's your editing software for the vid?\n\n## Comment ID l4h8zny with +2 score by [(Jatilq, Reddit, 2024-05-17)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4h8zny/) (in reply to ID 1ctcncj):\nCant get this to work. I even signed up for a api key. Wish it had an option to connect to LLMStudio. Its not giving me an error in the cmd screens. Just a red box popping up saying error when I search for something.\n\n### Comment ID l4ie8ev with +2 score by [(rashadphil, Reddit, 2024-05-17)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4ie8ev/) (in reply to ID l4h8zny):\nHey, I just updated the instructions to use docker. Let me know if you're still having problems.\n\n## Comment ID l4qqqv6 with +2 score by [(HumanAIGPT, Reddit, 2024-05-19)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4qqqv6/) (in reply to ID 1ctcncj):\nNice job,  thank you.  Gpt-4o doesn't work,  says disabled\n\n### Comment ID l4qsc7k with +2 score by [(rashadphil, Reddit, 2024-05-19)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4qsc7k/) (in reply to ID l4qqqv6):\nthanks, I had to disable it on the demo because it cost too much. you can clone the repo and use your own api key for gpt4-o. let me know if you have any problems!\n\n## Comment ID l6spgs4 with +2 score by [(klei10, Reddit, 2024-06-02)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l6spgs4/) (in reply to ID 1ctcncj):\nhi, great job.\n\n  \ni am trying to deploy it  but i am having this issue ==> No open ports detected on [0.0.0.0](http://0.0.0.0), continuing to scan...  \n\n\ncan you please  guide me how to deploy on render and vercel. i am not a tech guy .\n\n## Comment ID l4b55wn with +1 score by [(None, Reddit, 2024-05-16)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4b55wn/) (in reply to ID 1ctcncj):\n[deleted]\n\n### Comment ID l4b80hz with +3 score by [(rashadphil, Reddit, 2024-05-16)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4b80hz/) (in reply to ID l4b55wn):\nThat's a good question. ChatGPT's web browsing is helpful, but it still it's not exclusively designed for search. For example, when I'm looking up a recent event: \"what happened to ilya?\", ChatGPT might need more context to understand what I'm referring to, while Farfalle immediately finds the recent news on \"Ilya Sutskever\".\n\nhttps://preview.redd.it/1q7psu3kts0d1.png?width=3248&format=png&auto=webp&s=63c5db7fed574d6327b6ee2456fb25e1523baeee\n\n#### Comment ID l4b89ic with +4 score by [(rashadphil, Reddit, 2024-05-16)](https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/l4b89ic/) (in reply to ID l4b80hz):\nAnd also being able to swap out models is a nice bonus! Farfalle is using LLama3-70B hosted on Groq which runs extremely quickly!",
      "# Post ID 1csidgc: How to scrape website/pages and form dataset? with +9 score by [(ThrowawayProgress99, Reddit, 2024-05-15)](https://www.reddit.com/r/LocalLLaMA/comments/1csidgc/how_to_scrape_websitepages_and_form_dataset/)\nCouple disclaimers. I have no knowledge in this topic or what the current standard is. I don't have any large-scale ideas or anything at the moment like scraping a whole site. And I don't know how to do scraping while abiding by any limitations or rules the site may have. Here's a couple use cases I'd like to know how to do:\n\n1. Getting a single page at a time.\n2. Getting a page, and the pages of some links within that page, but not going wild and getting the whole site by going for every single link in an endless chain.\n\nWhat are the tools for scraping? Are you supposed to use a VPN or something when scraping? What happens to unique formatting, fonts, embedded images, etc.? That and other similar questions are also things I'd like to know.\n\nIdeally if I could get an LLM to analyze pages as it comes across them, and only take the ones that fall under the orders given to it, that'd be great, but I don't know if progress has reached there yet. For sites that use tagging or organization already, it wouldn't even have to open every page, just grab the pages that fall under the tagging I want.\n\n## Comment ID l45g7u6 with +8 score by [(matteogeniaccio, Reddit, 2024-05-15)](https://www.reddit.com/r/LocalLLaMA/comments/1csidgc/how_to_scrape_websitepages_and_form_dataset/l45g7u6/) (in reply to ID 1csidgc):\nThere are free APIs online that can do most of the work for you:\n\n* tavily has a search api that allows you to search something and get snippets and links\n\n* jina.ai can scrape a website and extract the main content of a webpage\n\nRight now I'm using a custom workflow:\n\n* spawn a web browser via python and selenium\n\n* open the desired web page\n\n* inject readability.js from mozilla to enable the \"reader mode\"\n\n* use html2text to extract the text of the page as a markdown document.\n* use beautifulsoup to parse the remaining parts of the web page\n\n### Comment ID l45jpah with +2 score by [(epicfilemcnulty, Reddit, 2024-05-15)](https://www.reddit.com/r/LocalLLaMA/comments/1csidgc/how_to_scrape_websitepages_and_form_dataset/l45jpah/) (in reply to ID l45g7u6):\nWow, nice “hack” with Mozilla’s reader mode, thanks!\n\n## Comment ID l46hh6e with +2 score by [(jferments, Reddit, 2024-05-15)](https://www.reddit.com/r/LocalLLaMA/comments/1csidgc/how_to_scrape_websitepages_and_form_dataset/l46hh6e/) (in reply to ID 1csidgc):\nFor scraping, look into the documentation for [requests](https://requests.readthedocs.io/en/latest/) and [Selenium](https://selenium-python.readthedocs.io/). You only need a VPN if you are trying to circumvent blocking/throttling based on IP, or are illegally using material. If you are doing everything above board, there is no reason to use a VPN. \n\nAs far as processing the HTML itself, [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) and [requests-html](https://requests-html.kennethreitz.org/) and the best place to start. \n\nFor converting into datasets, that really depends on what will be ingesting the data, but if you're using HuggingFace to train, you can start with one of their standard [datasets](https://huggingface.co/datasets) formats.",
      "# Post ID 1h1701e: Model Context Protocol is everything I've wanted with +66 score by [(cyanheads, Reddit, 2024-11-27)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/)\n\n\n## Comment ID lz97jof with +23 score by [(cyanheads, Reddit, 2024-11-27)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lz97jof/) (in reply to ID 1h1701e):\nModel Context Protocol is everything I've wanted before I really got started building out my tools/agents ecosystem. Claude desktop app now gets native everything - full access to the internet, your computer, smart home, whatever you can build. All natively available as tools to Claude. The tools functions &instructions are injected into the system prompt so it's pretty seamless.\n\nVery excited for what's coming.\n\nEdit: I uploaded the guide I created and used for creating MCP tools. You can see it [on my github.](https://github.com/cyanheads/ModelContextProtocol-Tools/blob/main/guides/creating_mcp_tools.md)\n\nAnother [example tool using a weather tool](https://ibb.co/QcYK6QP)\n\nEdit 2: [I gave Claude access to my local file system, allowing it to write and save a pac-man game to local disk.](https://www.reddit.com/r/ClaudeAI/comments/1h1bo6y/claude_desktop_app_natively_creating_and_saving_a/)\n\nEdit 3: [Claude researching recent quantum computing breakthroughs online, writing a blog post, and saving it to disk.](https://ibb.co/HhNq6L8)\n\n### Comment ID lzc0yup with +1 score by [(silent-spiral, Reddit, 2024-11-28)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzc0yup/) (in reply to ID lz97jof):\nyo. I edited the json  file and started a server successful, but Claude still claims it has no knowledge of the \"filesystem\" tool and in fact has no idea what MCP even is\n\n### Comment ID lz9ytk9 with +1 score by [(ktpr, Reddit, 2024-11-27)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lz9ytk9/) (in reply to ID lz97jof):\nThis requires [Claude Desktop](https://claude.ai/download), correct?\n\n#### Comment ID lzabqe5 with +1 score by [(cyanheads, Reddit, 2024-11-27)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzabqe5/) (in reply to ID lz9ytk9):\nYes that's correct. I think some of the docs also say only Enterprise accounts get access, but I'm only on Pro and it's working fine\n\n### Comment ID lz98tir with +1 score by [(Secret-Concern6746, Reddit, 2024-11-27)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lz98tir/) (in reply to ID lz97jof):\nCan you share more details about how you set it up? Was it manual and easy or what? I have been looking into it in a MCP compatible tool but didn't get time to test it concretely yet\n\n#### Comment ID lz9evgc with +4 score by [(cyanheads, Reddit, 2024-11-27)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lz9evgc/) (in reply to ID lz98tir):\nI did it using Cline and about $3 in API. I [created and used this guide](https://github.com/cyanheads/ModelContextProtocol-Tools/blob/main/guides/creating\\_mcp\\_tools.md) based on the mcp docs.\n\nI'll clean up the tavily tool and upload it sometime this week\n\n## Comment ID lzawszt with +4 score by [(wegwerfen, Reddit, 2024-11-27)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzawszt/) (in reply to ID 1h1701e):\nMCP documentation with step by step examples for Claude desktop available here:\n\nhttps://modelcontextprotocol.io/introduction\n\nWorks with Pro plan on both Mac and Windows desktop app.\n\n### Comment ID lzc0tbx with +1 score by [(silent-spiral, Reddit, 2024-11-28)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzc0tbx/) (in reply to ID lzawszt):\nI cannot figure out how to enable MCP! I edit the json and restart claude Desktop like im supposed to. im on pro plan.\n\n#### Comment ID lzcadny with +2 score by [(wegwerfen, Reddit, 2024-11-28)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzcadny/) (in reply to ID lzc0tbx):\nnote, I'm running on Windows so i'm not sure if this applies to Mac.\n\nOne issue I ran into was closing the Claude desktop app window does not completely quit the app on Windows. I had to go down into the system tray (bottom right corner) and open it and right click the Claude icon and quit.\n\nIf Claude desktop connects properly to the MCP, you should get a new icon, that looks like a pair of plugs, down with the paperclip icon. If it is there you can mouse over it and it will tell you what it is. All you need to do once connected is to prompt claude about the data in the database, if that is the one you are using.\n\nHere is a video demoing it:\n\nhttps://www.youtube.com/watch?v=VNb4tGAHgos\n\n## Comment ID lzcuvam with +3 score by [(wegwerfen, Reddit, 2024-11-28)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzcuvam/) (in reply to ID 1h1701e):\nCool use for the filesystem MCP.\n\nIf you use Obsidian, point it at your obsidian vault directory. Now it not only has read access to your vault but can create and edit pages as well.\n\n## Comment ID lzeqjfe with +1 score by [(sevenradicals, Reddit, 2024-11-28)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzeqjfe/) (in reply to ID 1h1701e):\nin your screenshot, what am i seeing that can't already be done with any other stock model?\n\n### Comment ID lzg9mzn with +1 score by [(cyanheads, Reddit, 2024-11-28)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzg9mzn/) (in reply to ID lzeqjfe):\nIt's using up to date info from online. It was also only the start - see my other tries \n\n[I gave Claude access to my local file system, allowing it to write and save a pac-man game to local disk.](https://www.reddit.com/r/ClaudeAI/comments/1h1bo6y/claude_desktop_app_natively_creating_and_saving_a/)\n\n[Claude researching recent quantum computing breakthroughs online, writing a blog post, and saving it to disk.](https://ibb.co/HhNq6L8)\n\n#### Comment ID lzj99he with +1 score by [(sevenradicals, Reddit, 2024-11-29)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lzj99he/) (in reply to ID lzg9mzn):\nwell, my point was more about the question.  anyone can ask Claude about rare dog breeds and it'll spit out a reasonable answer (rarest breeds don't change by the month).\n\n## Comment ID lza9afp with +1 score by [(Pro-editor-1105, Reddit, 2024-11-27)](https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/lza9afp/) (in reply to ID 1h1701e):\nhow do I use it.",
      "# Post ID 1i60gxp: What's Your Recent Favourite AI Assistant For Topic Research?  with +0 score by [(rahatrhm, Reddit, 2025-01-20)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/)\n\n\n\n\n## Comment ID m892dpc with +2 score by [(Impressive-Cry-1563, Reddit, 2025-01-20)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m892dpc/) (in reply to ID 1i60gxp):\nAI isn’t reliable for research. It only searches top 10 results on google.\n\n### Comment ID m8dv16n with +1 score by [(rahatrhm, Reddit, 2025-01-21)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8dv16n/) (in reply to ID m892dpc):\nThat's right. But AI helps the research process faster. I use AI as an assistant only\n\n## Comment ID m8982nk with +2 score by [(WerdAI, Reddit, 2025-01-20)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8982nk/) (in reply to ID 1i60gxp):\nWe use Tavily.com to automate research and information sourcing for writing articles in werd.ai and that's sufficient for the purpose.\nTavily itself let's you specify the max number of results retrieved, so you're not just limited to 10!\n\n### Comment ID m8dv3jq with +1 score by [(rahatrhm, Reddit, 2025-01-21)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8dv3jq/) (in reply to ID m8982nk):\n🔥\n\n## Comment ID m8a7umv with +2 score by [(LilFingaz, Reddit, 2025-01-21)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8a7umv/) (in reply to ID 1i60gxp):\nI use Google PSE to extract top ranking links, then Tavily to extract content from these links, llama 3 to review extracted content and build an outline that covers everything from these ranking pages.\n\n### Comment ID m8dur1m with +1 score by [(rahatrhm, Reddit, 2025-01-21)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8dur1m/) (in reply to ID m8a7umv):\nGreat workflow. I'll try this out. Thanks a lot❤️\n\n## Comment ID m8aaiz2 with +2 score by [(adelarenal, Reddit, 2025-01-21)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8aaiz2/) (in reply to ID 1i60gxp):\nPerplexity AI but the Pro version. It’s great.\n\n### Comment ID m8dujo0 with +1 score by [(rahatrhm, Reddit, 2025-01-21)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8dujo0/) (in reply to ID m8aaiz2):\nPerplexity is a great tool. I use it almost every task😍\n\n## Comment ID m8m3qap with +1 score by [(Im_Saadon, Reddit, 2025-01-22)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8m3qap/) (in reply to ID 1i60gxp):\nPreplexity AI. It’s a life saver!\n\n## Comment ID m8p5jvi with +1 score by [(mikevannonfiverr, Reddit, 2025-01-23)](https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/m8p5jvi/) (in reply to ID 1i60gxp):\nI’ve been using ChatGPT lately and it’s pretty solid for brainstorming ideas and diving deep into topics. I like how it can give me different angles to approach a project. Also, integrating it with tools like Notion makes organizing thoughts so much easier. Just a game changer for my workflow!"
    ],
    "sources": {
      "steam_url": null,
      "steam_reviews": null,
      "google_play_url": null,
      "google_play_reviews": null,
      "apple_store_url": null,
      "apple_reviews": null,
      "reddit_urls": [
        "https://www.reddit.com/r/Rag/comments/1gr8jnr/which_search_api_should_i_use_between_tavilycom/",
        "https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/",
        "https://www.reddit.com/r/LangChain/comments/1cc1dyq/how_are_you_guys_doing_internet_search/",
        "https://www.reddit.com/r/LangChain/comments/1auucox/agent_that_uses_a_vector_store_retriever_and_a/",
        "https://www.reddit.com/r/perplexity_ai/comments/1d3upmf/would_you_use_this_instead_of_perplexity/",
        "https://www.reddit.com/r/ChatGPTCoding/comments/1goq6b5/a_personal_notebooklm_and_perplexitylike_ai/",
        "https://www.reddit.com/r/OpenAI/comments/1ctcncj/farfalle_opensource_perplexity/",
        "https://www.reddit.com/r/LocalLLaMA/comments/1csidgc/how_to_scrape_websitepages_and_form_dataset/",
        "https://www.reddit.com/r/ClaudeAI/comments/1h1701e/model_context_protocol_is_everything_ive_wanted/",
        "https://www.reddit.com/r/content_marketing/comments/1i60gxp/whats_your_recent_favourite_ai_assistant_for/"
      ],
      "reddit_search_url": "https://www.google.com/search?q=site%3Areddit.com+%22Tavily%22+related%3Atavily.com+"
    }
  },
  "glassdoor_result": null,
  "news_result": [
    [
      "Tavily",
      "Tavily",
      "tavily.com",
      null,
      false,
      false
    ],
    [
      {
        "title": "Tavily",
        "link": "https://tavily.com/",
        "snippet": "Oct 23, 2024 ... Tavily is a search engine tailored for AI agents, delivering real-time, accurate results, intelligent query suggestions, and in-depth research capabilities.",
        "formattedUrl": "https://tavily.com/"
      },
      {
        "title": "API Reference | Tavily",
        "link": "https://docs.tavily.com/docs/rest-api/api-reference",
        "snippet": "Aug 10, 2024 ... Our REST API provides seamless access to Tavily Search, a powerful search engine for LLM agents, and Tavily Extract, an advanced web scraping solution ...",
        "formattedUrl": "https://docs.tavily.com/docs/rest-api/api-reference"
      },
      {
        "title": "Response times are slow - Other Tavily Topics - Tavily Community",
        "link": "https://community.tavily.com/t/response-times-are-slow/131",
        "snippet": "Sep 10, 2024 ... Hello Team We see that Tavily is taking a minimum of 4 seconds to reply even when we have set max of 3 responses to be retried.",
        "formattedUrl": "https://community.tavily.com/t/response-times-are-slow/131"
      },
      {
        "title": "Langchain | Tavily",
        "link": "https://docs.tavily.com/docs/integrations/langchain",
        "snippet": "Sep 16, 2024 ... How to use Tavily API with Langchain​ · os · from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper · from langchain.agents. · from ...",
        "formattedUrl": "https://docs.tavily.com/docs/integrations/langchain"
      },
      {
        "title": "Latest topics - Tavily Community",
        "link": "https://community.tavily.com/latest",
        "snippet": "Jul 11, 2024 ... 0, 17, January 23, 2025. Can we date bound the Tavily API like we do for days while using topic=\"news\"? API · all-services. 9, 106, January 23, 2025.",
        "formattedUrl": "https://community.tavily.com/latest"
      },
      {
        "title": "Precision in AI Research: Tavily's Company Researcher",
        "link": "https://blog.tavily.com/companyresearcher/",
        "snippet": "Nov 18, 2024 ... This tool integrates Tavily Search and Extract, in a workflow powered by LangGraph, to deliver precise, reliable insights.",
        "formattedUrl": "https://blog.tavily.com/companyresearcher/"
      },
      {
        "title": "Invoices now available on the Tavily Dashboard - Announcements ...",
        "link": "https://community.tavily.com/t/invoices-now-available-on-the-tavily-dashboard/58",
        "snippet": "Jul 30, 2024 ... Good news! As of July 30th, 2024, you can now see your invoices directly on ... Related topics. Topic, Replies, Views, Activity. Tavily JavaScript package ...",
        "formattedUrl": "https://community.tavily.com/t/invoices-now-available-on-the-tavily.../58"
      },
      {
        "title": "Effortless Web-Based RAG Evaluation Using Tavily and LangGraph",
        "link": "https://blog.tavily.com/effortless-web-based-rag-evaluation-using-tavily-and-langgraph/",
        "snippet": "Jan 20, 2025 ... Step 3: Web Search with Tavily · topic=\"news\" : Narrows the search to news-related content, targeting fresh and reliable sources. · days=3 : Searches for content ...",
        "formattedUrl": "https://blog.tavily.com/effortless-web-based-rag-evaluation-using-tavily-an..."
      },
      {
        "title": "tavily-ai/tavily-python: A python wrapper for Tavily search API - GitHub",
        "link": "https://github.com/tavily-ai/tavily-python",
        "snippet": "Aug 29, 2024 ... Performs a Tavily Search query and returns a str of content and sources within the provided token limit. It's useful for getting only related content from ...",
        "formattedUrl": "https://github.com/tavily-ai/tavily-python"
      },
      {
        "title": "tavily-python · PyPI",
        "link": "https://pypi.org/project/tavily-python/",
        "snippet": "Jul 19, 2024 ... The Tavily Python wrapper allows for easy interaction with the Tavily API, offering the full range of our search functionality directly from your Python ...",
        "formattedUrl": "https://pypi.org/project/tavily-python/"
      },
      {
        "title": "RamXX/mcp-tavily: An MCP server for Tavily's search API - GitHub",
        "link": "https://github.com/RamXX/mcp-tavily",
        "snippet": "Dec 9, 2024 ... Search recent news articles with Tavily's news search; Arguments: query ... Give me the top 10 AI-related news in the last 5 days. Debugging. You can use ...",
        "formattedUrl": "https://github.com/RamXX/mcp-tavily"
      },
      {
        "title": "Tavily Search | 🦜️ LangChain",
        "link": "https://python.langchain.com/docs/integrations/tools/tavily_search/",
        "snippet": "May 13, 2024 ... Tavily's Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.",
        "formattedUrl": "https://python.langchain.com/docs/integrations/tools/tavily_search/"
      },
      {
        "title": "LLM Enhanced Web Search: The Tavily & Lang Chain",
        "link": "https://www.kaggle.com/code/marcinrutecki/llm-enhanced-web-search-the-tavily-lang-chain",
        "snippet": "Apr 3, 2024 ... Tavily is a search API, specifically designed for AI agents and tailored for RAG purposes. Tavily's primary objective is to provide factual and reliable ...",
        "formattedUrl": "https://www.kaggle.com/.../llm-enhanced-web-search-the-tavily-lang-chain"
      },
      {
        "title": "TavilySearchAPIRetriever | 🦜️ LangChain",
        "link": "https://python.langchain.com/docs/integrations/retrievers/tavily/",
        "snippet": "May 13, 2024 ... Tavily's Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.",
        "formattedUrl": "https://python.langchain.com/docs/integrations/retrievers/tavily/"
      },
      {
        "title": "Tavily",
        "link": "https://www.crunchbase.com/organization/tavily/org_similarity_overview",
        "snippet": "Sep 23, 2024 ... +2 more. Choosito! search and learn turns the web into a leveled library of educational resources. Tavily and Choosito share similar descriptions and employee ...",
        "formattedUrl": "https://www.crunchbase.com/organization/tavily/org_similarity_overview"
      },
      {
        "title": "Boost Your RAG Performance with Tavily Search API | by Minh Le ...",
        "link": "https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e",
        "snippet": "Jul 29, 2024 ... Tavily specializes in improving search results for AI developers and autonomous AI agents. Furthermore, Tavily uses private financial, coding, news, and other ...",
        "formattedUrl": "https://medium.com/.../boost-your-rag-performance-with-tavily-search-api-..."
      },
      {
        "title": "Tavily Search MCP Agent | Glama",
        "link": "https://glama.ai/mcp/servers/p0w4whs3l4",
        "snippet": "Jan 8, 2025 ... This MCP server performs multi-topic searches in business, news, finance, and politics using the Tavily API, providing high-quality sources and intelligent ...",
        "formattedUrl": "https://glama.ai/mcp/servers/p0w4whs3l4"
      },
      {
        "title": "AI Agents in LangGraph - DeepLearning.AI",
        "link": "https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/",
        "snippet": "Jun 5, 2024 ... Build agentic AI workflows using LangChain's LangGraph and Tavily's agentic search. Learn directly from LangChain and Tavily founders.",
        "formattedUrl": "https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/"
      },
      {
        "title": "Context is King — Evaluating real-time LLM context quality with ...",
        "link": "https://emergentmethods.medium.com/context-is-king-evaluating-real-time-llm-context-quality-with-ragas-a8df8e815dc9",
        "snippet": "Jun 10, 2024 ... Edit 1: Tavily reminded us that for news, we should be using a topic ... Related Hall of Fame manager Joe Torre leads a roster of guest instructors ...",
        "formattedUrl": "https://emergentmethods.medium.com/context-is-king-evaluating-real-time-..."
      },
      {
        "title": "Tavily API Integration Examples | Restackio",
        "link": "https://www.restack.io/p/tavily-api-integration-answer",
        "snippet": "Jan 25, 2025 ... Explore practical Tavily API integration examples for AI research platforms and tools to enhance your projects ... Related answers. Google Tools For ...",
        "formattedUrl": "https://www.restack.io/p/tavily-api-integration-answer"
      }
    ],
    [
      "# [Tavily](https://tavily.com/)\n1 2 3 4 from tavily import TavilyClient tavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\") response = tavily_client.search(\"Who is Leo Messi?\") print(response)\n\n1 2 3 4 const { tavily } = require('@tavily/core'); const tvly = tavily({ apiKey: \"tvly-YOUR_API_KEY\" }); tvly.search(\"Who is Leo Messi?\") .then(results => console.log(results));",
      "# [API Reference](https://docs.tavily.com/docs/rest-api/api-reference)\n{\n\n\"results\":[\n\n{\n\n\"url\":\"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n\n\"raw_content\":\"Contents\\nArtificial intelligence\\nArtificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is a field of study in computer science that develops and studies intelligent machines. \\\"AI\\\" may also refer to the machines themselves.\\nAI technology is widely used throughout industry, government and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), and competing at the highest level in strategy games (such as chess and Go).[1]\\nArtificial intelligence was founded as an academic discipline in 1956.[2] The field went through multiple cycles of optimism[3][4] followed by disappointment and loss of funding,[5][6] but after 2012, when deep learning surpassed all previous AI techniques,[7] there was a vast increase in funding and interest.\\nThe various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals.[8]\\nTo solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience and many other fields.[9]\\nGoals\\nThe general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\\nReasoning, problem-solving\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[10] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[11]\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \\\"combinatorial explosion\\\": they became exponentially slower as the problems grew larger.[12]\\nEven humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[13]\\nAccurate and efficient reasoning is an unsolved problem.\\nKnowledge representation\\nKnowledge representation and knowledge engineering[14] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[15] scene interpretation,[16] clinical decision support,[17] knowledge discovery (mining \\\"interesting\\\" and actionable inferences from large databases),[18] and other areas.[19]\\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[20] Knowledge bases need to represent things such as:\\nobjects, properties, categories and relations between objects;\\n[21]\\nsituations, events, states and time;[22]\\ncauses and effects;[23]\\nknowledge about knowledge (what we know about what other people know);[24]\\ndefault reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[25] and many other aspects and domains of knowledge.\\nAmong the most difficult problems in KR are: the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[26] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \\\"facts\\\" or \\\"statements\\\" that they could express verbally).[13]\\nKnowledge acquisition is the difficult problem of obtaining knowledge for AI applications.[c] Modern AI gathers knowledge by \\\"scraping\\\" the internet (including Wikipedia). The knowledge itself was collected by the volunteers and professionals who published the information (who may or may not have agreed to provide their work to AI companies).[29] This \\\"crowd sourced\\\" technique does not guarantee that the knowledge is correct or reliable. The knowledge of Large Language Models (such as ChatGPT) is highly unreliable -- it generates misinformation and falsehoods (known as \\\"hallucinations\\\"). Providing accurate knowledge for these modern AI applications is an unsolved problem.\\nPlanning and decision making\\nAn \\\"agent\\\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][30]\\nIn automated planning, the agent has a specific goal.[31] In automated decision making, the agent has preferences – there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision making agent assigns a number to each situation (called the \\\"utility\\\") that measures how much the agent prefers it. For each possible action, it can calculate the \\\"expected utility\\\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[32]\\nIn classical planning, the agent knows exactly what the effect of any action will be.[33]\\nIn most real-world problems, however, the agent may not be certain about the situation they are in (it is \\\"unknown\\\" or \\\"unobservable\\\") and it may not know for certain what will happen after each possible action (it is not \\\"deterministic\\\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[34]\\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning) or the agent can seek information to improve its preferences.[35]\\nInformation value theory can be used to weigh the value of exploratory or experimental actions.[36]\\nThe space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain what the outcome will be.\\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g. by iteration), be heuristic, or it can be learned.[37]\\nGame theory describes rational behavior of multiple interacting agents, and is used in AI programs that make decisions that involve other agents.[38]\\nLearning\\nMachine learning is the study of programs that can improve their performance on a given task automatically.[39]\\nIt has been a part of AI from the beginning.[e]\\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[42]\\nSupervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[43]\\nIn reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \\\"good\\\".[44]\\nTransfer learning is when the knowledge gained from one problem is applied to a new problem.[45] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[46]\\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[47]\\nNatural language processing\\nNatural language processing (NLP)[48] allows programs to read, write and communicate in human languages such as English.\\nSpecific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[49]\\nEarly work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation[f]\\nunless restricted to small domains called \\\"micro-worlds\\\" (due to the common sense knowledge problem[26]).\\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[50] transformers (a deep learning architecture using an attention mechanism),[51] and others.[52] In 2019, generative pre-trained transformer (or \\\"GPT\\\") language models began to generate coherent text,[53][54] and by 2023 these models were able to get human-level scores on the bar exam, SAT, GRE, and many other real-world applications.[55]\\nPerception\\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[56]\\nThe field includes speech recognition,[57]\\nimage classification,[58]\\nfacial recognition, object recognition,[59]\\nand robotic perception.[60]\\nSocial intelligence\\nAffective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process or simulate human feeling, emotion and mood.[62]\\nFor example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\\nHowever, this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are.[63] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.[64]\\nGeneral intelligence\\nA machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.[8]\\nTools\\nAI research uses a wide variety of tools to accomplish the goals above.[b]\\nSearch and optimization\\nAI can solve many problems by intelligently searching through many possible solutions.[65] There are two very different kinds of search used in AI: state space search and local search.\\nState space search searches through a tree of possible states to try to find a goal state.[66]\\nFor example, Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[67]\\nSimple exhaustive searches[68]\\nare rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.[12]\\n\\\"Heuristics\\\" or \\\"rules of thumb\\\" can help to prioritize choices that are more likely to reach a goal.[69]\\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and counter-moves, looking for a winning position.[70]\\nLocal search uses mathematical optimization to find a numeric solution to a problem. It begins with some form of a guess and then refines the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. This process is called stochastic gradient descent.[71]\\nEvolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses).[72]\\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[73]\\nNeural networks and statistical classifiers (discussed below), also use a form of local search, where the \\\"landscape\\\" to be searched is formed by learning.\\nLogic\\nFormal Logic is used for reasoning and knowledge representation.[74]\\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \\\"and\\\", \\\"or\\\", \\\"not\\\" and \\\"implies\\\")[75]\\nand predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \\\"Every X is a Y\\\" and \\\"There are some Xs that are Ys\\\").[76]\\nLogical inference (or deduction) is the process of proving a new statement (conclusion) from other statements that are already known to be true (the premises).[77]\\nA logical knowledge base also handles queries and assertions as a special case of inference.[78]\\nAn inference rule describes what is a valid step in a proof. The most general inference rule is resolution.[79]\\nInference can be reduced to performing a search to find a path that leads from premises to conclusions, where each step is the application of an inference rule.[80]\\nInference performed this way is intractable except for short proofs in restricted domains. No efficient, powerful and general method has been discovered.[81]\\nFuzzy logic assigns a \\\"degree of truth\\\" between 0 and 1 and handles uncertainty and probabilistic situations.[82]\\nNon-monotonic logics are designed to handle default reasoning.[25]\\nOther specialized versions of logic have been developed to describe many complex domains (see knowledge representation above).\\nProbabilistic methods for uncertain reasoning\\nMany problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[83]\\nBayesian networks[84]\\nare a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm),[g][86]\\nlearning (using the expectation-maximization algorithm),[h][88]\\nplanning (using decision networks)[89]\\nand perception (using dynamic Bayesian networks).[90]\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[90]\\nPrecise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[91]\\nand information value theory.[92]\\nThese tools include models such as Markov decision processes,\\n[93]\\ndynamic decision networks,[90]\\ngame theory and mechanism design.[94]\\nClassifiers and statistical learning methods\\nThe simplest AI applications can be divided into two types: classifiers (e.g. \\\"if shiny then diamond\\\"), on one hand, and controllers (e.g. \\\"if diamond then pick up\\\"), on the other hand. Classifiers[95]\\nare functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \\\"observation\\\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[43]\\nThere are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm.[96] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[97]\\nThe naive Bayes classifier is reportedly the \\\"most widely used learner\\\"[98] at Google, due in part to its scalability.[99]\\nNeural networks are also used as classifiers.[100]\\nArtificial neural networks\\nArtificial neural networks[100] were inspired by the design of the human brain: a simple \\\"neuron\\\" N accepts input from other neurons, each of which, when activated (or \\\"fired\\\"), casts a weighted \\\"vote\\\" for or against whether neuron N should itself activate. In practice, the input \\\"neurons\\\" are a list of numbers, the \\\"weights\\\" are a matrix, the next layer is the dot product (i.e., several weighted sums) scaled by an increasing function, such as the logistic function. \\\"The resemblance to real neural cells and structures is superficial\\\", according to Russell and Norvig.[101][i]\\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.[102]\\nNeural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.[103]\\nIn feedforward neural networks the signal passes in only one direction.[104]\\nRecurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.[105]\\nPerceptrons[106]\\nuse only a single layer of neurons, deep learning[107] uses multiple layers.\\nConvolutional neural networks strengthen the connection between neurons that are \\\"close\\\" to each other – this is especially important in image processing, where a local set of neurons must identify an \\\"edge\\\" before the network can identify an object.[108]\\nDeep learning\\nDeep learning[107]\\nuses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.[110]\\nDeep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, image classification[111]\\nand others. The reason that deep learning performs so well in so many applications is not known as of 2023.[112]\\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[j]\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[k]\\nSpecialized hardware and software\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.[121]\\nHistorically, specialized languages, such as Lisp, Prolog, and others, had been used.\\nApplications\\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search),\\ntargeting online advertisements,[122]\\nrecommendation systems (offered by Netflix, YouTube or Amazon),\\ndriving internet traffic,[123][124]\\ntargeted advertising (AdSense, Facebook),\\nvirtual assistants (such as Siri or Alexa),[125]\\nautonomous vehicles (including drones,\\nADAS and self-driving cars),\\nautomatic language translation (Microsoft Translator, Google Translate),\\nfacial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and\\nimage labeling (used by Facebook, Apple's iPhoto and TikTok).\\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported they had incorporated \\\"AI\\\" in some offerings or processes.[126]\\nA few examples are energy storage,[127]\\nmedical diagnosis,\\nmilitary logistics,\\napplications that predict the result of judicial decisions,[128]\\nforeign policy,[129]\\nor supply chain management.\\nGame playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[130] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[131]\\nIn March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps.[132] Then it defeated Ke Jie in 2017, who at the time continuously held the world No. 1 ranking for two years.[133][134][135] Other programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus[l] and Cepheus.[137] DeepMind in the 2010s developed a \\\"generalized artificial intelligence\\\" that could learn many diverse Atari games on its own.[138]\\nIn the early 2020s, generative AI gained widespread prominence. ChatGPT, based on GPT-3, and other large language models, were tried by 14% of Americans adults.[139] The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion[140][141]\\nsparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat,[142]\\nthe fictional arrest of Donald Trump,[143]\\nand a hoax of an attack on the Pentagon,[144]\\nas well as the usage in professional creative arts.[145][146]\\nAlphaFold 2 (2020) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[147]\\nEthics\\nAI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \\\"solve intelligence, and then use that to solve everything else\\\".[148] However, as the use of AI has become widespread, several unintended consequences and risks have been identified.[149]\\nAnyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning.[150]\\nRisks and harm\\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\\nTechnology companies collect a wide range of data from their users, including online activity, geolocation data, video and audio.[151]\\nFor example, in order to build speech recognition algorithms, Amazon others have recorded millions of private conversations and allowed temps to listen to and transcribe some of them.[152]\\nOpinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.[153]\\nAI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.[154]\\nSince 2016, some privacy experts, such as Cynthia Dwork, began to view privacy in terms of fairness -- Brian Christian wrote that experts have pivoted \\\"from the question of 'what they know' to the question of 'what they're doing with it'.\\\".[155]\\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under a rationale of \\\"fair use\\\". Experts disagree about how well, and under what circumstances, this rationale will hold up in courts of law; relevant factors may include \\\"the purpose and character of the use of the copyrighted work\\\" and \\\"the effect upon the potential market for the copyrighted work\\\".[156] In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[157][158]\\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[159] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[160] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem.\\nIn 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films or human writing.\\nIt is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda.[161] AI pioneer Geoffrey Hinton expressed concern about AI enabling \\\"authoritarian leaders to manipulate their electorates\\\" on a large scale, among other risks.[162]\\nMachine learning applications will be biased if they learn from biased data.[163]\\nThe developers may not be aware that the bias exists.[164]\\nBias can be introduced by the way training data is selected and by the way a model is deployed.[165][163] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[166]\\nFairness in machine learning is the study of how to prevent the harm caused by algorithmic bias. It has become serious area of academic study within AI. Researchers have discovered it is not always possible to define \\\"fairness\\\" in a way that satisfies all stakeholders.[167]\\nOn June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \\\"gorillas\\\" because they were black. The system was trained on a dataset that contained very few images of black people,[168] a problem called \\\"sample size disparity\\\".[169] Google \\\"fixed\\\" this problem by preventing the system from labelling anything as a \\\"gorilla\\\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.[170]\\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist.\\nIn 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different -- the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[171] In 2017, several researchers[m] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[173]\\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \\\"race\\\" or \\\"gender\\\"). The feature will correlate with other features (like \\\"address\\\", \\\"shopping history\\\" or \\\"first name\\\"), and the program will make the same decisions based on these features as it would on \\\"race\\\" or \\\"gender\\\".[174]\\nMoritz Hardt said \\\"the most robust fact in this research area is that fairness through blindness doesn't work.\\\"[175]\\nCriticism of COMPAS highlighted a deeper problem with the misuse of AI. Machine learning models are designed to make \\\"predictions\\\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. Unfortunately, if an application then uses these predictions as recommendations, some of these \\\"recommendations\\\" will likely be racist.[176] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is necessarily descriptive and not proscriptive.[n]\\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[169]\\nAt its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022) the Association for Computing Machinery, in Seoul, South Korea, presented and published findings recommending that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.[178]\\nMost modern AI applications can not explain how they have reached a decision.[179] The large amount of relationships between inputs and outputs in deep neural networks and resulting complexity makes it difficult for even an expert to explain how they produced their outputs, making them a black box.[180]\\nThere have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, Justin Ko and Roberto Novoa developed a system that could identify skin diseases better than medical professionals, however it classified any image with a ruler as \\\"cancerous\\\", because pictures of malignancies typically include a ruler to show the scale.[181] A more dangerous example was discovered by Rich Caruana in 2015: a machine learning system that accurately predicted risk of death classified a patient that was over 65, asthma and difficulty breathing as \\\"low risk\\\". Further research showed that in high-risk cases like this, the hospital would allocate more resources and save the patient's life, decreasing the risk measured by the program.[182] Mistakes like these become obvious when we know how the program has reached a decision. Without an explanation, these problems may not not be discovered until after they have caused harm.\\nA second issue is that people who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are required to clearly and completely explain the reasoning behind any decision they make.[183] Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists.[o] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.[184]\\nDARPA established the XAI (\\\"Explainable Artificial Intelligence\\\") program in 2014 to try and solve these problems.[185]\\nThere are several potential solutions to the transparency problem. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.[186] Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network have learned and produce output that can suggest what the network is learning.[187] Supersparse linear integer models use learning to identify the most important features, rather than the classification. Simple addition of these features can then make the classification (i.e. learning is used to create a scoring system classifier, which is transparent).[188]\\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.[p] By 2015, over fifty countries were reported to be researching battlefield robots.[190] These weapons are considered especially dangerous for several reasons: if they kill an innocent person it is not clear who should be held accountable, it is unlikely they will reliably choose targets, and, if produced at scale, they are potentially weapons of mass destruction.[191] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.[192]\\nAI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes and generative AI aid in producing misinformation; advanced AI can make authoritarian centralized decision making more competitive with liberal and decentralized systems such as markets.[193]\\nTerrorists, criminals and rogue states can use weaponized AI such as advanced digital warfare and lethal autonomous weapons.\\nMachine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.[194]\\nFrom the early days of the development of artificial intelligence there have been arguments, for example those put forward by Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.[195]\\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.[196]\\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \\\"we're in uncharted territory\\\" with AI.[197] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[198] Risk estimates vary; for example, in the 2010s Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \\\"high risk\\\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \\\"high risk\\\".[q][200] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology (rather than social policy) creates unemployment (as opposed to redundancies).[196]\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \\\"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\\\" is \\\"worth taking seriously\\\".[201] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[202]\\nIn April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.[203][204]\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as the physicist Stephen Hawking puts it, \\\"spell the end of the human race\\\".[205] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \\\"self-awareness\\\" (or \\\"sentience\\\" or \\\"consciousness\\\") and becomes a malevolent character.[r] These sci-fi scenarios are misleading in several ways.\\nFirst, AI does not require human-like \\\"sentience\\\" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager).[207] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \\\"you can't fetch the coffee if you're dead.\\\"[208] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \\\"fundamentally on our side\\\".[209]\\nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[210]\\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[211] Personalities such as Stephen Hawking, Bill Gates, Elon Musk have expressed concern about existential risk from AI.[212]\\nIn the early 2010's, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[213]\\nHowever, after 2016, the study of current and future risks and possible solutions became a serious area of research.[214]\\nAI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI and in 2023 many leading AI experts issued the joint statement that \\\"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\\\".[215]\\nEthical machines and alignment\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[216]\\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[217]\\nThe field of machine ethics is also called computational morality,[217]\\nand was founded at an AAAI symposium in 2005.[218]\\nOther approaches include Wendell Wallach's \\\"artificial moral agents\\\"[219]\\nand Stuart J. Russell's three principles for developing provably beneficial machines.[220]\\nRegulation\\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.[221]\\nThe regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[222] According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.[223][224]\\nBetween 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[225]\\nMost EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, US and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[225]\\nThe Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[225] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[226]\\nIn 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.[227]\\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \\\"products and services using AI have more benefits than drawbacks\\\".[223] A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.[228]\\nIn a 2023 Fox News poll, 35% of Americans thought it \\\"very important\\\", and an additional 41% thought it \\\"somewhat important\\\", for the federal government to regulate AI, versus 13% responding \\\"not very important\\\" and 8% responding \\\"not at all important\\\".[229][230]\\nIn November 2023, a global AI safety summit was held in Bletchley Park to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.[231]\\nHistory\\nThe study of mechanical or \\\"formal\\\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \\\"0\\\" and \\\"1\\\", could simulate both mathematical deduction and formal reasoning, which is known as the Church–Turing thesis.[232] This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \\\"electronic brain\\\".[s][234] The first paper later recognized as \\\"AI\\\" was McCullouch and Pitts design for Turing-complete \\\"artificial neurons\\\" in 1943.[235]\\nThe field of AI research was founded at a workshop at Dartmouth College in 1956.[t][2] The attendees became the leaders of AI research in the 1960s.[u] They and their students produced programs that the press described as \\\"astonishing\\\":[v] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[w][3]\\nBy the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense[239] and laboratories had been established around the world.[240] Herbert Simon predicted, \\\"machines will be capable, within twenty years, of doing any work a man can do\\\".[241] Marvin Minsky agreed, writing, \\\"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\\\".[242]\\nThey had, however, underestimated the difficulty of the problem.[x] Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[244] and ongoing pressure from the US Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks approach would never be useful for solving real-world tasks, thus discrediting the approach altogether.[245] The \\\"AI winter\\\", a period when obtaining funding for AI projects was difficult, followed.[5]\\nIn the early 1980s, AI research was revived by the commercial success of expert systems,[246] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[4] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[6]\\nMany researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition.[247] A number of researchers began to look into \\\"sub-symbolic\\\" approaches.[248] Robotics researchers, such as Rodney Brooks, rejected \\\"representation\\\" in general and focussed directly on engineering machines that move and survive.[y]. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[83][253] But the most important development was the revival of \\\"connectionism\\\", including neural network research, by Geoffrey Hinton and others.[254] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[255]\\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \\\"narrow\\\" and \\\"formal\\\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[256]\\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \\\"artificial intelligence\\\".[257]\\nSeveral academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \\\"AGI\\\"), which had several well-funded institutions by the 2010s.[8]\\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[7]\\nFor many specific tasks, other methods were abandoned.[z]\\nDeep learning's success was based on both hardware improvements (faster computers,[259] graphics processing units, cloud computing[260])\\nand access to large amounts of data[261] (including curated datasets,[260] such as ImageNet).\\nDeep learning's success led to an enormous increase in interest and funding in AI.[aa]\\nThe amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019,[225]\\nand WIPO reported that AI was the most prolific emerging technology in terms of the number of patent applications and granted patents[262]\\nAccording to 'AI Impacts', about $50 billion annually was invested in \\\"AI\\\" around 2022 in the US alone and about 20% of new US Computer Science PhD graduates have specialized in \\\"AI\\\";[263]\\nabout 800,000 \\\"AI\\\"-related US job openings existed in 2022.[264]\\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[214]\\nPhilosophy\\nDefining artificial intelligence\\nAlan Turing wrote in 1950 \\\"I propose to consider the question 'can machines think'?\\\"[265]\\nHe advised changing the question from whether a machine \\\"thinks\\\", to \\\"whether or not it is possible for machinery to show intelligent behaviour\\\".[265]\\nHe devised the Turing test, which measures the ability of a machine to simulate human conversation.[266] Since we can only observe the behavior of the machine, it does not matter if it is \\\"actually\\\" thinking or literally has a \\\"mind\\\". Turing notes that we can not determine these things about other people[ab] but \\\"it is usual to have a polite convention that everyone thinks\\\"[267]\\nRussell and Norvig agree with Turing that AI must be defined in terms of \\\"acting\\\" and not \\\"thinking\\\".[268] However, they are critical that the test compares machines to people. \\\"Aeronautical engineering texts,\\\" they wrote, \\\"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\\\"[269] AI founder John McCarthy agreed, writing that \\\"Artificial intelligence is not, by definition, simulation of human intelligence\\\".[270]\\nMcCarthy defines intelligence as \\\"the computational part of the ability to achieve goals in the world.\\\"[271] Another AI founder, Marvin Minsky similarly defines it as \\\"the ability to solve hard problems\\\".[272] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \\\"intelligence\\\" of the machine—and no other philosophical discussion is required, or may not even be possible.\\nAnother definition has been adopted by Google,[273] a major practitioner in the field of AI.\\nThis definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\\nEvaluating approaches to AI\\nNo established unifying theory or paradigm has guided AI research for most of its history.[ac] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \\\"artificial intelligence\\\" to mean \\\"machine learning with neural networks\\\"). This approach is mostly sub-symbolic, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.\\nSymbolic AI (or \\\"GOFAI\\\")[275] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \\\"intelligent\\\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \\\"A physical symbol system has the necessary and sufficient means of general intelligent action.\\\"[276]\\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \\\"intelligent\\\" tasks were easy for AI, but low level \\\"instinctive\\\" tasks were extremely difficult.[277]\\nPhilosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \\\"feel\\\" for the situation, rather than explicit symbolic knowledge.[278]\\nAlthough his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree.[ad][13]\\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[280][281] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\\n\\\"Neats\\\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \\\"Scruffies\\\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 70s and 80s,[282]\\nbut eventually was seen as irrelevant. Modern AI has elements of both.\\nFinding a provably correct or optimal solution is intractable for many important problems.[12] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 80s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.[283][284]\\nGeneral intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\\nMachine consciousness, sentience and mind\\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \\\"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\\\"[285] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\nDavid Chalmers identified two problems in understanding the mind, which he named the \\\"hard\\\" and \\\"easy\\\" problems of consciousness.[286] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). Human information processing is easy to explain, however, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[287]\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[288]\\nPhilosopher John Searle characterized this position as \\\"strong AI\\\": \\\"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\\\"[ae]\\nSearle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[292]\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights.[293]\\nAny hypothetical robot rights would lie on a spectrum with animal rights and human rights.[294]\\nThis issue has been considered in fiction for centuries,[295]\\nand is now being considered by, for example, California's Institute for the Future; however, critics argue that the discussion is premature.[296]\\nFuture\\nSuperintelligence and the singularity\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[284]\\nIf research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \\\"intelligence explosion\\\" and Vernor Vinge called a \\\"singularity\\\".[297]\\nHowever, technologies can't improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[298]\\nTranshumanism\\nRobot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.[299]\\nEdward Fredkin argues that \\\"artificial intelligence is the next stage in evolution\\\", an idea first proposed by Samuel Butler's \\\"Darwin among the Machines\\\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.[300]\\nIn fiction\\nThought-capable artificial beings have appeared as storytelling devices since antiquity,[301]\\nand have been a persistent theme in science fiction.[302]\\nA common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[303]\\nIsaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \\\"Multivac\\\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics;[304]\\nwhile almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[305]\\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[306]\\nSee also\\nExplanatory notes\\nReferences\\nAI textbooks\\nThe two most widely used textbooks in 2023. (See the Open Syllabus).\\nThese were the four the most widely used AI textbooks in 2008:\\nLater editions.\\nHistory of AI\\nOther sources\\nFurther reading\\nExternal links\",\n\n\"images\":[]\n\n},\n\n{\n\n\"url\":\"https://en.wikipedia.org/wiki/Machine_learning\",\n\n\"raw_content\":\"Contents\\nMachine learning\\nMachine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\\nThe mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.[7][8]\\nML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\\nHistory and relationships to other fields[edit]\\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[9][10] The synonym self-teaching computers was also used in this time period.[11][12]\\nBy the early 1960s an experimental \\\"learning machine\\\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \\\"trained\\\" by a human operator/teacher to recognize patterns and equipped with a \\\"goof\\\" button to cause it to re-evaluate incorrect decisions.[13] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[14] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[15] In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[16]\\nTom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \\\"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,\\nimproves with experience E.\\\"[17] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \\\"Computing Machinery and Intelligence\\\", in which the question \\\"Can machines think?\\\" is replaced with the question \\\"Can machines do what we (as thinking entities) can do?\\\".[18]\\nModern-day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.[19]\\nArtificial intelligence[edit]\\nAs a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \\\"neural networks\\\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics.[21] Probabilistic reasoning was also employed, especially in automated medical diagnosis.[22]: 488\\nHowever, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[22]: 488 By 1980, expert systems had come to dominate AI, and statistics was out of favor.[23] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming, but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[22]: 708–710, 755 Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \\\"connectionism\\\", by researchers from other disciplines including Hopfield, Rumelhart, and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.[22]: 25\\nMachine learning (ML), reorganized and recognized as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.[23]\\nData mining[edit]\\nMachine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \\\"unsupervised learning\\\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\\nMachine learning also has intimate ties to optimization: many learning problems are formulated as minimization of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the pre-assigned labels of a set of examples).[24]\\nGeneralization[edit]\\nThe difference between optimization and machine learning arises from the goal of generalization: while optimization algorithms can minimize the loss on a training set, machine learning is concerned with minimizing the loss on unseen samples. Characterizing the generalization of various learning algorithms is an active topic of current research, especially for deep learning algorithms.\\nStatistics[edit]\\nMachine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalizable predictive patterns.[25] According to Michael I. Jordan, the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics.[26] He also suggested the term data science as a placeholder to call the overall field.[26]\\nConventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.[27]\\nLeo Breiman distinguished two statistical modeling paradigms: data model and algorithmic model,[28] wherein \\\"algorithmic model\\\" means more or less the machine learning algorithms like Random Forest.\\nSome statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.[29]\\nPhysics[edit]\\nAnalytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of deep neural networks.[30] Statistical physics is thus finding applications in the area of medical diagnostics.[31]\\nTheory[edit]\\nA core objective of a learner is to generalize from its experience.[6][32] Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\\nThe computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the Probably Approximately Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.\\nFor the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.[33]\\nIn addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\\nApproaches[edit]\\nMachine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \\\"signal\\\" or \\\"feedback\\\" available to the learning system:\\nSupervised learning[edit]\\nSupervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.[37] The data is known as training data, and consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal.\\nIn the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.[38] An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.[17]\\nTypes of supervised-learning algorithms include active learning, classification and regression.[39] Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. As an example, for a classification algorithm that filters emails, the input would be an incoming email, and the output would be the name of the folder in which to file the email.\\nSimilarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.\\nUnsupervised learning[edit]\\nUnsupervised learning algorithms take a set of data that contains only inputs, and find structure in the data, like grouping or clustering of data points. The algorithms, therefore, learn from test data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. A central application of unsupervised learning is in the field of density estimation in statistics, such as finding the probability density function.[40] Though unsupervised learning encompasses other domains involving summarizing and explaining data features. Unsupervised learning algorithms streamlined the process of survey and graph large indel based haplotypes of a gene of interest from pan-genome.[41]\\nCluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.\\nSemi-supervised learning[edit]\\nSemi-supervised learning falls between unsupervised learning (without any labeled training data) and supervised learning (with completely labeled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce a considerable improvement in learning accuracy.\\nIn weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.[42]\\nReinforcement learning[edit]\\nReinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcements learning algorithms use dynamic programming techniques.[43] Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.\\nDimensionality reduction[edit]\\nDimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables.[44] In other words, it is a process of reducing the dimension of the feature set, also called the \\\"number of features\\\". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D). This results in a smaller dimension of data (2D instead of 3D), while keeping all original variables in the model without changing the data.[45]\\nThe manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the area of manifold learning and manifold regularization.\\nOther types[edit]\\nOther approaches have been developed which do not fit neatly into this three-fold categorization, and sometimes more than one is used by the same machine learning system. For example, topic modeling, meta-learning.[46]\\nSelf-learning, as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA).[47] It is learning with no external rewards and no external teacher advice. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.[48]\\nThe self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine:\\nIt is a system with only one input, situation, and only one output, action (or behavior) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioral environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioral environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behavior, in an environment that contains both desirable and undesirable situations.[49]\\nSeveral learning algorithms aim at discovering better representations of the inputs provided during training.[50] Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering, and allows a machine to both learn the features and use them to perform a specific task.\\nFeature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labeled input data. Examples include artificial neural networks, multilayer perceptrons, and supervised dictionary learning. In unsupervised feature learning, features are learned with unlabeled input data.\\nExamples include dictionary learning, independent component analysis, autoencoders, matrix factorization[51] and various forms of clustering.[52][53][54]\\nManifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors.[55] Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.[56]\\nFeature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data has not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.\\nSparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions, and is assumed to be a sparse matrix. The method is strongly NP-hard and difficult to solve approximately.[57] A popular heuristic method for sparse dictionary learning is the K-SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.[58]\\nIn data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.[59] Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers, novelties, noise, deviations and exceptions.[60]\\nIn particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.[61]\\nThree broad categories of anomaly detection techniques exist.[62] Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as \\\"normal\\\" and \\\"abnormal\\\" and involves training a classifier (the key difference to many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set and then test the likelihood of a test instance to be generated by the model.\\nRobot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,[63][64] and finally meta-learning (e.g. MAML).\\nAssociation rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \\\"interestingness\\\".[65]\\nRule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \\\"rules\\\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[66] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.\\nBased on the concept of strong rules, Rakesh Agrawal, Tomasz Imieliński and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.[67] For example, the rule\\n{\\no\\nn\\ni\\no\\nn\\ns\\n,\\np\\no\\nt\\na\\nt\\no\\ne\\ns\\n}\\n⇒\\n{\\nb\\nu\\nr\\ng\\ne\\nr\\n}\\n{\\\\displaystyle \\\\{\\\\mathrm {onions,potatoes} \\\\}\\\\Rightarrow \\\\{\\\\mathrm {burger} \\\\}}\\nfound in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.\\nLearning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.[68]\\nInductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.\\nInductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.[69][70][71] Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.[72] The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.\\nModels[edit]\\nPerforming machine learning can involve creating a model, which is trained on some training data and then can process additional data to make predictions. Various types of models have been used and researched for machine learning systems.\\nArtificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \\\"learn\\\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\\nAn ANN is a model based on a collection of connected units or nodes called \\\"artificial neurons\\\", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a \\\"signal\\\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \\\"edges\\\". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.\\nThe original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\\nDeep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[73]\\nDecision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.\\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.[74]\\nAn SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\\nRegression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularization methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel[75]), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.\\nA Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.\\nA Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations.\\nGiven a set of observed points, or input–output examples, the distribution of the (unobserved) output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new, unobserved point.\\nGaussian processes are popular surrogate models in Bayesian optimization used to do hyperparameter optimization.\\nA genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.[77][78] Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.[79]\\nThe theory of belief functions, also referred to as evidence theory or Dempster–Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and\\nimprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g.,\\nDempster's rule of combination), just like how in a pmf-based Bayesian approach would combine probabilities. However, there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and Uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner's decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.[3][5][10] However, the computational complexity of these algorithms are dependent on the number of propositions (classes), and can lead a much higher computation time when compared to other machine learning approaches.\\nTraining models[edit]\\nTypically, machine learning models require a high quantity of reliable data in order for the models to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Bias models may result in detrimental outcomes thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and notably be integrated within machine learning engineering teams.\\nFederated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralizes the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralized server. This also increases efficiency by decentralizing the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.[80]\\nApplications[edit]\\nThere are many applications for machine learning, including:\\nIn 2006, the media-services provider Netflix held the first \\\"Netflix Prize\\\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million.[83] Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (\\\"everything is a recommendation\\\") and they changed their recommendation engine accordingly.[84] In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis.[85] In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.[86] In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists.[87] In 2019 Springer Nature published the first research book created using machine learning.[88] In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.[89] Machine learning was recently applied to predict the pro-environmental behavior of travelers.[90] Recently, machine learning technology was also applied to optimize smartphone's performance and thermal behavior based on the user's interaction with the phone.[91][92][93]\\nLimitations[edit]\\nAlthough machine lea",
      "# [Response times are slow on 2024-09-10](https://community.tavily.com/t/response-times-are-slow/131)\nHello Team\n\nWe see that Tavily is taking a minimum of 4 seconds to reply even when we have set max of 3 responses to be retried.\n\nIs this in the expected lines? What can we do to get the responses within a second?\n\nFYI, as of now we are using a Free plan for our POC and if its successful, would consider switching to an enterprise plan.\n\nHey there,\n\nThank you for your feedback. A ~3-second response time can occur due to a few factors beyond the number of documents retrieved. For instance, fetching raw content, images, or targeting specific domains can add a bit of time. The complexity of the queries you’re running also plays a part.\n\nWhen querying responses with topic=\"news\", you can expect shorter response times, so you might want to experiment with that if news queries are relevant to your needs.\n\nWe’re more than happy to work with you to optimize your setup and meet your needs as you continue exploring the API. Feel free to reach out here or privately at support@tavily.com",
      "# [Langchain](https://docs.tavily.com/docs/integrations/langchain)\n> Entering new AgentExecutor chain...\n\nInvoking: `tavily_search_results_json` with `{'query': 'latest burning man floods news'}`\n\n[{'url': 'https://www.cbsnews.com/news/flooding-burning-man-shelter-in-place/', 'content': 'Watch CBS News\\nNevada flooding forces Burning Man attendees to shelter in place\\nUpdated on:\\nSeptember 2, 2023 / 10:04 PM EDT\\n/ CBS/AP\\nThousands of Burning Man attendees trudged in sloppy mud on Saturday — many barefoot or wearing plastic bags on their feet — as flooding from storms swept through the Nevada desert, forcing organizers to close vehicular access to the counterculture festival. Vehicular gates will be closed for the remainder of the event, which began on Aug. 27 and was scheduled to end on Monday, according to the U.S. Bureau of Land Management, which oversees the Black Rock Desert where the festival is being held. \"\\nDue to recent rainfall, the Bureau of Land Management and the Pershing County Sheriff\\'s Office officials have closed the entrance to Burning Man for the remainder of the event. Superstar DJ and music producer Diplo shared a video to social media Saturday afternoon that showed several people riding on the back of a truck leaving the festival, one of whom appeared to be comedian Chris Rock.\\n Mike Jed, a festivalgoer, and fellow campers made a bucket toilet so people didn\\'t have to trudge as often through the mud to reach the portable toilets.\\n'}, {'url': 'https://www.npr.org/2023/09/03/1197497458/the-latest-on-the-burning-man-flooding', 'content': \"There are also reports that at least one person has died at the counterculture festival about a hundred miles north of Reno, Nev. Earlier this afternoon, I caught up with NPR's Claudia Peschiutta, who's at her first burn, and she told me it's muddy where she is, but that she and her camp family have been making the best of things.\\n National\\nThe latest on the Burning Man flooding\\nClaudia Peschiutta\\nAuthorities are investigating a death at the Burning Man festival in the Nevada desert after tens of thousands of people are stuck in camps because of rain.\\n SCOTT DETROW, HOST:\\nKnee-deep mud, warnings to conserve food and water, orders to shelter in place - this is all at Burning Man 2023 after torrential rains turned the Black Rock Desert into miles and miles of mud. I mean, mostly what I've seen from my personal experience is just any sort of need that you have, somebody, whether friend or neighbor or stranger, will jump in to help you out in some way. And I should mention that desert Wi-Fi is doing the best as it can as we talk to you, dropping in and out.\"}, {'url': 'https://www.nbcnews.com/news/us-news/live-blog/live-updates-burning-man-flooding-keeps-thousands-stranded-nevada-site-rcna103193', 'content': \"Profile\\nSections\\ntv\\nFeatured\\nMore From NBC\\nFollow NBC News\\nnews Alerts\\nThere are no new alerts at this time\\nBurning Man flooding keeps thousands stranded at Nevada site as authorities investigate 1 death\\nBurning Man attendees struggling to get home\\n70,000+ stuck at Burning Man: When will they be able to get out?\\n Thousands still stranded at Burning Man after torrential rain\\nBurning Man revelers unfazed by deluge and deep mud\\nReuters\\nThousands of Burning Man attendees partied hard on Sunday despite downpours that turned the Nevada desert where the annual arts and music festival takes place into a sea of sticky mud and led officials to order the multitudes to shelter in place.\\n Neal Katyal warns hiking in the mud\\ncan be 'worse than walking on ice'\\nDoha Madani\\nNeal Katyal, the former acting U.S. solicitor general, is among the Burning Man attendees who decided to take the risk and hike out of the festival grounds.\\n Videos posted to his Instagram story show Diplo walking through mud before, he says, he hitchhiked to Gerlach and Reno to make a flight to Washington, D.C.\\n“I just got done DJ’ing for three hours, after walking f---ing for four hours out of the desert and taking a flight, mud still on my face,” he said in a video posted to his Instagram story last night.\\n Burning Man memes are swamping social media\\nAngela Yang\\nAs heavy rain turns Burning Man 2023 into a muddy mess, a deluge of unsympathetic jokes has swamped the internet outside Black Rock City, the temporary location built annually for the nine-day festival in the remote desert of Nevada.\\n\"}, {'url': 'https://www.cnn.com/us/live-news/nevada-desert-burning-man-weather-rain-09-03-23/index.html', 'content': 'The festival’s 2023 theme is “Animalia,” which the Burning Man website explains, “will celebrate the animal world and our place in it — animals real and imagined, mythic and remembered — and explore the curious mental constructs that allow us to believe that imagined animals are real, real animals are imagined, and that somehow, despite all evidence to the contrary, mankind is somehow not part of the animal kingdom.”\\n Thousands stranded at Burning Man festival after heavy rains\\nBy Maureen Chowdhury, Steve Almasy and Matt Meyer, CNN\\nWhat we\\'re covering\\nPresident Biden has been briefed on the situation at Burning Man festival\\nFrom CNN\\'s Betsy Klein\\nPresident Joe Biden was briefed Sunday on the situation at the Burning Man festival in Black Rock Desert, Nevada, according to a White House official.\\n View Katyal\\'s post below:\\nSome of the 70,000 people stranded at Burning Man are walking out of the site, sheriff\\'s office says\\nFrom CNN\\'s Melissa Alonso\\nThere are currently \"a little over 70,000\" people stranded at the Burning Man festival in Nevada due to the mud and flooding, Pershing County Sheriff’s Sgt. Burning Man organizers working to provide cell service and medical resources as attendees shelter in place\\nFrom CNN\\'s Nouran Salahieh\\xa0and\\xa0Emma Tucker\\nBurning Man organizers say they are placing mobile cell trailers around the battered festival grounds, configuring their Wi-Fi system for public access, and sending buses to nearby Gerlach, Nevada, to pick up people who might have walked out of the desert and ferry them to Reno.\\n Festivalgoers are managing to have a good time despite being stuck in the mud, attendee says\\nDawne Looney, a Burning Man festival attendee, says people are making the best of the situation despite the heavy rain and mud stranding an estimated 70,000 of them in the desert.\\n'}, {'url': 'https://abcnews.go.com/US/burning-man-flooding-happened-stranded-festivalgoers/story?id=102908331', 'content': '\"\\nTop Stories\\nMacy\\'s Thanksgiving Day Parade temporarily halted by pro-Palestinian protesters\\nGuns N\\' Roses singer Axl Rose accused of alleged 1989 sexual assault by former model\\nFBI: Rainbow Bridge crash, explosion not connected to terrorism\\nToxic chemical spill from Kentucky train derailment forces residents to flee homes\\nHezbollah fires rockets at north Israel after an airstrike kills 5 of the group\\'s senior fighters\\nABC News Live\\n24/7 coverage of breaking news and live events ABC News\\nVideo\\nLive\\nShows\\nElection 2024\\n538\\nStream on\\nBurning Man flooding: What happened to stranded festivalgoers?\\n In response to the unusual weather, event organizers shut down traffic in or out of what is called Black Rock City -- where the festival is held in the desert -- including the local airport.\\n MORE: These US regions will experience scorching temperatures for the remainder of Labor Day weekend\\nOn Sunday, mobile cell trailers to boost cell service and charging stations were placed around the festival grounds amid the recovery efforts, according to organizers.\\n This is typically the driest time of the year for the desert, and it does not take much rain to make the desert floor a mud bath.\\n'}]The latest Burning Man festival, held in Nevada's Black Rock Desert, was hit by severe flooding due to storms, forcing thousands of attendees to shelter in place as the normally dry desert was turned into a muddy landscape. The vehicular gates were closed for the remainder of the event, a decision taken by the U.S. Bureau of Land Management and the Pershing County Sheriff's Office. There were reports of one death at the festival and authorities are investigating the incident. Despite the harsh conditions, festival attendees were seen making the best of the situation.\n\nThe festival, which began on August 27, 2023, and was supposed to end on September 4, 2023, saw over 70,000 attendees stuck due to the flooding. To aid attendees, festival organizers provided mobile cell trailers to boost cell service and charging stations around the festival grounds. They also worked on providing medical resources and public Wi-Fi access.\n\nNotably, many attendees, including celebrities like DJ Diplo, were seen leaving the festival by hitchhiking or walking through the mud. The floods led to a flurry of social media activity, including both messages of support and unsympathetic jokes. The President, Joe Biden, was also briefed on the situation at the festival.\n\n> Finished chain.",
      "# [Tavily Community](https://community.tavily.com/latest)\nPowered by Discourse, best viewed with JavaScript enabled",
      "# [Precision in AI Research: Tavily’s Company Researcher by Rotem Weiss on 2024-11-18](https://blog.tavily.com/companyresearcher/)\nIn AI research, accuracy is critical. Outdated data? Not useful. Models generating false information? A serious issue. And if you’ve ever tried gathering insights on companies with minimal online presence—or on similarly named entities—you know that many tools often fall short. That’s where Tavily’s Company Researcher comes in. This tool integrates Tavily Search and Extract, in a workflow powered by LangGraph, to deliver precise, reliable insights. Instead of just surface-level data, it generates comprehensive, current reports with in-depth detail.\n\nTavily’s Intelligent Search Layer\n\nTavily’s mission is to provide an intelligent search layer that connects large language models (LLMs) to the web, giving agents access to real-time, contextually relevant data. Tavily supports flexible search capabilities, enabling AI agents to fine-tune search strategies, retrieve raw content for analysis, or pull summaries for quick insights. Unlike static models bound to training data, Tavily’s Search and Extract endpoints combine semantic, contextual, and keyword search to deliver timely, relevant insights for data-driven decision-making.\n\nHow the Company Researcher Works\n\nThe Company Researcher automates a multi-stage workflow for real-time company analysis, integrating search and extraction with agentic behavior to generate high-quality results. Its modular and dynamic architecture allows for efficient gathering of both general context and targeted data. The use of feedback loops, combined with optional human-on-the-loop validation, ensures precise and reliable outputs. Here’s how it works:\n\nInitial Grounding with Tavily Extract: Each session begins with a user-provided company name and URL. Tavily Extract retrieves content from that site, creating a “ground truth” that anchors the search to follow. By grounding in verified data, each step operates within set accuracy boundaries, reducing hallucinations and inconsistencies.\n\nSub-Question Generation and Tavily Search: Dynamically generates specific sub-questions to guide Tavily’s search, focusing the search on high-value, relevant data instead of conducting a broad, unfocused search.\n\nAI-Driven Clustering: Retrieved documents are grouped by company, using the ground truth to verify accuracy, especially for similarly named entities. This clustering keeps only relevant sources in focus.\n\nHuman-on-the-Loop for Cluster Validation: If clustering doesn’t yield a definitive match, meaning that the correct cluster wasn't automatically identified, optional human validation can make manual adjustments, ensuring data quality.\n\nDocument Curation and Enrichment with Tavily Extract: Once a trusted cluster is identified, Tavily Extract pulls detailed data from these verified links, adding substantial depth to the research. This step enhances the precision and comprehensiveness of the final output.\n\nReport Generation and Evaluation: An LLM synthesizes the data into a structured report. If gaps are detected, new questions are generated to gather additional data, improving the report without restarting.\n\nMulti-Format Output: The final report is available in PDF or Markdown format, making it easy to share and integrate.\n\nHere is how I define the workflow IRL:\n\nKey Technical Features\n\nGrounding: The Foundation of Accuracy\n\nGrounding is core to Tavily’s Company Researcher workflow. It starts with establishing a reliable “ground truth” by using Tavily Extract on a verified company URL. This keeps the system aligned to the correct entity, especially in cases where similarly named companies exist. Creating a foundation to work from minimizes unrelated or erroneous information, improving output accuracy. Feedback loops that refer to the “ground truth” coupled with human-on-the-loop validation further reinforce this foundation, ensuring outputs are consistently relevant and curated for quality.\n\nTavily Search and Extract: Better Together for Precision\n\nTavily Extract is geared to pull raw information from specified sources. Allowing the agent to dig deep on the most important sources without the pressure of having to explore every possible lead. Tavily Search on the other hand, looks at the breadth of the web to identify the most relevant sources for your goal. By going broad it will ensure the scope of your research needs are covered. Tavily’s Company Researcher shows how you can utilize the strengths of each and have both tools work with one another to generate the results you want. In the end, only the most relevant pages are analyzed, providing accurate, contextually rich information, minimizing long context windows, and resulting in precise, actionable reports.\n\nDynamic Graph-Like Structure: Flexibility Meets Predictability\n\nThe Company Researcher uses a dynamic, graph-based structure that balances clear paths with flexibility. Traditional deterministic workflows work well for set steps but struggle in unpredictable real-world contexts. Fully dynamic workflows, like ReAct, handle unpredictability better but can lack structure and deterministic accuracy. The Company Researcher’s hybrid approach, implemented with LangGraph, maintains a clear path while adapting to real-world, real-time challenges, allowing for flexibility when data inputs vary.\n\nStructured Output: Consistency in Data\n\nStructured prompting ensures output consistency. While early LLMs could provide accurate information, their formatting was often inconsistent. I addressed this by embedding specific formatting into prompts, so each data cluster follows a set structure, making results easy to retrieve, reliable, and consistently organized.\n\nHere is an example of how it is used to define the clusters:\n\nAnd it is even simpler to call:\n\nThen, you can access each type of output because it is assigned to the cluster through the defined structure:\n\nAnd the Best Part: It’s Adaptable!\n\nTavily’s Company Researcher can be easily customized to fit a range of research needs. By making simple adjustments, you can expand its use beyond company research to tackle various data-intensive tasks, ensuring consistent and reliable results.\n\nModify Prompts: Consider tailoring the prompts used for question generation or report synthesis to better align with your specific research goals.\n\nExtend Workflow Nodes: Think about adding, removing, or altering workflow nodes to target specific types of analysis or areas of interest.\n\nCustomize Output Formats: Don’t hesitate to adjust output formats, such as using custom CSS for PDF styling, to align with your organization’s standards.\n\nGetting Started with Company Researcher:\n\nIn this section, we will walk you through the steps to download and start using Company Researcher.\n\nPrerequisites\n\nPython 3.11 or later: Python Installation Guide\n\nTavily API Key - Sign Up\n\nAnthropic API Key - Sign Up\n\nInstallation\n\nClone the Repository:\n\ngit clone https://github.com/danielleyahalom/company-researcher.git cd company-researcher\n\nCreate a Virtual Environment:\n\nTo avoid dependency conflicts, it's recommended to create and activate a virtual environment using venv:\n\npython -m venv venv source venv/bin/activate # macOS/Linux venv\\Scripts\\activate # Windows\n\nSet Up API Keys:\n\nConfigure your Anthropic and Tavily API keys as environment variables or place them in a .env file:\n\nexport TAVILY_API_KEY={Your Tavily API Key here} export ANTHROPIC_API_KEY={Your Anthropic API Key here}\n\nInstall Dependencies:\n\npip install -r requirements.txt\n\nRun the Application:\n\npython app.py\n\nOpen the App in Your Browser:\n\nhttp://localhost:5000",
      "# [Invoices now available on the Tavily Dashboard on 2024-07-30](https://community.tavily.com/t/invoices-now-available-on-the-tavily-dashboard/58)\nGood news!\n\nAs of July 30th, 2024, you can now see your invoices directly on the dashboard.\n\nThis was a highly requested feature, and we’re happy to finally make it available to everyone.\n\nWhat’s new?\n\nA new “invoices” tab has been added to the dashboard which lists your invoices and allows you to download them in PDF format.\n\nWhat’s changing?\n\nYou can still access your invoices through stripe, so if you prefer the old way, you’re good!\n\nAny questions?\n\nFeel free to post any feedback/questions you may have. We’ll be happy to help you.",
      "# [Effortless Web-Based RAG Evaluation Using Tavily and LangGraph by Eyal Ben Barouch on 2025-01-20](https://blog.tavily.com/effortless-web-based-rag-evaluation-using-tavily-and-langgraph/)\nIntroduction\n\nEvery data science enthusiast knows that a vital first step to building a successful model or algorithm is having a reliable evaluation set to aspire to. In the rapidly evolving landscape of Retrieval-Augmented Generation (RAG) and AI-driven search systems, the importance of high-quality eval datasets is crucial.\n\nIn this article, we introduce an agentic workflow designed to generate subject-specific dynamic evaluation datasets, enabling precise validation of web search augmented agents' performance.\n\nKnown RAG evaluation datasets, such as HotPotQA, CRAG, and MultiHop-RAG, have been pivotal in benchmarking and fine-tuning models. However, these datasets primarily focus on evaluating performance with static, pre-defined document sets. As a result, they fall short when it comes to evaluating web-based RAG systems, where data is dynamic, contextual, and ever-changing.\n\nThis gap presents a significant challenge: how do we effectively test and refine RAG systems designed for real-world web search scenarios? Enter the Real-Time Dataset Generator for RAG Evals — an agentic tool leveraging Tavily’s Search Layer and LangGraph framework to create diverse, relevant, and dynamic datasets tailored specifically for web based RAG agents.\n\nWhat is the Real-Time Dataset Generator?\n\nIf you’ve ever built an AI agent, you already know that evaluating it is just as challenging as creating it. When it comes to research agents or tailoring an agent for a specific subject, the process can become even more daunting. Why? Because it’s often a tedious, manual process — one that involves crafting domain-specific queries, curating relevant data, and ensuring the results align with the agent’s objectives. This approach is not only time-consuming but also prone to inconsistencies.\n\nAt its core, the Real-Time Dataset Generator is an agent designed to create datasets for evaluating other agents, automating the tedious processes of query generation, web data collection, and filtering. This enables developers and researchers to focus on building smarter, more capable agents.\n\nThe Generator offers a powerful solution for evaluating how effectively LLM based agents handle fact-based, up-to-date questions in time-sensitive domains such as news-focused agents delivering real-time updates, sports agents providing accurate game statistics, financial agents analyzing market trends, and more. By generating dynamic datasets aligned with current events, this tool ensures agents can be rigorously tested and refined for precise and relevant responses.\n\nHow it works?\n\nStep 1: Input\n\nThe workflow begins with user-provided inputs:\n\ninput = {num_qa: \"number of questions and answers\", QA_subject: \"subject of the Q&A\", save_to_langsmith: \"save locally or to Langsmith\"}\n\nStep 2: Domain Specific Search Query Generation\n\nIf a subject is provided (e.g., “NBA Basketball”), the system generates a set of search queries using this prompt:\n\nQA_QUERIES_SYSTEM_PROMPT = \"\"\" **Objective:** Produce {num_queries} clear, effective, and varied queries to gather the most relevant and recent information about the input subject. **Guidelines:** 1. Ensure clarity, specificity, and relevance to the subject. 2. Prioritize fresh and comprehensive results. \"\"\"\n\nThis ensures queries are tailored to gather high-quality, recent, and subject-specific information.\n\nStep 3: Web Search with Tavily\n\nThis step guarantees that the dataset reflects current and relevant information, particularly for web search RAG evaluation, where up-to-date data is crucial.This is the heart of the RAG Dataset Generator, transforming queries into actionable, high-quality data that forms the foundation of the evaluation set.\n\nquery_with_date = f\"{query} {datetime.now().strftime('%m-%Y')}\" tavily_response = await self.tavily_client.search( query=query_with_date, topic=\"news\", # Focuses search on recent news articles. days=3, # Searches content from the past 3 days. max_results=5 # Limits results to the top 5 most relevant sources. )\n\nKey Parameters of Tavily Search:\n\ntopic=\"news\":\n\nNarrows the search to news-related content, targeting fresh and reliable sources.\n\ndays=3:\n\nSearches for content published within the last three days, keeping the dataset relevant for real-world evaluation scenarios.\n\nmax_results=5:\n\nRetrieves up to five highly relevant results per query, avoiding information overload while maintaining quality.\n\nStep 4: Q&A Pair Generation\n\nFor each website returned by Tavily, the system generates question-answer pair using a map-reduce paradigm to ensure efficient processing across multiple sources. This step is implemented using LangGraph’s Send API.\n\ndef map_qa(state): # Map Function return [Send(\"generate_qa\", {\"page_content\": result.get('content', '')}) for url,result in state.search_results.items()]\n\n# nodes/generate_qa.py from web_search_benchmark_generator.prompts import QA_GENERATION_SYSTEM_PROMPT,QA_GENERATION_USER_PROMPT from langchain_core.messages import HumanMessage, SystemMessage from pydantic import BaseModel,Field from typing import List, Dict from web_search_benchmark_generator.state import QAState class QA(BaseModel): question: str = Field( ..., description=\"A question generated from the content.\" ) answer: str = Field( ..., description=\"The corresponding answer to the question.\" ) class QAList(BaseModel): qa_list: List[QA] = Field( ..., description=\"A list of QA pairs, each containing a question and its corresponding answer.\" ) class QAGenerator: def __init__(self,cfg,utils): self.model = cfg.LLM self.cfg = cfg self.default_system_prompt = QA_GENERATION_SYSTEM_PROMPT self.default_user_prompt = QA_GENERATION_USER_PROMPT self.utils = utils async def run(self, state: QAState): \"\"\" Generate 10 question-and-answer pairs based on the given page content. Args: state (QAState): The state containing the page content. Returns: List[Dict[str, str]]: A list of dictionaries containing question-answer pairs. \"\"\" msgs = \"🤔 Running QA Generator\" if self.cfg.DEBUG: print(msgs) page_content = state['page_content'] # Create system and user messages for the model system_message = SystemMessage(content=self.default_system_prompt) user_message = HumanMessage( content=self.default_user_prompt.format(page_content=page_content) ) messages = [system_message, user_message] try: response = await self.model.with_structured_output(QAList).ainvoke(messages) return {\"q_and_as\":response.qa_list} except Exception as e: # Handle and log errors msgs += f\"Error in QA Generator: {e}\" if self.cfg.DEBUG: print(msgs) raise ValueError(f\"Failed to generate QA pairs: {e}\")\n\nStep 5: Save the Evaluation Set\n\nFinally, the generated dataset is saved either locally or to Langsmith, based on the input configuration.\n\n# Create the dataset dataset = self.client.create_dataset( dataset_name=dataset_name, description=self.description, ) # Prepare inputs and outputs for bulk creation inputs = [{\"question\": qa.question} for qa in qa_list] outputs = [{\"expected_answer\": qa.answer} for qa in qa_list] # Save the examples self.client.create_examples( inputs=inputs, outputs=outputs, dataset_id=dataset.id, ) return {\"output_message\": f\"Dataset '{dataset_name}' saved in langsmith, You can access the dataset via the URL {dataset.url}.\"}\n\nOutput\n\nThe result is a well-structured, subject-specific evaluation dataset, ready for use in advanced evaluation methods like LLM-as-a-Judge.\n\nEvaluation of the Dataset Using LLM-as-a-Judge\n\nOnce the dataset is generated, its quality and relevance can be assessed using the LLM-as-a-Judge approach. This involves leveraging large language models to evaluate the accuracy, coherence, and completeness of the generated question-answer pairs. The LLM acts as an unbiased evaluator, scoring the answers based on alignment with expected outcomes or factual correctness. This method provides a scalable, automated way to validate datasets, ensuring they meet high standards for RAG system evaluation.\n\nAn LLM-as-a-judge prompt example:\n\nllm_judge_prompt = \"\"\" You are an unbiased evaluator tasked with assessing whether the generated answer aligns with the expected answer based on the provided question. Evaluate the generated answer's accuracy, coherence, and completeness compared to the expected answer. Provide a score from 1 to 10 for each criterion, followed by a brief explanation. Question: {question} Expected Answer: {expected_answer} Generated Answer: {generated_answer} Evaluation: - Accuracy: [Score: 1-10] - [Does the generated answer align with the expected answer?] - Coherence: [Score: 1-10] - [Is the generated answer clearly written and logically presented?] - Completeness: [Score: 1-10] - [Does the generated answer fully address the question as intended by the expected answer?] - Overall Feedback: [Your observations and suggestions for improvement] \"\"\"\n\nGetting Started with the Dataset Generator",
      "# [python: A python wrapper for Tavily search API by tavily-ai](https://github.com/tavily-ai/tavily-python)\n{ \"results\": [ { \"url\": \"https://en.wikipedia.org/wiki/Artificial_intelligence\", \"raw_content\": \"Contents\\nArtificial intelligence\\nArtificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is a field of study in computer science that develops and studies intelligent machines. \\\"AI\\\" may also refer to the machines themselves.\\nAI technology is widely used throughout industry, government and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), and competing at the highest level in strategy games (such as chess and Go).[1]\\nArtificial intelligence was founded as an academic discipline in 1956.[2] The field went through multiple cycles of optimism[3][4] followed by disappointment and loss of funding,[5][6] but after 2012, when deep learning surpassed all previous AI techniques,[7] there was a vast increase in funding and interest.\\nThe various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals.[8]\\nTo solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience and many other fields.[9]\\nGoals\\nThe general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\\nReasoning, problem-solving\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[10] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[11]\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \\\"combinatorial explosion\\\": they became exponentially slower as the problems grew larger.[12]\\nEven humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[13]\\nAccurate and efficient reasoning is an unsolved problem.\\nKnowledge representation\\nKnowledge representation and knowledge engineering[14] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[15] scene interpretation,[16] clinical decision support,[17] knowledge discovery (mining \\\"interesting\\\" and actionable inferences from large databases),[18] and other areas.[19]\\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[20] Knowledge bases need to represent things such as:\\nobjects, properties, categories and relations between objects;\\n[21]\\nsituations, events, states and time;[22]\\ncauses and effects;[23]\\nknowledge about knowledge (what we know about what other people know);[24]\\ndefault reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[25] and many other aspects and domains of knowledge.\\nAmong the most difficult problems in KR are: the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[26] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \\\"facts\\\" or \\\"statements\\\" that they could express verbally).[13]\\nKnowledge acquisition is the difficult problem of obtaining knowledge for AI applications.[c] Modern AI gathers knowledge by \\\"scraping\\\" the internet (including Wikipedia). The knowledge itself was collected by the volunteers and professionals who published the information (who may or may not have agreed to provide their work to AI companies).[29] This \\\"crowd sourced\\\" technique does not guarantee that the knowledge is correct or reliable. The knowledge of Large Language Models (such as ChatGPT) is highly unreliable -- it generates misinformation and falsehoods (known as \\\"hallucinations\\\"). Providing accurate knowledge for these modern AI applications is an unsolved problem.\\nPlanning and decision making\\nAn \\\"agent\\\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][30]\\nIn automated planning, the agent has a specific goal.[31] In automated decision making, the agent has preferences – there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision making agent assigns a number to each situation (called the \\\"utility\\\") that measures how much the agent prefers it. For each possible action, it can calculate the \\\"expected utility\\\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[32]\\nIn classical planning, the agent knows exactly what the effect of any action will be.[33]\\nIn most real-world problems, however, the agent may not be certain about the situation they are in (it is \\\"unknown\\\" or \\\"unobservable\\\") and it may not know for certain what will happen after each possible action (it is not \\\"deterministic\\\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[34]\\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning) or the agent can seek information to improve its preferences.[35]\\nInformation value theory can be used to weigh the value of exploratory or experimental actions.[36]\\nThe space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain what the outcome will be.\\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g. by iteration), be heuristic, or it can be learned.[37]\\nGame theory describes rational behavior of multiple interacting agents, and is used in AI programs that make decisions that involve other agents.[38]\\nLearning\\nMachine learning is the study of programs that can improve their performance on a given task automatically.[39]\\nIt has been a part of AI from the beginning.[e]\\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[42]\\nSupervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[43]\\nIn reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \\\"good\\\".[44]\\nTransfer learning is when the knowledge gained from one problem is applied to a new problem.[45] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[46]\\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[47]\\nNatural language processing\\nNatural language processing (NLP)[48] allows programs to read, write and communicate in human languages such as English.\\nSpecific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[49]\\nEarly work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation[f]\\nunless restricted to small domains called \\\"micro-worlds\\\" (due to the common sense knowledge problem[26]).\\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[50] transformers (a deep learning architecture using an attention mechanism),[51] and others.[52] In 2019, generative pre-trained transformer (or \\\"GPT\\\") language models began to generate coherent text,[53][54] and by 2023 these models were able to get human-level scores on the bar exam, SAT, GRE, and many other real-world applications.[55]\\nPerception\\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[56]\\nThe field includes speech recognition,[57]\\nimage classification,[58]\\nfacial recognition, object recognition,[59]\\nand robotic perception.[60]\\nSocial intelligence\\nAffective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process or simulate human feeling, emotion and mood.[62]\\nFor example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\\nHowever, this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are.[63] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.[64]\\nGeneral intelligence\\nA machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.[8]\\nTools\\nAI research uses a wide variety of tools to accomplish the goals above.[b]\\nSearch and optimization\\nAI can solve many problems by intelligently searching through many possible solutions.[65] There are two very different kinds of search used in AI: state space search and local search.\\nState space search searches through a tree of possible states to try to find a goal state.[66]\\nFor example, Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[67]\\nSimple exhaustive searches[68]\\nare rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.[12]\\n\\\"Heuristics\\\" or \\\"rules of thumb\\\" can help to prioritize choices that are more likely to reach a goal.[69]\\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and counter-moves, looking for a winning position.[70]\\nLocal search uses mathematical optimization to find a numeric solution to a problem. It begins with some form of a guess and then refines the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. This process is called stochastic gradient descent.[71]\\nEvolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses).[72]\\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[73]\\nNeural networks and statistical classifiers (discussed below), also use a form of local search, where the \\\"landscape\\\" to be searched is formed by learning.\\nLogic\\nFormal Logic is used for reasoning and knowledge representation.[74]\\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \\\"and\\\", \\\"or\\\", \\\"not\\\" and \\\"implies\\\")[75]\\nand predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \\\"Every X is a Y\\\" and \\\"There are some Xs that are Ys\\\").[76]\\nLogical inference (or deduction) is the process of proving a new statement (conclusion) from other statements that are already known to be true (the premises).[77]\\nA logical knowledge base also handles queries and assertions as a special case of inference.[78]\\nAn inference rule describes what is a valid step in a proof. The most general inference rule is resolution.[79]\\nInference can be reduced to performing a search to find a path that leads from premises to conclusions, where each step is the application of an inference rule.[80]\\nInference performed this way is intractable except for short proofs in restricted domains. No efficient, powerful and general method has been discovered.[81]\\nFuzzy logic assigns a \\\"degree of truth\\\" between 0 and 1 and handles uncertainty and probabilistic situations.[82]\\nNon-monotonic logics are designed to handle default reasoning.[25]\\nOther specialized versions of logic have been developed to describe many complex domains (see knowledge representation above).\\nProbabilistic methods for uncertain reasoning\\nMany problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[83]\\nBayesian networks[84]\\nare a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm),[g][86]\\nlearning (using the expectation-maximization algorithm),[h][88]\\nplanning (using decision networks)[89]\\nand perception (using dynamic Bayesian networks).[90]\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[90]\\nPrecise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[91]\\nand information value theory.[92]\\nThese tools include models such as Markov decision processes,\\n[93]\\ndynamic decision networks,[90]\\ngame theory and mechanism design.[94]\\nClassifiers and statistical learning methods\\nThe simplest AI applications can be divided into two types: classifiers (e.g. \\\"if shiny then diamond\\\"), on one hand, and controllers (e.g. \\\"if diamond then pick up\\\"), on the other hand. Classifiers[95]\\nare functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \\\"observation\\\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[43]\\nThere are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm.[96] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[97]\\nThe naive Bayes classifier is reportedly the \\\"most widely used learner\\\"[98] at Google, due in part to its scalability.[99]\\nNeural networks are also used as classifiers.[100]\\nArtificial neural networks\\nArtificial neural networks[100] were inspired by the design of the human brain: a simple \\\"neuron\\\" N accepts input from other neurons, each of which, when activated (or \\\"fired\\\"), casts a weighted \\\"vote\\\" for or against whether neuron N should itself activate. In practice, the input \\\"neurons\\\" are a list of numbers, the \\\"weights\\\" are a matrix, the next layer is the dot product (i.e., several weighted sums) scaled by an increasing function, such as the logistic function. \\\"The resemblance to real neural cells and structures is superficial\\\", according to Russell and Norvig.[101][i]\\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.[102]\\nNeural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.[103]\\nIn feedforward neural networks the signal passes in only one direction.[104]\\nRecurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.[105]\\nPerceptrons[106]\\nuse only a single layer of neurons, deep learning[107] uses multiple layers.\\nConvolutional neural networks strengthen the connection between neurons that are \\\"close\\\" to each other – this is especially important in image processing, where a local set of neurons must identify an \\\"edge\\\" before the network can identify an object.[108]\\nDeep learning\\nDeep learning[107]\\nuses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.[110]\\nDeep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, image classification[111]\\nand others. The reason that deep learning performs so well in so many applications is not known as of 2023.[112]\\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[j]\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[k]\\nSpecialized hardware and software\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.[121]\\nHistorically, specialized languages, such as Lisp, Prolog, and others, had been used.\\nApplications\\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search),\\ntargeting online advertisements,[122]\\nrecommendation systems (offered by Netflix, YouTube or Amazon),\\ndriving internet traffic,[123][124]\\ntargeted advertising (AdSense, Facebook),\\nvirtual assistants (such as Siri or Alexa),[125]\\nautonomous vehicles (including drones,\\nADAS and self-driving cars),\\nautomatic language translation (Microsoft Translator, Google Translate),\\nfacial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and\\nimage labeling (used by Facebook, Apple's iPhoto and TikTok).\\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported they had incorporated \\\"AI\\\" in some offerings or processes.[126]\\nA few examples are energy storage,[127]\\nmedical diagnosis,\\nmilitary logistics,\\napplications that predict the result of judicial decisions,[128]\\nforeign policy,[129]\\nor supply chain management.\\nGame playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[130] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[131]\\nIn March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps.[132] Then it defeated Ke Jie in 2017, who at the time continuously held the world No. 1 ranking for two years.[133][134][135] Other programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus[l] and Cepheus.[137] DeepMind in the 2010s developed a \\\"generalized artificial intelligence\\\" that could learn many diverse Atari games on its own.[138]\\nIn the early 2020s, generative AI gained widespread prominence. ChatGPT, based on GPT-3, and other large language models, were tried by 14% of Americans adults.[139] The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion[140][141]\\nsparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat,[142]\\nthe fictional arrest of Donald Trump,[143]\\nand a hoax of an attack on the Pentagon,[144]\\nas well as the usage in professional creative arts.[145][146]\\nAlphaFold 2 (2020) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[147]\\nEthics\\nAI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \\\"solve intelligence, and then use that to solve everything else\\\".[148] However, as the use of AI has become widespread, several unintended consequences and risks have been identified.[149]\\nAnyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning.[150]\\nRisks and harm\\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\\nTechnology companies collect a wide range of data from their users, including online activity, geolocation data, video and audio.[151]\\nFor example, in order to build speech recognition algorithms, Amazon others have recorded millions of private conversations and allowed temps to listen to and transcribe some of them.[152]\\nOpinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.[153]\\nAI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.[154]\\nSince 2016, some privacy experts, such as Cynthia Dwork, began to view privacy in terms of fairness -- Brian Christian wrote that experts have pivoted \\\"from the question of 'what they know' to the question of 'what they're doing with it'.\\\".[155]\\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under a rationale of \\\"fair use\\\". Experts disagree about how well, and under what circumstances, this rationale will hold up in courts of law; relevant factors may include \\\"the purpose and character of the use of the copyrighted work\\\" and \\\"the effect upon the potential market for the copyrighted work\\\".[156] In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[157][158]\\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[159] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[160] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem.\\nIn 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films or human writing.\\nIt is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda.[161] AI pioneer Geoffrey Hinton expressed concern about AI enabling \\\"authoritarian leaders to manipulate their electorates\\\" on a large scale, among other risks.[162]\\nMachine learning applications will be biased if they learn from biased data.[163]\\nThe developers may not be aware that the bias exists.[164]\\nBias can be introduced by the way training data is selected and by the way a model is deployed.[165][163] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[166]\\nFairness in machine learning is the study of how to prevent the harm caused by algorithmic bias. It has become serious area of academic study within AI. Researchers have discovered it is not always possible to define \\\"fairness\\\" in a way that satisfies all stakeholders.[167]\\nOn June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \\\"gorillas\\\" because they were black. The system was trained on a dataset that contained very few images of black people,[168] a problem called \\\"sample size disparity\\\".[169] Google \\\"fixed\\\" this problem by preventing the system from labelling anything as a \\\"gorilla\\\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.[170]\\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist.\\nIn 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different -- the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[171] In 2017, several researchers[m] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[173]\\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \\\"race\\\" or \\\"gender\\\"). The feature will correlate with other features (like \\\"address\\\", \\\"shopping history\\\" or \\\"first name\\\"), and the program will make the same decisions based on these features as it would on \\\"race\\\" or \\\"gender\\\".[174]\\nMoritz Hardt said \\\"the most robust fact in this research area is that fairness through blindness doesn't work.\\\"[175]\\nCriticism of COMPAS highlighted a deeper problem with the misuse of AI. Machine learning models are designed to make \\\"predictions\\\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. Unfortunately, if an application then uses these predictions as recommendations, some of these \\\"recommendations\\\" will likely be racist.[176] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is necessarily descriptive and not proscriptive.[n]\\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[169]\\nAt its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022) the Association for Computing Machinery, in Seoul, South Korea, presented and published findings recommending that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.[178]\\nMost modern AI applications can not explain how they have reached a decision.[179] The large amount of relationships between inputs and outputs in deep neural networks and resulting complexity makes it difficult for even an expert to explain how they produced their outputs, making them a black box.[180]\\nThere have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, Justin Ko and Roberto Novoa developed a system that could identify skin diseases better than medical professionals, however it classified any image with a ruler as \\\"cancerous\\\", because pictures of malignancies typically include a ruler to show the scale.[181] A more dangerous example was discovered by Rich Caruana in 2015: a machine learning system that accurately predicted risk of death classified a patient that was over 65, asthma and difficulty breathing as \\\"low risk\\\". Further research showed that in high-risk cases like this, the hospital would allocate more resources and save the patient's life, decreasing the risk measured by the program.[182] Mistakes like these become obvious when we know how the program has reached a decision. Without an explanation, these problems may not not be discovered until after they have caused harm.\\nA second issue is that people who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are required to clearly and completely explain the reasoning behind any decision they make.[183] Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists.[o] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.[184]\\nDARPA established the XAI (\\\"Explainable Artificial Intelligence\\\") program in 2014 to try and solve these problems.[185]\\nThere are several potential solutions to the transparency problem. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.[186] Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network have learned and produce output that can suggest what the network is learning.[187] Supersparse linear integer models use learning to identify the most important features, rather than the classification. Simple addition of these features can then make the classification (i.e. learning is used to create a scoring system classifier, which is transparent).[188]\\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.[p] By 2015, over fifty countries were reported to be researching battlefield robots.[190] These weapons are considered especially dangerous for several reasons: if they kill an innocent person it is not clear who should be held accountable, it is unlikely they will reliably choose targets, and, if produced at scale, they are potentially weapons of mass destruction.[191] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.[192]\\nAI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes and generative AI aid in producing misinformation; advanced AI can make authoritarian centralized decision making more competitive with liberal and decentralized systems such as markets.[193]\\nTerrorists, criminals and rogue states can use weaponized AI such as advanced digital warfare and lethal autonomous weapons.\\nMachine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.[194]\\nFrom the early days of the development of artificial intelligence there have been arguments, for example those put forward by Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.[195]\\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.[196]\\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \\\"we're in uncharted territory\\\" with AI.[197] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[198] Risk estimates vary; for example, in the 2010s Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \\\"high risk\\\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \\\"high risk\\\".[q][200] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology (rather than social policy) creates unemployment (as opposed to redundancies).[196]\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \\\"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\\\" is \\\"worth taking seriously\\\".[201] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[202]\\nIn April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.[203][204]\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as the physicist Stephen Hawking puts it, \\\"spell the end of the human race\\\".[205] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \\\"self-awareness\\\" (or \\\"sentience\\\" or \\\"consciousness\\\") and becomes a malevolent character.[r] These sci-fi scenarios are misleading in several ways.\\nFirst, AI does not require human-like \\\"sentience\\\" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager).[207] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \\\"you can't fetch the coffee if you're dead.\\\"[208] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \\\"fundamentally on our side\\\".[209]\\nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[210]\\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[211] Personalities such as Stephen Hawking, Bill Gates, Elon Musk have expressed concern about existential risk from AI.[212]\\nIn the early 2010's, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[213]\\nHowever, after 2016, the study of current and future risks and possible solutions became a serious area of research.[214]\\nAI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI and in 2023 many leading AI experts issued the joint statement that \\\"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\\\".[215]\\nEthical machines and alignment\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[216]\\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[217]\\nThe field of machine ethics is also called computational morality,[217]\\nand was founded at an AAAI symposium in 2005.[218]\\nOther approaches include Wendell Wallach's \\\"artificial moral agents\\\"[219]\\nand Stuart J. Russell's three principles for developing provably beneficial machines.[220]\\nRegulation\\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.[221]\\nThe regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[222] According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.[223][224]\\nBetween 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[225]\\nMost EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, US and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[225]\\nThe Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[225] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[226]\\nIn 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.[227]\\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \\\"products and services using AI have more benefits than drawbacks\\\".[223] A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.[228]\\nIn a 2023 Fox News poll, 35% of Americans thought it \\\"very important\\\", and an additional 41% thought it \\\"somewhat important\\\", for the federal government to regulate AI, versus 13% responding \\\"not very important\\\" and 8% responding \\\"not at all important\\\".[229][230]\\nIn November 2023, a global AI safety summit was held in Bletchley Park to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.[231]\\nHistory\\nThe study of mechanical or \\\"formal\\\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \\\"0\\\" and \\\"1\\\", could simulate both mathematical deduction and formal reasoning, which is known as the Church–Turing thesis.[232] This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \\\"electronic brain\\\".[s][234] The first paper later recognized as \\\"AI\\\" was McCullouch and Pitts design for Turing-complete \\\"artificial neurons\\\" in 1943.[235]\\nThe field of AI research was founded at a workshop at Dartmouth College in 1956.[t][2] The attendees became the leaders of AI research in the 1960s.[u] They and their students produced programs that the press described as \\\"astonishing\\\":[v] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[w][3]\\nBy the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense[239] and laboratories had been established around the world.[240] Herbert Simon predicted, \\\"machines will be capable, within twenty years, of doing any work a man can do\\\".[241] Marvin Minsky agreed, writing, \\\"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\\\".[242]\\nThey had, however, underestimated the difficulty of the problem.[x] Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[244] and ongoing pressure from the US Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks approach would never be useful for solving real-world tasks, thus discrediting the approach altogether.[245] The \\\"AI winter\\\", a period when obtaining funding for AI projects was difficult, followed.[5]\\nIn the early 1980s, AI research was revived by the commercial success of expert systems,[246] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[4] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[6]\\nMany researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition.[247] A number of researchers began to look into \\\"sub-symbolic\\\" approaches.[248] Robotics researchers, such as Rodney Brooks, rejected \\\"representation\\\" in general and focussed directly on engineering machines that move and survive.[y]. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[83][253] But the most important development was the revival of \\\"connectionism\\\", including neural network research, by Geoffrey Hinton and others.[254] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[255]\\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \\\"narrow\\\" and \\\"formal\\\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[256]\\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \\\"artificial intelligence\\\".[257]\\nSeveral academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \\\"AGI\\\"), which had several well-funded institutions by the 2010s.[8]\\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[7]\\nFor many specific tasks, other methods were abandoned.[z]\\nDeep learning's success was based on both hardware improvements (faster computers,[259] graphics processing units, cloud computing[260])\\nand access to large amounts of data[261] (including curated datasets,[260] such as ImageNet).\\nDeep learning's success led to an enormous increase in interest and funding in AI.[aa]\\nThe amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019,[225]\\nand WIPO reported that AI was the most prolific emerging technology in terms of the number of patent applications and granted patents[262]\\nAccording to 'AI Impacts', about $50 billion annually was invested in \\\"AI\\\" around 2022 in the US alone and about 20% of new US Computer Science PhD graduates have specialized in \\\"AI\\\";[263]\\nabout 800,000 \\\"AI\\\"-related US job openings existed in 2022.[264]\\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[214]\\nPhilosophy\\nDefining artificial intelligence\\nAlan Turing wrote in 1950 \\\"I propose to consider the question 'can machines think'?\\\"[265]\\nHe advised changing the question from whether a machine \\\"thinks\\\", to \\\"whether or not it is possible for machinery to show intelligent behaviour\\\".[265]\\nHe devised the Turing test, which measures the ability of a machine to simulate human conversation.[266] Since we can only observe the behavior of the machine, it does not matter if it is \\\"actually\\\" thinking or literally has a \\\"mind\\\". Turing notes that we can not determine these things about other people[ab] but \\\"it is usual to have a polite convention that everyone thinks\\\"[267]\\nRussell and Norvig agree with Turing that AI must be defined in terms of \\\"acting\\\" and not \\\"thinking\\\".[268] However, they are critical that the test compares machines to people. \\\"Aeronautical engineering texts,\\\" they wrote, \\\"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\\\"[269] AI founder John McCarthy agreed, writing that \\\"Artificial intelligence is not, by definition, simulation of human intelligence\\\".[270]\\nMcCarthy defines intelligence as \\\"the computational part of the ability to achieve goals in the world.\\\"[271] Another AI founder, Marvin Minsky similarly defines it as \\\"the ability to solve hard problems\\\".[272] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \\\"intelligence\\\" of the machine—and no other philosophical discussion is required, or may not even be possible.\\nAnother definition has been adopted by Google,[273] a major practitioner in the field of AI.\\nThis definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\\nEvaluating approaches to AI\\nNo established unifying theory or paradigm has guided AI research for most of its history.[ac] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \\\"artificial intelligence\\\" to mean \\\"machine learning with neural networks\\\"). This approach is mostly sub-symbolic, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.\\nSymbolic AI (or \\\"GOFAI\\\")[275] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \\\"intelligent\\\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \\\"A physical symbol system has the necessary and sufficient means of general intelligent action.\\\"[276]\\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \\\"intelligent\\\" tasks were easy for AI, but low level \\\"instinctive\\\" tasks were extremely difficult.[277]\\nPhilosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \\\"feel\\\" for the situation, rather than explicit symbolic knowledge.[278]\\nAlthough his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree.[ad][13]\\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[280][281] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\\n\\\"Neats\\\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \\\"Scruffies\\\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 70s and 80s,[282]\\nbut eventually was seen as irrelevant. Modern AI has elements of both.\\nFinding a provably correct or optimal solution is intractable for many important problems.[12] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 80s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.[283][284]\\nGeneral intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\\nMachine consciousness, sentience and mind\\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \\\"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\\\"[285] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\nDavid Chalmers identified two problems in understanding the mind, which he named the \\\"hard\\\" and \\\"easy\\\" problems of consciousness.[286] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). Human information processing is easy to explain, however, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[287]\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[288]\\nPhilosopher John Searle characterized this position as \\\"strong AI\\\": \\\"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\\\"[ae]\\nSearle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[292]\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights.[293]\\nAny hypothetical robot rights would lie on a spectrum with animal rights and human rights.[294]\\nThis issue has been considered in fiction for centuries,[295]\\nand is now being considered by, for example, California's Institute for the Future; however, critics argue that the discussion is premature.[296]\\nFuture\\nSuperintelligence and the singularity\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[284]\\nIf research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \\\"intelligence explosion\\\" and Vernor Vinge called a \\\"singularity\\\".[297]\\nHowever, technologies can't improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[298]\\nTranshumanism\\nRobot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.[299]\\nEdward Fredkin argues that \\\"artificial intelligence is the next stage in evolution\\\", an idea first proposed by Samuel Butler's \\\"Darwin among the Machines\\\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.[300]\\nIn fiction\\nThought-capable artificial beings have appeared as storytelling devices since antiquity,[301]\\nand have been a persistent theme in science fiction.[302]\\nA common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[303]\\nIsaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \\\"Multivac\\\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics;[304]\\nwhile almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[305]\\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[306]\\nSee also\\nExplanatory notes\\nReferences\\nAI textbooks\\nThe two most widely used textbooks in 2023. (See the Open Syllabus).\\nThese were the four the most widely used AI textbooks in 2008:\\nLater editions.\\nHistory of AI\\nOther sources\\nFurther reading\\nExternal links\", \"images\": [\"https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-en.svg\"] }, { \"url\": \"https://www.britannica.com/science/autumn-season\", \"raw_content\": \"Autumn | Definition, Characteristics, & Facts | Britannica\\n\\nSearch Britannica Click here to search\\n\\nSearch Britannica Click here to search\\nSubscribe Now\\nSubscribe\\nLogin\\n\\nHome\\nHistory & Society\\nScience & Tech\\nBiographies\\nAnimals & Nature\\nGeography & Travel\\nArts & Culture\\n\\nMoney\\n\\n\\nGames & Quizzes\\n\\nVideos\\nOn This Day\\nOne Good Fact\\nDictionary\\nNew Articles\\n\\nHistory & Society\\n\\nLifestyles & Social Issues\\nPhilosophy & Religion\\nPolitics, Law & Government\\nWorld History\\n\\nScience & Tech\\n\\nHealth & Medicine\\nScience\\nTechnology\\n\\nBiographies\\n\\nBrowse Biographies\\n\\nAnimals & Nature\\n\\nBirds, Reptiles & Other Vertebrates\\nBugs, Mollusks & Other Invertebrates\\nEnvironment\\nFossils & Geologic Time\\nMammals\\nPlants\\n\\nGeography & Travel\\n\\nGeography & Travel\\n\\nArts & Culture\\n\\nEntertainment & Pop Culture\\nLiterature\\nSports & Recreation\\n\\nVisual Arts\\n\\n\\nCompanions\\n\\nDemystified\\nImage Galleries\\nInfographics\\nLists\\nPodcasts\\nSpotlight\\nSummaries\\nThe Forum\\nTop Questions\\n\\n#WTFact\\n\\n\\n100 Women\\n\\nBritannica Kids\\nSaving Earth\\nSpace Next 50\\nStudent Center\\n\\nAsk the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture Money Videos\\nautumn\\nTable of Contents\\nIntroduction References & Edit History Quick Facts & Related Topics\\nImages & Videos\\n \\nRelated Questions\\n\\nWhat does Earth look like?\\n\\nRead Next\\n\\nWhy Do Leaves Change Colors in the Fall?\\n\\n22 Questions About Time and Timekeeping Answered\\n\\nWhy Do Leaves Fall in Autumn?\\n\\nThe Perils of an Early Spring\\n\\nFirst Day of Fall\\nDiscover\\n\\n7 Scary Surgical Instruments, Then and Now\\n\\nWhere Does the Name Europe Come From?\\n\\nCruel and Unusual Punishments: 15 Types of Torture\\n\\nWhat’s the Difference Between Hispanic and Latino?\\n\\nAll 119 References in “We Didn’t Start the Fire,” Explained\\n\\nWhy Is a Baker’s Dozen 13?\\n\\n10 Famous Artworks by Leonardo da Vinci\\nContents\\nScience Earth Science, Geologic Time & Fossils Earth Sciences\\nautumn\\nseason\\nActions\\nCite\\n_verified_Cite\\nWhile every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions.\\nSelect Citation Style\\nCopy Citation\\nShare\\nShare\\nShare to social media\\nFacebook X\\nURL\\nhttps://www.britannica.com/science/autumn-season\\nGive Feedback\\nExternal Websites\\nFeedback\\nCorrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login).\\nFeedback Type \\nYour Feedback Submit Feedback\\nThank you for your feedback\\nOur editors will review what you’ve submitted and determine whether to revise the article.\\nExternal Websites\\n\\nLiveScience - Autumn: The Cooling-Off Season\\n\\nBritannica Websites\\nArticles from Britannica Encyclopedias for elementary and high school students.\\n\\nautumn - Children's Encyclopedia (Ages 8-11)\\nautumn - Student Encyclopedia (Ages 11 and up)\\n\\nPrint Cite\\n_verified_Cite\\nWhile every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions.\\nSelect Citation Style\\nCopy Citation\\nShare\\nShare\\nShare to social media\\nFacebook X\\nURL\\nhttps://www.britannica.com/science/autumn-season\\nFeedback\\nExternal Websites\\nFeedback\\nCorrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login).\\nFeedback Type \\nYour Feedback Submit Feedback\\nThank you for your feedback\\nOur editors will review what you’ve submitted and determine whether to revise the article.\\nExternal Websites\\n\\nLiveScience - Autumn: The Cooling-Off Season\\n\\nBritannica Websites\\nArticles from Britannica Encyclopedias for elementary and high school students.\\n\\nautumn - Children's Encyclopedia (Ages 8-11)\\nautumn - Student Encyclopedia (Ages 11 and up)\\n\\nAlso known as: fall\\nWritten and fact-checked by\\nThe Editors of Encyclopaedia Britannica Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree. They write new content and verify and edit content received from contributors.\\nThe Editors of Encyclopaedia Britannica\\nLast Updated: Aug 29, 2024 • Article History\\nTable of Contents\\n\\nautumn\\nSee all media\\nRelated Topics:\\ncalendar\\nharvest\\nyear\\nIndian summer\\nautumnal equinox\\n(Show more)\\nSee all related content →\\nRecent News\\nAug. 29, 2024, 4:45 PM ET (AP)\\nFall is bringing fantasy (and romantasy), literary fiction, politics and Taylor-ed book offerings\\nautumn, season of the year between summer and winter during which temperatures gradually decrease. It is often called fall in the United States because leaves fall from the trees at that time. Autumn is usually defined in the Northern Hemisphere as the period between the autumnal equinox (day and night equal in length), September 22 or 23, and the winter solstice (year’s shortest day), December 21 or 22; and in the Southern Hemisphere as the period between March 20 or 21 and June 21 or 22. The autumn temperature transition between summer heat and winter cold occurs only in middle and high latitudes; in equatorial regions, temperatures generally vary little during the year. In the polar regions autumn is very short. For physical causes of the seasons, see season.\\n\\nWhat causes the seasons?In many parts of the world, weather cycles through the four seasons like clockwork: spring, summer, autumn, and winter.(more)\\nSee all videos for this article\\n\\nWhy do some trees lose their leaves in autumn?Learn why leaves of deciduous trees change colour in autumn.(more)\\nSee all videos for this article\\nThe concept of autumn in European languages is connected with the harvesting of crops; in many cultures autumn, like the other seasons, has been marked by rites and festivals revolving around the season’s importance in food production. Animals gather food in autumn in preparation for the coming winter, and those with fur often grow thicker coats. Many birds migrate toward the Equator to escape the falling temperatures. A common autumn phenomenon in the central and eastern United States and in Europe is Indian summer, a period of unseasonably warm weather that sometimes occurs in late October or November.\\nThe Editors of Encyclopaedia BritannicaThis article was most recently revised and updated by Meg Matthias.\", \"images\": [\"https://cdn.britannica.com/mendel/eb-logo/MendelNewThistleLogo.png\", \"https://cdn.britannica.com/mendel/eb-logo/MendelNewThistleLogo.png\", \"https://cdn.britannica.com/88/137188-004-A05832DA/Boston-Public-Garden.jpg\", \"https://cdn.britannica.com/62/247262-138-1891B9BE/what-causes-seasons.jpg?w=400&h=225&c=crop\", \"https://cdn.britannica.com/23/179623-138-8D7F3C16/leaves-trees-colour.jpg?w=400&h=225&c=crop\", \"https://cdn.britannica.com/01/144901-004-07156D4A/Great-Smoky-Mountains-National-Park-Tennessee.jpg\", \"https://cdn.britannica.com/45/158545-004-A787D7AA/autumn-foliage-North-Cascades-National-Park-Washington.jpg\", \"https://cdn.britannica.com/62/180762-138-850D2106/journey-New-England-2013.jpg?w=400&h=225&c=crop\", \"https://cdn.britannica.com/28/180828-138-C9C052FB/video-Otago-New-Zealand-South-Island.jpg?w=400&h=225&c=crop\", \"https://cdn.britannica.com/88/137188-050-8C779D64/Boston-Public-Garden.jpg?w=400&h=300&c=crop\"], }, { \"url\": \"https://docs.tavily.com/docs/welcome\", \"raw_content\": \"Introduction\\nHey there! 👋\\nWe're a team of AI researchers and developers who are passionate about helping you build the next generation of AI assistants.\\nOur mission is to empower individuals and organizations with accurate, unbiased, and factual information.\\nTavily Search API​\\nBuilding an AI agent that leverages realtime online information is not a simple task. Scraping doesn't scale and requires expertise to refine, current search engine APIs don't provide explicit information to queries but simply potential related articles (which are not always related), and are not very customziable for AI agent needs. This is why we're excited to introduce the first search engine for AI agents - Tavily Search API.\\nTavily Search API is a search engine optimized for LLMs, aimed at efficient, quick and persistent search results. Unlike other search APIs such as Serp or Google, Tavily focuses on optimizing search for AI developers and autonomous AI agents. We take care of all the burden of searching, scraping, filtering and extracting the most relevant information from online sources. All in a single API call! \\nTo try the API in action, you can now use our hosted version on our API Playground.\\nIf you're an AI developer looking to integrate your application with our API, or seek increased API limits, please reach out!\\nWhy choose the Tavily Search API?​\\nHow does the Search API work?​\\nCurrent search APIs such as Google, Serp and Bing retrieve search results based on user query. However, the results are sometimes irrelevant to the goal of the search, and return simple site URLs and snippets of content which are not always relevant. Because of this, any developer would need to then scrape the sites to extract relevant content, filter irrelevant information, optimize the content to fit LLM context limits, and more. This task is a burden and requires a lot of time and effort to complete. The Tavily Search API takes care of all of this for you in a single API call.\\nTavily Search API aggregates up to 20 sites per a single API call, and uses proprietary AI to score, filter and rank the top most relevant sources and content to your task, query or goal.\\nIn addition, Tavily allows developers to add custom fields such as context and limit response tokens to enable the optimal search experience for LLMs.\\nTavily can also help your AI agent make better decisions by including a short answer for cross-agent communication.\\nRemember: With LLM hallucinations, it's crucial to optimize for RAG with the right context and information.\\nGetting started​\\n🙋‍♂️ Got questions? Stumbled upon an issue? Or simply intrigued? Don't hesitate! Our support team is always on standby, eager to assist. Join us, dive deep, and redefine your search experience! Contact us!\\nGPT Researcher​\\nIn this digital age, quickly accessing relevant and trustworthy information is more crucial than ever. However, we've learned that none of today's search engines provide a suitable tool that provides factual, explicit and objective answers without the need to continuously click and explore multiple sites for a given research task. \\nThis is why we've built the trending open source GPT Researcher. GPT Researcher is an autonomous agent that takes care of the tedious task of research for you, by scraping, filtering and aggregating over 20+ web sources per a single research task. \\nTo learn more about GPT Researcher, check out the documentation page.\\n\", \"images\": [\"https://docs.tavily.com/img/tavily.png\", \"https://docs.tavily.com/img/tavily-dark.png\"] } ], \"failed_results\": [ ], \"response_time\": 0.02 }",
      "# [tavily-python on 2024-09-16](https://pypi.org/project/tavily-python/)\nTavily Python Wrapper\n\nThe Tavily Python wrapper allows for easy interaction with the Tavily API, offering the full range of our search functionality directly from your Python programs. Easily integrate smart search capabilities into your applications, harnessing Tavily's powerful search features.\n\nInstalling\n\npip install tavily-python\n\nUsage\n\nBelow are some code snippets that show you how to interact with our API. The different steps and components of this code are explained in more detail in the API Methods section further down.\n\nGetting and printing the full Search API response\n\nfrom tavily import TavilyClient # Step 1. Instantiating your TavilyClient tavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\") # Step 2. Executing a simple search query response = tavily_client.search(\"Who is Leo Messi?\") # Step 3. That's it! You've done a Tavily Search! print(response)\n\nThis is equivalent to directly querying our REST API.\n\nGenerating context for a RAG Application\n\nfrom tavily import TavilyClient # Step 1. Instantiating your TavilyClient tavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\") # Step 2. Executing a context search query context = tavily_client.get_search_context(query=\"What happened during the Burning Man floods?\") # Step 3. That's it! You now have a context string that you can feed directly into your RAG Application print(context)\n\nThis is how you can generate precise and fact-based context for your RAG application in one line of code.\n\nGetting a quick answer to a question\n\nfrom tavily import TavilyClient # Step 1. Instantiating your TavilyClient tavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\") # Step 2. Executing a Q&A search query answer = tavily_client.qna_search(query=\"Who is Leo Messi?\") # Step 3. That's it! Your question has been answered! print(answer)\n\nThis is how you get accurate and concise answers to questions, in one line of code. Perfect for usage by LLMs!\n\nAPI Methods\n\nClient\n\nNEW! We have released a Beta of our asynchronous Tavily client. It is available in version 0.3.4 of our Python package. The asynchronous client's interface is identical to the synchronous client's, the only difference being that all methods are asynchronous. Try it now with the AsyncTavilyClient class!\n\nThe TavilyClient class is the entry point to interacting with the Tavily API. Kickstart your journey by instantiating it with your API key. If you want to use Tavily asynchronously, you will need to instantiate an AsyncTavilyClient instead.\n\nOnce you do so, you're ready to search the Web in one line of code! All you need is to pass a str as a query to one of our methods (detailed below) and you'll start searching!\n\nMethods\n\nsearch(query, **kwargs)\n\nPerforms a Tavily Search query and returns the response as a well-structured dict.\n\nAdditional parameters can be provided as keyword arguments (detailed below). The keyword arguments supported by this method are: search_depth, topic, days, max_results, include_domains, exclude_domains, include_answer, include_raw_content, include_images.\n\nReturns a dict with all related response fields. If you decide to use the asynchronous client, returns a coroutine resolving to that dict. The details of the exact response format are given in the Search Responses section further down.\n\nget_search_context(query, **kwargs)\n\nPerforms a Tavily Search query and returns a str of content and sources within the provided token limit. It's useful for getting only related content from retrieved websites without having to deal with context extraction and token management.\n\nThe core parameter for this function is max_tokens, an int. It defaults to 4000. It is provided as a keyword argument.\n\nAdditional parameters can be provided as keyword arguments (detailed below). The keyword arguments supported by this method are: search_depth, topic, days, max_results, include_domains, exclude_domains.\n\nReturns a str containing the content and sources of the results. If you decide to use the asynchronous client, returns a coroutine resolving to that str.\n\nqna_search(query, **kwargs)\n\nPerforms a search and returns a string containing an answer to the original query. This is optimal to be used as a tool for AI agents.\n\nAdditional parameters can be provided as keyword arguments (detailed below). The keyword arguments supported by this method are: search_depth (defaults to \"advanced\"), topic, days, max_results, include_domains, exclude_domains.\n\nReturns a str containing a short answer to the search query. If you decide to use the asynchronous client, returns a coroutine resolving to that str.\n\nKeyword Arguments (optional)\n\nsearch_depth: str - The depth of the search. It can be \"basic\" or \"advanced\". Default is \"basic\" unless specified otherwise in a given method.\n\ntopic: str - The category of the search. This will determine which of our agents will be used for the search. Currently, only \"general\" and \"news\" are supported. Default is \"general\".\n\ndays: int (optional) - The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the \"news\" search topic. Default is 3.\n\nmax_results: int - The maximum number of search results to return. Default is 5.\n\ninclude_images: bool - Include a list of query-related images in the response. Default is False.\n\ninclude_answer: bool - Include a short answer to original query. Default is False.\n\ninclude_raw_content: bool - Include the cleaned and parsed HTML content of each search result. Default is False.\n\ninclude_domains: list[str] - A list of domains to specifically include in the search results. Default is None, which includes all domains.\n\nexclude_domains: list[str] - A list of domains to specifically exclude from the search results. Default is None, which doesn't exclude any domains.\n\nSearch Responses\n\nanswer: str- The answer to your search query. This will be None unless include_answer is set to True.\n\nquery: str - Your search query.\n\nresponse_time: float - Your search result response time.\n\nimages: list[str] - A list of query-related image URLs.\n\nresults: list - A list of sorted search results ranked by relevancy. Each result is in the following format:\n\ntitle: str - The title of the search result URL.\n\nurl: str - The URL of the search result.\n\ncontent: str - The most query related content from the scraped URL. We use proprietary AI and algorithms to extract only the most relevant content from each URL, to optimize for context quality and size.\n\nraw_content: str - The parsed and cleaned HTML of the site. For now includes parsed text only. Please note that this will be None unless include_raw_content is set to True.\n\nscore: float - The relevance score of the search result.\n\npublished_date: str (optional) - The publication date of the source. This is only available if you are using \"news\" as your search topic.\n\nWhen you send a search query, the response dict you receive will be in the following format:\n\nresponse = { \"query\" = \"The query provided in the request\", \"answer\" = \"A short answer to the query\", # This will be None if include_answer is set to False in the request \"follow_up_questions\": None, # This feature is still in development \"images\" = [ \"Image 1 URL\", \"Image 2 URL\", \"Image 3 URL\", \"Image 4 URL\", \"Image 5 URL\" ], # This will be an empty list if include_images is not set to True \"results\" = [ { \"title\": \"Source 1 Title\", \"url\": \"Source 1 URL\", \"content\": \"Source 1 Content\", \"score\": 0.99 # This is the \"relevancy\" score of the source. It ranges from 0 to 1. }, { \"title\": \"Source 2 Title\", \"url\": \"Source 2 URL\", \"content\": \"Source 2 Content\", \"score\": 0.97 }, ] # This list will have max_results elements }\n\nError Handling\n\nThe Tavily Python SDK includes comprehensive error handling to ensure smooth interaction with the API. Below are the specific exceptions that might be raised during usage:\n\nMissing API Key: If no API key is provided when initializing the TavilyClient, a tavily.MissingAPIKeyError will be raised. Ensure you pass a valid API key to the TavilyClient during instantiation.\n\nfrom tavily import TavilyClient, MissingAPIKeyError try: tavily_client = TavilyClient(api_key=\"\") except MissingAPIKeyError: print(\"API key is missing. Please provide a valid API key.\")\n\nInvalid API Key: If the API key provided is invalid, a tavily.InvalidAPIKeyError will be raised when sending a search query. Double-check that your API key is correct and active.\n\nfrom tavily import TavilyClient, InvalidAPIKeyError tavily_client = TavilyClient(api_key=\"invalid-api-key\") try: response = tavily_client.search(\"Who is Leo Messi?\") except InvalidAPIKeyError: print(\"Invalid API key provided. Please check your API key.\")\n\nUsage Limit Exceeded: If the API key provided is valid but the request fails due to exceeding the rate limit, surpassing the plan's monthly limit, or hitting the key's pre-set monthly limit, a tavily.UsageLimitExceededError will be raised. Consider upgrading your plan or checking your usage limits.\n\nfrom tavily import TavilyClient, UsageLimitExceededError tavily_client = TavilyClient(api_key=\"valid-api-key\") try: response = tavily_client.search(\"Who is Leo Messi?\") except UsageLimitExceededError: print(\"Usage limit exceeded. Please check your plan's usage limits or consider upgrading.\")\n\nThese errors ensure that you are aware of the specific issues related to your API key usage, allowing you to take appropriate actions to resolve them.\n\nLicense\n\nThis project is licensed under the terms of the MIT license.\n\nContact\n\nIf you are encountering issues while using Tavily, please email us at support@tavily.com. We'll be happy to help you.",
      "# [tavily: An MCP server for Tavily's search API](https://github.com/RamXX/mcp-tavily)\nA Model Context Protocol server that provides AI-powered web search capabilities using Tavily's search API. This server enables LLMs to perform sophisticated web searches, get direct answers to questions, and search recent news articles with AI-extracted relevant content.\n\nAvailable Tools\n\ntavily_web_search - Performs comprehensive web searches with AI-powered content extraction.\n\nquery (string, required): Search query\n\nmax_results (integer, optional): Maximum number of results to return (default: 5, max: 20)\n\nsearch_depth (string, optional): Either \"basic\" or \"advanced\" search depth (default: \"basic\")\n\ntavily_answer_search - Performs web searches and generates direct answers with supporting evidence.\n\nquery (string, required): Search query\n\nmax_results (integer, optional): Maximum number of results to return (default: 5, max: 20)\n\nsearch_depth (string, optional): Either \"basic\" or \"advanced\" search depth (default: \"advanced\")\n\ntavily_news_search - Searches recent news articles with publication dates.\n\nquery (string, required): Search query\n\nmax_results (integer, optional): Maximum number of results to return (default: 5, max: 20)\n\ndays (integer, optional): Number of days back to search (default: 3)\n\ntavily_web_search\n\nSearch the web using Tavily's AI-powered search engine\n\nArguments:\n\nquery (string, required): Search query\n\ntavily_answer_search\n\nSearch the web and get an AI-generated answer with supporting evidence\n\nArguments:\n\nquery (string, required): Search query\n\ntavily_news_search\n\nSearch recent news articles with Tavily's news search\n\nArguments:\n\nquery (string, required): Search query\n\ndays (integer, optional): Number of days back to search\n\nSimply run:\n\npip install mcp-tavily\n\nor if you have uv installed:\n\nuv pip install mcp-tavily\n\nClone this repository and build and install the program with your default Python interpreter (recommended).\n\nAfter installation, you can run it as a script using:\n\nThe server requires a Tavily API key to function. You can obtain one from Tavily's website. The API key can be provided in two ways:\n\nAs an environment variable:\n\nAs a command-line argument:\n\npython -m mcp_server_tavily --api-key=your_api_key_here\n\nAdd to your Claude settings:\n\nUsing pip installation\n\n\"mcpServers\": { \"tavily\": { \"command\": \"python\", \"args\": [\"-m\", \"mcp_server_tavily\"] }, \"env\": { \"TAVILY_API_KEY\": \"your_api_key_here\" } }\n\nIf you see any issue, you may want to use the full path for the Python interpreter you are using. You can do a which python to find out the exact path if needed.\n\nRemember to set the TAVILY_API_KEY environment variable or provide it via the --api-key argument.\n\nFor a regular search:\n\nTo generate a report with explicit exclusions:\n\nTo force Claude to use the answer mode function call, be explicit in your ask:\n\nFor news, use:\n\nYou can use the MCP inspector to debug the server. For uvx installations:\n\nOr if you've installed the package in a specific directory or are developing on it:\n\nWe encourage contributions to help expand and improve mcp-server-tavily. Whether you want to add new search capabilities, enhance existing functionality, or improve documentation, your input is valuable.\n\nFor examples of other MCP servers and implementation patterns, see: https://github.com/modelcontextprotocol/servers\n\nPull requests are welcome! Feel free to contribute new ideas, bug fixes, or enhancements to make mcp-server-tavily even more powerful and useful.\n\nmcp-server-tavily is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.",
      "# [Tavily Search](https://python.langchain.com/docs/integrations/tools/tavily_search/)\nTavily's Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\n\nClassPackageSerializableJS supportPackage latestTavilySearchResultslangchain-community❌✅\n\nReturns artifactNative asyncReturn dataPricing✅✅Title, URL, content, answer1,000 free searches / month\n\nThe integration lives in the langchain-community package. We also need to install the tavily-python package.\n\nWe also need to set our Tavily API key. You can get an API key by visiting this site and creating an account.\n\nIt's also helpful (but not needed) to set up LangSmith for best-in-class observability:\n\nHere we show how to instantiate an instance of the Tavily search tools, with\n\nThe TavilySearchResults tool takes a single \"query\" argument, which should be a natural language query:\n\nWe can also invoke the tool with a model-generated ToolCall, in which case a ToolMessage will be returned:\n\nWe can use our tool in a chain by first binding it to a tool-calling model and then calling it:\n\nHere's the LangSmith trace for this run.\n\nFor detailed documentation of all TavilySearchResults features and configurations head to the API reference: https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html",
      "# [LLM Enhanced Web Search: The Tavily & Lang Chain by marcinrutecki on 2024-04-03](https://www.kaggle.com/code/marcinrutecki/llm-enhanced-web-search-the-tavily-lang-chain)\n",
      "# [TavilySearchAPIRetriever](https://python.langchain.com/docs/integrations/retrievers/tavily/)\n[Document(metadata={'title': 'The Legend of Zelda: Breath of the Wild - Nintendo Switch Wiki', 'source': 'https://nintendo-switch.fandom.com/wiki/The_Legend_of_Zelda:_Breath_of_the_Wild', 'score': 0.9961155, 'images': []}, page_content='The Legend of Zelda: Breath of the Wild is an open world action-adventure game published by Nintendo for the Wii U and as a launch title for the Nintendo Switch, and was released worldwide on March 3, 2017. It is the nineteenth installment of the The Legend of Zelda series and the first to be developed with a HD resolution. The game features a gigantic open world, with the player being able to ...'),\n\nDocument(metadata={'title': 'The Legend of Zelda: Breath of the Wild - Zelda Wiki', 'source': 'https://zelda.fandom.com/wiki/The_Legend_of_Zelda:_Breath_of_the_Wild', 'score': 0.9804313, 'images': []}, page_content='[]\\nReferences\\nThe Legend of Zelda \\xa0·\\nThe Adventure of Link \\xa0·\\nA Link to the Past (& Four Swords) \\xa0·\\nLink\\'s Awakening (DX; Nintendo Switch) \\xa0·\\nOcarina of Time (Master Quest; 3D) \\xa0·\\nMajora\\'s Mask (3D) \\xa0·\\nOracle of Ages \\xa0·\\nOracle of Seasons \\xa0·\\nFour Swords (Anniversary Edition) \\xa0·\\nThe Wind Waker (HD) \\xa0·\\nFour Swords Adventures \\xa0·\\nThe Minish Cap \\xa0·\\nTwilight Princess (HD) \\xa0·\\nPhantom Hourglass \\xa0·\\nSpirit Tracks \\xa0·\\nSkyward Sword (HD) \\xa0·\\nA Link Between Worlds \\xa0·\\nTri Force Heroes \\xa0·\\nBreath of the Wild \\xa0·\\nTears of the Kingdom\\nZelda (Game & Watch) \\xa0·\\nThe Legend of Zelda Game Watch \\xa0·\\nLink\\'s Crossbow Training \\xa0·\\nMy Nintendo Picross: Twilight Princess \\xa0·\\nCadence of Hyrule \\xa0·\\nGame & Watch: The Legend of Zelda\\nCD-i Games\\n Listings[]\\nCharacters[]\\nBosses[]\\nEnemies[]\\nDungeons[]\\nLocations[]\\nItems[]\\nTranslations[]\\nCredits[]\\nReception[]\\nSales[]\\nEiji Aonuma and Hidemaro Fujibayashi accepting the \"Game of the Year\" award for Breath of the Wild at The Game Awards 2017\\nBreath of the Wild was estimated to have sold approximately 1.3 million copies in its first three weeks and around 89% of Switch owners were estimated to have also purchased the game.[52] Sales of the game have remained strong and as of June 30, 2022, the Switch version has sold 27.14 million copies worldwide while the Wii U version has sold 1.69 million copies worldwide as of December 31, 2019,[53][54] giving Breath of the Wild a cumulative total of 28.83 million copies sold.\\n It also earned a Metacritic score of 97 from more than 100 critics, placing it among the highest-rated games of all time.[59][60] Notably, the game received the most perfect review scores for any game listed on Metacritic up to that point.[61]\\nIn 2022, Breath of the Wild was chosen as the best Legend of Zelda game of all time in their \"Top 10 Best Zelda Games\" list countdown; but was then placed as the \"second\" best Zelda game in their new revamped version of their \"Top 10 Best Zelda Games\" list in 2023, right behind it\\'s successor Tears of Video Game Canon ranks Breath of the Wild as one of the best video games of all time.[74] Metacritic ranked Breath of the Wild as the single best game of the 2010s.[75]\\nFan Reception[]\\nWatchMojo placed Breath of the Wild at the #2 spot in their \"Top 10 Legend of Zelda Games of All Time\" list countdown, right behind Ocarina of Time.[76] The Faces of Evil \\xa0·\\nThe Wand of Gamelon \\xa0·\\nZelda\\'s Adventure\\nHyrule Warriors Series\\nHyrule Warriors (Legends; Definitive Edition) \\xa0·\\nHyrule Warriors: Age of Calamity\\nSatellaview Games\\nBS The Legend of Zelda \\xa0·\\nAncient Stone Tablets\\nTingle Series\\nFreshly-Picked Tingle\\'s Rosy Rupeeland \\xa0·\\nTingle\\'s Balloon Fight DS \\xa0·\\n'),\n\nDocument(metadata={'title': 'The Legend of Zelda: Breath of the Wild - Zelda Wiki', 'source': 'https://zeldawiki.wiki/wiki/The_Legend_of_Zelda:_Breath_of_the_Wild', 'score': 0.9627432, 'images': []}, page_content='The Legend of Zelda\\xa0•\\nThe Adventure of Link\\xa0•\\nA Link to the Past (& Four Swords)\\xa0•\\nLink\\'s Awakening (DX; Nintendo Switch)\\xa0•\\nOcarina of Time (Master Quest; 3D)\\xa0•\\nMajora\\'s Mask (3D)\\xa0•\\nOracle of Ages\\xa0•\\nOracle of Seasons\\xa0•\\nFour Swords (Anniversary Edition)\\xa0•\\nThe Wind Waker (HD)\\xa0•\\nFour Swords Adventures\\xa0•\\nThe Minish Cap\\xa0•\\nTwilight Princess (HD)\\xa0•\\nPhantom Hourglass\\xa0•\\nSpirit Tracks\\xa0•\\nSkyward Sword (HD)\\xa0•\\nA Link Between Worlds\\xa0•\\nTri Force Heroes\\xa0•\\nBreath of the Wild\\xa0•\\nTears of the Kingdom\\nZelda (Game & Watch)\\xa0•\\nThe Legend of Zelda Game Watch\\xa0•\\nHeroes of Hyrule\\xa0•\\nLink\\'s Crossbow Training\\xa0•\\nMy Nintendo Picross: Twilight Princess\\xa0•\\nCadence of Hyrule\\xa0•\\nVermin\\nThe Faces of Evil\\xa0•\\nThe Wand of Gamelon\\xa0•\\nZelda\\'s Adventure\\nHyrule Warriors (Legends; Definitive Edition)\\xa0•\\nHyrule Warriors: Age of Calamity\\nBS The Legend of Zelda\\xa0•\\nAncient Stone Tablets\\nFreshly-Picked Tingle\\'s Rosy Rupeeland\\xa0•\\nTingle\\'s Balloon Fight DS\\xa0•\\nToo Much Tingle Pack\\xa0•\\nRipened Tingle\\'s Balloon Trip of Love\\nSoulcalibur II\\xa0•\\nWarioWare Series\\xa0•\\nCaptain Rainbow\\xa0•\\nNintendo Land\\xa0•\\nScribblenauts Unlimited\\xa0•\\nMario Kart 8\\xa0•\\nSplatoon 3\\nSuper Smash Bros (Series)\\nSuper Smash Bros.\\xa0•\\nSuper Smash Bros. Melee\\xa0•\\nSuper Smash Bros. Brawl\\xa0•\\nSuper Smash Bros. for Nintendo 3DS / Wii U\\xa0•\\n It also earned a Metacritic score of 97 from more than 100 critics, placing it among the highest-rated games of all time.[60][61] Notably, the game received the most perfect review scores for any game listed on Metacritic up to that point.[62]\\nAwards\\nThroughout 2016, Breath of the Wild won several awards as a highly anticipated game, including IGN\\'s and Destructoid\\'s Best of E3,[63][64] at the Game Critic Awards 2016,[65] and at The Game Awards 2016.[66] Following its release, Breath of the Wild received the title of \"Game of the Year\" from the Japan Game Awards 2017,[67] the Golden Joystick Awards 2017,<ref\"Our final award is for the Ultimate Game of the Year. Official website(s)\\nOfficial website(s)\\nCanonicity\\nCanonicity\\nCanon[citation needed]\\nPredecessor\\nPredecessor\\nTri Force Heroes\\nSuccessor\\nSuccessor\\nTears of the Kingdom\\nThe Legend of Zelda: Breath of the Wild guide at StrategyWiki\\nBreath of the Wild Guide at Zelda Universe\\nThe Legend of Zelda: Breath of the Wild is the nineteenth main installment of The Legend of Zelda series. Listings\\nCharacters\\nBosses\\nEnemies\\nDungeons\\nLocations\\nItems\\nTranslations\\nCredits\\nReception\\nSales\\nBreath of the Wild was estimated to have sold approximately 1.3 million copies in its first three weeks and around 89% of Switch owners were estimated to have also purchased the game.[53] Sales of the game have remained strong and as of September 30, 2023, the Switch version has sold 31.15 million copies worldwide while the Wii U version has sold 1.7 million copies worldwide as of December 31, 2021,[54][55] giving Breath of the Wild a cumulative total of 32.85 million copies sold.\\n The Legend of Zelda: Breath of the Wild\\nThe Legend of Zelda: Breath of the Wild\\nThe Legend of Zelda: Breath of the Wild\\nDeveloper(s)\\nDeveloper(s)\\nPublisher(s)\\nPublisher(s)\\nNintendo\\nDesigner(s)\\nDesigner(s)\\n')]",
      "# [Boost Your RAG Performance with Tavily Search API by Minh Le Duc, medium.com on 2024-07-29](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e)\nIntroduction\n\nLLMs and RAG systems have shown to be advantageous over time. They not only provide engaging discussions that deliver helpful information, but they also open up new avenues for tailored and intelligent applications, transforming areas ranging from customer service to scientific research. Despite their unique and powerful skills, there is evidence that they can produce plausible-sounding but inaccurate information, particularly when confronted with unclear questions or a lack of relevant data. Furthermore, they have demonstrated a lack of knowledge updates, causing them to occasionally present “old” information.\n\nTo mitigate those issues, the ability to connect to reliable and up-to-date resources is essential. Using an additional tool to retrieve external knowledge can help RAG and LLMs access up-to-date information, mitigating hallucinations and enhancing factual accuracy.\n\nThe Tavily Search API is suitable for that job. It is a search engine designed specifically for LLMs and RAG, with the goal of providing efficient, rapid, and permanent search results. Tavily specializes in improving search results for AI developers and autonomous AI agents. Furthermore, Tavily uses private financial, coding, news, and other internal data sources to supplement web content. As a result, Tavily empowers developers to build more accurate, insightful, and contextually aware AI applications.\n\nIn this article, we will talk about the Tavily Search API, diving into its functionalities and how it leverages AI for enhanced search. The structure of this writing is as follows:\n\nUnderstanding the Power of Tavily Search API: A quick overview of the Tavily Search API, including why it is important and how it works.\n\nCode in Action: Start with a basic code example showcasing a simple search query using Tavily.\n\nConclusion.\n\nUnderstanding the Power of Tavily Search API\n\nTavily Search API is a specialized search engine designed to supercharge AI applications. Unlike traditional search engines, Tavily is optimized for Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) tasks. It delivers efficient, quick, and persistent search results, focusing on providing the most relevant information for AI developers and autonomous agents.\n\nTavily is a search engine built from the ground up for AI models. Tavily’s developers understand the unique challenges faced by LLMs and RAG systems, and they’ve designed Tavily to be the ultimate solution. With a focus on speed, accuracy, and relevance, Tavily delivers search results tailored to AI applications. The platform handles the heavy lifting of data collection, filtering, and extraction, empowering us to build exceptional AI models.\n\nCurrent search APIs like Google, Serp, and Bing provide irrelevant results, requiring developers to scrape sites, filter irrelevant information, and optimize content for LLM context limits, a task that requires skills. The Tavily Search API takes a smarter approach. It does the heavy lifting for us by:\n\nSifting Through the Noise: Tavily searches across 20+ sites in one go, then uses intelligent AI to pinpoint the most relevant information for our specific task or query.\n\nGiving Control: We can fine-tune our searches with custom fields like context and token limits, ensuring your AI gets the perfect data it needs.\n\nMaking Your AI Smarter: Tavily even helps our AI make better decisions by suggesting follow-up searches and providing concise answers for better communication between agents.\n\nCode in Action\n\nWe will program our experiment in Python, therefore, we need to install the Tavily’s Python SDK via command line pip install tavily-python. The package simplifies interaction with the Tavily API, allowing us to use all of their search features straight from our Python scripts.\n\nTo access the tool, we visit Tavily’s dashboard and get API key.\n\nHere is the Tavily’s dashboard. Tavily limits 1000 searches, including deleted keys.\n\nThe Tavily provides 3 simple ways of searching:\n\nsearch: performs a Tavily Search query and returns the response as a well-structured dict.\n\nget_search_context: performs a Tavily Search query and returns a str of content and sources within the provided token limit. It's useful for getting only related content from retrieved websites without having to deal with context extraction and token management.\n\nqna_search: performs a search and returns a string containing an answer to the original query. This is optimal to be used as a tool for AI agents.\n\nTogether, the code implementation will be:\n\nimport os\n\nfrom dotenv import load_dotenv\n\nfrom tavily import TavilyClient\n\nload_dotenv()\n\nTAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n\n# Step 1. Instantiating your TavilyClient\n\ntavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n\n# Step 2.1. Executing a simple search query\n\nresponse = tavily_client.search(\"Who is Leo Messi?\")\n\n# Step 2.2. Executing a context search query\n\n# answer = tavily_client.get_search_context(query=\"Who is Leo Messi?\")\n\n# Step 2.3. Executing a Q&A search query\n\n# answer = tavily_client.qna_search(query=\"Who is Leo Messi?\")\n\n# Step 3. Get the result!!!\n\nprint(result)\n\nConclusion\n\nIn our exploration of the Tavily Search API, we’ve delved into its functionalities, demystifying how it harnesses AI to enhance search. The Tavily Search API emerges as a vital tool for developers seeking to build more robust and reliable LLMs and RAG systems. By providing accurate, contextually relevant information, Tavily helps mitigate the challenges of hallucinations and outdated knowledge, paving the way for more trustworthy and insightful AI applications.\n\nAs AI continues to evolve and permeate various aspects of our lives, the need for reliable and efficient search capabilities will only increase. Tavily plays a crucial role in this evolution, allowing developers to create AI applications that are both intelligent and trustworthy. With its focus on accuracy, speed, and adaptability, Tavily Search API is a game-changer for the future of AI-powered search and information retrieval.\n\nReference",
      "# [Tavily Search MCP Agent](https://glama.ai/mcp/servers/p0w4whs3l4)\n🔍 My Tavily Search MCP Agent\n\nI've created a powerful Model Context Protocol (MCP) Server powered by the Tavily API. With this, you can get high-quality, reliable information from business, news, finance, and politics - all through a robust and developer-friendly interface.\n\n🌟 Why I Built Tavily Search MCP\n\nIn today's fast-paced digital landscape, I recognized the need for quick access to precise information. I needed a web search tool that works with my sequential thinking MCP server. That's why I developed Tavily Search MCP, which excels with:\n\n⚡️ Lightning-fast async search responses\n\n🛡️ Built-in fault tolerance with automatic retries\n\n🎯 Clean, markdown-formatted results\n\n🔍 Smart content snippets\n\n🛠️ Comprehensive error handling\n\n🖼️ Optional image results\n\n📰 Specialized news search\n\n🚀 Quick Start\n\nInstalling via Smithery\n\nTo install Tavily Search for Claude Desktop automatically via Smithery:\n\nInstalling Manually\n\nHere's how you can get up and running with my project in minutes:\n\n💡 Core Features\n\n⚡️ Performance & Reliability\n\nI've implemented asynchronous request handling\n\nBuilt-in error handling and automatic retries\n\nConfigurable request timeouts\n\nComprehensive logging system\n\n🎯 Search Configuration\n\nI've made the search depth configurable (basic/advanced)\n\nAdjustable result limits (1-20 results)\n\nClean markdown-formatted output\n\nSnippet previews with source URLs\n\nOptional image results\n\nSpecialized news search topic\n\n🛡️ Error Handling\n\nAPI authentication validation\n\nRate limit detection\n\nNetwork error recovery\n\nRequest timeout management\n\n🛠️ Developer Integration\n\nPrerequisites\n\nPython 3.11 or higher\n\nUV Package Manager (Installation Guide)\n\nTavily API key (Get one here)\n\nClaude Desktop Setup\n\nI've optimized the Claude Desktop experience with this configuration:\n\n📁 Configuration paths:\n\nWindows: %APPDATA%\\Claude\\claude_desktop_config.json\n\nUnix/MacOS: ~/.config/Claude/claude_desktop_config.json\n\nProject Architecture\n\nI've designed a clean, modular structure to make development a breeze:\n\nKey Components\n\nServer (server.py)\n\nI've implemented the MCP protocol\n\nRequest handling and routing\n\nError recovery and health monitoring\n\nClient (client.py)\n\nTavily API integration\n\nRetry mechanism with exponential backoff\n\nResult formatting and processing\n\nError handling and logging\n\nTests (test_server.py and test_client.py)\n\nComprehensive unit tests for both server and client\n\nEnsures reliability and correctness of the implementation\n\nUsage Examples\n\nHere are some examples of how to use the enhanced search capabilities I've implemented:\n\nBasic search:\n\nAdvanced search with images:\n\nNews-specific search:\n\nSearch with raw content:\n\nTroubleshooting Guide\n\nConnection Issues\n\nIf things don't work as expected, follow these steps I've outlined:\n\nVerify your configuration paths\n\nCheck the Claude Desktop logs:\n\n# Windows type %APPDATA%\\Claude\\logs\\latest.log # Unix/MacOS cat ~/.config/Claude/logs/latest.log\n\nTest the server manually using the quick start commands\n\nAPI Troubleshooting\n\nIf you're experiencing API issues:\n\nValidate your API key permissions\n\nCheck your network connection\n\nMonitor the API response in the server logs\n\nRunning Tests\n\nTo run the unit tests for this project, follow these steps:\n\nInstall the development dependencies:\n\nuv pip install -e \".[dev]\"\n\nRun the tests using pytest:\n\npytest mcp_tavily_search\n\nThis will run all the tests in the mcp_tavily_search directory, including both test_client.py and test_server.py.\n\nCommunity and Support\n\nI encourage you to report issues and contribute on GitHub\n\nShare your implementations and improvements\n\nJoin our discussions and help others\n\nSecurity and Best Practices\n\nSecurity is paramount in my implementation. The server includes:\n\nSecure API key handling through environment variables\n\nAutomatic request timeout management\n\nComprehensive error tracking and logging\n\nLicense\n\nI've licensed this project under MIT. See the LICENSE file for details.\n\nAcknowledgments\n\nI'd like to give special thanks to:",
      "# [AI Agents in LangGraph on 2024-06-02](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/)\nLangChain, a popular open source framework for building LLM applications, recently introduced LangGraph. This extension allows developers to create highly controllable agents.\n\nIn this course you will learn to build an agent from scratch using Python and an LLM, and then you will rebuild it using LangGraph, learning about its components and how to combine them to build flow-based applications.\n\nAdditionally, you will learn about agentic search, which returns multiple answers in an agent-friendly format, enhancing the agent’s built-in knowledge. This course will show you how to use agentic search in your applications to provide better data for agents to enhance their output.\n\nIn detail:\n\nBuild an agent from scratch, and understand the division of tasks between the LLM and the code around the LLM.\n\nImplement the agent you built using LangGraph.\n\nLearn how agentic search retrieves multiple answers in a predictable format, unlike traditional search engines that return links.\n\nImplement persistence in agents, enabling state management across multiple threads, conversation switching, and the ability to reload previous states.\n\nIncorporate human-in-the-loop into agent systems.\n\nDevelop an agent for essay writing, replicating the workflow of a researcher working on this task.\n\nStart building more controllable agents using LangGraph!",
      "# [Context is King — Evaluating real-time LLM context quality with Ragas by Emergent Methods, emergentmethods.medium.com on 2024-06-10](https://emergentmethods.medium.com/context-is-king-evaluating-real-time-llm-context-quality-with-ragas-a8df8e815dc9)\nResults — Context Precision💎\n\nTable 1 shows that the ground truth answer is more often contained in the documents for AskNews, compared to JinaAI and Tavily. This is highlighted by the 78% improvement in performance for AskNews compared to JinaAI.\n\nResults — Context Quality 👑\n\nWe take a closer look at how the context is retrieved from each service, and what impact that has on the LLM trying to use the context to answer the question.\n\n1. “What was the score of the Yankees game?” — Latest News 🗞\n\nAskNews\n\nThe context from AskNews includes a broad range of details, including published date, source, sentiment, entity extractions, and full summaries.\n\nContext from AskNews (truncated, see Google colab for full output):\n\n<doc>\n\n[1]:\n\nTitle: Yankees 10-1 Royals (12 Jun, 2024) Final Score\n\nSummary: Aaron Judge hit his 25th home run of the season, a 436-foot, two-run drive into the fountain behind the center-field seats, as the New York Yankees defeated the Kansas City Royals 10-1 on Tuesday night, securing their 11th win in 14 games.\n\nSource: ESPN\n\nPublished: June 12 2024 03:46\n\nPerson: Aaron Judge\n\nNumber: 14, 11th, 25th\n\nQuantity: 10-1, two-run, 436-foot\n\nLocation: center-field\n\nSports: New York Yankees, Kansas City Royals\n\nDate: Tuesday\n\nClassification: Sports\n\nSentiment: 1\n\nReporting voice: Objective\n\n</doc>\n\n<doc>\n\n[2]:\n\nTitle: Yankees vs Royals final score, results: New York wins third straight in 10-1 rout\n\nSummary: The New York Yankees defeated the Kansas City Royals 10-1, winning their third straight game. The Yankees' offense was led by Aaron Judge and Giancarlo Stanton, who both hit home runs, and Austin Wells, who hit a three-run homer. Marcus Stroman pitched 5.2 innings, allowing no runs and lowering his season ERA to 2.82. The Yankees have now won seven straight games away from Yankee Stadium and have a 26-11 record on the road, the best in MLB.\n\nSource: The Sporting News\n\nPublished: June 12 2024 02:55\n\nSports: MLB, New York Yankees, Yankees, Kansas City Royals\n\nQuantity: 10-1, 5.2 innings, 26-11, 2.82\n\nPerson: Marcus Stroman, Austin Wells\n\nLocation: Yankee Stadium\n\nClassification: Sports\n\nSentiment: 1\n\nReporting voice: Objective\n\n</doc>\n\n<doc>\n\n[3]:\n\nTitle: Yankees Launch Three Home Runs In 10-1 Rout Of Royals\n\nSummary: The Yankees defeated the Royals 10-1 on Tuesday night, with three home runs from Judge, Stanton, and Wells. The team scored four runs in the fourth inning, capped off by Wells' three-run shot. Judge and Stanton added home runs in the seventh, and the Yankees' pitching staff was led by Stroman, who pitched 5.2 scoreless innings. Marinaccio made his return to the team and pitched 2.1 innings, striking out three and allowing one walk. The Yankees will continue their four-game series with the Royals on Wednesday night.\n\nSource: WhatsNew2day\n\nPublished: June 12 2024 02:48\n\nSports: Yankees, Royals\n\nQuantity: 10-1, one walk, 2.1 innings, 5.2\n\nDate: Tuesday, Wednesday\n\nPerson: Stroman, Stanton, Wells, Judge, Marinaccio\n\nTime: fourth inning, seventh\n\nNumber: three\n\nClassification: Sports\n\nSentiment: 1\n\nReporting voice: Objective\n\n</doc>\n\n<doc>\n\n[4]:\n\nTitle: Yankees launch three home runs in 10-1 rout of Royals\n\nSummary: The New York Yankees defeated the Kansas City Royals 10-1 on Tuesday night, with a strong performance from their offense and pitching. The Yankees used the long ball to score runs, with Austin Wells hitting a three-run homer and Aaron Judge and Giancarlo Stanton adding solo shots. Marcus Stroman pitched 5.2 scoreless innings, and Ron Marinaccio earned the win in relief. Anthony Rizzo returned to the lineup after missing two games and had a solid game, making a great catch and reaching base on an error. Marinaccio was named the game MVP.\n\nSource: Yahoo\n\nPublished: June 12 2024 02:48\n\nSports: Yankees, Kansas City Royals, New York Yankees\n\nQuantity: 5.2, 10-1\n\nDate: Tuesday\n\nPerson: Ron Marinaccio, Giancarlo Stanton, Austin Wells, Marcus Stroman, Anthony Rizzo\n\nTitle: MVP\n\nClassification: Sports\n\nSentiment: 1\n\nReporting voice: Objective\n\n</doc>\n\n<doc>\n\n[5]:\n\nTitle: Yankees beat the Kansas City Royals 4-2 at Monday's night game\n\nSummary: The New York Yankees' Juan Soto returned to the lineup after missing a three-game series against the Los Angeles Dodgers due to left forearm inflammation. Soto went 1 for 3 with a walk as the designated hitter in a 4-2 win over the Kansas City Royals. He is batting .318 with 17 home runs, 53 RBIs, and a 1.024 OPS. Manager Aaron Boone said the team is easing Soto back into the outfield and wants to make sure he is fully healthy before returning to the field. The Yankees also gave Aaron Judge a night off, and Anthony Rizzo was left out of the lineup for a second straight game. Boone said the team is providing Rizzo with a mental break and time to work on his hitting mechanics.\n\nSource: NBC New York\n\nPublished: June 11 2024 18:59\n\nSports: Los Angeles Dodgers, New York Yankees, Kansas City Royals, Yankees\n\nMedicine: left forearm inflammation\n\nQuantity: .318, 53 RBIs, 1.024 OPS, 1 for 3, 4-2, 17 home runs\n\nTitle: Manager\n\nPerson: Aaron Boone, Aaron Judge, Boone\n\nClassification: Sports\n\nSentiment: 1\n\nReporting voice: Objective\n\n</doc>\n\nThis contains sufficient information for the LLM to answer the question.\n\nLLM Response using AskNews context (answer_correctness: 0.53):\n\nThe score of the Yankees game was 10–1.\n\nJinaAI\n\nThe context from JinAI contains a broad range of historical Yankees games, but none of them are the latest Dodgers games. The documents have no publication date, making it even more difficult for the LLM to answer a time-sensitive question.\n\nContext from JinaAI:\n\n<doc>\n\n[1]\n\nYankees Game Recaps - Pinstripe Alley\n\nA franchise rookie record 14 strikeouts ... quartet of Juan Soto hits led <strong>the</strong> <strong>Yankees</strong> to another win. ... Aaron Judge stayed hot, Giancarlo Stanton continued his excellent season, and <strong>the</strong> <strong>Yankees</strong> kept up their winning ways. ... Clarke Schmidt worked eight innings for the first time in his career to complete the sweep. ... A four-hit <strong>game</strong> for <strong>the</strong> <strong>Yankee</strong> captain and a scoreless Stroman outing ...\n\n</doc>\n\n<doc>\n\n[2]\n\nYankees Scores: Scoreboard, Results and Highlights | New York Yankees\n\nThe official scoreboard of the New York <strong>Yankees</strong> including Gameday, video, highlights and box <strong>score</strong>.\n\n</doc>\n\n<doc>\n\n[3]\n\nMLB Scores: Scoreboard, Results and Highlights | MLB.com\n\nGet up-to-date MLB <strong>scores</strong> from today’s <strong>games</strong>, as well as <strong>scores</strong> from all the 2023 MLB season <strong>games</strong>.\n\n</doc>\n\n<doc>\n\n[4]\n\nNew York Yankees score, schedule & standings\n\nWhen the match starts, you will be able to follow New York Yankees vs Los Angeles Dodgers scores, updated live as the match progress. Statistics are updated at the end of the game. New York Yankees previous match was against Minnesota Twins in MLB, match ended with result <strong>9 - 5</strong> (New York Yankees ...\n\n</doc>\n\n<doc>\n\n[5]\n\nNew York Yankees | News & Stats | Baseball\n\nTrending News &amp; Rumors for Football, Basketball, Baseball, Hockey, Soccer &amp; More\n\n</doc>\n\nThis results in an LLM that is unable to provide the score. We should also note that on many queries to Jina, we received empty responses and had to run a retry.\n\nLLM response using JinaAI context (answer_correctness: 0.21):\n\nBased on the given documents, the score of the Yankees game is not explicitly mentioned.\n\nTavily\n\nThe context from Tavily also contains a broad range of historical Yankees games. One of the documents says something about the Dodgers, but is not relevant to the most recent game. The documents have no publication date, making it even more difficult for the LLM to answer a time-sensitive question.\n\nContext from Tavily:\n\n<doc>\n\n[1]\n\nNew York Yankees Scores, Stats and Highlights - ESPN\n\nVisit ESPN for New York Yankees live scores, video highlights, and latest news. Find standings and the full 2024 season schedule. ... and the New York Yankees finished a three-game sweep with a 5 ...\n\n</doc>\n\n<doc>\n\n[2]\n\nAstros vs. Yankees final score, results: Houston sweeps New York for ...\n\nAstros vs. Yankees live updates, highlights from ALCS Game 4 (All times Eastern) 12:08 p.m. -- After taking a ball, Judge grounds out to Pressly to end it.The Yankees win their second straight AL ...\n\n</doc>\n\n<doc>\n\n[3]\n\nOfficial New York Yankees Website | MLB.com\n\npic.twitter.com/FAUuxi36qC\n\nFormer Yankees manager Joe Torre dons the uniform again and walks out to the mound to take Carlos Rodón out of the game\n\nCarlos Rodón speaks on the moment that iconic Yankees manager Joe Torre walked to the mound to pull him from the game\n\nOswaldo Cabrera clubs a long home run to right field to give the Yankees a 1-0 lead in the 3rd\n\nCarlos Rodón strikes out five over 5 2/3 no-hit innings and gets congratulated by Hall of Fame manager Joe Torre in his spring start against the Phillies\n\nAaron Boone discusses Aaron Judge preparing to return from an abdominal injury, saying he should be back in the lineup on Wednesday\n\nThe data behind Oswaldo Cabrera's home run\n\nThe data behind Carlos Rodón's outing\n\nPregame in Paradise 🌴 pic.twitter.com/HKSQ0BYRaT\n\nSpencer Jones, Addison Barger and more take the field as the top prospects from the Blue Jays and the Yankees face off at Spring Breakout\n\nClayton Beeter strikes out two across four innings in his Spring Training outing against the Red Sox\n\nWill Warren strikes out five across 2 2/3 innings in his Spring Training outing against the Red Sox Related\n\nHall of Fame manager Joe Torre leads a roster of guest instructors that includes Yankee legends Ron Guidry, Andy Pettitte and CC Sabathia, Bryan Hoch writes in his Yankees Beat newsletter.\n\nAfter pitching 5 2/3 no-hit innings, Carlos Rodón was taken out by legendary Yankees manager Joe Torre.\n\nWatch on MLB.TV or listen on At Bat: Aaron Judge is back in the lineup tonight vs. Pittsburgh.\n\n</doc>\n\n<doc>\n\n[4]\n\nYankees Scores: Scoreboard, Results and Highlights\n\nThe official scoreboard of the New York Yankees including Gameday, video, highlights and box score. Tickets. Individual Game Tickets Promotions ... Yankees Game Recaps Yankees Cut4 Yankees Manager Postgame Yankees Reviews Yankees HOPE Week Yankees Curtain Calls Most Popular Yankees Productions Yankees Podcasts MLB Network.\n\n</doc>\n\n<doc>\n\n[5]\n\nYankees vs Dodgers final score, results: New York limps to 2-1 loss in ...\n\n06-07-2024 • 10 min read. Getty Images. The New York Yankees and Los Angeles Dodgers put on quite the show Friday night in the Bronx, resulting in the latter snapping New York's eight-game ...\n\n</doc>\n\nThe LLM is unable to answer.\n\nLLM response with Tavily context (answer_correctness: 0.30):\n\nBased on the provided documents, the score of the Yankees game is not explicitly mentioned.\n\nExa\n\nThe context from Exa seems to be updated on the latest Orioles Yankees gam, but it does not contain the score, so the LLM cannot answer.\n\nContext from Exa:\n\n<doc>\n\n[1]\n\nTitle:Orioles vs. Yankees - MLB Game Summary - June 11, 2017 | ESPN\n\nHighlights:3 5 4th Holliday singled to shallow center, Hicks and Judge scored. 3 7 6th Judge homered to left center (496 feet). 3 8 6th Castro homered to left (392 feet), Holliday scored. 3 10 7th Hicks doubled to deep right center, Torreyes and Gardner scored. 3 12 7th Judge homered to right center (401 feet), Hicks scored.\n\nPublished:2017-06-11\n\n</doc>\n\n<doc>\n\n[2]\n\nTitle:Mets vs. Yankees - MLB Box Score - June 11, 2019 | ESPN\n\nHighlights:Mets Hitting Batting 2BRosario (11, Tarpley); McNeil (15, Paxton) HRGómez (3, 5th inning off Adams 0 on, 2 Out); Davis (7, 4th inning off Adams 1 on, 0 Out); Alonso (22, 1st inning off Paxton 2 on, 0 Out) RBIGómez (9), Ramos (35), Hechavarria (14), Rosario (35), Conforto (30), Davis 2 (20), Alonso 3 (49) 2Out RBIGómez, Hechavarria, Rosario GIDPRamos Team LOB7 Team RISP6-10 (Davis 1-1, Hechavarria 1-2, Gómez 0-1, Alonso 1-1, Conforto 1-1, Rosario 1-2, Ramos 1-2) Yankees Hitting Batting HRGardner (10, 9th inning off Gagnon 0 on, 0 Out) RBIGardner (25), Urshela (30), Frazier (33), Torres (33) Team LOB8 Team RISP2-8 (Torres 1-1, Sánchez 1-2, Voit 0-1, Frazier 0-3, Urshela 0-1) Fielding DP1 (Urshela-LeMahieu-Voit) EUrshela (9, pop up) Mets Pitching Pitching First-pitch strikes/Batters FacedVargas 16/27; Familia 3/5; Lugo 2/3; Gagnon 1/4 Called strikes-Swinging strikes-Foul balls-In play strikesVargas-12-9-17-22; Familia-4-3-0-2; Lugo-4-4-2-0; Gagnon-4-2-1-3 Ground Balls-Fly BallsVargas 6-9; Familia 1-0; Gagnon 2-1 Game ScoresJ Vargas 47 Yankees Pitching Pitching HBPFrazier (by Tarpley) First-pitch strikes/Batters FacedPaxton 8/17; Tarpley 3/5; Cessa 1/3; Adams 10/19 Called strikes-Swinging strikes-Foul balls-In play strikesPaxton-9-3-13-14; Tarpley-1-3-7-2; Cessa-1-2-6-3; Adams-8-5-25-13 Ground Balls-Fly BallsPaxton 3-4; Tarpley 1-0; Cessa 3-0; Adams 4-6 Game ScoresJ Paxton 19\n\nPublished:2019-06-11\n\n</doc>\n\n<doc>\n\n[3]\n\nTitle:Didi, arms lead Yanks to victory | 06/12/2018\n\nHighlights:© 2023 MLB Advanced Media, LP. All rights reserved.\n\nPublished:2018-06-12\n\n</doc>\n\n<doc>\n\n[4]\n\nTitle:Aaron Judge Stats, Fantasy & News\n\nHighlights:100 in 2019 (Gardner, Gregorius, Sánchez)..is the seventh player drafted and signed by the Yankees to hit at least 100HR with the club (Gardner, Posada, Jeter, Mattingly, Munson and Pagliarulo)...Hit a game-tying solo HR with two outs in the eighth inning on 8/31 vs. Oakland..was his seventh career HR to tie the game or give the Yankees the lead in the eighth inning or later and third of the season (also a go-ahead solo HR in the top of the 11th inning on 7/5 at Tampa Bay and a go-ahead two-run HR in the bottom of the eighth on 7/16 vs. Tampa Bay)...Reached base four times in Game 1 of 9/12 doubleheader at Detroit, scoring a career-high-tying 4R and recording a season-high-tying 3BB..hit a two-run HR in Game 2...Started in RF in each of the Yankees' nine postseason games..hit a two-run HR in the fourth inning of ALCS Game 2 at Houston..marked his eighth career postseason HR (in his 23rd career playoff game), becoming the fourth Yankee to hit 8HR within his first 23 postseason games (also Lou Gehrig-9HR, Mickey Mantle-8HR and Bernie Williams-8HR). In 112 games with the Yankees (88 starts in RF, 19 at DH, 1 in CF), hit .278 (115-for-413) with 77R, 22 doubles, 27HR, 67RBI, 76BB and 6SB…the Yankees went 21-6 when he homered in 2018...Was a finalist for the AL Gold Glove Award in RF...Hit .352/.471/.699 (69-for-196) with 47R, 14 doubles, 18HR, 45RBI and 20 multi-hit games in 56 contests at Yankee Stadium…did not go consecutive home games without a hit over a 59-game stretch at Yankee Stadium (9/17/17-7/26/18)…hit safely in 17 consecutive home games from 9/17/17-4/16/18…had at least 1RBI in a franchise-record 14 straight home games from 9/18/17-4/7/18…was tied for the fourth-longest such streak in the Majors since RBI became an official statistic in 1920...Appeared in each of the Yankees' first 56 games of the season (3/29-6/4 G2)...Hit 25HR before the All-Star break, becoming the fourth player to hit at least 25HR before the break in two different seasons as a Yankee and just the second to do so in consecutive years, joining Roger Maris (1960-61), Mickey Mantle (1956 and '61) and Jason Giambi (2003 and '06)...Had a career-long 14-game hitting streak from 9/17/17-3/29/18…had an eight-game streak of drawing at least one walk from 9/24/17-3/29/18, matching the longest streak of his career...Made his first Major League start (and appearance) in CF in 3/31 loss at Toronto...Reached base safely in 23 of his 25 games in April (all except 4/27 and 4/29 at Los Angeles-AL), including each of his first 21 games of the month...Was 3-for-3 with an HR off Red Sox starter Chris Sale on 4/10…entered 0-for-12 with 10K in his career vs. Sale…became the first player to record 3H off Sale in one game since he joined the Red Sox before the 2017 season…prior to Judge, the last player with a three-hit game vs. Sale was Detroit's Miguel Cabrera, who went 4-for-4 with two solo HRs against Sale on 9/5/16 at Chicago-AL...Celebrated his 26th birthday on 4/26…his 63 career homers prior to turning 26 rank 13th in franchise history and are fifth-most in the last 50 years (Mattingly-94, Murcer-77, Jeter-70, Sánchez-71)...Had at least 1RBI in seven straight games from 5/6-13 (14RBI), tying the longest RBI streak of his career (also 7G: 9/24-30/17)...Hit game-winning two-run HR in the 13th on 6/6 at Toronto…was his first career extra-inning HR and was the latest Yankees HR to break a 0-0 tie since Alex Rodriguez's 15th-inning two-run \"walk-off\" HR on 8/7/09 vs. Boston...Hit game-winning solo HR in the eighth inning on 6/9 at the Mets…was the third straight game the Yankees hit a go-ahead HR in the eighth-inning-or-later, their first time doing so since 8/29-31/77 (three straight - Chambliss, Rivers and Nettles)…Judge hit two of those homers after having just one go-ahead HR in the eighth-inning or-later over his first 239 career games...Started in LF and went 1-for-2 with 1R, 1HR, 1RBI and 1BB in the AL's All-Star Game win on 7/17…his solo HR off Scherzer to lead off the second inning was the first of 10HR hit in the game and the first All-Star homer by a Yankee since Jason Giambi in 2003…became the third Yankee to homer in an All-Star Game at age 26-or-younger, joining Joe DiMaggio (1936) and Mickey Mantle (1955 and '56)…was selected by fans to his second straight AllStar team…is one of five position players drafted by the Yankees to make the All-Star team multiple times as a Yankee (also Thurman Munson, Don Mattingly, Derek Jeter and Jorge Posada)…received a fan-elected starting assignment for the second straight year and is the first Yankee to start at least two straight ASGs since Robinson Canó (2010-13) and first Yankees OF to start two straight since Curtis Granderson (2011-12)...Was 1-for-1 with 1R in 7/26 win vs. Kansas City before being removed from the game in the fourth for PH (Andújar) after being hit by a pitch in the first inning…underwent an MRI at NewYork-Presbyterian Hospital and was diagnosed with a chip fracture of the right wrist (ulnar styloid bone)…was placed on the 10-day disabled list with the injury from 7/27-9/14 (missed 45 team games)…in a simulated game at Yankee Stadium on 9/17, had 11 live at-bats off of RHP A.J. Cole, RHP Chance Adams and minor-league LHP Phillip Diehl...Hit the Yankees' 264th home run of the season with a solo HR in the eighth inning of 9/28 win at Boston, tying the single-season Major League record (1997 Seattle Mariners)…was his first HR since 7/21 vs. the Mets, snapping a 15-game homerless stretch (49AB) and 11-game stretch without a homer since returning from the D.L...Hit .421/.500/.947 (8-for-19) with 6R, 1 double, 3HR, 4RBI and 3BB in five postseason games…homered in each of the first 3G, joining Hank Bauer (1958 World Series Games 1-3) as the only Yankees to homer in each of the team's first three postseason games in a year (note: Johnny Mize homered in 1952 World Series Games 3-5 after missing the first 2G of the Series)…became the third player to begin a postseason with 3G with at least 2H and 1HR, joining St. Louis' Matt Carpenter in 2014 and the Yankees' Hank Bauer in 1958...Hit a two-run HR in the first inning of the Wild Card Game…with an exit velocity of 116.1 mph, was briefly the hardest-hit postseason HR of the Statcast era (since 2015), until Stanton's HR surpassed it later in the game...Set a postseason career high in hits in ALDS Game 1 at Boston, going 3-for-5 with a ninth-inning solo HR. In 155 games with the Yankees (141 starts in RF, 10 at DH), hit .284 (154-for-542) with 128R, 24 doubles, 3 triples, 52HR, 114RBI, 127BB and 9SB... according to MLB Statcast, had a 94.9 mph average exit velocity on balls in play, highest among all Major League hitters…his solo HR on 6/10 vs. Baltimore had an exit velocity of 121.1 mph, setting a record for hardest hit HR in the Statcast-era (since 2015)…received his ﬁrst career Silver Slugger Award... Placed second in AL Most Valuable Player voting, totaling 279 points (2 ﬁrst place votes, 27 second place votes, 1 third place vote)…is the second rookie all time to ﬁnish second in MVP voting, joining Mike Trout in 2012 (won by Miguel Cabrera)…only two rookies (in either league) have won the award: Boston's Fred Lynn in 1975 and Seattle's Ichiro Suzuki in 2001 both won the AL MVP as rookies... Was unanimously named AL Jackie Robinson \"Rookie of the Year\" by the BBWAA…was the ninth Yankee to win the award and second by a unanimous vote (also Derek Jeter in 1996)…was the only player listed on every ballot... Was named MLB \"Rookie of the Year\" by Baseball America, the ﬁrst Yankee to win the award since Derek Jeter (1996)…was also named 2017 Sporting News AL \"Rookie of the Year,\" as voted on by a panel of AL players…was selected to the Topps MLB All-Star Rookie Team... Led the American League in runs scored (128, 2nd MLB), home runs (52, 2nd MLB), walks (127, 2nd MLB) and and ranked second in RBI (114, 6th MLB), on-base pct.\n\nPublished:2023-02-26\n\n</doc>\n\n<doc>\n\n[5]\n\nTitle:Sports\n\nHighlights:Any commercial use or distribution without the express written consent of STATS PERFORM is strictly prohibited.\n\nPublished:2021-10-26\n\n</doc>\n\nLLM response with Exa context (answer_correctness: 0.20):\n\nBased on the provided documents, there is no specific information about the score of a Yankees game on June 12, 2024.\n\n2. “Who won the SuperBowl?” — General Web 📚\n\nAskNews\n\nAskNews context is filled with contextual details to help the LLM understand time and entities throughout.\n\nContext from AskNews:\n\n<doc>\n\n[1]:\n\nTitle: Biden receives Super Bowl winner Kansas City\n\nSummary: US President Joe Biden received the Kansas City Chiefs, the winners of the Super Bowl, at the White House. The team's star player, Travis Kelce, was also present, who has been making headlines for his relationship with pop star Taylor Swift. The Chiefs have won three Super Bowls in the last five years and are aiming for a fourth title next season, which would be a historic achievement in the NFL. Chiefs boss Clark Hunt expressed his enthusiasm for the visit and the challenge of making it an annual occurrence.\n\nSource: Kronen Zeitung\n\nPublished: June 01 2024 06:55\n\nTitle: US President\n\nPerson: Joe Biden, Taylor Swift, Clark Hunt\n\nSports: NFL, Kansas City Chiefs, Chiefs\n\nEvent: Super Bowls, Super Bowl\n\nTime: five years\n\nClassification: Sports\n\nSentiment: 1\n\nReporting voice: Objective\n\n</doc>\n\n<doc>\n\n[2]:\n\nTitle: Biden is hosting the Kansas City Chiefs – minus Taylor Swift – to mark the team's Super Bowl title\n\nSummary: President Joe Biden is hosting the Kansas City Chiefs at the White House to celebrate their third Super Bowl victory in five years. The team will be attending the event on the South Lawn, but Taylor Swift, the girlfriend of tight end Travis Kelce, will not be present. The Chiefs won the Super Bowl in February with a come-from-behind overtime win over the San Francisco 49ers. This is a tradition for major championship sports teams to be invited to the White House. Kicker Harrison Butker, who made headlines for criticizing some of Biden's policies, will also be attending the event.\n\nSource: Yahoo\n\nPublished: May 31 2024 17:41\n\nTitle: President\n\nPerson: Biden, Joe Biden, Travis Kelce, Taylor Swift, Harrison Butker\n\nSports: Kansas City Chiefs, Chiefs, San Francisco 49ers\n\nEvent: Super Bowl\n\nTime: five years\n\nLocation: South Lawn\n\nDate: February\n\nClassification: Politics\n\nSentiment: 1\n\nReporting voice: Objective\n\n</doc>\n\n<doc>\n\n[3]:\n\nTitle: Tom Brady: Chiefs face 'big challenge' in attempt to win third consecutive Super Bowl\n\nSummary: Tom Brady, the most accomplished player in American football history, believes that winning three consecutive Super Bowls is a significant challenge. The Kansas City Chiefs are currently favored to win this year's Super Bowl and would become the first team in 20 years to win three consecutive championships if they succeed. Brady acknowledges the Chiefs' talent, coaching, and continuity, but also notes the variables that come into play, including luck and health. He believes that winning three in a row is nearly impossible, citing the difficulty of winning one Super Bowl in the first place.\n\nSource: MSN\n\nPublished: May 28 2024 15:26\n\nPerson: Brady, Tom Brady\n\nNationality: American\n\nEvent: Super Bowls, health, Super Bowl\n\nSports: Kansas City Chiefs\n\nTime: 20 years\n\nClassification: Sports\n\nSentiment: 0\n\nReporting voice: Objective\n\n</doc>\n\n<doc>\n\n[4]:\n\nTitle: Which NFL teams have never won a Super Bowl in their team's history?\n\nSummary: There are 12 NFL teams that have never won a Super Bowl. The article discusses the chances of these teams winning the Super Bowl in the 2024 season. The Minnesota Vikings are rebuilding their quarterback room and may not be thinking Super Bowl this year, but could have a window open in 2025. The Buffalo Bills may not even win the AFC East this year due to the loss of an elite wide receiver and potential regression of their offense. The Cincinnati Bengals, who appeared in the Super Bowl three years ago, are a strong contender with a healthy Joe Burrow, but their quarterback's injury issues are a concern. The article concludes that only the Bengals have a good chance of winning the Super Bowl in 2024.\n\nSource: NFL Spin Zone\n\nPublished: May 25 2024 20:00\n\nNumber: 12\n\nSports: Cincinnati Bengals, Buffalo Bills, Minnesota Vikings, NFL\n\nEvent: Super Bowl\n\nDate: 2025, 2024\n\nLocation: AFC East\n\nPerson: Joe Burrow\n\nClassification: Sports\n\nSentiment: 0\n\nReporting voice: Conversational\n\n</doc>\n\n<doc>\n\n[5]:\n\ntitle: Patrick Mahomes insists Chiefs WILL seal historic Super Bowl three-peat... as he reveals the truth behind this year's game-winning touchdown\n\nsummary: Kansas City Chiefs quarterback Patrick Mahomes believes his team will win the Super Bowl again next year, which would be the first three-peat in the Super Bowl era. Mahomes and the Chiefs won their second consecutive championship earlier this year, and he revealed that the game-winning touchdown to Mecole Hardman in overtime was not the original plan. The intended target was Jerick McKinnon, but Mahomes saw Hardman open and threw the ball to him instead. Mahomes has pledged to run the same play, called 'corndog', for a touchdown in a third straight Super Bowl. However, with Hardman being a free agent and Kadarius Toney falling out of favor, it's unclear who will be the targeted receiver for the play.\n\nsource: Daily Mail\n\npublished: May 02 2024 23:59\n\nOrganization: Kansas City Chiefs, Chiefs\n\nPerson: Patrick Mahomes, Mecole Hardman, Hardman, Kadarius Toney, Jerick McKinnon\n\nEvent: Super Bowl\n\nDate: next year, this year\n\nTime: overtime\n\nclassification: Sports\n\nsentiment: 1\n\n</doc>\n\nLLM output using AskNews context (answer_correctness: 0.996):\n\nThe Kansas City Chiefs won the Super Bowl this year.\n\nJinaAI\n\nThe context has a range of different superbowls discussed, and again, no publication dates to help the LLM ground itself in the time-sensitive question.\n\nContext from JinaAI:\n\n<doc>\n\n[1]\n\nList of Super Bowl champions\n\nThe Cowboys won Super Bowl XXX the following year for three titles in four seasons, and thus were two wins away from four consecutive Super Bowl titles. The <strong>New England Patriots</strong> won Super Bowls XLIX, LI, and LIII for three titles in five seasons. They also appeared in and lost Super Bowl LII ...\n\n</doc>\n\n<doc>\n\n[2]\n\nSuper Bowl Winners and Results\n\nThe <strong>Pittsburgh Steelers and New England Patriots</strong> are tied at 6 Super Bowl victories each. They are followed by the Dallas Cowboys and San Francisco 49ers at 5 wins each. A total of 12 NFL teams have never won the Super Bowl. This list includes: Cleveland Browns, Detroit Lions, Houston Texans, ...\n\n</doc>\n\n<doc>\n\n[3]\n\nWho Played in (and Who Won!) the Last 10 Super Bowls\n\nHere, see how it shook out, and look back on the previous 10 winners of the Super Bowl. ... Travis Kelce. ... Back-to-back, baby! The <strong>Kansas City Chiefs</strong> won their second consecutive Super Bowl on Feb. 11, 2024, after overtaking the San Francisco 49ers in overtime with a score of 25-22 at Allegiant ...\n\n</doc>\n\n<doc>\n\n[4]\n\nSuper Bowl Winners List - Full NFL winners list from 1967 to 2024 - MARCA in English\n\nCheck the updated ranking of all the winners, runners-up, MVP and scores of <strong>the</strong> <strong>Super</strong> <strong>Bowl</strong> winners <strong>year</strong> <strong>by</strong> <strong>year</strong> since the beginning in 1967.\n\n</doc>\n\n<doc>\n\n[5]\n\nSuper Bowl LVI\n\nThe <strong>Los Angeles Rams</strong> finished the 2021 season with a 12–5 record under fifth-year head coach Sean McVay. This was their fifth Super Bowl appearance, third as a Los Angeles–based team, and second under McVay. The franchise held a 1–3 Super Bowl record prior to the game, winning Super Bowl ...\n\n</doc>\n\nThe response from JinaAI does not contain sufficient context to answer the question.\n\nLLM response with JinaAI context (answer_correctness: 0.20):\n\nBased on the given documents, it is not possible to determine who won the Super Bowl this year.\n\nTavily\n\nThe context from Tavily appears to be a poorly scraped webpage, filled with different historical superbowls.\n\nContext from Tavily:\n\n<doc>\n\n[1]\n\nKansas City Chiefs win Super Bowl LVIII: Patrick Mahomes throws game ...\n\nPatrick Mahomes leads the Kansas City Chiefs to a 25-22 victory over the San Francisco 49ers to become Super Bowl champions for the third time in five seasons; Mahomes named Super Bowl MVP for the ...\n\n</doc>\n\n<doc>\n\n[2]\n\nKansas City Chiefs win Super Bowl for second year in a row - NBC News\n\nMinutes later, Mahomes' 3-yard touchdown pass to Mecole Hardman ended in a 25-22 Kansas City victory. Sunday's win had a similar vibe to the 2020 Super Bowl when the Chiefs staged a dramatic ...\n\n</doc>\n\n<doc>\n\n[3]\n\n2021 Super Bowl score: Tom Brady wins seventh ring as Buccaneers ...\n\nWhile the field goal was a disappointing result, it did cut the deficit to 14-6, and with the Chiefs getting the ball in the second half, they seemed to be in a good position.\n\nThe frustrations were notable on both sides of the ball for KC, which committed 10 penalties for 100 yards in the game with many miscues coming in key situations that cost the Chiefs on the scoreboard.\n\nJust as the Packers' offensive line was dominated by the Bucs' front in the NFC Championship Game, so too was the Chiefs' offensive line in the Super Bowl.\n\nSorry!\n\nBreech's picks: 2 thrillers decide who'll be in SB LVIII\n\n15 wild facts to know about the title games\n\nTitle games preview: Odds, picks and more\n\nNew Chiefs wrinkle that turned 'O' around\n\nPlayoff schedule: Dates, times, TV\n\nRaiders find new GM, to hire former Chargers executive\n\nEagles' Johnson out as OC: Top 5 potential replacements\n\nTitle game injuries: Where the game turned\n\nToward the tail end of the first half, it seemed like the Chiefs might be working their way back into the game.\n\n</doc>\n\n<doc>\n\n[4]\n\nTom Brady wins Super Bowl No. 7, Buccaneers beat Chiefs 31-9\n\n(AP Photo/Ashley Landis)\n\nTampa Bay Buccaneers quarterback Tom Brady (12) celebrates during the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021 in Tampa, Fla. (Ben Liebenberg via AP)\n\nTampa Bay Buccaneers quarterback Tom Brady (12) celebrates during the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021 in Tampa, Fla. (Ben Liebenberg via AP)\n\nTampa Bay Buccaneers quarterback Tom Brady reacts after getting stopped at the goal line against the Kansas City Chiefs during the first half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Ashley Landis)\n\nTampa Bay Buccaneers quarterback Tom Brady reacts after getting stopped at the goal line against the Kansas City Chiefs during the first half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Ashley Landis)\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) celebrates with Mike Evans (13) and quarterback Tom Brady (12) after Gronkowski scored a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Mark LoMoglio)\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) celebrates with Mike Evans (13) and quarterback Tom Brady (12) after Gronkowski scored a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Mark LoMoglio)\n\nTampa Bay Buccaneers tight end Rob Gronkowski celebrates after catching a 17-yard touchdown pass during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Gregory Bull)\n\nTampa Bay Buccaneers tight end Rob Gronkowski celebrates after catching a 17-yard touchdown pass during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Gregory Bull)\n\nTAMPA, Fla. (AP) — Tom Brady made the Buccaneers, their fans and their city believe from the moment he arrived in Tampa Bay.\n\n(AP Photo/Ashley Landis)\n\nTampa Bay Buccaneers quarterback Tom Brady (12) celebrates during the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021 in Tampa, Fla. (Ben Liebenberg via AP)\n\nTampa Bay Buccaneers quarterback Tom Brady reacts after getting stopped at the goal line against the Kansas City Chiefs during the first half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Ashley Landis)\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) celebrates with Mike Evans (13) and quarterback Tom Brady (12) after Gronkowski scored a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Mark LoMoglio)\n\nTampa Bay Buccaneers tight end Rob Gronkowski celebrates after catching a 17-yard touchdown pass during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Gregory Bull)\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) reacts after scoring a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Charlie Riedel)\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) reacts after scoring a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Charlie Riedel)\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) reacts after scoring a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Charlie Riedel)\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) reacts after scoring a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Charlie Riedel)\n\nSecurity tries to grab a fan on the field during the second half of the NFL Super Bowl 55 football game between the Tampa Bay Buccaneers and the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Mark Humphrey)\n\nKansas City Chiefs quarterback Patrick Mahomes breaks away from Tampa Bay Buccaneers outside linebacker Jason Pierre-Paul during the second half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Ashley Landis)\n\nKansas City Chiefs quarterback Patrick Mahomes breaks away from Tampa Bay Buccaneers outside linebacker Jason Pierre-Paul during the second half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Ashley Landis)\n\nTampa Bay Buccaneers quarterback Tom Brady (12) talks with Kansas City Chiefs strong safety Tyrann Mathieu (32) after throwing a touchdown pass during the first half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Gregory Bull)\n\nTampa Bay Buccaneers quarterback Tom Brady (12) talks with Kansas City Chiefs strong safety Tyrann Mathieu (32) after throwing a touchdown pass during the first half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Gregory Bull)\n\nTampa Bay Buccaneers quarterback Tom Brady celebrates with the Vince Lombardi Trophy after the NFL Super Bowl 55 football game against the Kansas City Chiefs Sunday, Feb. 7, 2021, in Tampa, Fla. Security tries to grab a fan on the field during the second half of the NFL Super Bowl 55 football game between the Tampa Bay Buccaneers and the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Mark Humphrey)\n\nKansas City Chiefs quarterback Patrick Mahomes breaks away from Tampa Bay Buccaneers outside linebacker Jason Pierre-Paul during the second half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Ashley Landis)\n\nTampa Bay Buccaneers quarterback Tom Brady (12) talks with Kansas City Chiefs strong safety Tyrann Mathieu (32) after throwing a touchdown pass during the first half of the NFL Super Bowl 55 football game Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Gregory Bull)\n\nTampa Bay Buccaneers quarterback Tom Brady celebrates with the Vince Lombardi Trophy after the NFL Super Bowl 55 football game against the Kansas City Chiefs Sunday, Feb. 7, 2021, in Tampa, Fla. Tom Brady wins Super Bowl No. 7, Buccaneers beat Chiefs 31-9\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) reacts after scoring a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Charlie Riedel)\n\nTampa Bay Buccaneers’ Rob Gronkowski (87) reacts after scoring a touchdown during the first half of the NFL Super Bowl 55 football game against the Kansas City Chiefs, Sunday, Feb. 7, 2021, in Tampa, Fla. (AP Photo/Charlie Riedel)\n\n</doc>\n\n<doc>\n\n[5]\n\nSuper Bowl 2021: Tom Brady wins seventh title as Tampa Bay ... - BBC\n\nThe former player and broadcaster opens up about what motivated him and his very humble origins\n\nExposing organised crime\n\nA three-part series following one specialist police unit over an extraordinary two-year operation\n\nFeatured\n\nThe political row that lost Arizona a Super Bowl\n\nThe 1993 Super Bowl was to be a landmark event for Arizona but it disappeared out of the state in a swirl of politics, polemic and division.\n\nTop Stories\n\nWatch: UK Snooker Championship - Murphy v Vafaei & Carter v Selt\n\nWSL: Shaw scores hat-trick as Man City put seven past Tottenham - reaction\n\nVenables the best English coach we've had - Lineker\n\nElsewhere on the BBC\n\nThe dark side of one of the most beautiful places on earth\n\nDI Ruth Calder returns to her native Shetland on the trail of a vulnerable witness...\n\nWhile the Chiefs came into the post-season as the top seed in the AFC Conference, Tampa Bay were the NFC's fifth seed and became the first wildcard team to win a Super Bowl since the Green Bay Packers 10 years ago after a remarkable play-off run.\n\nThe Chiefs finally got some offence going to reply with a field goal, 61 seconds from half-time, and just as they did in the NFC Championship game against the Packers, Tampa Bay claimed a crucial score right before the half as Brady completed a 71-yard drive by finding Brown in the end zone.\n\nThe Weeknd was the interval act and, for the first time in the game's 55-year history, he was largely forced to perform from the stands, rather than the pitch, in compliance with strict coronavirus protocols.\n\n</doc>\n\nIt seems that one of the documents had the right answer hidden inside of it, but the LLM is confused by the poorly engineered context, especially the lack of publication dates for the LLM to ground itself:\n\nLLM response from Tavily context (answer_correctness:0.22):\n\nThe Tampa Bay Buccaneers won the Super Bowl this year.\n\nExa\n\nThe context from Exa appears to be a poorly scraped webpage, filled with different historical superbowls.\n\nContext from Exa:\n\n<doc>\n\n[1]\n\nTitle:Official New England Patriots News and Analysis\n\nHighlights:View the Cheerleader roster, appearance schedule, news, photos and more! Supporting charitable and philanthropic agencies throughout New England\n\nPublished:2023-02-01\n\n</doc>\n\n<doc>\n\n[2]\n\nTitle:Official Website of the Kansas City Chiefs | Chiefs.com\n\nHighlights:A look at some of the community focused events held throughout the week of the 2023 NFL Draft in Kansas City Missouri. Stay up to date on news, access your tickets, stream live games, sign-up for Chiefs Kingdom Rewards & much more Get all your Chiefs gear from the official Chiefs Pro Shop\n\nPublished:2012-06-02\n\n</doc>\n\n<doc>\n\n[3]\n\nTitle:New England Patriots Football - Patriots News, Scores, Stats, Rumors & More | ESPN\n\nHighlights:Tom Brady Sr., Tom Brady's Father, joins the show to talk about his legendary son's retirement. Greeny and Hembo wrap up the hour talking about some NFC East trash talk and Hembo starts using words from Shakespearean times. 3d\n\nPublished:2023-02-06\n\n</doc>\n\n<doc>\n\n[4]\n\nTitle:Philadelphia Eagles\n\nHighlights:news Eagles, Nouryon celebrate National Teacher Appreciation Week May 10, 2023 Members of the community, including students, teachers, and school administrators, are encouraged to submit nominations between Wednesday, May 10, and Thursday, October 26.\n\nPublished:2012-06-02\n\n</doc>\n\n<doc>\n\n[5]\n\nTitle:Tampa Bay Buccaneers\n\nHighlights:gallery Bucs' 2023 Schedule Gallery View photos of the Bucs 2023 schedule. MORE PHOTOS Follow Us Advertising\n\nPublished:2023-02-06\n\n</doc>\n\nThe context does not contain sufficient context for the LLM to produce the correct answer.\n\nLLM response using Exa context (answer_correctness: 0.46):\n\nBased on the given documents, there is no information available to determine who won the Super Bowl this year.\n\nCheck out the Google Colab output for the other questions:\n\n3.“What are the best features of the latest NodeJS version?” — Knowledge Search\n\nWhere we saw the LLM using JinaAI context say “the best features are not explicitly mentioned”\n\n4.“What is the current Fed Reserve interest rate?” — Google-esque\n\nWhere we saw all three services provide sufficient context for the current Federal Reserve interest rate. But the context engineering for JinaAI and Tavily are loaded with extraneous (and expensive) tokens, likely due to naive web scrapes.\n\nFeature comparison",
      "# [Tavily API Integration Examples](https://www.restack.io/p/tavily-api-integration-answer)\nTo begin integrating the Tavily API, you first need to set up your application environment. This involves selecting the appropriate environment for your self-hosted app based on its current status. It's important to note that this environment differs from the one set up in Chatwoot, particularly regarding the TWITTER_ENVIRONMENT, which will be discussed later.\n\nApp Setup\n\nOnce your project is established, proceed to the app setup. You will need to create an API key and secret. Follow these steps:\n\nSet the App Name: Choose a unique name for your application.\n\nGenerate API Keys: After setting the app name, you will receive your API key and API secret keys. Make sure to save these keys securely.\n\nKey Configuration\n\nUse the API Key as TWITTER_CONSUMER_KEY in Chatwoot.\n\nUse the API Secret Key as TWITTER_CONSUMER_SECRET in Chatwoot.\n\n!Project App Name\n\nDevelopment Environment\n\nAfter completing the initial setup, you should configure your development environment. This step is crucial for ensuring that your application can communicate effectively with the Tavily API. Follow the guidelines provided in the official documentation to set up your development environment correctly.\n\nAdditional Resources\n\nFor further details on the Tavily API integration, refer to the official documentation. This will provide you with comprehensive examples and best practices for utilizing the API effectively. Ensure that you are familiar with the API endpoints and their respective functionalities to maximize your integration efforts.\n\nBy following these steps, you will be well on your way to successfully integrating the Tavily API into your application, allowing for enhanced functionality and user experience.\n\nCore Queries with Tavily API\n\nThe Tavily API provides a robust framework for executing web searches through various query types. This section delves into the specifics of utilizing the API effectively, focusing on the search endpoint, which allows users to perform detailed searches based on keywords, phrases, or even complex queries.\n\nQuery Types\n\nKeyword Search: This is the most straightforward method, where users can input specific keywords to retrieve relevant results. The API processes these keywords and returns a list of matching entries.\n\nPhrase Search: For more precise results, users can enclose phrases in quotes. This ensures that the API searches for the exact sequence of words, filtering out irrelevant results.\n\nBoolean Search: The Tavily API supports Boolean operators such as AND, OR, and NOT, enabling users to refine their searches further. For example, a query like \"artificial intelligence\" AND \"machine learning\" will return results that include both terms.\n\nExample Usage\n\nHere’s a simple example of how to use the Tavily API for a keyword search:\n\nimport requests url = 'https://api.tavily.com/search' params = {'query': 'latest AI research', 'api_key': 'YOUR_API_KEY'} response = requests.get(url, params=params) results = response.json() print(results)\n\nResponse Structure\n\nThe API returns a JSON object containing the search results. Here’s a breakdown of the response structure:\n\nresults: An array of search results, each containing:\n\ntitle: The title of the result.\n\nurl: The link to the source.\n\nsnippet: A brief description of the content.\n\nBest Practices\n\nRate Limiting: Be mindful of the API's rate limits to avoid throttling. Implementing exponential backoff strategies can help manage request rates effectively.\n\nCaching Results: To enhance performance, consider caching results for frequently searched queries. This reduces the number of API calls and speeds up response times for users.\n\nError Handling: Always implement error handling to manage potential issues such as network errors or invalid API keys. This ensures a smoother user experience.\n\nConclusion\n\nBy leveraging the Tavily API, users can perform comprehensive web searches tailored to their specific needs. The flexibility of query types and the structured response format make it a powerful tool for developers looking to integrate search capabilities into their applications.\n\nThe Tavily API offers a range of advanced features that enhance its functionality and usability for developers. These features allow for more nuanced configurations and optimizations that can significantly improve the performance of applications utilizing the API.\n\nAdvanced Settings\n\nThe Tavily API provides several advanced settings that can be configured to tailor the API's behavior to specific use cases. These settings include:\n\nQuery Optimization: Fine-tune how queries are processed to improve response times and accuracy.\n\nData Source Integration: Seamlessly integrate multiple data sources to enrich the information returned by the API.\n\nCustom Response Formats: Specify the format of the API responses to better suit the needs of your application.\n\nAdvanced QA Topics\n\nAs you scale to more complex questions and larger datasets, the Tavily API incorporates advanced techniques to enhance query understanding and data retrieval. Here are some key functionalities:\n\nTechniques for Better Query Understanding\n\nNatural Language Processing (NLP): Leverage NLP capabilities to interpret user queries more effectively, allowing for more accurate responses.\n\nContextual Awareness: The API can maintain context across multiple queries, improving the relevance of responses based on previous interactions.\n\nData Retrieval Enhancements\n\nIntelligent Caching: Implement caching strategies to reduce latency and improve the speed of data retrieval.\n\nDynamic Query Adjustment: The API can automatically adjust queries based on real-time data analysis, ensuring optimal results.\n\nIntegration Examples\n\nTo illustrate the capabilities of the Tavily API, consider the following integration examples:\n\n{ \"query\": \"What are the latest trends in AI?\", \"response_format\": \"json\", \"data_sources\": [\"source1\", \"source2\"] }\n\nThis example demonstrates how to structure a query that retrieves the latest trends in AI while specifying the desired response format and data sources.\n\nBy utilizing these advanced features, developers can create more robust applications that leverage the full potential of the Tavily API, ensuring a seamless user experience and efficient data handling."
    ],
    "# Tavily Company and Product Report\n\n## Company Overview\n\nTavily is an innovative technology company focused on enhancing the capabilities of AI agents through its specialized search API. The company aims to provide accurate, real-time, and contextually relevant information to developers and organizations looking to build intelligent applications. Tavily's mission is to empower users with reliable data, addressing the challenges of outdated or irrelevant information that often plagues traditional search engines [(Minh Le Duc, Medium, 2024-07-29)](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e).\n\n### Key Features and Offerings\n\n- **Tavily Search API**: This API is designed specifically for AI applications, allowing for efficient and rapid search results tailored to the needs of AI developers. It aggregates data from multiple sources, filtering and ranking the most relevant content for specific queries [(Minh Le Duc, Medium, 2024-07-29)](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e).\n  \n- **Company Researcher Tool**: This tool integrates Tavily's search and extraction capabilities, enabling users to generate comprehensive reports on companies. It employs a multi-stage workflow that includes grounding in verified data, sub-question generation, and AI-driven clustering to ensure accuracy and relevance [(Rotem Weiss, Tavily Blog, 2024-11-18)](https://blog.tavily.com/companyresearcher/).\n\n- **Dynamic Graph-Like Structure**: Tavily's architecture allows for flexibility in data retrieval while maintaining a clear path for processing, which is crucial for real-time applications [(Rotem Weiss, Tavily Blog, 2024-11-18)](https://blog.tavily.com/companyresearcher/).\n\n## Product Overview: Tavily\n\nTavily's primary product, the Tavily Search API, is a search engine optimized for large language models (LLMs) and retrieval-augmented generation (RAG) tasks. It is designed to provide developers with a powerful tool for integrating real-time information into their AI applications.\n\n### Product Features\n\n- **Real-Time Data Access**: Tavily allows AI agents to access up-to-date information, significantly reducing the risk of \"hallucinations\" or inaccuracies in AI-generated responses [(Minh Le Duc, Medium, 2024-07-29)](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e).\n\n- **Customizable Search Parameters**: Users can tailor their search queries with various parameters, including search depth, topic, and the number of results, ensuring that the API meets specific needs [(Minh Le Duc, Medium, 2024-07-29)](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e).\n\n- **Integration with Other Tools**: Tavily can be integrated with other platforms and tools, enhancing its functionality and allowing for a more seamless user experience [(Minh Le Duc, Medium, 2024-07-29)](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e).\n\n### Performance and Reliability\n\nTavily has been noted for its speed and reliability, with asynchronous request handling and built-in error recovery mechanisms. This ensures that users receive timely and accurate information, which is critical for applications that rely on real-time data [(Minh Le Duc, Medium, 2024-07-29)](https://medium.com/@minhle_0210/boost-your-rag-performance-with-tavily-search-api-607a6437ab8e).\n\n## Recent Developments\n\n- **New Features**: As of July 30, 2024, Tavily introduced an \"invoices\" tab on its dashboard, allowing users to view and download their invoices directly, a feature that was highly requested by users [(Tavily Community, 2024-07-30)](https://community.tavily.com/t/invoices-now-available-on-the-tavily-dashboard/58).\n\n- **Community Engagement**: Tavily has been actively engaging with its user community, addressing feedback regarding response times and optimizing the API for better performance. Users have reported response times averaging around three seconds, which can vary based on query complexity [(Tavily Community, 2024-09-10)](https://community.tavily.com/t/response-times-are-slow/131).\n\n## Executive Insights\n\nWhile specific executive quotes were not available in the reviewed articles, the overall sentiment from the company’s communications emphasizes a commitment to improving user experience and providing high-quality, reliable data for AI applications. The focus on community feedback and continuous improvement reflects a proactive approach to product development.\n\n## Market Position and Scale\n\nTavily is positioned as a leader in the niche of AI-optimized search engines, catering specifically to developers and organizations that require accurate and timely information for their AI applications. The company is leveraging the growing demand for AI solutions across various industries, which is expected to continue expanding in the coming years.\n\n### User Base and Growth Potential\n\nTavily's user base includes AI developers and organizations looking to enhance their applications with real-time data. The increasing reliance on AI technologies across sectors such as finance, healthcare, and customer service presents significant growth opportunities for Tavily as it continues to refine its offerings and expand its market reach.\n\n## Conclusion\n\nTavily is a forward-thinking company that is making significant strides in the AI and search technology space. With its specialized search API and commitment to providing accurate, real-time information, Tavily is well-positioned to meet the evolving needs of AI developers and organizations. The recent enhancements to its product offerings and active engagement with the user community further solidify its reputation as a reliable partner in the AI landscape.\n\nFor prospective candidates and investors, Tavily represents a promising opportunity in a rapidly growing market, driven by innovation and a strong focus on user needs."
  ],
  "lineage": {
    "run_at": "2025-02-04T18:40:59.872686",
    "git_sha": "08c0ab7"
  }
}