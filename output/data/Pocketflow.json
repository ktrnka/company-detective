{
  "summary_markdown": "# About Pocketflow\n\nPocketflow is a technology company that specializes in providing innovative solutions for data management and workflow automation. The company was founded with the vision of simplifying complex processes and enhancing productivity for businesses across various industries. While specific details about the company's founding date, employee count, and revenue are not publicly available, Pocketflow is known for its focus on developing frameworks and tools for artificial intelligence (AI) and machine learning applications.\n\nPocketflow offers a range of services designed to streamline operations and improve efficiency, including data management solutions, workflow automation tools, custom software development, and integration services for existing systems. The company's flagship product, the Pocketflow Platform, is a comprehensive tool for managing data workflows and automating processes. Additionally, Pocketflow provides API integrations and an analytics dashboard to help businesses make informed decisions.\n\nThe company serves a diverse clientele, including small businesses, large enterprises, and various sectors such as finance, healthcare, and education. Pocketflow operates on a B2B model, building long-term relationships with its customers by delivering tailored solutions that meet their specific needs.\n\nPocketflow's products are distributed and sold to users through direct engagement with businesses, leveraging its expertise in AI to offer lightweight and user-friendly frameworks that facilitate the creation of AI agents with memory capabilities. The company's approach to AI is characterized by simplicity, modular design, and effective memory management, making it a preferred choice for developers building conversational agents.\n\nThird parties describe Pocketflow as a company focused on making AI processes more accessible to developers and researchers. The company's lightweight frameworks and user-friendly design are often highlighted as key strengths, particularly in comparison to competitors like LangChain [(Singh, TechGig, 2025)](https://content.techgig.com/technology/why-developers-are-not-using-langchain/articleshow/118705898.cms).\n\n# Key Personnel\n\nThe leadership team at Pocketflow consists of experienced professionals with backgrounds in technology, business development, and project management. While specific names and roles are not detailed in the available sources, the team's combined expertise drives the company's mission to innovate and provide exceptional service to clients. Their commitment to making AI technology accessible is reflected in the design philosophy of Pocketflow's products, which prioritize ease of use and modularity.\n\n# News\n\n## Recent Developments\n\n### Tutorial and Community Engagement\nA recent tutorial titled \"Build AI Agent Memory From Scratch — Tutorial For Dummies\" was published on March 24, 2025. This tutorial explains how to use Pocketflow to create AI agents with memory capabilities, emphasizing the framework's ease of use and practical applications in building conversational agents [(Huang, Dev.to, 2025)](https://dev.to/zachary62/build-ai-agent-memory-from-scratch-tutorial-for-dummies-47ma).\n\n### Comparison with Competitors\nIn a recent article discussing the decline of LangChain, developers have started to favor alternatives like Pocketflow due to its reliability and user-friendliness. The article highlights that many developers find Pocketflow to be more modular and flexible compared to other frameworks, making it a preferred choice for building AI applications [(Singh, TechGig, 2025)](https://content.techgig.com/technology/why-developers-are-not-using-langchain/articleshow/118705898.cms).\n\n## Company Scale and Community Feedback\nWhile specific metrics regarding Pocketflow's employee count and revenue are not publicly available, the growing interest in the framework, as evidenced by community discussions and tutorials, suggests a positive reception among developers. The framework's simplicity and effectiveness have led to a burgeoning community of users who appreciate its straightforward approach to AI memory management.\n\n# Conclusion\n\nPocketflow is positioned as a valuable tool for developers looking to create AI agents with memory capabilities. Its lightweight design, ease of use, and positive community feedback make it a compelling choice in the landscape of AI frameworks. As the demand for intelligent conversational agents continues to grow, Pocketflow's innovative approach may well establish it as a leader in this niche market.",
  "target": [
    "Pocketflow",
    "Pocketflow",
    "pocketflow.dev",
    null,
    false,
    false,
    null,
    [
      false,
      false
    ]
  ],
  "webpage_result": {
    "summary_markdown": "# Pocketflow Company Overview\n\n## Company History\nPocketflow is a technology company that specializes in providing innovative solutions for data management and workflow automation. The company was founded with the vision of simplifying complex processes and enhancing productivity for businesses across various industries.\n\n## Services\nPocketflow offers a range of services designed to streamline operations and improve efficiency, including:\n\n- Data management solutions\n- Workflow automation tools\n- Custom software development\n- Integration services for existing systems\n\n## Products\nThe company provides several key products that cater to different business needs:\n\n- **Pocketflow Platform**: A comprehensive platform for managing data workflows and automating processes.\n- **API Integrations**: Tools that allow seamless connectivity between different software applications.\n- **Analytics Dashboard**: A product that offers insights and analytics to help businesses make informed decisions.\n\n## Customers\nPocketflow serves a diverse clientele, including small businesses, large enterprises, and various sectors such as finance, healthcare, and education. The company prides itself on building long-term relationships with its customers by delivering tailored solutions that meet their specific needs.\n\n## Leadership Team\nThe leadership team at Pocketflow consists of experienced professionals with backgrounds in technology, business development, and project management. Their combined expertise drives the company's mission to innovate and provide exceptional service to clients.\n\n## Culture\nPocketflow fosters a collaborative and inclusive work environment that encourages creativity and innovation. The company values teamwork, continuous learning, and a commitment to excellence, which are integral to its success and growth.\n\nFor more information, visit [Pocketflow](https://pocketflow.dev/).",
    "page_markdowns": [
      "# [Pocketflow](https://pocketflow.dev/)\n"
    ],
    "search_results": [
      {
        "title": "Pocketflow",
        "link": "https://pocketflow.dev/",
        "snippet": "An LLM Framework for LLMs. A lightweight orchestrator that lets AI build and maintain workflows. Start Building",
        "formattedUrl": "https://pocketflow.dev/"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Robert Scoble (@Scobleizer) / X](https://twitter.com/Scobleizer) - Introducing Pocketflow. Here's how we use it to automate lead gen.\n- [Helena Zhang (@helenaeverley) / X](https://x.com/helenaeverley?lang=en) - Introducing Pocketflow. Here's how we use it to automate lead gen.\n\n# Job boards\n- No unique job board pages found.\n\n# App stores\n- No app store pages found.\n\n# Product reviews\n- No detailed product reviews found.\n\n# News articles (most recent first, grouped by event)\n- **PocketFlow in AI Development**\n  - [Why Developers Are Not Using LangChain anymore](https://content.techgig.com/technology/why-developers-are-not-using-langchain/articleshow/118705898.cms) - Mar 5, 2025 - Developers find better alternatives like PydanticAI and PocketFlow more reliable.\n  - [Build AI Agent Memory From Scratch — Tutorial For Dummies](https://dev.to/zachary62/build-ai-agent-memory-from-scratch-tutorial-for-dummies-47ma) - 5 days ago - A guide using PocketFlow for building AI agents.\n  - [Genius DevCamp Winners. Foundational AI — March 14–16, 2025](https://medium.com/developer-camp/genius-devcamp-winners-e7bcf7c3f325) - 1 day ago - Pocketflow used in an AI agent system for managing cognitive load.\n\n- **PocketFlow in Molecular Design**\n  - [Efficient Generation of Protein Pockets with PocketGen](https://www.biorxiv.org/content/10.1101/2024.02.25.581968v4.full.pdf) - Sep 23, 2024 - Discusses Pocketflow's role in molecular generative modeling.\n  - [Artificial intelligence enabled smart design and manufacturing of ...](https://onlinelibrary.wiley.com/doi/full/10.1002/mgea.56) - Jul 16, 2024 - PocketFlow generating novel ligand molecules.\n  - [Generalized Protein Pocket Generation with Prior-Informed Flow ...](https://papers.nips.cc/paper_files/paper/2024/file/43eeff8a47075418c3e2b8b204053448-Paper-Conference.pdf) - Discusses PocketFlow's application in protein-ligand modeling.\n\n# Key employees (grouped by employee)\n- **Helena Zhang**\n  - [Helena Zhang - Building Pocketflow - Pocketflow.ai | LinkedIn](https://www.linkedin.com/in/helena-everley-zhang) - Experience in building Pocketflow.\n\n# Other pages on the company website\n- [Pocketflow](https://pocketflow.dev/) - An LLM Framework for LLMs. A lightweight orchestrator for AI workflows.\n\n# Other\n- **Research and Development**\n  - [Saoge123/PocketFlow: an autoregressive flow model ... - GitHub](https://github.com/Saoge123/PocketFlow) - Application of PocketFlow in protein design.\n  - [PocketFlow: An Automated Framework for Compressing and ...](https://openreview.net/pdf?id=H1fWoYhdim) - Discusses the framework's capabilities in model compression.\n  - [NeurIPS Poster Generalized Protein Pocket Generation with Prior ...](https://neurips.cc/virtual/2024/poster/94801) - Research on PocketFlow's application in protein generation.",
  "crunchbase_markdown": null,
  "customer_experience_result": {
    "output_text": "# Positive Sentiment\n\n## Simplicity and Usability\n- \"I was expecting something bad, but I am pleasantly surprised by the simplicity of it. Great job!\" [(sergeant113, Reddit, 2025-02-04)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/maw3ypm/)\n- \"This is incredibly clean and intuitive. I’ve been looking at frameworks to start experimenting with an agentic PoC. I will definitely be using this!\" [(NTSpike, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8azlha/)\n- \"Love the simplicity, great work!\" [(Brilliant-Day2748, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m88yfgf/)\n- \"Thanks! Good trade off between flexibility and ease of use. Will take closer look.\" [(amohakam, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m870h2g/)\n\n## Enjoyment and Productivity\n- \"I've been using PocketFlow and I'm really enjoying it.\" [(Nearby-Asparagus-298, Reddit, 2025-03-02)](https://github.com/the-pocket/PocketFlow)\n- \"Surprisingly, Cursor understands Pocket Flow really well - its generated code is modular, maintainable, and has greatly boosted my productivity over the past year.\" [(Willing-Site-8137, Reddit, 2025-03-04)](https://www.reddit.com/r/PromptEngineering/comments/1j2yok2/i_used_a_100line_llm_framework_to_let_ai_agents/)\n- \"I love how you've managed to create the agent framework from first principles. Excellent work.\" [(noellarkin, Reddit, 2025-03-27)](https://www.reddit.com/r/LLMDevs/comments/1jkdsk5/build_your_own_ai_memory_tutorial_for_dummies/mjzk8f1/)\n\n## Innovative Features\n- \"Pocketflow introduces a 'one-shot' approach where developers can execute multi-step operations with a single command, eliminating repetitive tasks and maintaining deep context.\" [(help-me-grow, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjyq9zl/)\n- \"Pocketflow offers AI-powered features such as precise code editing, direct file replacements, and seamless file navigation to reduce manual effort.\" [(help-me-grow, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjyq9zl/)\n- \"The entire framework is just a nested directed graph—perfect for multi-step agents, recursion, and decision-making.\" [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/)\n\n# Constructive Criticism\n\n## Complexity and Engineering\n- \"I suspect this is more likely to make people think 'this person doesn't know what they are doing and they are wasting my time' than 'wow I should really check that out'.\" [(lgastako, Reddit, 2025-03-04)](https://www.reddit.com/r/PromptEngineering/comments/1j2yok2/i_used_a_100line_llm_framework_to_let_ai_agents/mfwt77x/)\n- \"Most llm frameworks are an unnecessary mess of abstractions. You don’t need to have 5 base classes for simple api wrapper property.\" [(Ok-Radish-8394, Reddit, 2025-02-25)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meowht4/)\n- \"The reason lang chain sucks is not that it's many lines of code, it's that it's simultaneously over and under engineered.\" [(FrostyContribution35, Reddit, 2025-03-25)](https://www.reddit.com/r/LocalLLaMA/comments/1jjlk7c/build_your_own_ai_memory_tutorial_for_dummies/mjpog59/)\n\n## Suggestions for Improvement\n- \"I think you should stop emphasizing the fact that it's 100 lines and you wrote it over Christmas.\" [(lgastako, Reddit, 2025-03-04)](https://www.reddit.com/r/PromptEngineering/comments/1j2yok2/i_used_a_100line_llm_framework_to_let_ai_agents/mfwt77x/)\n- \"I have to check it out. I’m building a layer on top of langchain that would be considered 'bloated', but it serializes all the objects.\" [(LavishnessNo6243, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejd863/)",
    "intermediate_steps": [
      "- \"I’ve seen a lot of frustration around complex Agent frameworks like LangChain. Over the holidays, I challenged myself to see how small an Agent framework could be if we removed every non-essential piece. The result is PocketFlow: a 100-line LLM agent framework for what truly matters.\" [(Willing-Site-8137, Reddit, 2025-01-20)](cache://reddit/38)\n- \"I was expecting something bad, but I am pleasantly surprised by the simplicity of it. Great job!\" [(sergeant113, Reddit, 2025-02-04)](cache://reddit/95)\n- \"This is incredibly clean and intuitive. I’ve been looking at frameworks to start experimenting with an agentic PoC. I will definitely be using this!\" [(NTSpike, Reddit, 2025-01-21)](cache://reddit/72)\n- \"Love the simplicity, great work!\" [(Brilliant-Day2748, Reddit, 2025-01-20)](cache://reddit/68)\n- \"Thanks! Good trade off between flexibility and ease of use. Will take closer look.\" [(amohakam, Reddit, 2025-01-20)](cache://reddit/60)\n- \"Pocketflow introduces a 'one-shot' approach where developers can execute multi-step operations with a single command, eliminating repetitive tasks and maintaining deep context.\" [(help-me-grow, Reddit, 2025-03-27)](cache://reddit/27)\n- \"Pocketflow offers AI-powered features such as precise code editing, direct file replacements, and seamless file navigation to reduce manual effort.\" [(help-me-grow, Reddit, 2025-03-27)](cache://reddit/27)\n- \"I enjoy reading your take on Task Decomposition, Map Reduce, and Agent Orchestration.\" [(sergeant113, Reddit, 2025-02-04)](cache://reddit/95)\n- \"I plan to make many soon!\" [(Willing-Site-8137, Reddit, 2025-02-24)](cache://reddit/12)",
      "- \"I've been using PocketFlow and I'm really enjoying it.\" [(Nearby-Asparagus-298, Reddit, 2025-03-02)](cache://github/140)",
      "- \"I love how you've managed to create the agent framework from first principles. Excellent work.\" [(noellarkin, Reddit, 2025-03-27)](cache://reddit/245)\n- \"Surprisingly, Cursor understands Pocket Flow really well - its generated code is modular, maintainable, and has greatly boosted my productivity over the past year.\" [(Willing-Site-8137, Reddit, 2025-03-04)](cache://reddit/247)\n- \"The entire framework is just a nested directed graph—perfect for multi-step agents, recursion, and decision-making.\" [(Weak_Birthday2735, Reddit, 2025-02-24)](cache://reddit/239)\n- \"I suspect this is more likely to make people think 'this person doesn't know what they are doing and they are wasting my time' than 'wow I should really check that out'.\" [(lgastako, Reddit, 2025-03-04)](cache://reddit/253)\n- \"Most llm frameworks are an unnecessary mess of abstractions. You don’t need to have 5 base classes for simple api wrapper property.\" [(Ok-Radish-8394, Reddit, 2025-02-25)](cache://reddit/312)\n- \"I think you should stop emphasizing the fact that it's 100 lines and you wrote it over Christmas.\" [(lgastako, Reddit, 2025-03-04)](cache://reddit/253)\n- \"I have to check it out. I’m building a layer on top of langchain that would be considered 'bloated', but it serializes all the objects.\" [(LavishnessNo6243, Reddit, 2025-02-24)](cache://reddit/294)\n- \"The reason lang chain sucks is not that it's many lines of code, it's that it's simultaneously over and under engineered.\" [(FrostyContribution35, Reddit, 2025-03-25)](cache://reddit/242)"
    ],
    "url_to_review": {},
    "review_markdowns": [
      "# Post ID 1i5tjd0: I Built an Agent Framework in just 100 Lines!! with +116 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/)\nI’ve seen a lot of frustration around complex Agent frameworks like LangChain. Over the holidays, I challenged myself to see how small an Agent framework could be if we removed every non-essential piece. The result is **PocketFlow**: a 100-line LLM agent framework for what truly matters. \n\n# Why Strip It Down?\n\n**Complex Vendor or Application Wrappers Cause Headaches**\n\n* *Hard to Maintain:* Vendor APIs evolve (e.g., OpenAI introduces a new client after 0.27), leading to bugs or dependency issues.\n* *Hard to Extend:* Application-specific wrappers often don’t adapt well to your unique use cases.\n\n**We Don’t Need Everything Baked In**\n\n* *Easy to DIY (with LLMs):* It’s often easier just to build your own up-to-date wrapper—an LLM can even assist in coding it when fed with documents.\n* *Easy to Customize:* Many advanced features (multi-agent orchestration, etc.) are nice to have but aren’t always essential in the **core** framework. Instead, the **core** should focus on fundamental primitives, and we can layer on tailored features as needed.\n\nThese 100 lines capture what I see as the core abstraction of most LLM frameworks: a nested directed graph that breaks down tasks into multiple LLM steps, with branching and recursion to enable agent-like decision-making. From there, you can:\n\n**Layer on Complex Features (When You Need Them)**\n\n* Single-Agent\n* Multi-Agent Collaboration\n* Retrieval-Augmented Generation (RAG)\n* Task Decomposition\n* Or any other feature you can dream up!\n\nBecause the codebase is tiny, it’s easy to see where each piece fits and how to modify it without wading through layers of abstraction.\n\nI’m adding more examples and would love feedback. If there’s a feature you’d like to see or a specific use case you think is missing, please let me know!\n\n## Comment ID m86fszn with +11 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m86fszn/) (in reply to ID 1i5tjd0):\n**Links**\n\n* GitHub Repo: [https://github.com/the-pocket/PocketFlow/](https://github.com/the-pocket/PocketFlow/)\n\n**Example Features**\n\n* Single-Agent Documentation: [https://the-pocket.github.io/PocketFlow/design\\_pattern/agent.html](https://the-pocket.github.io/PocketFlow/design_pattern/agent.html)\n* Multi-Agent Collaboration: [https://the-pocket.github.io/PocketFlow/design\\_pattern/multi\\_agent.html](https://the-pocket.github.io/PocketFlow/design_pattern/multi_agent.html)\n* Retrieval-Augmented Generation (RAG): [https://the-pocket.github.io/PocketFlow/design\\_pattern/rag.html](https://the-pocket.github.io/PocketFlow/design_pattern/rag.html)\n* Task Decomposition: [https://the-pocket.github.io/PocketFlow/design\\_pattern/workflow.html](https://the-pocket.github.io/PocketFlow/design_pattern/workflow.html)\n\n### Comment ID m86s4ty with +6 score by [(becoming_stoic, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m86s4ty/) (in reply to ID m86fszn):\nThank you! This helps!\n\n## Comment ID m86u888 with +9 score by [(_pdp_, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m86u888/) (in reply to ID 1i5tjd0):\nYou can probably create an agent framework in 5 lines of code - just a while loop which calls the OpenAI sdk.\n\nIt is a joke. :)\n\nGood job\n\n### Comment ID m86w2sx with +1 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m86w2sx/) (in reply to ID m86u888):\nif vendor lock-in is okayish lol\n\n## Comment ID m86j26y with +5 score by [(subhashp, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m86j26y/) (in reply to ID 1i5tjd0):\nAwesome! I will study this.\n\n### Comment ID m86j9vu with +2 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m86j9vu/) (in reply to ID m86j26y):\nThank you!\n\n## Comment ID m87jatg with +3 score by [(mmark92712, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m87jatg/) (in reply to ID 1i5tjd0):\nLines of heroine? 🫢\n\n### Comment ID m87lhnx with +2 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m87lhnx/) (in reply to ID m87jatg):\nSmoke it if you find it addictive\n\n## Comment ID m86wuec with +2 score by [(youGottaBeKiddink, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m86wuec/) (in reply to ID 1i5tjd0):\nThis looks super interesting! Can you create an example chatbot which can be programmed to trigger certain vendor specific tasks? This is the most common usecase. For example \"I want order a large hamburger\" would trigger \"AddToCart(Hamburger, Large)\"\n\n### Comment ID m86yep5 with +2 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m86yep5/) (in reply to ID m86wuec):\nCheck this out!!  \n[https://chatgpt.com/share/678e87ef-5b6c-8000-aa1c-9dd0b356e445](https://chatgpt.com/share/678e87ef-5b6c-8000-aa1c-9dd0b356e445)\n\n#### Comment ID m871hl0 with +2 score by [(youGottaBeKiddink, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m871hl0/) (in reply to ID m86yep5):\nSuper! Thanks.\n\n## Comment ID m870h2g with +2 score by [(amohakam, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m870h2g/) (in reply to ID 1i5tjd0):\nThanks! Good trade off between flexibility and ease of use. Will take closer look.\n\n### Comment ID m878kx0 with +1 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m878kx0/) (in reply to ID m870h2g):\nThank you!\n\n## Comment ID m876oz6 with +2 score by [(emsiem22, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m876oz6/) (in reply to ID 1i5tjd0):\nLove it! Challenge succeeded! And more. I think I will use this. Thank you\n\n### Comment ID m878sqo with +1 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m878sqo/) (in reply to ID m876oz6):\nThank you!\n\n## Comment ID m87789k with +2 score by [(beehuman2024, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m87789k/) (in reply to ID 1i5tjd0):\nGreat job\n\n### Comment ID m878t1n with +1 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m878t1n/) (in reply to ID m87789k):\nThank you!\n\n## Comment ID m87hgk4 with +2 score by [(qa_anaaq, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m87hgk4/) (in reply to ID 1i5tjd0):\nLangchain started as 99 lines of code. So be careful. \n\nJk. Nice work :)\n\n### Comment ID m87j5ir with +1 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m87j5ir/) (in reply to ID m87hgk4):\nThanks I'll upload the 100 lines! Plan to make the other code optional extras.\n\n## Comment ID m88yfgf with +2 score by [(Brilliant-Day2748, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m88yfgf/) (in reply to ID 1i5tjd0):\nLove the simplicity, great work!\n\n### Comment ID m891t6t with +1 score by [(Willing-Site-8137, Reddit, 2025-01-20)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m891t6t/) (in reply to ID m88yfgf):\nThank you!\n\n## Comment ID m8addoh with +2 score by [(man_avec_plan, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8addoh/) (in reply to ID 1i5tjd0):\nDo you have a walkthrough on how to use the system design guidance agent?\n\n### Comment ID m8asl5f with +1 score by [(Willing-Site-8137, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8asl5f/) (in reply to ID m8addoh):\nOh yes thanks for asking! That's the tutorial I'm preparing lol. I will probably make another post for the tutorial and let you know!\n\n## Comment ID m8azlha with +2 score by [(NTSpike, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8azlha/) (in reply to ID 1i5tjd0):\nThis is incredibly clean and intuitive. I’ve been looking at frameworks to start experimenting with an agentic PoC. I will definitely be using this!\n\n### Comment ID m8b1or0 with +1 score by [(Willing-Site-8137, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8b1or0/) (in reply to ID m8azlha):\nThank you! Let me know your feedback!\n\n#### Comment ID m8cpad2 with +2 score by [(NTSpike, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8cpad2/) (in reply to ID m8b1or0):\nWill do! I'm a technical PM but haven't written code in awhile. I was reading through other frameworks looking for a place to start (PydanticAI, Atomic Agents, CrewAI) and while they were robust, I struggled with how to get started.\n\nYours was the first where it was immediately clear how to fit the pieces together for something simple with a pathway to stack them together for higher-level concepts!\n\n## Comment ID m8bhcr5 with +2 score by [(AriYasaran, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8bhcr5/) (in reply to ID 1i5tjd0):\nLooks cool  \ndid you check [https://github.com/huggingface/smolagents](https://github.com/huggingface/smolagents)  \nit can help you\n\n### Comment ID m8d5pe7 with +1 score by [(Willing-Site-8137, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8d5pe7/) (in reply to ID m8bhcr5):\nSmolagents is great for easy setup but, like other frameworks, abstracts LLM calls. This can limit flexibility for specialized calls or complex optimizations.\n\n#### Comment ID m8d8wul with +1 score by [(AriYasaran, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8d8wul/) (in reply to ID m8d5pe7):\nYa fair but its relatively easy to modify its code base\n\n## Comment ID m8bifz5 with +2 score by [(Excellent_Top_9172, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8bifz5/) (in reply to ID 1i5tjd0):\nVery nice job\n\n### Comment ID m8d5q7j with +1 score by [(Willing-Site-8137, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8d5q7j/) (in reply to ID m8bifz5):\nThank you!\n\n## Comment ID m8bl1h7 with +2 score by [(lol_shit, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8bl1h7/) (in reply to ID 1i5tjd0):\nI've been building AI agents since last couple of years and created a product out of it for no code use if anyone want to try and give feedback, check it out [unitron.ai](http://unitron.ai)\n\n### Comment ID m8d5t4x with +1 score by [(Willing-Site-8137, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8d5t4x/) (in reply to ID m8bl1h7):\nLooks cool!\n\n## Comment ID m8cbeej with +2 score by [(shanza2120, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8cbeej/) (in reply to ID 1i5tjd0):\nLooks nice\n\n### Comment ID m8d5vzs with +1 score by [(Willing-Site-8137, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8d5vzs/) (in reply to ID m8cbeej):\nThank you!\n\n## Comment ID m8g7yhp with +2 score by [(Royal-Paper8813, Reddit, 2025-01-22)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8g7yhp/) (in reply to ID 1i5tjd0):\nI want to revisit this post in the future.\n\n### Comment ID m8g8j76 with +2 score by [(Willing-Site-8137, Reddit, 2025-01-22)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8g8j76/) (in reply to ID m8g7yhp):\nI will remind you to revisit in the future\n\n## Comment ID m89iu9f with +1 score by [(wlynncork, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m89iu9f/) (in reply to ID 1i5tjd0):\nYour git says this only tested in unix.\nAny Mac or windows support?\n\n### Comment ID m89k3wr with +1 score by [(Willing-Site-8137, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m89k3wr/) (in reply to ID m89iu9f):\nSorry where did my git say only tested in unix?\n\n#### Comment ID m8bud9l with +1 score by [(wlynncork, Reddit, 2025-01-21)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m8bud9l/) (in reply to ID m89k3wr):\nInstallation\nPocketFlow is developed and tested on Linux, using Python 3.6 and TensorFlow 1.10.0\n\n## Comment ID m90elkn with +1 score by [(williamtkelley, Reddit, 2025-01-25)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m90elkn/) (in reply to ID 1i5tjd0):\nI'm still new to Agents and graphs, but does this do both or just the graph/workflow part? I am currently playing around with PydanticAI, not that much yet, but like the simple examples I have created. Does PocketFlow completely replace that or can they be used together?\n\n### Comment ID m90hkys with +2 score by [(Willing-Site-8137, Reddit, 2025-01-25)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m90hkys/) (in reply to ID m90elkn):\n1. Both Agents and Graphs  \n2. Here are the results from ChatGPT for the comparison, which I think are accurate:\n\n[https://chatgpt.com/share/67943358-bb48-8000-925a-4ff240fc7d33](https://chatgpt.com/share/67943358-bb48-8000-925a-4ff240fc7d33)\n\nTL;DR:  \nIf you only need simple agents and validation, use PydanticAI.  \nIf you want more complex and extensible agents and workflows, use Pocket Flow.\n\nI’m biased, but if you’re just starting to learn, I recommend Pocket Flow plus a chat assistant to help you understand what’s going on. PydanticAI abstracts things a bit too much. Pocket Flow provides the bare minimum so easier to see what’s happening under the hood.\n\n#### Comment ID m90i23t with +1 score by [(williamtkelley, Reddit, 2025-01-25)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/m90i23t/) (in reply to ID m90hkys):\nThanks for the quick reply. Can I use Pydantic itself with PockeFlow? I use it to get validated structured output from the LLM.\n\n## Comment ID maw3ypm with +1 score by [(sergeant113, Reddit, 2025-02-04)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/maw3ypm/) (in reply to ID 1i5tjd0):\nI was expecting something bad, but I am pleasantly surprised by the simplicity of it. Great job!\n\nPlus:  I enjoy reading your take on Task Decomposition, Map Reduce, and Agent Orchestration.\n\nMinus: I think your section on Structured Output is a bit sparse despite how important it is as the foundation for all other tasks.\n\nHave you considered fleshing out Structured Output & Tool Calling more? I know that Pydantic is anti-pattern to your yaml-based approach, but I would love to see its integration here since so many people have already adopted Pydantic as the gold-standard for structured output and tool calling validation.\n\nAnyways, subscribed!\n\n### Comment ID may2v6v with +1 score by [(Willing-Site-8137, Reddit, 2025-02-04)](https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/may2v6v/) (in reply to ID maw3ypm):\nThank you!!\n\nPydantic complements the YAML-based approach rather than competing with it. YAML is to generate data, while Pydantic handles validation. Will flesh it out!",
      "# Post ID 1iyy610: I built an open-source LLM App that ELI5 YouTube video (full design doc included) with +43 score by [(Willing-Site-8137, Reddit, 2025-02-26)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/)\n\n\n## Comment ID meyd0sq with +7 score by [(Willing-Site-8137, Reddit, 2025-02-26)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/meyd0sq/) (in reply to ID 1iyy610):\nI built a small LLM app that explains YouTube videos to me like I’m five:  \n[https://github.com/The-Pocket/Tutorial-Youtube-Made-Simple](https://github.com/The-Pocket/Tutorial-Youtube-Made-Simple)  \nFor example, Lex recently did a podcast about DeepSeek—it's really interesting, but it’s 5 hours long, and I don’t want to sit through all 5 hours.  \nWith this app, I can get the gist in just 10 minutes and then decide if the full video is worth the time.\n\nI’ve open-sourced everything, including a detailed design doc, for anyone who wants to explore or modify it.   \nThis app is an example project built with Pocket Flow, a 100-line LLM framework I created previously:  \n[https://github.com/The-Pocket/PocketFlow](https://github.com/The-Pocket/PocketFlow)   \nWith Pocket Flow + Cursor AI, I put this project together in just a few hours.   \nI mostly worked on the design doc while Cursor AI did all the coding.  \nI’ll release a step-by-step YouTube tutorial on how I built this project in a few hours—stay tuned!\n\n### Comment ID mf0hhnc with +1 score by [(LifeScientist123, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf0hhnc/) (in reply to ID meyd0sq):\nNice idea, but Gemini already does this for free!? Is it more complicated than copy pasting the video transcript into ChatGpT and telling it to ELI5?\n\n#### Comment ID mf0huix with +2 score by [(Willing-Site-8137, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf0huix/) (in reply to ID mf0hhnc):\nGreat point! Here is the result I got from Gemini which is very bad (likely because I don't subscribe and not Gemini Advanced). \n\nAnd for comparison: [https://the-pocket.github.io/Tutorial-Youtube-Made-Simple/examples/DeepSeek%2C%20China%2C%20OpenAI%2C%20NVIDIA%2C%20xAI%2C%20TSMC%2C%20Stargate%2C%20and%20AI%20Megaclusters%20%7C%20Lex%20Fridman%20Podcast%20%23459.html](https://the-pocket.github.io/Tutorial-Youtube-Made-Simple/examples/DeepSeek%2C%20China%2C%20OpenAI%2C%20NVIDIA%2C%20xAI%2C%20TSMC%2C%20Stargate%2C%20and%20AI%20Megaclusters%20%7C%20Lex%20Fridman%20Podcast%20%23459.html)\n\nhttps://preview.redd.it/7b5443s3tlle1.png?width=640&format=png&auto=webp&s=ec5f907f7ac6b6c3b60ea242b0a2a1a6f32f6d5d\n\n#### Comment ID mf0ih6a with +1 score by [(Willing-Site-8137, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf0ih6a/) (in reply to ID mf0hhnc):\nI also tried o1, it is better but still not satisfactory. It missed important points, and it was too terse.\n\n#### Comment ID mf0zfaa with +1 score by [(AMadHammer, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf0zfaa/) (in reply to ID mf0hhnc):\nI tried building a browser extension to turn that process into a one button click but gave up halfway. Did anyone build anything similar? Otherwise maybe I should continue working on it.\n\n## Comment ID mf22li5 with +2 score by [(valdecircarvalho, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf22li5/) (in reply to ID 1iyy610):\nNice! I've coded something similar yesterday.   \nSuggestion: Move the prompt to a external file. It will be easier to update and change the prompt if needed.\n\n### Comment ID mf32fyl with +1 score by [(Willing-Site-8137, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf32fyl/) (in reply to ID mf22li5):\nThank you!\n\n## Comment ID mf40zvv with +1 score by [(w4rlock999, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf40zvv/) (in reply to ID 1iyy610):\nWhat youtube scraping you use? I have mine (summarize and chat with youtube app) but it stopped working sometime last year due to youtube changing policy 😢\n\n### Comment ID mf5c529 with +2 score by [(Willing-Site-8137, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf5c529/) (in reply to ID mf40zvv):\nPlease find the youtube scraping function here: [https://github.com/The-Pocket/Tutorial-Youtube-Made-Simple/blob/main/utils/youtube\\_processor.py](https://github.com/The-Pocket/Tutorial-Youtube-Made-Simple/blob/main/utils/youtube_processor.py)\n\n## Comment ID mf55uee with +1 score by [(VintageGenious, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/mf55uee/) (in reply to ID 1iyy610):\nJust watch the vids",
      "# Post ID 1j1gb88: Why are developers moving away from LangChain? with +177 score by [(Chatur_Baniya59, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/)\nI've noticed that LangChain is starting to fall out of favor with developers, and I personally have begun to dislike the experience as well. The framework feels bloated, with too many dependencies and unnecessary complexity. A lot of components have been moved into separate packages, making it harder to manage. Overall, I feel like it’s becoming over-engineered.\n\nWhat are your thoughts on this? Why do you think developers are moving away from LangChain? Also, what lightweight and developer-friendly alternatives do you use?\n\n## Comment ID mfjkjzl with +79 score by [(ConsciousDissonance, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjkjzl/) (in reply to ID 1j1gb88):\nI wanted to like langchain and have used it for a few projects. But i will probably never use it again because It’s unstable, the interface constantly changes, the documentation is regularly out of date, and the abstractions are overly complicated.\n\n### Comment ID mfjzta8 with +30 score by [(suavestallion, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjzta8/) (in reply to ID mfjkjzl):\nDude...the documents have changed entirely 3 times over. It's infuriating\n\n#### Comment ID mflk2po with +24 score by [(puergeminus, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mflk2po/) (in reply to ID mfjzta8):\nand it is still dogshit documentation\n\n### Comment ID mfkc505 with +5 score by [(Jamb9876, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkc505/) (in reply to ID mfjkjzl):\nIt is nice if I want a quick POC but for anything serious I can do it from scratch with fewer dependencies. \nLast week I had to fix their code to work with the oracle cloud gen ai service. That was annoying.\n\n#### Comment ID mfl08gt with +1 score by [(Weak_Birthday2735, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfl08gt/) (in reply to ID mfkc505):\nTry https://github.com/The-Pocket-World/Pocket-Flow-Framework!!\n\n### Comment ID mfkfbvo with +6 score by [(Tuxedotux83, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkfbvo/) (in reply to ID mfjkjzl):\nThis might be something LangChain must address actually- decide on a certain design and stick to it at least partially, while leaving backward compatibility for whatever is getting deprecated for a certain amount of time.\n\nThing is LC is still relatively young so things change rapidly\n\n#### Comment ID mfrznbc with +3 score by [(lionmeetsviking, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfrznbc/) (in reply to ID mfkfbvo):\nI’ve used lot of immature frameworks, but none that would be so messed up as LangChain. Wanted to like it, but had to abandon it due to all the reasons mentioned above.\n\n### Comment ID mfo7csk with +3 score by [(General-Jaguar-8164, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfo7csk/) (in reply to ID mfjkjzl):\nWhat do you use nowadays?\n\n#### Comment ID mg1mnqg with +2 score by [(ConsciousDissonance, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mg1mnqg/) (in reply to ID mfo7csk):\nKind of a mish mash of things, see the answer here: [https://www.reddit.com/r/LangChain/comments/1j1gb88/comment/mg1mffn/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/LangChain/comments/1j1gb88/comment/mg1mffn/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)\n\n### Comment ID mfzc8r9 with +2 score by [(nathan-portia, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfzc8r9/) (in reply to ID mfjkjzl):\nBasically exactly my experience. Have you found good replacements?\n\n#### Comment ID mg1mffn with +3 score by [(ConsciousDissonance, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mg1mffn/) (in reply to ID mfzc8r9):\nNot really. I tend to use a combination of custom code and specialized libraries atm. I'll pull in a structured generation library (outlines, instructor, guidance, etc..), an agent library (crewai, pydanticai, llama-index..), document ingestion library (usually llama-index), RAG libraries (usually libs that match the backing datastore/retrieval system + custom code), prompt management library (sometimes just a json file, sometimes more), evals library (depends on the situation), and I'll sometimes use types from langchain for simple things like message types.\n\nIf there's something I find in langchain that I really want to use but seems over engineered, then I'll just read the implementation and write my own code for it or find a separate library. On rare occasions I'll grab a small piece of langchain if its something that doesn't demand I pull everything in.\n\nIts not really a clean AIO solution, but I don't have stability issues and can isolate problems when they occur. Each individual library generally has good interfaces and reliable documentation since they don't have a huge surface areas they're trying to cover, its easier to shop around for something with amenable abstractions when I only need to use it for one thing. And updates in one area don't break everything else.\n\nSome specialized libraries, specifically the agent ones use langchain under the hood, same for some vector store libraries. I don't have any issue with that really as long as \\*I\\* don't have to deal with the langchain interfaces myself beyond a surface level.\n\n### Comment ID mfl6289 with +1 score by [(Niightstalker, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfl6289/) (in reply to ID mfjkjzl):\nWell it’s currently still under rapid development with version 0.3.x. That is common for libraries in their early development. If you want it stable wait for version 1.0.0.\n\n#### Comment ID mfli7sq with +1 score by [(TheAngryGuy1, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfli7sq/) (in reply to ID mfl6289):\nU mean Langchain is not \"ready\" for production as of today 0.3x ? \n\nI understand that instability is possible and common, but why not go for major version tracks instead of always evolving minor versions ? That would allow one to choose, depending on it's project the \"stable\" or \"latest features\" version.\n\nThat would also give you more flexibility to rework the codebase deeply for major version, while keeping stable version. Just like Node is doing, and has become a standard.\n\n## Comment ID mfjfdvt with +105 score by [(sonicviz, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjfdvt/) (in reply to ID 1j1gb88):\nhttps://preview.redd.it/vyy5nfczs6me1.png?width=1200&format=png&auto=webp&s=96c0beba2440189c3fb3e2ce598eefe0d59d19b1\n\n### Comment ID mfjtb3h with +21 score by [(funbike, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjtb3h/) (in reply to ID mfjfdvt):\nLangchain beat that curve.  It hit the peak in the first few months and has stayed there since.\n\n#### Comment ID mfk6wy8 with +12 score by [(fantastiskelars, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfk6wy8/) (in reply to ID mfjtb3h):\nYou dont like the awesome .pipe syntax they made for no reason?\n\n\n\n### Comment ID mflsh9i with +1 score by [(phenobarbital_, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mflsh9i/) (in reply to ID mfjfdvt):\nOn my experience, move away from the simple ConversationHistory (I used the Redis version) to an over-engineered was a bad experience, I'm agree what Langchain is overcomplicating things for no reason.\nBut, funny thing, pgVector is a solution very rudimentary with no isolation, saving everything in one single table (I made my own solution saving over my postgres tables), I think they've put the focus on building code that looks and *feels* enterprise-level rather than solving problems easily.\n\n## Comment ID mfjsplr with +32 score by [(aeum3893, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjsplr/) (in reply to ID 1j1gb88):\nNobody’s mentioning an alternative yet. I wanna know smarts peoples of Reddit\n\n### Comment ID mfjwdff with +14 score by [(NovelNo2600, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjwdff/) (in reply to ID mfjsplr):\nExactly, I have seen many times people saying that langchain/langgraph is not production ready, but never got details which is production ready\n\n#### Comment ID mfk1pgd with +7 score by [(aeum3893, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfk1pgd/) (in reply to ID mfjwdff):\nThere is none. And actually Langchain has some strong recent case studies.\n\nI’m quite sure some other frameworks will pop up to compete with Langchain but as for today LangChain is the best you can get to build serious AI agents\n\n### Comment ID mfm20jg with +10 score by [(qudat, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfm20jg/) (in reply to ID mfjsplr):\nMaybe? https://www.llamaindex.ai\n\n#### Comment ID mft9b9u with +2 score by [(joonini, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mft9b9u/) (in reply to ID mfm20jg):\nI use llama index for my agents, they are in production and is pretty good the documentation is amazing! Pydantic as well! Not sure why this frameworks are less known\n\n### Comment ID mfkp5ek with +4 score by [(Nearby-Asparagus-298, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkp5ek/) (in reply to ID mfjsplr):\ndiy\n\n### Comment ID mfkqwwm with +9 score by [(Preacher2013, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkqwwm/) (in reply to ID mfjsplr):\nPydantic AI. I posted the same on another subreddit a few days back: it’s simple and pythonic without stupid abstractions. Langchain/langraph are the only frameworks I’ve ever used where I feel like I’m fighting the framework. Atomic Agents is also very good.\n\n### Comment ID mfmid7s with +3 score by [(dheemonk, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfmid7s/) (in reply to ID mfjsplr):\nPydantic\n\n#### Comment ID mfoc2ri with +1 score by [(aeum3893, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfoc2ri/) (in reply to ID mfmid7s):\nIm keeping an eye on that one\n\n### Comment ID mfplhym with +3 score by [(2deep2steep, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfplhym/) (in reply to ID mfjsplr):\nPython is the alternative, the hard part of agents isn’t the abstractions lol\n\n### Comment ID mfupibq with +3 score by [(ashpreetbedi, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfupibq/) (in reply to ID mfjsplr):\nCheckout: https://github.com/agno-agi/agno\n\nSuper simple, very lightweight - 10000x faster than langgraph at agent creation. 20k stars. Used in production at many companies. \n\nDisclaimer: I’m the author.\n\n#### Comment ID mfvh3ct with +3 score by [(aeum3893, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfvh3ct/) (in reply to ID mfupibq):\nThat is awesome. Thanks for plugging that in\n\n### Comment ID mfkrpx6 with +6 score by [(zerubeus, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkrpx6/) (in reply to ID mfjsplr):\nBuild yours, don't waste your time, not a whole framework because I doubt you need that for the job, but the pipeline you need for your current system, you'll be surprised how easier things will get.\n\n#### Comment ID mfplqyi with +2 score by [(2deep2steep, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfplqyi/) (in reply to ID mfkrpx6):\nIt’s *so* easy to build no one should ever waste time with this nonsense\n\n### Comment ID mflkvy0 with +2 score by [(TheAngryGuy1, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mflkvy0/) (in reply to ID mfjsplr):\nIf you're in TS you may look it https://github.com/mastra-ai/mastra that looks still fresh paint, but exemple code looks much cleaner.\n\n@LangchainTeam : the visual appeal of code is important, while the mastra doc seems very clean, the JS exemple of langgraph are bloated with \"bad looking\" code like \nConst x = somearray[length-1], i mean that's just ugly and should be abstracted. \n\nI'm a heavy Langchain user, and respecting the team work and effort, that's a great way to harmonize IA/agent code between projects. But lacks of value, stability and simplicity is killing the golden goose. \n\nAlso as a JS dev, the LangX JS lib feels a bit always running after the Python lib, but that's also the case with HuggingFace, where the whole JS devs are totally non-represented. But that's for another thread... \nBut we JS devs (at least, I) will go INSTANTLY in a more efficient lib that is JS/TS first, as most devs went from angular to react not because it was less overhead.\n\n### Comment ID mfqunta with +2 score by [(gentleseahorse, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfqunta/) (in reply to ID mfjsplr):\nLiteLLM. You don't need a \"framework\", you need a single interface to all the model providers.\n\n### Comment ID mfww2ye with +2 score by [(Wonderful-Sea4215, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfww2ye/) (in reply to ID mfjsplr):\nVanilla python. LLMs are super easy.\n\n### Comment ID mfkbdbq with +2 score by [(blad30x, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkbdbq/) (in reply to ID mfjsplr):\nI've been using PocketFlow and I'm really enjoying it. [https://github.com/the-pocket/PocketFlow](https://github.com/the-pocket/PocketFlow)\n\n### Comment ID mfrd9kz with +1 score by [(dasRentier, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfrd9kz/) (in reply to ID mfjsplr):\nWhy do you need a framework? Maybe for prototyping - strong advocate for just rolling with super simple code and focusing on the prompts.\n\n### Comment ID mft2nhb with +1 score by [(Upstairs_Shake7790, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mft2nhb/) (in reply to ID mfjsplr):\ni use haystack on production\n\n### Comment ID mfz3zqo with +1 score by [(Consistent_Essay1139, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfz3zqo/) (in reply to ID mfjsplr):\nThere’s a few if your doing multi agent things like crew ai and autogen\n\n### Comment ID mg986d8 with +1 score by [(h666777, Reddit, 2025-03-06)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mg986d8/) (in reply to ID mfjsplr):\nJust DiY. Horrendous skill issue if you can't implement anything langchain does yourself with 10x less overhead.\n\n### Comment ID mgpatjq with +1 score by [(betelgeuseian, Reddit, 2025-03-08)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mgpatjq/) (in reply to ID mfjsplr):\nJust use the api directly.\n\n## Comment ID mfjtwey with +7 score by [(positivitittie, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjtwey/) (in reply to ID 1j1gb88):\nlol I thought developers been falling out with LangChain the whole time.\n\n## Comment ID mfjvbqv with +11 score by [(abhishek_satish96, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjvbqv/) (in reply to ID 1j1gb88):\nI’ve been using Pydantic AI lately. It’s a whole lot less complicated and bloated, it comes with no default agent’s like Langchain, but the structure is fairly straightforward and extremely flexible IMO.\n\n### Comment ID mfk0p9o with +3 score by [(imtourist, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfk0p9o/) (in reply to ID mfjvbqv):\nSame here, I started with Lanchain/langraph and have settled in with Pydantic.   Simpler to construct code, packages are not moving around or getting deprecated every few weeks, generally more enjoyable to use.\n\n### Comment ID mfm7fai with +2 score by [(Ranteck, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfm7fai/) (in reply to ID mfjvbqv):\nIt works for production?\n\n#### Comment ID mfn47ek with +2 score by [(Strange-Tomatillo-46, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfn47ek/) (in reply to ID mfm7fai):\nNo way. I’m a big fan of PydanticAI, but using it in production is highly discouraged and irresponsible. I use it in my side projects because I believe that, at some point, it will become the standard, but it is at least a year away from being production-ready.\n\nI love using LangGraph in production—I’ve been using it for the past year, and it’s really stable. My only complaint is that they need to clean up their library. They’ve added so many unnecessary things that sometimes overcomplicate things, to the point where I end up implementing my own versions of some of their functions. But anyway, I still use part of it. Also, they have to organize better the documentation.\n\n### Comment ID mfz2rgw with +1 score by [(TheUserIsDrunk, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfz2rgw/) (in reply to ID mfjvbqv):\nThis problem in this thread 👆\n\nPeople are comparing LangChain with agent frameworks like Pydantic AI, CrewAI, Agno, etc. Apples vs oranges.\n\n## Comment ID mfjev64 with +17 score by [(YOLOLJJ, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjev64/) (in reply to ID 1j1gb88):\nFor me the only reason why I am still using langchain is for langgraph. It’s a fantastic framework that is super flexible to build complex systems. Sometimes I can get a bit complex I agree (have had issues with passing in states to agents) but langgraph is really great if you want to build a complex ai system\n\n### Comment ID mfjmraw with +6 score by [(wait-a-minut, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjmraw/) (in reply to ID mfjev64):\nWhat do you like about langgraph? I did a hackathon this weekend with it and have some mixed feelings \n\nLike at its core it felt really powerful but it seemed also super overly complex with a lot of weird footguns and random ways of doing things \n\nAfter spending 26 hours nonstop building with it I kind of want to pick everyone else’s brain on it and just make just it’s not just me.\n\n#### Comment ID mfjsiyo with +5 score by [(YOLOLJJ, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjsiyo/) (in reply to ID mfjmraw):\nIt’s easy to build agentic workflows that include sub graphs. Yes it sucks it updates so quickly but with library versioning it’s not bad. We save time not having to build from scratch and have good results\n\n#### Comment ID mfl0cnc with +1 score by [(Weak_Birthday2735, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfl0cnc/) (in reply to ID mfjmraw):\nWait would love to know your thoughts on [https://github.com/The-Pocket-World/Pocket-Flow-Framework](https://github.com/The-Pocket-World/Pocket-Flow-Framework)\n\n### Comment ID mfkoh7p with +3 score by [(cjberra, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkoh7p/) (in reply to ID mfjev64):\nThe way I see it, Langgraph is more of an orchestration framework. You can use most other agentic frameworks with it, for example Pydantic AI and Langgraph can be used together.\n\n#### Comment ID mflz8yl with +2 score by [(YOLOLJJ, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mflz8yl/) (in reply to ID mfkoh7p):\nYeah that’s fair. I think that’s probably how I’d describe it\n\n## Comment ID mfjxs3x with +3 score by [(shadowsyntax43, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjxs3x/) (in reply to ID 1j1gb88):\nToo many breaking changes. I hate it at this point. But I do not think there's a viable alternative.\n\n## Comment ID mflqcli with +4 score by [(thats_a_nice_toast, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mflqcli/) (in reply to ID 1j1gb88):\nI'm very new to all of this and I just started playing around with LangChain. What I've noticed:\n\n- The documentation is absolutely horrendous.\n- It seems very fragmented. I needed like an hour just to figure out the libraries and imports to create a very basic embedding and chat script.\n- I looked up a recent example and the first thing that was printed was \"this library is deprecated, use this other one instead\".\n\nVery annoying experience.\n\n## Comment ID mfjt2ww with +3 score by [(funbike, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfjt2ww/) (in reply to ID 1j1gb88):\nThe code is terrible.  There's more to a library than how to use it.  There's debugging and understanding the internals.\n\nI switched to agno (formerly phidata), which is much easier to work with.\n\n## Comment ID mfkduex with +3 score by [(calcsam, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkduex/) (in reply to ID 1j1gb88):\na friend likes using letta. for anyone doing js stuff there's mastra\n\n### Comment ID mfzs6sy with +1 score by [(dev902, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfzs6sy/) (in reply to ID mfkduex):\nMastra is something that's encouraging and is an excellent decision to ditch LC and LangGraph to proceed with Mastra.\nIt is pretty exciting to work with Mastra AI.\n\nThough I'm now biased with Mastra because of their Simplicity.\n\n## Comment ID mfkep33 with +3 score by [(Tuxedotux83, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkep33/) (in reply to ID 1j1gb88):\nLangChain is what? I am relatively new to LangChain and I am a pretty senior dev, don’t think it is getting less use it’s just niche (being used for specific use cases rather than generic usage like some other frameworks)\nAlso lots of people don’t like the complexity, and they turn to framework that might have LangChain functionality built into their internals but offer a higher level and simpler interface\n\n## Comment ID mfkw1vl with +3 score by [(TheDeadlyPretzel, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkw1vl/) (in reply to ID 1j1gb88):\nSo, here's my take... I am an experienced software engineer (15+ years of experience), and I tested out all the LLM frameworks and libraries, most of them, LangChain included, were written by people rather inexperienced in creating tools for other developers to use, but were rather young data scientists themselves, not developer-experience engineers...\n\nMay I suggest you have a look at my framework, Atomic Agents: [https://github.com/BrainBlend-AI/atomic-agents](https://github.com/BrainBlend-AI/atomic-agents) with now just under 3K stars the feedback has been stellar and a lot of people are starting to prefer it over the others\n\nIt aims to be:  \n\\- Developer Centric  \n\\- Have a stable core  \n\\- Lightweight  \n\\- Everything is based around structured input&output  \n\\- Everything is based on solid programming principles  \n\\- Everything is **hyper self-consistent** (agents & tools are all just Input -> Processing -> Output, all structured)  \n\\- It's not painful like the langchain ecosystem :')  \n\\- It gives you 100% control over any agentic pipeline or multi-agent system, instead of relinquishing that control to the agents themselves like you would with CrewAI etc (which I found, most of my clients really need that control)\n\nHere are some articles, examples & tutorials (don't worry the medium URLs are not paywalled if you use these URLs)  \n**Intro**: [**https://medium.com/ai-advances/want-to-build-ai-agents-c83ab4535411?sk=b9429f7c57dbd3bda59f41154b65af35**](https://medium.com/ai-advances/want-to-build-ai-agents-c83ab4535411?sk=b9429f7c57dbd3bda59f41154b65af35)\n\n**Docs:** [**https://brainblend-ai.github.io/atomic-agents/**](https://brainblend-ai.github.io/atomic-agents/)\n\n**Quickstart examples**: [**https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples/quickstart**](https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples/quickstart)\n\n**A deep research example**: [**https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples/deep-research**](https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples/deep-research)\n\n**An agent that can orchestrate tool & agent calls**: [**https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples/orchestration-agent**](https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples/orchestration-agent)\n\n**A fun one, extracting a recipe from a Youtube video**: [**https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples/youtube-to-recipe**](https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples/youtube-to-recipe)\n\n**How to build agents with longterm memory:** [**https://generativeai.pub/build-smarter-ai-agents-with-long-term-persistent-memory-and-atomic-agents-415b1d2b23ff?sk=071d9e3b2f5a3e3adbf9fc4e8f4dbe27**](https://generativeai.pub/build-smarter-ai-agents-with-long-term-persistent-memory-and-atomic-agents-415b1d2b23ff?sk=071d9e3b2f5a3e3adbf9fc4e8f4dbe27)\n\nI think delivering quality software is important, but also realized if I was going to try to get clients, I had to be able to deliver fast as well.\n\nSo I looked at langchain, crewai, autogen, some low-code tools even, and as a developer with 15+ years experience I hated every single one of them - langchain/langgraph due to the fact it wasn't made by experienced developers and it really shows, plus they have 101 wrappers for things that don't need it and in fact, only hinder you (all it serves is as good PR to make VC happy and money for partnerships)\n\nCrewAI & Autogen couldn't give the control most CTOs are demanding, and most others even worse..\n\nSo, I made **Atomic Agents** out of spite and necessity for my own work, and now I end up getting hired specifically to rewrite codebases from langchain/langgraph to Atomic Agents, do PoCs with Atomic Agents, ... which I lowkey did not expect it to become this popular and praised, but I guess the most popular things are those that solve problems, and that is what I set out to do for myself before opensourcing it\n\nAlso created a subreddit for it just recently, it's still suuuuper young so nothing there really yet [**r/AtomicAgents**](https://www.reddit.com/r/AtomicAgents/)\n\n## Comment ID mfm1n8d with +2 score by [(WineOrDeath, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfm1n8d/) (in reply to ID 1j1gb88):\nI have liked LangChain and am pretty heavily invested in it supporting one of my clients with paid accounts with LangSmith and LangGraph.\n\nThat being said, the more I use it the more I hate it for the following reasons: \n\n1. There is no concept of \"stable.\" Everything is changing so quickly that code my team wrote a month ago no longer functions.  They are constantly making breaking changes to EVERYTHING for no apparent value.  It is just like some LC dev decided they didn't like how a particular function looked so they decided to rewrite it.\n\n2. Packages, packages, packages!  If you have never tried to maintain some large, multi-agent things in production then you have not lived!  But trying to keep things running with different package versions is nearly impossible, especially as you start moving beyond LC and bringing in LS and LG.\n\n3. The documentation blows goats and is typically a few versions behind.  Discoverability is apparently not a thing.  Online courses are woefully behind and what content does exist is really not helpful.  What does exist is not user friendly.  It is like they have never heard of a Dev Rel team. \n\nI actually went to AWS re:Invent in 2024 hoping to take a bunch of workshops from LC and talk to them about stuff.  Interestingly, the AWS folks taught plenty of workshops that happened to use LC, the LC had zero presence there.  Super frustrating.\n\n## Comment ID mfsq6el with +2 score by [(fasti-au, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfsq6el/) (in reply to ID 1j1gb88):\nOther new shiny\n\n## Comment ID mfkklna with +2 score by [(cxpugli, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkklna/) (in reply to ID 1j1gb88):\nI don't get this hate Langchain gets (and I'm pretty sure this is a reddit bubble).\n\nMany people who complain about it lack enough coding experience. \n\nIf you've been working with Python for at least a few years you should already know that dependency hell and breaking changes are a constant thing and you need to learn how to better manage it in your project.\n\nLanhchain is OS, any can edit its documentation. However, it's better and much easier to waste time complaining about it.\n\n## Comment ID mfk9qsp with +1 score by [(danishxr, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfk9qsp/) (in reply to ID 1j1gb88):\nIs  DSPy any good as an alternative?\n\n### Comment ID mfo10t3 with +1 score by [(himeros_ai, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfo10t3/) (in reply to ID mfk9qsp):\nIt's mostly for prompt optimization engineering and lacks all the main building blocks for a functional application. Funny enough their backend is actually LiteLLM.\n\n#### Comment ID mg410lb with +1 score by [(Nasrodine, Reddit, 2025-03-05)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mg410lb/) (in reply to ID mfo10t3):\nu/danishxr  DSPy is designed for automating model optimization. Its output can be leveraged by another AI application to solve specific tasks. Imagine linking an agent to your optimized model to handle tasks the model alone couldn’t solve.  \nu/himeros_ai, please, what is the issue with LiteLLM ?\n\n## Comment ID mfkb2qe with +1 score by [(CertainShop8289, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkb2qe/) (in reply to ID 1j1gb88):\nSemantic Kernel? The philosophy behind it is to bring stability and ease of interoperability.\n\n## Comment ID mfkch8d with +1 score by [(Fluid-Albatross3419, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkch8d/) (in reply to ID 1j1gb88):\nI have been through multiple cases where I personally started with Langchain/Langflow but then ended up with my own specific code for specific Usecase.\n\n## Comment ID mfkdz0k with +1 score by [(Few_Primary8868, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkdz0k/) (in reply to ID 1j1gb88):\nOnly reason I am sticking with langchain is langgraph. It is a most intuitive way to implement agentic system and easy to communicate.\n\n### Comment ID mfoqrab with +1 score by [(himeros_ai, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfoqrab/) (in reply to ID mfkdz0k):\nTry Autogen2...\n\n## Comment ID mfkhrdt with +1 score by [(bitplenty, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkhrdt/) (in reply to ID 1j1gb88):\nBecause it’s a hot mess with very low code quality\n\n## Comment ID mfkp6oo with +1 score by [(codeyman2, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkp6oo/) (in reply to ID 1j1gb88):\nI moved away after releasing a production system because every bug fix entails a full system rewrite.. \n\nAnd quite frankly, I never really needed anything more than a set of utility functions.. not some idiomatic imposition to force me to refactor the code.\n\n## Comment ID mfkpnw4 with +1 score by [(cjberra, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkpnw4/) (in reply to ID 1j1gb88):\nIf you use LangChain with lower level abstractions from LangChain, I really don't think a lot of these complaints are valid.\n\n## Comment ID mfkvli3 with +1 score by [(MindIndividual4397, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkvli3/) (in reply to ID 1j1gb88):\nI can understand the criticism of LangChain. It has evolved rapidly, but with that, it has also gained complexity. The many dependencies and the fragmented ecosystem sometimes make it difficult to navigate.\n\nI’ve tried LangGraph, and I think it at least attempts to solve these issues better. It provides a clearer structure for managing flows without feeling as bloated as LangChain. However, I don’t see it as a perfect replacement—it really depends on what you’re trying to build.\n\nAre there any other lightweight alternatives that you prefer?\n\n## Comment ID mfkwf97 with +1 score by [(pacmanpill, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkwf97/) (in reply to ID 1j1gb88):\n0 doc\n\n## Comment ID mfl145t with +1 score by [(datamutant, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfl145t/) (in reply to ID 1j1gb88):\nI have been trying to move from Vanilla Python to LangChain several times. Every time there is some kind of a problem in the documentation and I just do it with Vanilla Python instead.\n\n## Comment ID mfl4y7h with +1 score by [(Luckyboy_Rahul, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfl4y7h/) (in reply to ID 1j1gb88):\nWhat's the most popular competitor of the LangChain?\n\n### Comment ID mfmtvb4 with +1 score by [(Odd_Concern_2156, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfmtvb4/) (in reply to ID mfl4y7h):\nMastra is blowing up right now. \n\nI started using it and it's way cleaner, but still has some ways to go. \n\nBut it's coming for Langchain ;)\n\n## Comment ID mfl8tn1 with +1 score by [(lioninawhat, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfl8tn1/) (in reply to ID 1j1gb88):\nWhat a cumbersome, poorly maintained developer API.\n\n## Comment ID mflhxxs with +1 score by [(qa_anaaq, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mflhxxs/) (in reply to ID 1j1gb88):\nA big part of the problem is AI engineering in general, which is by nature non-deterministic. I understand there are things one can do to mitigate this fact, but not always. \n\nAnd then you try to build an incredibly complicated, one-stop-shop abstraction on top of that reality (with terrible documentation, to boot), and you're bound for instability and, unfortunately, failure. \n\nLangchain is fine for simple things. But it does not scale well towards complex needs because too many little things go wrong when trying to execute on a larger (complex) thing. \n\nI'm sure they have the attitude of \"haters gonna hate\", but unfortunately for them this is very much a case of \"pretty much everyone with decent experience has complaints\" and they don't listen. \n\nI always compare this situation to something like React or Fastapi/Flask etc. Langchain wants to replace (abstract) core engineering, like how React replaced vanilla HTML etc web building. But langchain is trying to do too much from the get-go without getting the basics stable first. We can see data that says how much React is used in production. I'd love to see this for langchain but we never will. So the scheme will continue.\n\n## Comment ID mflrl00 with +1 score by [(kbkk, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mflrl00/) (in reply to ID 1j1gb88):\nAs someone who's trialing Langchain (JS) at their company, here's my take:\n\n\\- The abstractions are leaky most of the time. And I do not mean AI itself but they fall short on very basic stuff (off the top of my head, non comprehensive list):  \n  \\- API Retries (had to implement it myself!! and IIRC it swallows parts of the error response so can't always act accordingly)  \n  \\- LLM providers lagging with features, could've been easily circumvented by allowing us to inject req headers, query strings, etc. but no! you have to wait till they implement them via a nice named flag :)   \n  \\- wrt. above still haven't figured out how to get Caching work with Bedrock  \n  \\- classes extending classes extending classes - tedious debugging  \n  \\- VectorStore integrations lacking basic methods like \"if doc exists\", extended filtering (i.e. filter by a column in addition to vector search)\n\n\\- Initially I thought LangChain would get me observability (integrated with our OTel stack) - oh boy, I had to try like 5 different solutions before I found one working somewhat correctly. \n\n\\- LangChain docs and \"support\" is a JOKE. They have connected an AI responder to the GH issues, finding anything useful is beyond impossible.\n\n  \nAt this moment, I am highly skeptical of LangChain and I avoid coupling any code to it.\n\n## Comment ID mflwrcq with +1 score by [(goatthezen, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mflwrcq/) (in reply to ID 1j1gb88):\nIs it just me, an old donkey yelling at the clouds, or do all the young dudes these days whine about frameworks being bloated and overengineered with pointless abstraction, simply because they’re too green to grasp why an abstract class or interface exists?\n\nI remember being like that too, but luckily, I didn’t have social media back then to broadcast my ignorance\n\n## Comment ID mfme5l9 with +1 score by [(Idiot_monk, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfme5l9/) (in reply to ID 1j1gb88):\nThe promise of LLMs, for me at least, was less complicated architecture/codebase, simpler interfaces and communication mechanism. Langchain is exact opposite of that. I hate it with a passion.\n\n## Comment ID mfmrvcd with +1 score by [(o5mfiHTNsH748KVq, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfmrvcd/) (in reply to ID 1j1gb88):\nI think most senior+ engineers recognized Langchain as reinventing workflow engines lol. All agents are is less deterministic workflows where the state transitions are decided by an LLM.\n\nIt’s just a RAD tool with quick integrations that are shottily coded because they take PRs from randos with little review for consistency.\n\n### Comment ID mfqsbkq with +1 score by [(Environmental-Web584, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfqsbkq/) (in reply to ID mfmrvcd):\nWhen I discovered Lang chain I gave a look at the code. After 5 minutes I decided I would not use it. It's a templating lib + state machine, a badly designed one\n\n## Comment ID mfn0nsw with +1 score by [(Whyme-__-, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfn0nsw/) (in reply to ID 1j1gb88):\nI would rather use pydantic ai or Ag2 for stability and less technical debt\n\n## Comment ID mfnl1vz with +1 score by [(West-Code4642, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfnl1vz/) (in reply to ID 1j1gb88):\nIt's unneeded.  It doesn't save time at all. Just roll your own glue and utility code. It's not rocket science. Langchains is obviously made by people with little programming experience.\n\n## Comment ID mfny4x7 with +1 score by [(Repulsive-Memory-298, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfny4x7/) (in reply to ID 1j1gb88):\nPeople always acted like it was so amazing and helpful. No, it never did anything that special. Most of this takes 5 minutes to implement from scratch and you get to fully understand what happens. \n\nit sounds good on paper. People used it because it was among the first, but it was never really needed. people only thought it was needed because they had never done agentic AI before. \n\nId say the biggest thing that Langhan ever did was make all of this seem super over complicated and way more convoluted than it really should be\n\n## Comment ID mfnz9lp with +1 score by [(theswifter01, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfnz9lp/) (in reply to ID 1j1gb88):\nCuz it sucks and provides no value other than a quickstart\n\n## Comment ID mfofpcn with +1 score by [(WhatsTheDamage1999, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfofpcn/) (in reply to ID 1j1gb88):\nIs there a community? I try to join off the Langchain home page and just get an expired Slack link. You'd think someone would notice something like that isn't working. If there is an active community, maybe someone can mention how to join?\n\nedit: it's frustrating when things don't work as expected, probably a bug, hard to tell because verbose doesn't do anything, community link is broken, nowhere to ask. yeah maybe a skill issue but more stuff seems broken than one would expect, takes a morning to go down a rabbit hole and get nowhere.\n\n## Comment ID mfon7qb with +1 score by [(magic6435, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfon7qb/) (in reply to ID 1j1gb88):\nWhat is, \"Begging the question\" for $200 Alex.\n\n## Comment ID mfpjju1 with +1 score by [(Heavy-Letter2802, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfpjju1/) (in reply to ID 1j1gb88):\nI just started looking at langgraph to start to get my fees wet into llms and agents. \n\nIs that a good starting point or any other resources I should be considering\n\n## Comment ID mfq4qc9 with +1 score by [(spersingerorinda, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfq4qc9/) (in reply to ID 1j1gb88):\nWe built on langchain early, but when it was time to move to multi-agent orchestration I couldn't stomach Langgraph, so I ended up building my own framework. I recently ported the Langgraph Open Research agent over. You can see my version here: [https://github.com/supercog-ai/agentic/blob/main/examples/oss\\_deep\\_research.py#L79](https://github.com/supercog-ai/agentic/blob/main/examples/oss_deep_research.py#L79), and the original langgraph here: https://github.com/langchain-ai/open\\_deep\\_research/blob/main/src/open\\_deep\\_research/graph.py. I like looking at a real example, and this was is illustrative. Things like:  \nCommand(goto=\\[ Send(\"magic string name of node\",...)\\])\n\nare pretty suss.\n\n## Comment ID mfq8v8c with +1 score by [(rainupjc, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfq8v8c/) (in reply to ID 1j1gb88):\nIt’s so confusing. Period.\n\n## Comment ID mfqv1vb with +1 score by [(Sudden-Outside-7217, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfqv1vb/) (in reply to ID 1j1gb88):\nWe also see that a lot of customers from langchain are moving to our LLMops platform orq.ai.\n\nThey all mention that langchain is becoming to bloated\n\n## Comment ID mfrb2eg with +1 score by [(townofsalemfangay, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfrb2eg/) (in reply to ID 1j1gb88):\nBecause it's overly complicated and the process documents continue to change year over year.\n\n## Comment ID mfrtcmu with +1 score by [(Comfortable-You1890, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfrtcmu/) (in reply to ID 1j1gb88):\nEven AI code assistants cannot help you with Langchain because of their breaking changes.\n\n## Comment ID mfsdrr2 with +1 score by [(Mickloven, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfsdrr2/) (in reply to ID 1j1gb88):\nLayers of abstraction\n\n## Comment ID mftd87z with +1 score by [(Kindly_Manager7556, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mftd87z/) (in reply to ID 1j1gb88):\nIt makes no sense to abstract away an API call? lol\n\n## Comment ID mfun59t with +1 score by [(juanvieiraML, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfun59t/) (in reply to ID 1j1gb88):\nDespite the documentation problems, as it changes a lot, we must understand that it is a very new area of ​​activity, full of new things almost every day. But I've done countless tests on applications with LLMs and agents, and I can say that Langchain is the best, as it optimizes execution. It was a very efficient framework in terms of performance.\n\n## Comment ID mfv3oyj with +1 score by [(Any_Particular_4383, Reddit, 2025-03-03)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfv3oyj/) (in reply to ID 1j1gb88):\nGive it some time, it's still young…\n\n## Comment ID mfxenv8 with +1 score by [(MathAngelMom, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfxenv8/) (in reply to ID 1j1gb88):\n[LearnSQL.com](http://LearnSQL.com) is offering a free course each month. This month it's window functions in Postgres: [https://learnsql.com/blog/free-postgresql-course-window-functions/](https://learnsql.com/blog/free-postgresql-course-window-functions/)\n\nWindow functions are essential for data analytics\n\n## Comment ID mfxlvxn with +1 score by [(NoEye2705, Reddit, 2025-03-04)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfxlvxn/) (in reply to ID 1j1gb88):\nDirect API calls are just simpler. LangChain feels like using a sledgehammer for nails.\n\n## Comment ID mg5h4rz with +1 score by [(Character-Ad5001, Reddit, 2025-03-05)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mg5h4rz/) (in reply to ID 1j1gb88):\nfacts fr fr, any alternative frameworks, am tired of langchain\n\n## Comment ID mg7q496 with +1 score by [(oculusshift, Reddit, 2025-03-05)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mg7q496/) (in reply to ID 1j1gb88):\nToo much abstraction, hard to debug. \nThings could be done simpler with just API call + your logic wrapper.\n\n## Comment ID mga09um with +1 score by [(BreakfastSecure6504, Reddit, 2025-03-06)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mga09um/) (in reply to ID 1j1gb88):\nIt's bag of shit , unstable, poor doc, etc\n\n## Comment ID mgaywcp with +1 score by [(tjthomas101, Reddit, 2025-03-06)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mgaywcp/) (in reply to ID 1j1gb88):\nWhat's the recommended alternative for now?\n\n## Comment ID mgdctcd with +1 score by [(Parabola2112, Reddit, 2025-03-06)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mgdctcd/) (in reply to ID 1j1gb88):\nNo idea why it was popular to begin with. Don’t need a framework to make API calls.\n\n## Comment ID mfk6scl with +1 score by [(fantastiskelars, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfk6scl/) (in reply to ID 1j1gb88):\nIt is bloated and badly design. It does basically nothing...\n\nUse the AI package from vercel. It is simple and reliable.\n\n### Comment ID mfkfur1 with +3 score by [(Tuxedotux83, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfkfur1/) (in reply to ID mfk6scl):\nI wouldn’t say it’s badly designed, it’s just complex to use and they still have the issue of making changes that break existing code (no backward compatibility) but that is solvable if LC want to give it a focus.\n\nAlso claiming it does nothing is also a big claim, for me it works so far pretty well- AFTER spending a ton of time figuring out things, I will admit, it is not beginner friendly, I say this as a dev with two decades of experience- on the flip side not everything have to be beginner friendly\n\n#### Comment ID mfl0f69 with +2 score by [(Weak_Birthday2735, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/mfl0f69/) (in reply to ID mfkfur1):\n[https://www.reddit.com/r/LangChain/comments/1iwrhuu/i\\_built\\_an\\_llm\\_framework\\_in\\_179\\_lineswhy\\_are\\_the/](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/)",
      "# Post ID 1jkv8dc: I reverse-engineered Claude Code & Cursor AI agents. Here's how they actually work with +51 score by [(Weak_Birthday2735, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/)\nAfter diving into the tools powering Claude Code and Cursor, I discovered the secret that makes these coding agents tick:\n\nUnder the hood, they use:\n\n* View tools that read/parse files with line-by-line precision\n* Edit tools making surgical code changes via string replacement\n* GrepTool & GlobTool for intelligent file navigation\n* BatchTool for parallel operation execution\n* Agent delegation systems for specialized tasks\n\nCheck out our deep dive into this. Link to substack is in the comments. \n\n## Comment ID mjysuyt with +14 score by [(kopfrechner, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjysuyt/) (in reply to ID 1jkv8dc):\nGrats for reverse engineer those tools.\nAt least Antrophic provides this information publicly too 😅\n https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview#tools-available-to-claude\n\n## Comment ID mjyl3ei with +29 score by [(help-me-grow, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjyl3ei/) (in reply to ID 1jkv8dc):\nwas this post written with AI?\n\n### Comment ID mjypb2d with +36 score by [(ohmypaka, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjypb2d/) (in reply to ID mjyl3ei):\nVibe posting\n\n#### Comment ID mjyq2cx with +2 score by [(help-me-grow, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjyq2cx/) (in reply to ID mjypb2d):\nalways 😎\n\n### Comment ID mk0ate0 with +2 score by [(buythedip0000, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mk0ate0/) (in reply to ID mjyl3ei):\nCheckout my substack for answer\n\n#### Comment ID mk0dk3d with +1 score by [(help-me-grow, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mk0dk3d/) (in reply to ID mk0ate0):\nlet me have my agent do it for me 😎\n\n### Comment ID mjypoyc with +1 score by [(Weak_Birthday2735, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjypoyc/) (in reply to ID mjyl3ei):\nhaha no\n\n#### Comment ID mjyqaq7 with +3 score by [(help-me-grow, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjyqaq7/) (in reply to ID mjypoyc):\nalso see you on Friday!\n\n#### Comment ID mjyq9zl with +4 score by [(help-me-grow, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjyq9zl/) (in reply to ID mjypoyc):\nwell this was:\n\n* **Fragmented Developer Workflows**: Developers often struggle with fragmented tasks like file reading, code editing, dependency management, and testing, which disrupt focus, introduce errors, and consume valuable time.\n* **One-Shot Paradigm**: Pocketflow introduces a \"one-shot\" approach where developers can execute multi-step operations with a single command, eliminating repetitive tasks and maintaining deep context.\n* **AI-Driven Code Management**: Inspired by tools like Cursor and Claude Code, Pocketflow offers AI-powered features such as precise code editing, direct file replacements, and seamless file navigation to reduce manual effort.\n* **Parallel Task Execution**: Developers can efficiently run tasks like builds and tests concurrently using Pocketflow’s BatchTool, saving time and improving productivity.\n* **Enhanced Contextual Awareness**: Pocketflow goes beyond existing solutions by maintaining state across operations, adapting to a developer's project-specific patterns, and intelligently sequencing complex tasks for more effective workflow automation.\n\n## Comment ID mjzv91i with +5 score by [(funbike, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjzv91i/) (in reply to ID 1jkv8dc):\nThe list in the post is no secret.  These are the bare minimum tools that any coding agent needs (except maybe batchtool).\n\nThe hard part is code understanding (esp of huge codebases) and planning.  So, the agent algorithm/logic, and prompt instructions on how to plan, how to understand code, how to break tasks down.   These are the hard things and I see no description of how it's done in this article.\n\n## Comment ID mk0867f with +3 score by [(xemantic, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mk0867f/) (in reply to ID 1jkv8dc):\nI made this educational open source agent (GPL) which is good enough at coding to modify itself by adding new tools and writing own prompts, most of the time flawlessly. It's maybe 500 lines of code on top of my SDK for Anthropic API. There are no much secrets in techniques of building agents like this:\n\n[https://github.com/xemantic/claudine/](https://github.com/xemantic/claudine/)\n\nClone it, build it, run it, and prompt: \"Clone this project: git@github.com:xemantic/claudine.git, analyze it's code base, add GrepTool & GlobTool for intelligent file navigation\"\n\nThen as a question: \"Are you aware that this is the very code accessing you at the moment?\" ;)\n\n## Comment ID mjzoews with +5 score by [(pokemonplayer2001, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjzoews/) (in reply to ID 1jkv8dc):\nZero value content, incredible.\n\n## Comment ID mk1jvf7 with +2 score by [(Future_AGI, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mk1jvf7/) (in reply to ID 1jkv8dc):\nSolid breakdown. The real magic is in how these tools coordinate—especially with agent delegation. Curious if you ran into any limitations in their approach? Anything they should be doing but aren’t?\n\n## Comment ID mk0h1pz with +1 score by [(noiv, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mk0h1pz/) (in reply to ID 1jkv8dc):\nDoes Claude know its own code?\n\n## Comment ID mk3vogw with +1 score by [(No_Wrangler_2674, Reddit, 2025-03-28)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mk3vogw/) (in reply to ID 1jkv8dc):\nHmm\n\n## Comment ID mk6zp2c with +1 score by [(ReasonablePool1111, Reddit, 2025-03-28)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mk6zp2c/) (in reply to ID 1jkv8dc):\nApplyingfor the link\n\n## Comment ID mjyh480 with +1 score by [(Weak_Birthday2735, Reddit, 2025-03-27)](https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/mjyh480/) (in reply to ID 1jkv8dc):\n[https://substack.com/home/post/p-159963558](https://substack.com/home/post/p-159963558)",
      "# Post ID 1ix3fla: Video Tutorial: 100 Lines to Let Cursor AI Build Agents for You with +28 score by [(Willing-Site-8137, Reddit, 2025-02-24)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/)\nHi all, I created a short tutorial to show how Pocket Flow—a 100-line LLM framework—can help Cursor AI build LLM agents.\n\n**Background:**  \nLast month, I posted on reddit a 100-line LLM Framework I built over the holidays.  \n***TLDR:*** It uses a graph abstraction but supports workflows, multiple agents, RAG, and more.  \nIt received much more attention and upvotes than I expected. Thank you all for your support!!\n\nHowever, many wondered why they’d need such a low-level framework.  \nI feel like the real value isn’t coming across:\n\n>***It is a framework used by LLM agents to build LLM agents!***  \n***It is a framework used by LLM agents to build LLM agents!***  \n***It is a framework used by LLM agents to build LLM agents!***  \n***It is a framework used by LLM agents to build LLM agents!***  \n***It is a framework used by LLM agents to build LLM agents!***\n\nI really want to highlight this point—it’s tough to convey just by text.  \nThat’s why I made a quick video showing this idea in action using Cursor AI, one of the simplest coding AI Agents.  \nIn order for Cursor AI to work with Pocket Flow:\n\n1. Provide the Pocket Flow documentation as the cursor rule file. \n2. That's it! Because Pocket Flow is small and easy for cursor AI to understand, it works surprisingly well!\n\n\n\nAlso, this is my first-ever YouTube video, so it might feel a bit off.  \nPlease let me know your feedback or questions!  \nI plan to make tutorial to build more complex use cases with Pocket Flow + Cursor AI in the coming weeks.  \nIf there’s a specific LLM project you’d like to see me build, let me know!\n\n## Comment ID meiu5ue with +4 score by [(Willing-Site-8137, Reddit, 2025-02-24)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/meiu5ue/) (in reply to ID 1ix3fla):\nYouTube Video: [https://www.youtube.com/watch?v=0Pv5HVoVBYE](https://www.youtube.com/watch?v=0Pv5HVoVBYE)  \nPocket Flow: [https://github.com/The-Pocket/PocketFlow](https://github.com/The-Pocket/PocketFlow)  \nCursor rule file: [https://github.com/The-Pocket/PocketFlow/blob/main/assets/.cursorrules](https://github.com/The-Pocket/PocketFlow/blob/main/assets/.cursorrules)  \nCookbook: [https://github.com/The-Pocket/PocketFlow/blob/main/cookbook/pocketflow\\_demo.ipynb](https://github.com/The-Pocket/PocketFlow/blob/main/cookbook/pocketflow_demo.ipynb)\n\n## Comment ID mekfhya with +1 score by [(Mxm3000, Reddit, 2025-02-24)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/mekfhya/) (in reply to ID 1ix3fla):\nThe link directs to youtube kids and I can’t access it\n\n### Comment ID mekj4aw with +3 score by [(Willing-Site-8137, Reddit, 2025-02-24)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/mekj4aw/) (in reply to ID mekfhya):\nWhoops... Sorry this link doesn't work? [https://www.youtube.com/watch?v=0Pv5HVoVBYE](https://www.youtube.com/watch?v=0Pv5HVoVBYE)\n\n#### Comment ID mekpr34 with +1 score by [(Mxm3000, Reddit, 2025-02-24)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/mekpr34/) (in reply to ID mekj4aw):\nStill can’t access it on my end. What’s the name of your channel?\n\n## Comment ID melnl5r with +1 score by [(Sonofg0tham, Reddit, 2025-02-24)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/melnl5r/) (in reply to ID 1ix3fla):\nThanks for sharing. I'm brand new to agents but have experience with cursor. Do you have any use cases for your build?\n\n### Comment ID melqz5p with +1 score by [(Willing-Site-8137, Reddit, 2025-02-24)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/melqz5p/) (in reply to ID melnl5r):\nThank you! I know I haven't done a good job explaining, but it's supposed to be a general purpose framework for any agents. Any use case you want to see? I plan to make many soon!\n\n## Comment ID metvluh with +1 score by [(NTSpike, Reddit, 2025-02-26)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/metvluh/) (in reply to ID 1ix3fla):\nThis is super interesting. It makes sense that PocketFlow would be great with vibe coding. Gonna give this a spin this weekend.\n\n## Comment ID mezw8o5 with +1 score by [(blad30x, Reddit, 2025-02-27)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/mezw8o5/) (in reply to ID 1ix3fla):\nBrother, I know someone who owns a pharmacy, and I want to develop a system to integrate their system with WhatsApp. Can PocketFlow help me with that? Initially, I thought about using N8N, but dragging those blocks is a hassle. I’d prefer something more like Cursor, where I can code directly (I have experience as a dev). However, since it’s a large pharmacy, the demand could scale quickly, and I’ll need to integrate with other solutions. I’ll need powerful tools and a solid RAG system.\n\n### Comment ID mf00s9l with +1 score by [(Willing-Site-8137, Reddit, 2025-02-27)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/mf00s9l/) (in reply to ID mezw8o5):\nAre you mainly looking for a setup where, e.g., patients can ask about their prescriptions on WhatsApp and have an LLM pull data from the pharmacy’s system to answer them?\n\n#### Comment ID mf01pzj with +1 score by [(blad30x, Reddit, 2025-02-27)](https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/mf01pzj/) (in reply to ID mf00s9l):\nThe patient contacts the pharmacy via WhatsApp to check the availability of a medication, either by text or image. The agent starts the conversation with a greeting and searches for the medication in the system. It then returns with price information. If the user requests delivery, the agent sends a payment link and waits for confirmation. Once the payment is approved, the agent asks for the necessary delivery details. The entire conversation is saved so that, after a few days, the agent can follow up with the patient, sending a message like: “Hi, how are you? I hope you're feeling better! Do you need anything else?”",
      "# Post ID 1iwrhuu: I Built an LLM Framework in 179 Lines—Why Are the Others So Bloated? 🤯 with +216 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/)\nEvery LLM framework we looked at felt **unnecessarily complex**—massive dependencies, vendor lock-in, and features I’d never use. So we set out to see: **How simple can an LLM framework actually be?**\n\n🔗 **Repo:** [PocketFlow](https://github.com/The-Pocket-World/Pocket-Flow-Framework)\n\n# Here’s Why We Stripped It Down:\n\n* **Forget OpenAI Wrappers** – APIs change, clients break, and vendor lock-in sucks. Just feed the docs to an LLM, and it’ll generate your wrapper.\n* **Flexibility** – No hard dependencies = easy swaps to open-source models like Mistral, Llama, or self-deployed models.\n* **Smarter Task Execution** – The entire framework is just a **nested directed graph**—perfect for **multi-step agents, recursion, and decision-making.**\n\n# What Can You Do With It?\n\n* Build  [multi-agent setups](https://the-pocket-world.github.io/Pocket-Flow-Framework/multi_agent/), [RAG](https://the-pocket-world.github.io/Pocket-Flow-Framework/rag/), and [task decomposition](https://the-pocket-world.github.io/Pocket-Flow-Framework/decomp/) with just a few tweaks.\n* Works with coding assistants like ChatGPT & Claude—just paste the docs, and they’ll generate workflows for you.\n* **Understand WTF is actually happening** under the hood, instead of dealing with black-box magic.\n\nWould love feedback and would love to know what features you would strip out—or add—to keep it minimal but powerful?\n\nhttps://preview.redd.it/qz9n33ga00le1.png?width=2118&format=png&auto=webp&s=2aeae0ea6633abe56ed0135edc00962a45d62680\n\nJoin our community! [https://discord.gg/b3DhyfCK](https://discord.gg/b3DhyfCK)\n\n## Comment ID meh1kow with +37 score by [(Kimononono, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meh1kow/) (in reply to ID 1iwrhuu):\ni remember finding this crawling github. It stuck out to me how much longer the docs were than the actual code. Made me compare me how libraries like LangChain typically subclass and abstract the core to provide specific patterns / strategies while treating documentation / usage as an afterthought. Here, the documentation itself forms the abstraction and is the focus; the actual subclassing/implementation is left to the user.\n\n### Comment ID meh1zqh with +6 score by [(Kimononono, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meh1zqh/) (in reply to ID meh1kow):\nreminds me of shadcn now. How it basically does the same thing as historical component libraries but without the abstraction. Think it’d be helpful to build your own set of premade components using your core. Providing the same functionality but without people complaining about how unusable the library is since you never actual abstract away the implementations\n\n#### Comment ID meiegu7 with +2 score by [(qa_anaaq, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meiegu7/) (in reply to ID meh1zqh):\nInteresting comparison.\n\n### Comment ID meiwajs with +1 score by [(zipzapbloop, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meiwajs/) (in reply to ID meh1kow):\nWhich, honestly, is probably the way to go for a lot of things. Particularly systems that dont need to be sprawling codebases at all can probably be best specified in natural language, and pseudocode and then users with their long context coding assistants can generate the code specifically tailored to their needs.\n\n## Comment ID mehmkbk with +10 score by [(_pdp_, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mehmkbk/) (in reply to ID 1iwrhuu):\nI had a look at the code. You've built a simple state machine. State machine are almost aways the worst time of choice when it comes to composition. In other words organising everything in flows of Nodes while still writing code is worse then for example carefully providing the data structures yourself and deal with the concurrency and dataflow based on the application specific requirements.\n\nI will play around with it though. :)\n\n### Comment ID mej6acg with +3 score by [(visualagents, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mej6acg/) (in reply to ID mehmkbk):\nAgree and langgraph falls victim to similar flawed theory. Langgraph is a single thread of execution yet instead of just writing linear code that is easy to read it forces you into a graph/node contrivance without being event driven or parallel execution (the actual principles of a dataflow).\n\n#### Comment ID mejvw2n with +3 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejvw2n/) (in reply to ID mej6acg):\nWe actually do allow for parallel nodes and flows! For example, with you can use an AsyncParallelBatchNode to run execAsync() concurrently for each item—which is great for tasks like summarizing multiple texts simultaneously. \n\nWe also support an AsyncParallelBatchFlow, where sub-flows run in parallel with different parameters (e.g., processing multiple files concurrently). \n\nAlso wanted to note that the state machine structure still leverages async/await (and even Promise.all) to effectively overlap I/O operations. That being said, I am all ears for suggestions on making the dataflow more organically event-driven\n\n### Comment ID mejexez with +3 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejexez/) (in reply to ID mehmkbk):\nThanks for the feedback and example. I opted for a state machine for its simplicity! I'm open to finding a way to balance simple state transitions with tailored data structures though\n\n## Comment ID mejd863 with +6 score by [(LavishnessNo6243, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejd863/) (in reply to ID 1iwrhuu):\nI have to check it out. I’m building a layer on top of langchain that would be considered “bloated”, but it serializes all the objects, and uses common pydantic models for architectures, allowing a lot of cool manipulations post compile time. Will be posting online soon. \n\nCompletely agree with you on the modularity, and also build out models to build out models similar to this. Excited to check it out.\n\n### Comment ID mejwk2x with +1 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejwk2x/) (in reply to ID mejd863):\nThank you! Happy we agree on modularity approach and building models to build models - I think it really opens up possibilities for dynamic post-compilation manipulations!\n\n## Comment ID mehyh6d with +2 score by [(Traditional_Pipe9067, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mehyh6d/) (in reply to ID 1iwrhuu):\nchecked the repo, that's cool work\n\n### Comment ID mejfcav with +1 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejfcav/) (in reply to ID mehyh6d):\nThank you!!\n\n## Comment ID mehzlvm with +2 score by [(None, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mehzlvm/) (in reply to ID 1iwrhuu):\n[removed]\n\n### Comment ID mejfet6 with +1 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejfet6/) (in reply to ID mehzlvm):\nThanks so much and yes this will stay with MIT license\n\n## Comment ID meis3cy with +2 score by [(solilobee, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meis3cy/) (in reply to ID 1iwrhuu):\ncommenting to explore this later\\~\n\n### Comment ID mejwn59 with +1 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejwn59/) (in reply to ID meis3cy):\nThank you!\n\n## Comment ID mej2wai with +2 score by [(R-e-d_R-u-m, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mej2wai/) (in reply to ID 1iwrhuu):\nRemind me! 1 day\n\n### Comment ID mej330n with +1 score by [(RemindMeBot, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mej330n/) (in reply to ID mej2wai):\nI will be messaging you in 1 day on [**2025-02-25 15:21:46 UTC**](http://www.wolframalpha.com/input/?i=2025-02-25%2015:21:46%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mej2wai/?context=3)\n\n[**3 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLangChain%2Fcomments%2F1iwrhuu%2Fi_built_an_llm_framework_in_179_lineswhy_are_the%2Fmej2wai%2F%5D%0A%0ARemindMe%21%202025-02-25%2015%3A21%3A46%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201iwrhuu)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|\n\n## Comment ID meowht4 with +2 score by [(Ok-Radish-8394, Reddit, 2025-02-25)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meowht4/) (in reply to ID 1iwrhuu):\nMost llm frameworks are an unnecessary mess of abstractions. You don’t need to have 5 base classes for simple api wrapper property. And don’t get me started on the complexity of the documentation for this. \n\nPeople moved from Java only to do worse in the abstractions department.\n\n## Comment ID meyos8n with +2 score by [(Echo9Zulu-, Reddit, 2025-02-26)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meyos8n/) (in reply to ID 1iwrhuu):\nIt might be really cool to build a robotics workflow using Magma with Pocketflow. \n\nPerhaps using graphs to organize different control schemes for different functions, combined with something inspired by CodeAgent from smolagents where the agent defines its own tools, could yield a seriously potent robotics agent for different kinds of operating scenarios. Maybe even having a stronger model for different tasks controlling a Magma in a round Robin like loop. \n\nI don't know typescript yet so I can't comment on how significant the 179 lines are. The insight about nested directed graphs is excellent. It's the same insight which inspired exposing only the conversation dict in my project [OpenArc](https://github.com/SearchSavior/OpenArc) since that's the meat of what an LLM engine for building agents should require. Other projects which break the system prompt into it's own field baffles me. \n\nYou mentioned using the documentation to build out larger design patterns with llms. I am curious to know how you are thinking about building out more tooling for PocketFlow. It reminds me of how llms often will hack things together with standard python libraries to match my intention even if better tools exist... do you think PocketFlow could be prompt extendable, that it's contribution might come from it's design pattern over the actual implementation?\n\nJust a brain dump. Cool project!!!\n\n### Comment ID mf0d72d with +3 score by [(Weak_Birthday2735, Reddit, 2025-02-27)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mf0d72d/) (in reply to ID meyos8n):\nLove this brain dump! A Magma + Pocketflow robotics workflow sounds powerful. Using graphs to organize control schemes and combining it with CodeAgent, where the agent defines its own tools, could make for a super adaptable robotics system. The round-robin idea with stronger models for different tasks is also really interesting—almost like a team of specialized agents coordinating dynamically.\n\nTotally with you with your OpenArc approach of exposing just the conversation dict.\n\nFor future tooling, I’m thinking about:\n\n1. Self-modifying agents – Agents should be able to create and refine their own tools inside a PocketFlow pipeline.\n2. Better multi-agent coordination – Especially for robotics, where different models can specialize and work together.\n\nAnd yes to prompt-extendable workflows / letting LLMs modify their own structure - we need a flexible way to structure LLM workflows so that they can evolve as tools emerge\n\n## Comment ID mf8c2hn with +2 score by [(zvictord, Reddit, 2025-02-28)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mf8c2hn/) (in reply to ID 1iwrhuu):\nIf you want this to be considered for serious use I see 2 main lacking points:\n\n* it needs to be importable from a registry\n* it needs an ` examples ` folder with examples ranging from basic to full fledged applications\n\n## Comment ID mf9z7gh with +2 score by [(EternityForest, Reddit, 2025-02-28)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mf9z7gh/) (in reply to ID 1iwrhuu):\nWhat's the advantage of the minimalism when LLMs themselves are so heavy? Does it help make more efficient use of them with fewer tokens?\n\n## Comment ID meha249 with +1 score by [(Signal-Indication859, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meha249/) (in reply to ID 1iwrhuu):\nk, I get the appeal of simplicity in LLM frameworks; complexity adds friction. However, if you think you need something lighter and more flexible, look into making it compatible with more data sources. Also, consider an easier approach for onboarding new users—could help minimize the learning curve. \n\nIf you ever feel like jugglling too many frameworks, preswald might be worth checking out\n\n### Comment ID mejybe9 with +1 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejybe9/) (in reply to ID meha249):\nYes we will make onboarding easier and preswald is great!\n\n#### Comment ID meojwfz with +1 score by [(Signal-Indication859, Reddit, 2025-02-25)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meojwfz/) (in reply to ID mejybe9):\nthank you!!!\n\n## Comment ID meiebnq with +1 score by [(Deadaelus83, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meiebnq/) (in reply to ID 1iwrhuu):\nLooked at your code, first off, well done for building something that solves a problem. \n\nMy question is, how is this different to the approach LangGraph took?\n\n### Comment ID mejzjzy with +2 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mejzjzy/) (in reply to ID meiebnq):\nWe think LangGraph’s approach can feel rigid and tends to enforce a strictly linear, single-threaded execution model! We also want to do more than just manage state transitions!! \n\nFor example, we can handle asynchronous capabilities—like node cloning to avoid race conditions and dedicated AsyncParallelBatchNodes and AsyncParallelBatchFlows—to enable parallel execution. This means you can run I/O-bound tasks concurrently (such as multiple LLM calls) without being restricted to a single-threaded, linear flow. \n\nALSO - we have made sure to not lock users into app-specific or vendor-specific models! \n\nhttps://preview.redd.it/zprvgifil4le1.png?width=1574&format=png&auto=webp&s=433e881f249fa13b58e387218c99909f793f2887\n\n#### Comment ID midruve with +1 score by [(Deepshark7822, Reddit, 2025-03-18)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/midruve/) (in reply to ID mejzjzy):\nHi. Can you please share the link of this paper. I will read it.\n\n## Comment ID meksdwn with +1 score by [(Mindless_Swimmer1751, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meksdwn/) (in reply to ID 1iwrhuu):\nDo you have LLM friendly docs? The docs are a bit opaque so I’d love to throw this into O1, give it an end goal, and then say : build this using this specific framework. Similar to svelte5 LLM friendly doc format https://svelte.dev/docs/llms  ie llms.txt\n\n### Comment ID mel6a92 with +3 score by [(Weak_Birthday2735, Reddit, 2025-02-24)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mel6a92/) (in reply to ID meksdwn):\nYes! Happy to work on that!\n\n## Comment ID mengxbu with +1 score by [(BoulderTennisGuy, Reddit, 2025-02-25)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mengxbu/) (in reply to ID 1iwrhuu):\nCommented\n\n## Comment ID menq1rb with +1 score by [(Bubbly_Lengthiness22, Reddit, 2025-02-25)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/menq1rb/) (in reply to ID 1iwrhuu):\nBasically what one really needs to do is just the observer pattern and done\n\n## Comment ID meo3twj with +1 score by [(brian920128, Reddit, 2025-02-25)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meo3twj/) (in reply to ID 1iwrhuu):\ndoes it have page attention implemented\n\n## Comment ID meqkgoh with +1 score by [(ericbureltech, Reddit, 2025-02-25)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/meqkgoh/) (in reply to ID 1iwrhuu):\nNice work! I am glad that many AI developers are coming from the JavaScript ecosystem (at least in my local area) : we know a bit about frameworks :')\n\nHowever as a professional trainer, I still have a few points in favor of frameworks:  \n\\- Getting a job. Frameworks being used as skills labels is a bad thing but that's how it works until we have something better. People need to pay the rent.  \n\\- Helps you staying focused when implementing your apps. Most people just want a simple RAG or chatbot, and want the framework to help them if they suddenly want something fancier. Custom development may involve human resources and skills that most companies don't have.  \n\\- A good framework can feel good ! I don't find LangChain too intrusive, in the sense that you can eg use basic chains within for loops and call it a day, I haven't even started to explore LangGraph\n\n## Comment ID mfly55i with +1 score by [(deustamorto, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mfly55i/) (in reply to ID 1iwrhuu):\nIs this a fork of the [python version](https://www.reddit.com/r/LangChain/comments/1hsq6ac/i_built_an_llm_framework_in_just_100_lines/)?\n\n### Comment ID mfmqei3 with +1 score by [(Weak_Birthday2735, Reddit, 2025-03-02)](https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/mfmqei3/) (in reply to ID mfly55i):\nThis is the official one that we will take to prod!",
      "# Post ID 1jkdsk5: Build Your Own AI Memory – Tutorial For Dummies with +6 score by [(No_Plane3723, Reddit, 2025-03-26)](https://www.reddit.com/r/LLMDevs/comments/1jkdsk5/build_your_own_ai_memory_tutorial_for_dummies/)\nHey folks! I just published a quick, beginner friendly tutorial showing how to build an AI memory system from scratch. It walks through:\n\n* Short-term vs. long-term memory\n* How to store and retrieve older chats\n* A minimal implementation with a simple self-loop you can test yourself\n\nNo fancy jargon or complex abstractions—just a friendly explanation with sample code using [PocketFlow](https://github.com/The-Pocket/PocketFlow), a 100-line framework. If you’ve ever wondered how a chatbot remembers details, check it out!\n\n[https://zacharyhuang.substack.com/p/build-ai-agent-memory-from-scratch](https://zacharyhuang.substack.com/p/build-ai-agent-memory-from-scratch)\n\n## Comment ID mjzk8f1 with +1 score by [(noellarkin, Reddit, 2025-03-27)](https://www.reddit.com/r/LLMDevs/comments/1jkdsk5/build_your_own_ai_memory_tutorial_for_dummies/mjzk8f1/) (in reply to ID 1jkdsk5):\nI was going through the pocketflow repo yesterday, I love how you've managed to create the agent framework from first principles. Excellent work.\n\n### Comment ID mk0mb8g with +1 score by [(No_Plane3723, Reddit, 2025-03-27)](https://www.reddit.com/r/LLMDevs/comments/1jkdsk5/build_your_own_ai_memory_tutorial_for_dummies/mk0mb8g/) (in reply to ID mjzk8f1):\nThank you",
      "# Post ID 1j2yok2: I used a 100-line LLM Framework to let AI Agents build Agents for me (Step-by-Step Video Tutorial) with +70 score by [(Willing-Site-8137, Reddit, 2025-03-04)](https://www.reddit.com/r/PromptEngineering/comments/1j2yok2/i_used_a_100line_llm_framework_to_let_ai_agents/)\nI made a video tutorial on a personal hack that can let Cursor AI build complex LLM Agents and greatly improve my productivity : [https://youtu.be/wc9O-9mcObc](https://youtu.be/wc9O-9mcObc)\n\nFor example, in this tutorial, I mostly write the high-level design doc, and Cursor AI handles all the implementation and coding to build an [AI YouTube Summarizer](https://github.com/The-Pocket/Tutorial-Youtube-Made-Simple). The secret is [Pocket Flow](https://github.com/The-Pocket/PocketFlow), a 100-line framework that fits easily into Cursor’s [rules](https://docs.cursor.com/context/rules-for-ai), remains flexible for all sorts of designs, and nudges Cursor to follow good coding practices.\n\n**Background of 100-line framework**\n\nI built this [100-line LLM framework](https://github.com/The-Pocket/PocketFlow) over Christmas. It provides the core “graph abstraction” that LLM workflows need—for ([multi-](https://the-pocket.github.io/PocketFlow/design_pattern/multi_agent.html))[agents](https://the-pocket.github.io/PocketFlow/design_pattern/agent.html), [Retrieval-Augmented Generation (RAG)](https://the-pocket.github.io/PocketFlow/design_pattern/rag.html), [workflow](https://the-pocket.github.io/PocketFlow/design_pattern/workflow.html), and more. I built this because:\n\n1. Most big frameworks have *messy abstractions*, deprecated methods, and annoying dependencies that are very hard to use.\n2. These issues don’t just confuse humans; they confuse AI coding assistants as well! For example, if you let *Cursor AI* build a LLM project with those frameworks, you’ll likely run into a bunch of version or deprecation errors.\n\nSo I stripped everything down to **100 lines**, making it easy for AI tools (like *Cursor AI*) to read and build on top of it as “rules.” Surprisingly, **Cursor understands Pocket Flow really well**\\-its generated code is modular, maintainable, and has *greatly boosted my productivity* over the past year.\n\n**Demo in the YouTube Video**\n\nTo demonstrate this further, I made [this *YouTube video*](https://www.youtube.com/watch?v=wc9O-9mcObc) showing exactly how I fed *Cursor AI* the **Pocket Flow** docs and a high-level design to build LLM apps. I asked *Cursor AI* to create a [YouTube “explainer” agent ](https://github.com/The-Pocket/Tutorial-Youtube-Made-Simple)that summarizes long videos into *simple “5-year-old-friendly” terms*—for instance, it can condense Lex Fridman’s *5-hour DeepSeek* interview into a [concise, sharp summary](https://the-pocket.github.io/Tutorial-Youtube-Made-Simple/examples/DeepSeek%2C%20China%2C%20OpenAI%2C%20NVIDIA%2C%20xAI%2C%20TSMC%2C%20Stargate%2C%20and%20AI%20Megaclusters%20%7C%20Lex%20Fridman%20Podcast%20%23459.html). The entire development took me *less than an hour*—and you can do the same!\n\nI’m very new to YouTube, so *please, please, please* give me your feedback on which parts are unclear! If there’s another LLM project you’d like to see me build with Pocket Flow + Cursor, let me know!\n\n## Comment ID mfwt77x with +12 score by [(lgastako, Reddit, 2025-03-04)](https://www.reddit.com/r/PromptEngineering/comments/1j2yok2/i_used_a_100line_llm_framework_to_let_ai_agents/mfwt77x/) (in reply to ID 1j2yok2):\nJust my 2 cents worth of advice: I know you are proud of it, and it probably does a lot in 100 lines, but I think you should stop emphasizing the fact that it's 100 lines and you wrote it over Christmas.  I suspect this is more likely to make people think \"this person doesn't know what they are doing and they are wasting my time\" than \"wow I should really check that out\".  \n\nInstead I would suggest focusing more on the value that it provides, especially as compared to other frameworks.   \n\neg. The reason lang chain sucks is not that it's many lines of code, it's that it's simultaneously over and under engineered and the result is having to understand and assemble a big pile of poorly documented abstractions all piled on top of each other to do even relatively simple tasks.  If these are the users you want to lure to your framework then you should focus on how few lines of code it takes and how straightforward it is to accomplish some of these tasks using your framework, not how many lines of code the framework itself is.\n\n### Comment ID mfwu85q with +2 score by [(Willing-Site-8137, Reddit, 2025-03-04)](https://www.reddit.com/r/PromptEngineering/comments/1j2yok2/i_used_a_100line_llm_framework_to_let_ai_agents/mfwu85q/) (in reply to ID mfwt77x):\nGreat advice! I do want to emphasize the 100-line limit because otherwise it's a bit hard to differentiate from, for example, smolagents—which has thousands of lines and a dependency size of 200 MB (for Hugging Face). I totally agree that the value needs to be much better articulated. Thank you!",
      "# Post ID 1ibb7ui: I Built an Agent Framework in just 100 Lines!! with +12 score by [(Willing-Site-8137, Reddit, 2025-01-27)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/)\nI’ve seen a lot of frustration around complex Agent frameworks like LangChain. Over the holidays, I challenged myself to see how small an Agent framework could be if we removed every non-essential piece. The result is **PocketFlow**: a 100-line LLM agent framework for what truly matters. Check it out here: [GitHub Link](https://github.com/the-pocket/PocketFlow/)\n\n***Why Strip It Down?***\n\n*Complex Vendor or Application Wrappers Cause Headaches*\n\n* *Hard to Maintain:* Vendor APIs evolve (e.g., OpenAI introduces a new client after 0.27), leading to bugs or dependency issues.\n* *Hard to Extend:* Application-specific wrappers often don’t adapt well to your unique use cases.\n\n*We Don’t Need Everything Baked In*\n\n* *Easy to DIY (with LLMs):* It’s often easier just to build your own up-to-date wrapper—an LLM can even assist in coding it when fed with documents.\n* *Easy to Customize:* Many advanced features (multi-agent orchestration, etc.) are nice to have but aren’t always essential in the **core** framework. Instead, the **core** should focus on fundamental primitives, and we can layer on tailored features as needed.\n\nThese 100 lines capture what I see as the core abstraction of most LLM frameworks: a nested directed graph that breaks down tasks into multiple LLM steps, with branching and recursion to enable agent-like decision-making. From there, you can:\n\n**Layer on Complex Features (When You Need Them)**\n\n* [Single-Agent](https://the-pocket.github.io/PocketFlow/design_pattern/agent.html)\n* [Multi-Agent Collaboration](https://the-pocket.github.io/PocketFlow/design_pattern/multi_agent.html)\n* [Retrieval-Augmented Generation (RAG)](https://the-pocket.github.io/PocketFlow/design_pattern/rag.html)\n* [Task Decomposition](https://the-pocket.github.io/PocketFlow/design_pattern/workflow.html)\n* Or any other feature you can dream up!\n\nBecause the codebase is tiny, it’s easy to see where each piece fits and how to modify it without wading through layers of abstraction.\n\nI’m adding more examples and would love feedback. If there’s a feature you’d like to see or a specific use case you think is missing, please let me know!\n\n## Comment ID m9ietgf with +2 score by [(enpap_x, Reddit, 2025-01-27)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9ietgf/) (in reply to ID 1ibb7ui):\nv cool, congrats.  would it be a big jump to ingest JSON style RAGs?\n\n### Comment ID m9izdwb with +1 score by [(Willing-Site-8137, Reddit, 2025-01-27)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9izdwb/) (in reply to ID m9ietgf):\nThanks! What do you mean by JSON style RAGs?\n\n#### Comment ID m9rij96 with +1 score by [(enpap_x, Reddit, 2025-01-29)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9rij96/) (in reply to ID m9izdwb):\nI have an application that generates JSON documents for the AI to ingest.  I am working mainly with the DATABRICKS platform and it supports these documents.  Interested in your framework as a alternative for smaller installs where the enterprise solutions are not really needed.  Some background reading on JSON RAG ingestion:  [https://medium.com/@glenpatzlaff/raw-json-to-measurable-rag-insights-in-a-matter-of-minutes-with-langchain-and-trulens-f36e4415b079](https://medium.com/@glenpatzlaff/raw-json-to-measurable-rag-insights-in-a-matter-of-minutes-with-langchain-and-trulens-f36e4415b079)\n\n## Comment ID m9ku5y3 with +1 score by [(AdditionalWeb107, Reddit, 2025-01-28)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9ku5y3/) (in reply to ID 1ibb7ui):\nHave we completely run out of ideas ? Everyone is building frameworks.\n\n### Comment ID m9kv98h with +3 score by [(Willing-Site-8137, Reddit, 2025-01-28)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9kv98h/) (in reply to ID m9ku5y3):\nThe real reason I built this was that I didn’t want to learn LangChain, LangGraph, CrewAI, etc  because they looked complex. But I worried miss out on something. \n\nIt turns out I’m not missing anything—the complexity really isn’t necessary.\n\n### Comment ID m9kunkd with +2 score by [(Willing-Site-8137, Reddit, 2025-01-28)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9kunkd/) (in reply to ID m9ku5y3):\nLOL I feel you.\n\n## Comment ID m9mtbnl with +1 score by [(Matematikis, Reddit, 2025-01-28)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9mtbnl/) (in reply to ID 1ibb7ui):\nIn JS you could write it in 1 line, maybe next project?\n\n### Comment ID m9nikom with +1 score by [(Willing-Site-8137, Reddit, 2025-01-28)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9nikom/) (in reply to ID m9mtbnl):\nLOL I also hope it is readable\n\n## Comment ID m9q6i39 with +1 score by [(Appropriate-Bet-3655, Reddit, 2025-01-28)](https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/m9q6i39/) (in reply to ID 1ibb7ui):\nThis looks great!! I did the same not under 100 lines though but the idea is to give developers the control https://github.com/axar-ai/axar",
      "# Post ID 1jjlk7c: Build Your Own AI Memory – Tutorial For Dummies with +74 score by [(Willing-Site-8137, Reddit, 2025-03-25)](https://www.reddit.com/r/LocalLLaMA/comments/1jjlk7c/build_your_own_ai_memory_tutorial_for_dummies/)\nHey folks! I just published a quick, beginner friendly tutorial showing how to build an AI memory system from scratch. It walks through:\n\n* Short-term vs. long-term memory\n* How to store and retrieve older chats\n* A minimal implementation with a simple self-loop you can test yourself\n\nNo fancy jargon or complex abstractions—just a friendly explanation with sample code using [PocketFlow](https://github.com/The-Pocket/PocketFlow), a 100-line framework. If you’ve ever wondered how a chatbot remembers details, check it out!\n\n[https://zacharyhuang.substack.com/p/build-ai-agent-memory-from-scratch](https://zacharyhuang.substack.com/p/build-ai-agent-memory-from-scratch)\n\n## Comment ID mjpog59 with +3 score by [(FrostyContribution35, Reddit, 2025-03-25)](https://www.reddit.com/r/LocalLLaMA/comments/1jjlk7c/build_your_own_ai_memory_tutorial_for_dummies/mjpog59/) (in reply to ID 1jjlk7c):\nSaved for later\n\n### Comment ID mjpwq49 with +3 score by [(Willing-Site-8137, Reddit, 2025-03-25)](https://www.reddit.com/r/LocalLLaMA/comments/1jjlk7c/build_your_own_ai_memory_tutorial_for_dummies/mjpwq49/) (in reply to ID mjpog59):\nThank you!!"
    ],
    "sources": {
      "steam_url": null,
      "steam_reviews": null,
      "google_play_url": null,
      "google_play_reviews": null,
      "apple_store_url": null,
      "apple_reviews": null,
      "reddit_urls": [
        "https://www.reddit.com/r/AI_Agents/comments/1i5tjd0/i_built_an_agent_framework_in_just_100_lines/",
        "https://www.reddit.com/r/LangChain/comments/1iyy610/i_built_an_opensource_llm_app_that_eli5_youtube/",
        "https://www.reddit.com/r/LangChain/comments/1j1gb88/why_are_developers_moving_away_from_langchain/",
        "https://www.reddit.com/r/AI_Agents/comments/1jkv8dc/i_reverseengineered_claude_code_cursor_ai_agents/",
        "https://www.reddit.com/r/AI_Agents/comments/1ix3fla/video_tutorial_100_lines_to_let_cursor_ai_build/",
        "https://www.reddit.com/r/LangChain/comments/1iwrhuu/i_built_an_llm_framework_in_179_lineswhy_are_the/",
        "https://www.reddit.com/r/LLMDevs/comments/1jkdsk5/build_your_own_ai_memory_tutorial_for_dummies/",
        "https://www.reddit.com/r/PromptEngineering/comments/1j2yok2/i_used_a_100line_llm_framework_to_let_ai_agents/",
        "https://www.reddit.com/r/LLMDevs/comments/1ibb7ui/i_built_an_agent_framework_in_just_100_lines/",
        "https://www.reddit.com/r/LocalLLaMA/comments/1jjlk7c/build_your_own_ai_memory_tutorial_for_dummies/"
      ],
      "reddit_search_url": "https://www.google.com/search?q=site%3Areddit.com+%22Pocketflow%22+related%3Apocketflow.dev+"
    }
  },
  "glassdoor_result": null,
  "news_result": [
    [
      "Pocketflow",
      "Pocketflow",
      "pocketflow.dev",
      null,
      false,
      false,
      null,
      [
        false,
        false
      ]
    ],
    [
      {
        "title": "(PDF) PocketFlow is a data-and-knowledge-driven structure-based ...",
        "link": "https://www.researchgate.net/publication/378874436_PocketFlow_is_a_data-and-knowledge-driven_structure-based_molecular_generative_model",
        "snippet": "Dec 9, 2024 ... PocketFlow is a useful deep generative model, capable of generating innovative bioactive molecules from scratch given a protein binding pocket.",
        "formattedUrl": "https://www.researchgate.net/.../378874436_PocketFlow_is_a_data-and-kn..."
      },
      {
        "title": "Build AI Agent Memory From Scratch — Tutorial For Dummies - DEV ...",
        "link": "https://dev.to/zachary62/build-ai-agent-memory-from-scratch-tutorial-for-dummies-47ma",
        "snippet": "5 days ago ... Great news: it's way easier than you think! In this super-friendly guide, you ... For this guide, we'll use PocketFlow - a tiny framework (just 100 lines!)",
        "formattedUrl": "https://dev.to/.../build-ai-agent-memory-from-scratch-tutorial-for-dummies-..."
      },
      {
        "title": "Deep active learning with high structural discriminability for ...",
        "link": "https://www.nature.com/articles/s42003-024-06758-6",
        "snippet": "Aug 31, 2024 ... PocketFlow is a data-and-knowledge-driven structure-based molecular ... We argue that this phenomenon may be related to the samples selected in the ...",
        "formattedUrl": "https://www.nature.com/articles/s42003-024-06758-6"
      },
      {
        "title": "Why Developers Are Not Using LangChain anymore",
        "link": "https://content.techgig.com/technology/why-developers-are-not-using-langchain/articleshow/118705898.cms",
        "snippet": "Mar 5, 2025 ... They find better alternatives like PydanticAI and PocketFlow more reliable and user-friendly, opting to build their own stacks instead. LangChain needs ...",
        "formattedUrl": "https://content.techgig.com/technology/why...are-not.../118705898.cms"
      },
      {
        "title": "Efficient generation of protein pockets with PocketGen | Nature ...",
        "link": "https://www.nature.com/articles/s42256-024-00920-9",
        "snippet": "Nov 15, 2024 ... Related research has explored the co-design of sequence and structure in ... PocketFlow is a data-and-knowledge-driven structure-based molecular ...",
        "formattedUrl": "https://www.nature.com/articles/s42256-024-00920-9"
      },
      {
        "title": "New algorithm for functional protein design outperforms traditional ...",
        "link": "https://phys.org/news/2024-12-algorithm-functional-protein-outperforms-traditional.html",
        "snippet": "Dec 9, 2024 ... PocketGen builds on previous works FAIR and PocketFlow and consists of two core components. First is a dual-layer graph Transformer encoder inspired by ...",
        "formattedUrl": "https://phys.org/news/2024-12-algorithm-functional-protein-outperforms-tr..."
      },
      {
        "title": "Why Developers are Quitting LangChain",
        "link": "https://analyticsindiamag.com/ai-features/why-developers-are-quitting-langchain/",
        "snippet": "Mar 3, 2025 ... However, just like LangChain, PydanticAI also faces similar issues. Another emerging alternative is PocketFlow, which aims to provide a more modular and ...",
        "formattedUrl": "https://analyticsindiamag.com/ai.../why-developers-are-quitting-langchain/"
      },
      {
        "title": "Landscape of High-Performance Python to Develop Data Science ...",
        "link": "https://dl.acm.org/doi/10.1145/3617588",
        "snippet": "May 13, 2024 ... ... related domains. But to our knowledge, we propose the first survey of ... Used by other libraries and software such as H5py, vtk, dask, and PocketFlow.",
        "formattedUrl": "https://dl.acm.org/doi/10.1145/3617588"
      },
      {
        "title": "Leveraging Advanced RAG Techniques for Knowledge ...",
        "link": "https://medium.com/@nabilw/leveraging-advanced-rag-techniques-for-knowledge-management-and-ai-development-e442ac74ff8f",
        "snippet": "May 1, 2024 ... Cursor and PocketFlow: The Minimalist Duo Revolutionizing Coding Today. We're ... How to create an MPC Server that brings news from a web site with Claude Desktop ...",
        "formattedUrl": "https://medium.com/.../leveraging-advanced-rag-techniques-for-knowledge..."
      },
      {
        "title": "Untitled",
        "link": "https://epoch.ai/data/all_ai_models.csv",
        "snippet": "Mar 17, 2025 ... ... news/mistral-small-3-1,,,,,,,,,,,,,,,,,,,,,,,,Unverified,2025-03-18 15 ... PocketFlow,Biology,\"University of Science and Technology of China,State Key ...",
        "formattedUrl": "https://epoch.ai/data/all_ai_models.csv"
      },
      {
        "title": "starred/README.md at master · gaahrdner/starred · GitHub",
        "link": "https://github.com/gaahrdner/starred/blob/master/README.md",
        "snippet": "Jul 15, 2024 ... dwisiswant0/siml - siml is a CLI tool for discovering similar, related to, competitive, or alternative options to a given site. ... Tencent/PocketFlow - An ...",
        "formattedUrl": "https://github.com/gaahrdner/starred/blob/master/README.md"
      },
      {
        "title": "The Collective",
        "link": "https://tympanus.net/codrops/news/",
        "snippet": "1 day ago ... A beginner-friendly tutorial demystifying LLM agents, explaining them as simple graphs with decision loops, using PocketFlow for clear, hands-on learning.",
        "formattedUrl": "https://tympanus.net/codrops/news/"
      },
      {
        "title": "How to Make Notice on Absa App | TikTok",
        "link": "https://www.tiktok.com/discover/how-to-make-notice-on-absa-app",
        "snippet": "5 days ago ... 101.2K1w ago. tsholorabotsho. Tsholo Rabotsho. The voice behind Absa's new PocketFlow ad. ... related to the challenge. Why Are Hashtags for TikTok Important ...",
        "formattedUrl": "https://www.tiktok.com/discover/how-to-make-notice-on-absa-app"
      },
      {
        "title": "awesome-azure-openai-llm/README_all_in_one.md at main ...",
        "link": "https://github.com/kimtth/awesome-azure-openai-llm/blob/main/README_all_in_one.md",
        "snippet": "Mar 12, 2025 ... This repository contains references to Azure OpenAI, Large Language Models (LLM), and related services and libraries. ... PocketFlow: Minimalist LLM Framework in ...",
        "formattedUrl": "https://github.com/kimtth/awesome-azure.../README_all_in_one.md"
      },
      {
        "title": "Artificial intelligence enabled smart design and manufacturing of ...",
        "link": "https://onlinelibrary.wiley.com/doi/full/10.1002/mgea.56",
        "snippet": "Jul 16, 2024 ... PocketFlow generating novel ligand molecules inside protein binding pockets is a data-and-knowledge-driven structure-based molecular generative model, which ...",
        "formattedUrl": "https://onlinelibrary.wiley.com/doi/full/10.1002/mgea.56"
      },
      {
        "title": "h1alexbel/sr-texts · Datasets at Hugging Face",
        "link": "https://huggingface.co/datasets/h1alexbel/sr-texts/viewer/default/train?p=1",
        "snippet": "Aug 31, 2024 ... | | | PocketFlow | use AutoML to do model compression. | | | TensorFlow ... related to Flutter development or participate in the development of JHenTai.",
        "formattedUrl": "https://huggingface.co/datasets/h1alexbel/sr-texts/viewer/default/train?p..."
      },
      {
        "title": "A structure-based framework for selective inhibitor design and ...",
        "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11903766/",
        "snippet": "Mar 12, 2025 ... ... related targets and the generation of dual-target inhibitors. In both cases ... PocketFlow is a data-and-knowledge-driven structure-based molecular ...",
        "formattedUrl": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11903766/"
      },
      {
        "title": "Bank Confirmation Letter from Absa Bank | TikTok",
        "link": "https://www.tiktok.com/discover/bank-confirmation-letter-from-absa-bank",
        "snippet": "5 days ago ... 49 Likes, TikTok video from IOL NEWS (@iolnews): “IOL NEWS. 84551w ago ... The voice behind Absa's new PocketFlow ad. #tsholorabotsho #trending #fyp.",
        "formattedUrl": "https://www.tiktok.com/discover/bank-confirmation-letter-from-absa-bank"
      },
      {
        "title": "Obsidian-node-canvas Alternatives and Reviews",
        "link": "https://www.libhunt.com/r/obsidian-node-canvas",
        "snippet": "8 days ago ... Your docs would be more readable if you made the code blocks just wide enough so that the lines don't wrap. pocketflow.ai/ whitepaper link is 404ing btw.| ...",
        "formattedUrl": "https://www.libhunt.com/r/obsidian-node-canvas"
      },
      {
        "title": "Junzhou Huang",
        "link": "https://ranger.uta.edu/~huang/Publication.htm",
        "snippet": "Nov 30, 2024 ... [152] Jiaxiang Wu, Yao Zhang, Haoli Bai, Huasong Zhong, Jinlong Hou, Wei Liu, Wenbing Huang and Junzhou Huang, \"PocketFlow: An Automated Framework for ...",
        "formattedUrl": "https://ranger.uta.edu/~huang/Publication.htm"
      }
    ],
    [
      "# [Build AI Agent Memory From Scratch — Tutorial For Dummies by Zachary Huang on 2025-03-24](https://dev.to/zachary62/build-ai-agent-memory-from-scratch-tutorial-for-dummies-47ma)\nEver wondered why some chatbots remember your name days later, while others forget what you said 5 minutes ago? This guide explains AI memory in super simple terms - no tech background needed!\n\nHave you ever told a chatbot your name, only for it to ask again in the same conversation? Or been surprised when it remembered your birthday weeks later? Let's break down how AI memory actually works - the simple truth!\n\nGreat news: it's way easier than you think! In this super-friendly guide, you'll discover:\n\nThe shockingly simple trick behind AI memory\n\nHow chatbots keep track of what you've told them\n\nWhy good memory makes the difference between helpful and frustrating AI\n\nFor this guide, we'll use PocketFlow - a tiny framework (just 100 lines!) that cuts through all the fancy jargon to show you how AI memory really works. While most tools hide all the important stuff under complicated code, PocketFlow puts everything right in front of you so you can actually understand it.\n\nWant to see the working code? You can check out and run the complete implementation at GitHub: PocketFlow Chat Memory.\n\nWhy Learn Memory with PocketFlow?\n\nMost AI tools are like pre-built furniture with hidden screws and hard-to-read instructions. PocketFlow is different - it's like a simple DIY starter kit with just 100 lines of code that includes only the essential tools you need to build something real and useful!\n\nWhat makes this perfect for learning:\n\nBasic tools only: Just the essential tools you actually need, not a confusing workshop full of advanced equipment\n\nClear instructions: Every step is visible and understandable, like a DIY tutorial with pictures for each step\n\nExpand at your own pace: Start simple, then add more advanced features when you're comfortable\n\nThat's it! Everything else is just details around these core concepts.\n\nThe Simple DIY Kit from PocketFlow\n\nImagine your AI as a bustling coffee shop. PocketFlow provides the following building blocks:\n\nNodes are like different stations (taking orders, checking recipes, brewing coffee, archiving receipts).\n\nFlow is like the daily routine that keeps each station running smoothly.\n\nShared Store is like your master order binder, keeping track of all current orders, recipes, and past receipts.\n\nIn our coffee shop system:\n\nEach station (Node) has three simple jobs:\n\nPrep: Gather what you need (like the right cup or recipe).\n\nExec: Perform the main task (like brewing the drink).\n\nPost: Update the binder and decide what to do next (like archiving an old receipt).\n\nThe shop's routine (Flow) moves between stations based on needs:\n\n\"If we need a recipe, look it up in the binder.\"\n\n\"If we have too many orders on the counter, move some receipts to the archive.\"\n\nWhat is Memory in Easy Terms?\n\nThink of AI memory like a simple note-taking system:\n\nShort-term memory: \"Sticky notes\" on your desk for recent info.\n\nLong-term memory: A \"filing cabinet\" for older info sorted by topic.\n\nRetrieval: Flipping through that cabinet to find what you need.\n\nJust as you'd forget details if you never wrote them down, an AI forgets unless it systematically stores and retrieves information. To handle lots of older messages without losing track, an AI might use embeddings or summaries: Imagine you have a box of vacation photos:\n\nEmbeddings are like giving each photo a \"fingerprint\" that captures what's in it—so later, if you search for \"beach,\" you can quickly pull out all the beach photos.\n\nSummaries work like writing \"cliff notes\" on the back of each picture (\"family at the beach in Maui\"), then reading those notes to decide which photo to grab.\n\nBoth methods help the AI skip flipping through every word, either by matching \"fingerprints\" (embeddings) or by checking short \"cliff notes\" (summaries) to instantly recall the details. In this tutorial, we will focus on embeddings.\n\nWant to see these methods in action? Frameworks like LangChain provide:\n\nConversation Buffer Window\n\nConversation Summary Memory\n\nVector Store Retriever Memory\n\nFeeling intimidated? No worries—we'll walk through simple examples with minimal runnable code in PocketFlow.\n\nHow to DIY Memory from Scratch?\n\nLet's break down what we need to build our memory system:\n\nSelf-Loop Flow: Think of this as the librarian's daily routine. They listen to questions, check references, answer patrons, and file away old materials—then start over with the next visitor.\n\nShared Store: Like the library's central information system, with both the open desk (short-term memory for current questions) and archive room (long-term memory for older topics).\n\nPicture a library customer service desk. It's a continuous loop where information flows between you, the librarian, and the archive shelves.\n\nQuestion Node: The front desk librarian jots down your question.\n\nRetrieve Node: The librarian checks the catalog and archived collections.\n\nAnswer Node: The librarian uses the found resources to help you.\n\nEmbed Node: The archivist who labels and files older notes.\n\nNo fancy math—just a neat loop that keeps all your conversations at your fingertips!\n\nBefore We Code: Let's Walk Through the Librarian Example\n\nLet's see how our \"librarian\" handles a real conversation over time:\n\nDay 1: You mention your pet\n\nYou tell the librarian: \"I have a golden retriever named Max who loves to play fetch.\"\n\nThe librarian jots this down in a \"current notes\" binder at the front desk.\n\nYou chat about a few other things.\n\nEventually, once there are too many notes, the librarian moves some details to the archive shelves in the back.\n\nTo make it easier to find later, the librarian files the note about \"golden retriever, Max, fetch\" under a special topic label (an \"embedding\").\n\nNow it's safely stored in the archive for long-term reference.\n\nA week later: You ask about your dog\n\nYou return and ask: \"What was my dog's name again?\"\n\nThe librarian writes your question down and assigns it a topic label.\n\nThey check the archive shelves for any labels matching \"dog,\" \"golden retriever,\" or \"Max.\"\n\nThey find the original note about your golden retriever, Max.\n\nThey bring that note to the front desk.\n\nThe librarian says: \"Your dog's name is Max. He's a golden retriever who loves to play fetch.\"\n\nIt feels like real remembering because:\n\nThe librarian initially organized your info before putting it away.\n\nThey used a topic-based label (embedding) for archiving.\n\nWhen you asked again, they looked up that label, retrieved the note, and combined it with your current question to give a complete answer.\n\nNow let's build such a librarian-inspired memory system from scratch!\n\nFollowing along with the code? You can find the complete working implementation of these memory components at GitHub: PocketFlow Chat Memory to explore the details.\n\nStep 1: Set Up the Shared Store\n\nThe Shared Store is our single \"source of truth\" for everything your AI needs to remember. It's where we keep both short-term details (like the most recent conversation) and long-term archives (where older chats get embedded and indexed).\n\nmessages: Acts like short-term memory, holding recent user and assistant messages.\n\nvector_index: A data structure (like a search index) for retrieving conversations by \"topic fingerprint.\"\n\nvector_items: A list of older, archived chats plus their embeddings, so they can be pulled back into the conversation.\n\nAll our Nodes (Question, Retrieve, Answer, Embed) will read and write from this dictionary, keeping everything in sync. That's the beauty of a single \"notebook\" for your AI's memory!\n\nStep 2: Define Each Node\n\na. Question Node – Receives user input and adds it to short-term memory\n\nFor the prep: Like a librarian opening a fresh notebook page. We create a place to store our conversation if none exists yet.\n\nFor the exec: Our librarian asks \"How can I help you?\" and waits for your question. If you say \"exit,\" we close up shop.\n\nFor the post: The librarian writes your question in the log book. If you said \"exit,\" we say goodbye. Otherwise, we save your message and move on to check our records.\n\nb. Retrieve Node – Searches the archives for relevant info\n\nFor the prep: Our librarian reads your latest question and checks if we have any archives to search. If either is missing, we skip this step.\n\nFor the exec: Our librarian creates a \"topic card\" for your question and searches the archives for the closest match – like finding which file cabinet might contain information about \"golden retrievers.\"\n\nFor the post: Our librarian keeps any relevant file they found on the desk. Either way, we proceed to formulating an answer.\n\nc. Answer Node – Combines new and old info to generate a response\n\nFor the prep: Our librarian gathers all needed resources: recent conversation notes and any relevant archived files, arranging them for easy reference.\n\nFor the exec: With all information at hand, our librarian crafts a thoughtful response that incorporates both recent and past knowledge.\n\nFor the post: Our librarian writes down their answer, then decides if it's time to archive older notes (if we have more than 6 messages) or just continue helping.\n\nd. Embed (Archive) Node – Moves older conversations into long-term memory\n\nFor the prep: If our desk is getting cluttered (more than 6 messages), our librarian takes the oldest conversation pair and prepares it for filing.\n\nFor the exec: Our librarian creates a label for the file by combining the conversation into one document and giving it a special \"topic fingerprint\" for easy retrieval later.\n\nFor the post: Our librarian files the labeled conversation in the archives, creating a filing system if needed, then returns to the front desk ready for the next question.\n\nStep 3. Connect the Nodes in a Self-Loop Flow\n\nNow let's make the system run by connecting each node into a self-loop flow and choosing a starting point:\n\nAs soon as we call chat_flow.run(shared), the system:\n\nEnters the Question Node (prep → exec → post).\n\nJumps to the node name returned by the post step (\"retrieve\").\n\nContinues through Retrieve, Answer, Embed as each node's post method dictates.\n\nKeeps looping until a node returns None (meaning it's time to stop)\n\nAll the Flow class does is respect these returns—once a node finishes its post, Flow calls the next node by name. If a node ever returns None, the entire conversation ends. That's our self-loop in action:\n\nQuestion → Retrieve → Answer → Embed → Question → ... → None (exit)\n\nThat's it! You now have a working self-loop where each node does its job—collecting user input, retrieving old chats, generating answers, and archiving older messages. Once you run this code, your AI will \"remember\" and \"forget\" just like a neatly organized notebook.\n\nStep 4. Run and Test\n\nReady to run this code? Here's how:\n\nSet up your API key:\n\nRun the application:\n\nHere's a simple example showing how your AI's memory works in practice:\n\nUser: \"Remember, my cat is Whiskers\"\n\nAssistant: \"Got it! I'll keep that in mind.\"\n\n(The system saves \"Whiskers\" to short-term memory.)\n\nUser: \"What's the weather today?\"\n\nAssistant: \"I don't have real-time info right now, but you can check a weather app!\"\n\n(This question doesn't impact memory storage.)\n\n...\n\nUser: \"What's my cat's name again?\"\n\nAssistant: \"Your cat's name is Whiskers.\"\n\n(The system pulls \"Whiskers\" from memory.)\n\nBehind the Scenes (Simplified):\n\nShort-Term stores recent info (like the cat's name).\n\nLong-Term archives older details once short-term gets full.\n\nFlow decides whether to use short-term or check long-term memory when you ask something.\n\nEven if you ask unrelated questions in between, the system can still recall \"Whiskers\" whenever you need it!\n\nAI Memory Demystified: The Simple Secret\n\nYou've now learned the straightforward secret behind AI memory. No fancy magic—just smart organization and looping processes. Here's what makes it tick:\n\nSelf-Loop Flow: A simple cycle that continuously handles your input, finds related past info, generates helpful answers, and archives older messages.\n\nShared Store: One organized place to hold both short-term (\"sticky notes\") and long-term (\"filing cabinet\") memory.\n\nMemory Retrieval: Quickly finding relevant conversations from the archives when needed.\n\nContextual Responses: Combining new questions and retrieved info to form meaningful answers.\n\nNext time you interact with an AI assistant that seems to \"remember\" things, you'll instantly recognize these simple ideas at work.",
      "# [Deep active learning with high structural discriminability for molecular mutagenicity prediction on 2024-08-31](https://www.nature.com/articles/s42003-024-06758-6)\nIn the field of modern drug discovery, mutagenicity has received great attention due to its high correlation with carcinogenicity and heritable variation1,2,3. Mutagenicity refers to permanent, transmissible changes in the quantity or structure of the genetic material of cells and organisms. These changes may occur in individual genes, gene clusters or entire chromosomes which can impact processes such as cell growth, differentiation, and apoptosis4,5. Many approved drugs have been withdrawn from the market because they have been identified as mutagens in humans or animals. A typical instance is furazolidone, it has been used to treat diarrhoea and enteritis caused by bacteria or protozoan infections, including traveler’s diarrhoea, cholera and bacteremic salmonellosis. However, Nitrofurans are recognized by The Food and Drug Administration as mutagens and carcinogens, and can no longer be used since 19916. Therefore, for new drugs, it is important to assess their mutagenicity which helps to evaluate their safety and potential risks, as well as provides a basis for toxicological assessment.\n\nOne of the most widely used methods for identifying the mutagenicity of chemicals is the Ames test1,7,8,9. However, due to the enormous number of molecules in chemical space, it is practically impossible to test every molecule for its mutagenicity using experimental methods. As an alternative, in silico methods have gained significant attention for predicting mutagenicity before clinical drug development trials10,11,12. Researchers have proposed some deep learning methods aimed at accurately predicting molecular mutagenicity13,14,15,16,17,18,19. However, since traditional mutagenicity prediction methods usually train the entire neural network at once using labeled data, the scarcity of labeled data limits the performance of in silico methods in prediction tasks20,21. Furthermore, from the perspective of data selection, not all molecules contribute significantly to the improvement of model performance. Randomly selecting new molecules from a vast chemical space for wet lab annotation often entails substantial resource consumption and may not necessarily lead to equivalent performance gains22. Therefore, the current challenge is to expand the labeled molecules as fast as possible from a large chemical space at a lower cost.\n\nActive learning is a promising strategy to tackle this challenge23, it adopts a human-in-the-loop paradigm, employing an iterative strategy of data collection, annotation, and training to assist experimentalists in guiding both data collection and model training. It involves targeted exploration within a vast chemical space, utilizing a specific set of rules to identify molecules that maximize the enhancement of model performance. By validating these molecules through wet lab experiments, active learning achieves greater improvements in model performance compared to random selection strategies, all within the same experimental annotation budget. As a result, active learning reduces annotation costs and saves time through active guidance. Specifically, active learning commences with a small set of labeled data. The initial labeled data is used to train a deep learning model, and a well-designed query strategy is used to select a subset of the unlabeled data which are deemed to be the most informative ones. The molecules are submitted to a wet lab for labeling and then combined with the original labeled data to form a larger training set, which is used to retrain the model. The selection process is repeated until the desired performance is achieved or the annotation budget is exhausted. Due to the success in computer vision24,25,26, active learning has gained increasing attention from researchers in drug discovery and has been applied in various fields such as guiding chemical reaction screening22,27 and drug-drug interaction28. Recent reviews have also emphasized the significant role of active learning in scientific discovery, which has gradually attracted the attention of researchers29. It should be noted that Bayesian optimization and active learning are two different approaches. Bayesian optimization focuses on finding the optimal value, while active learning is to reduce the amount of labeled data by selecting the most informative examples to label30.\n\nCurrent research has demonstrated that, when using the same annotation cost, exploring more informative regions through active learning can achieve higher performance than random exploration31,32. With the query strategy guided by the active learning algorithm, we can effectively evaluate the informativeness of each molecule and selectively explore the vast chemical space, reducing the huge annotation cost. Therefore, active learning is well suited for mutagenicity prediction problems where annotation costs are high.\n\nIn this paper, we present a deep active learning pipeline called muTOX-AL (mutagenicity TOXicity-Active Learning), for molecular mutagenicity prediction. By iteratively selecting informative samples through active learning strategies, it significantly reduces the cost of data labeling and accelerates the process of drug discovery. The results show that compared to passive random exploration strategies, active learning can greatly reduce the required training sample size. Specifically, the contributions of this paper include:\n\n1) We propose an active learning strategy for molecular mutagenicity prediction. We use uncertainty (i.e., samples that are hard to distinguish by the model) as a measure of sample informativeness and score the samples by a trained uncertainty estimation module (see “Methods” for more details).\n\n2) Compared to traditional and state-of-the-art active learning methods, our approach achieves the same testing accuracy using fewer samples, especially compared to the random strategy, reducing about 57% of training molecules. This demonstrates the effectiveness and superiority of our method.\n\n3) We provide an explanation for why the selected molecules are more informative via t-SNE visualization. The visualization demonstrates that these molecules are located closer to the classification boundary of the model, which further supports their value in improving model performance.\n\n4) muTOX-AL demonstrates significant structural discriminability. On the one hand, the model prefers selecting samples with low structural similarity, preventing overfitting of simple relationships. On the other hand, the model also considers samples with similar structures but different properties, providing a more comprehensive understanding of the complex relationship between molecular structure and mutagenicity.\n\nmuTOX-AL overview\n\nmuTOX-AL is developed upon a deep active learning technique. The schematic diagram of active learning is shown in Fig. 1: A small number of labeled samples are used for training, and then the trained model is used to select the most informative samples from the unlabeled pool. These samples are given to the oracle for labeling, and then added to the labeled pool. We use uncertainty as a measure of sample informativeness (see “Methods” for more details).\n\nThe whole framework of muTOX-AL, as shown in Fig. 2, consists of four parts: the feature extraction module, the backbone module, the uncertainty estimation module, and the loss calculation module. In the training phase (Phase 1), the total training set is divided into two parts: an initialed labeled pool of 200 randomly selected samples and an unlabeled pool of all remaining samples. In this case, we make all samples in the unlabeled pool “blind,” i.e., the labels are not visible to the model, to simulate a real scenario with fewer labeled samples and more unlabeled samples. The molecular fingerprints and descriptors of the samples in the initial labeled pool are extracted as input features for the backbone module, which is responsible for predicting mutagenicity of the molecules. The uncertainty estimation module is used to determine the informativeness of the samples. The deeper features obtained by the hidden layer of the backbone module are extracted as input of the uncertainty estimation module. Finally, models are jointly trained by calculating the total loss of the backbone module and the uncertainty estimation module. In the active learning phase (Phase 2), the trained model calculates the uncertainty scores of all samples in the unlabeled pool. Next, the samples with the highest uncertainty scores are given to the oracle for annotation and added to the labeled pool. Here, the labels of the selected “blind” samples are revealed to the model to simulate the interaction with a real wet lab scenario. The above process is iterated until the entire label budget is exhausted or a predefined stopping condition is met.\n\nStatistical analysis of the dataset\n\nIn this study, muTOX-AL was trained using the TOXRIC dataset, and the performance of the proposed method was verified. TOXRIC dataset was collected and collated from the TOXRIC website (https://toxric.bioinforai.tech/home) and includes a total of 7495 compounds33. We used a randomized five-fold cross-validation approach for model training and performance validation, where each fold was used in turn as a test set, while the remaining four folds were used as a training set (total training set sample size = 5988 samples). To gain insight on the distribution of mutagenicity labels as well as chemical structure domains of the samples in the dataset, we performed the following statistical analyses on the TOXRIC dataset.\n\nFirst, we performed a labeling analysis on the overall data, as shown in Fig. 3A. TOXRIC dataset is balanced, the number of positive samples was 4196, accounting for 56.05%, while the number of negative samples was 3289. Overall, the prediction scores on the dataset are less affected by the class imbalance.\n\nSecond, we visualized the chemical space in which the TOXRIC dataset is embedded. We generated MACCS fingerprints for the samples in the dataset and performed principal component analyses, the results are shown in Fig. 3B. The distribution of the dataset is relatively diffuse, suggesting that the data are highly variable in the direction of the principal components and that the samples occupy a broad and dispersed chemical space.\n\nFinally, we investigated the relationship between structural domains and mutagenicity in the TOXRIC dataset. Using locally sensitive hash forest indexing and k nearest neighbors (kNN) plots, we represent and visualize the TOXRIC dataset as a minimum spanning tree (MSP)34, with the structural similarity distribution illustrated in Fig. 3C. This visual representation enabled the identification of clusters of structurally homogeneous molecules for both non-mutagens and mutagens. It was observed that it is challenging to directly distinguish molecular subgroups with specific substructures based on structure alone. In addition, the distribution of each fold of data in the five-fold cross-validation was analyzed (see Supplementary Fig. 1 for details). Specifically, we visualized the distribution of samples over the structural domains in the training and test sets by means of the MSP. In each fold, the molecules in the test set are uniformly distributed in different structural domains.\n\nComparisons between different active learning methods\n\nTo verify the effectiveness of the muTOX-AL, we compare muTOX-AL with other active learning strategies such as random strategy, margin-based active learning strategy35, entropy-based active learning strategy36, TOD37 active learning strategy and Core-set active learning strategy38. We use some common evaluation metrics for active learning performance. Figure 4A, B shows the Accuracy and F1-score of muTOX-AL with five active learning baselines on the mutagenicity dataset, where the x-axis represents the number of labeled samples per cycle and the y-axis represents the accuracy and F1-score, respectively, other metrics can be found in Supplementary Fig. 4. From Fig. 4A, B, we can see that muTOX-AL performs best among all active learning methods, which uses only about 24% of training sets to achieve 95% of the accuracy of supervised learning using all training samples (5988 samples). The result demonstrating that our active learning strategy is able to explore more informative molecules in chemical space, which are usually more helpful for prediction tasks. The random strategy has the lowest performance because it does not make use of any information about the samples. In addition, the four remaining active learning strategies outperform the random strategy but perform slightly worse than muTOX-AL.\n\nTo further illustrate that active learning can significantly reduce labeling costs, we set the test performance threshold to 95% of the supervised learning performance using all training samples (5988 samples), comparing the sample sizes used by different active learning strategies at this threshold. For example, if the supervised learning accuracy using all samples is 84.76%, the performance threshold is 80.52%. From Table 1, we can see that our approach uses the least number of samples on most metrics when reaching the same performance threshold. The random query strategy always uses the largest number of molecules, indicating that random exploration in chemical space tends to enter relatively less informative regions and thus requires more annotation costs than active learning strategies. In particular, the last row of the table calculates the percentage of samples reduced by using the active learning strategy of this paper compared to the random query strategy. We can see that active exploration of the chemical space using the active learning strategy can reduce the training sample size by up to nearly 57%. This result is promising and demonstrates that using active learning methods can significantly reduce the number of samples that need to be labeled while maintaining competitive performance. In addition, our backbone module can achieve competitive test performance on a variety of evaluation metrics compared to several machine learning and deep learning baselines when using all training samples (see Supplementary Table 7).\n\nIn addition, to demonstrate the generalization performance of muTOX-AL on external data, we additionally collected mutagenicity data from Li et al.21 as an external testing set (Li’s Dataset), excluding samples identical to those in the TOXRIC dataset. The performance of two models was evaluated: (i) a model trained using the active learning algorithm to select the most informative 2600 TOXRIC samples (trained and saved when the “Number of Labeled Samples = 2600” in Fig. 4); (ii) a model trained using all 5988 TOXRIC samples (i.e., the four subsets of the 7485 samples) without active learning (Supplementary Table 7). The performance of the above two models on Li’s dataset is shown in Supplementary Fig. 5 and Supplementary Table 8. It can be found that the performance of the model trained using only 2600 TOXRIC samples on Li’s dataset is close to the performance of the model trained using all 5988 TOXRIC samples. It is encouraging and confirms that active learning can be instructive for data collection and selection. In particular, with an uncertainty sampling strategy in the presence of a large chemical space, we are able to achieve competitive performance by selecting only a small number of samples, which greatly reduces human and resources consumption due to exhaustive random screening. In terms of Precision and Specificity, the model trained with the 2600 samples selected by muTOX-AL even outperforms the model trained with all 5988 samples, which is consistent with the findings in the current research22. This indicates that not all samples have a positive effect on the model performance and proves that active learning is able to select the most helpful samples for model training and remove the redundant samples effectively.\n\nThe uncertainty estimation module designed in muTOX-AL is more helpful in selecting informative samples\n\nThis section attempts to explore the effect on the ability to select informative samples when the feature dimension or network depth of the uncertainty estimation module is increased. Supplementary Fig. 6 shows the schematic diagram of the two uncertainty estimation modules. Supplementary Fig. 6A displays the structure of two different hidden layer features which are used as input to the uncertainty estimation module, while Supplementary Fig. 6B presents the structure in that only a single hidden layer feature is used, but with an additional linear layer and a Rectified Linear Unit (ReLU) activation function.\n\nFigure 5 illustrates the active learning curves for the two structures described above (source data for the curves and p-values calculated by independent t-tests are shown in Supplementary Tables 9, 10). It can be observed that the performance is slightly decreased while the two structures shown in Supplementary Fig. 6 are used. It is also demonstrated that the uncertainty estimation module designed in muTOX-AL can be more helpful in selecting informative samples. There are two possible explanations for this: (i) a simple network may be more effective in improving performance when the dataset is not large enough; (ii) increasing the complexity of the uncertainty estimation module when the backbone module network is not deep may not be conducive to the joint training of the models.\n\nFurthermore, we conducted ablation studies on the input features of our model, with detailed results provided in Supplementary Fig. 3.\n\nmuTOX-AL can select samples that are closer to the classification boundary\n\nTo further confirm the effectiveness of our deep active learning strategy, we first use the embeddings of data points before the classifier (“Embeddings” shown in Fig. 2) to be downscaled by t-SNE visualization and display it in a two-dimensional map. Figure 6A shows the visualization of both muTOX-AL and the random query strategy.\n\nIn Fig. 6A, the boundary between positive and negative samples becomes more apparent as the cycle progresses, indicating that with the sample size increasing, the trained model can distinguish between positive and negative samples more evident. In addition, the data distribution of the proposed method is more concentrated, and the boundary is clearer than that of the random query strategy, which implies that muTOX-AL has a better prediction performance. Additionally, in each cycle, the samples selected using the random query strategy are scattered throughout the embedding space, whereas the samples selected by the proposed muTOX-AL are more concentrated on the classification boundary, which suggests that muTOX-AL can successfully select the samples with the highest uncertainty, i.e., those samples that are more difficult for the model to classify. To further quantify the distance of the sample from the classification boundary, we train a support vector machine (SVM) classifier based on the Radial Basis Function kernel function using the same embeddings mentioned above and calculate the distances of the selected samples from the SVM classification hyperplane in each cycle. As the distances calculated by SVM are signed values, we take absolute values for them, plot violin plots and use t-tests to obtain p-values for both distributions. The results are shown in Fig. 6B, with the x-axis representing muTOX-AL and random strategy and the y-axis representing the absolute values of the distances. Figure 6B demonstrates that the p-values are consistently less than 0.05 in different cycles, indicating that the distribution of the distances is significantly different between the two methods and that muTOX-AL picks samples with smaller distances.\n\nIn total, muTOX-AL tends to select samples closer to the classification boundary. By preferentially selecting such samples and feeding them into the model for training, this strategy allows the model to fully learn the distribution of features of the most informative samples, thus achieving competitive performance with a small size of the dataset.\n\nmuTOX-AL has high molecular structural discriminability\n\nGenerally, samples with lower molecular similarity are considered to have greater uncertainty and vice versa39. However, this need not always be the case, small molecules with similar structures may have opposite properties, and a typical example is chiral molecules40,41. For instance, thalidomide, which has both levorotatory and dextrorotatory structures, the levorotatory body is therapeutic and can reduce early pregnancy reactions, but its chiral partner (the dextrorotatory body) is mutagenic42. Therefore, a model is considered to have high structural discriminability when the samples selected by the model satisfy both of the following conditions: (i) low structural similarity between the selected samples; (ii) the presence of molecules with similar structures but opposite properties.\n\nFirst, to demonstrate muTOX-AL is able to select samples with low structural similarity, we analyzed the structural similarity among the samples selected by each active learning cycle. Specifically, we used the Tanimoto coefficient43 to calculate the structural similarity between the 300 samples selected in each cycle. For each cycle, a heatmap of the selected samples was plotted (Fig. 7A). To directly compare the difference in structural similarity between the selected structures from different cycles, the distribution of structural similarity is shown in the box plots (Fig. 7B).\n\nFigure 7A, B shows that the small molecules with higher structural similarity are selected in early cycles. We argue that this phenomenon may be related to the samples selected in the initial cycles being few and the power of deep learning is not sufficiently exploited, which echoes the slightly worse performance of our model in the initial cycles. As the number of cycles increases, the performance of the model increases rapidly, which indicates that muTOX-AL tends to select samples with lower structural similarity, i.e., molecules with higher uncertainty.\n\nSecond, to illustrate that muTOX-AL is able to selects samples with similar structures but opposite properties. Figure 8 and Supplementary Table 11 show the sets of molecules with such properties selected by each active learning cycle. As can be seen in Fig. 8, these sets of molecules include isomers, chiral molecules, and molecules with varying numbers of substituents, etc. These small variances often result in a polarity change of the molecule, which leads to contrary properties. However, for feature extraction methods based on molecular structure, there is low feature differentiation between these structurally similar molecules; in other words, the uncertainty of such molecules is significant.\n\nIn addition, to demonstrate that the muTOX-AL can still select samples with similar structures but opposite properties in the out-of-domain case (outside of the TOXRIC dataset), we collected 50 molecules from the literature, which are not present in the TOXRIC dataset (see Supplementary Data). Subsequently, the uncertainty of each molecule was obtained using the trained muTOX-AL (the model after the 9th iteration of active learning), and these samples were ranked according to the uncertainty value. Finally, we selected the top 30% of the ranked samples to find the set of molecules with similar structures but opposite properties among them, and the results are displayed in Fig. 9. Therefore, muTOX-AL can find samples with similar structure but opposite properties, which are also the ones with high uncertainty.\n\nOverall, although the model tends to select samples with low structural similarity, samples with similar structures but different properties are still considered, and this avoids the over-fitting of simple relationships. This is the evidence of the high molecule structural discriminability of muTOX-AL.\n\nDatasets\n\nTOXRIC dataset33\n\nThe raw data used in this study were the C. Xu’s Ames data collection45, which is one of the commonly used data sets for developing the prediction models. The entire database was prepared as follows46. Firstly, any inorganic molecules, that is, those without carbon atoms within the structure are removed. Secondly, the molecules with unspecified stereochemistry were removed. Thirdly, the molecules were standardized using the InChI key47. Finally, duplicates were identified and removed using the InChI key across the data collection. Ultimately, in total, 7485 compounds were used for the model building. The data sets contained 4196 mutagens and 3289 non-mutagens. The dataset is available in https://toxric.bioinforai.tech/home.\n\nLi’s dataset21\n\nThe dataset was constructed from data sourced from three distinguished databases: the Chemical Carcinogenesis Research Information System, the National Toxicology Program, and the Instituto Superiore di Sanita for Salmonella Typhimurium. Further refinement was achieved by removing samples that were duplicates of those found in the Ames dataset, thus establishing a new, independently verified external test set. Statistical analysis of the dataset was shown in Supplementary Fig. 2.\n\nMolecular descriptors and fingerprint features\n\nThe fingerprint features include three sets of topological path-based features (Extended Connectivity Fingerprints with a diameter of 2, 4, and 6, ECFP2, ECFP4, and ECFP6) and one set of substructure-key SMARTS-based features MACCS.\n\nECFP fingerprints are generated based on the connectivity between atoms in a molecule, taking into account the bonds, hybridization states, and functional groups. ECFP fingerprints use circular fingerprints, where the radius of the circle defines the maximum distance between atoms that can be included in a particular substructure. According to different radius, ECFP is divided into ECFP2, ECFP4, and ECFP6.\n\nMACCS fingerprints are generated based on the structural features of a molecule, such as the presence of aromatic rings, functional groups, and atom types. Each structural key in the fingerprint is assigned a binary value, where 1 indicates the presence of the key and 0 indicates the absence of the key.\n\nRDKit2D descriptors are selected as input features to complement the fingerprint features. RDKit2D descriptors can provide information on a wide range of molecular properties, including size, shape, polarity, and flexibility. Some examples of RDKit2D descriptors include the number of atoms, the molecular weight, the number of rotatable bonds, and the number of hydrogen bond donors and acceptors.\n\nDeep active learning strategy\n\nActive learning aims at selecting the most informative samples from a pool of unlabeled samples in the entire sample space. Defining the amount of information in a sample is the biggest challenge in the active learning problem. To describe the deep active learning scenario proposed in this paper, an unlabeled sample pool consisting of \\(N\\) unlabeled molecules is assumed to be \\({{{{\\mathrm{U}}}}}_{N}=\\{({x}_{1},{y}_{1}),{..}.,({x}_{N},{y}_{N})\\}\\), where \\({x}_{i}\\) is the feature of the molecule and \\({y}_{i}\\) is the toxicity label corresponding to \\({x}_{i}\\). First, we randomly select \\(M\\) samples from \\({{{{\\mathrm{U}}}}}_{N}\\) and give them to the oracle for annotation, which generates an initial pool of annotated samples \\({ {{\\mathcal L}} }_{M} = \\{({x}_{1},{y}_{1}),{..}.,({x}_{M},{y}_{M})\\}\\). Then the five features of all samples in the initial annotated sample pool \\({ {\\mathcal L} }_{M}\\) are extracted and input to the backbone module \\({f}_{{{{\\rm{b}}}}}\\). The output of the hidden layer of the network, which can be considered the embeddings of the input features, is fed into the uncertainty estimation module \\({f}_{{{{\\rm{u}}}}}\\). The model’s parameters are updated by jointly optimizing \\({f}_{{{{\\rm{b}}}}}\\) and \\({f}_{{{{\\rm{u}}}}}\\) according to the defined total loss.\n\nFramework architecture\n\nFeature extraction module\n\nMolecular fingerprints and molecular descriptors are widely used in similarity searching and classification. Four molecular fingerprints and one molecular descriptor are used in this work. They are ECFP2, ECFP4, and ECFP6 (2048 bits), MACCS keys (MACCS, 166 bits) and RDKit2D. All the fingerprints and molecular descriptors were calculated by the RDKit python package.\n\nBackbone module\n\nAs shown in Fig. 2, considering the higher dimensionality of extended connectivity fingerprints compared to other features, we first stitch ECFP2, ECFP4, and ECFP6 in the channel dimension to form a three-channel fusion feature, which is then fed into two convolution blocks. In each convolutional block, a 1D convolutional layer and an average pooling layer are used first to extract features and remove redundant information, thus reducing the parameters of the network. Then the ReLU activation function follows, which introduces a non-linear element to enhance the representation ability of the network and mitigate the problems of gradient disappearance and gradient explosion. With the two convolution blocks mentioned above, it is possible to further extract features while reducing the dimensionality, which helps in the subsequent classification steps. The output of the convolution block is stitched with the lower dimensional MACCS fingerprints and RDKit2D descriptors to achieve feature fusion. The fused features are then fed into a linear block consisting of a linear layer, a ReLU layer and a Dropout layer, where the Dropout layer is used to prevent overfitting of the input. Finally, a linear classifier is used to classify the mutagenicity of the molecule.\n\nUncertainty estimation module\n\nIn active learning, the key issues are the criteria for measuring the informativeness of the samples and the design of the query module. For the first problem, the most commonly used measure is uncertainty-based querying, i.e., querying the samples that are most difficult for the model to classify. Uncertainty-based querying has been shown to be more applicable in classification problems with small samples48, so we choose uncertainty as the measure of informativeness. In deep learning, the loss is often used as a measure of the difference between the predicted and true values of a model. The samples with the largest losses can usually be regarded as the samples which are the hardest for the model to distinguish. Therefore, the uncertainty estimation can be converted into the loss estimation. Since the model loss values cannot be computed for samples without true labels, a module needs to be designed to estimate the loss values for unlabeled samples. By training an uncertainty estimation module using labeled samples, we can predict the loss of unlabeled samples and thus estimate their uncertainty. The uncertainty estimation module designed in this paper is shown in Fig. 2. To make good use of features extracted by the hidden layer of the backbone module, we use it as input to the uncertainty estimation module. Inspired by Yoo et al.49, the module consists of a global average pooling layer, two linear layers and a ReLU layer, where the global average pooling layer aims to integrate feature information, and the introduction of linear and non-linear activation layers enables the network to learn better. A final linear layer maps the features into a scalar that outputs the uncertainty scores of unlabeled samples. We did not use more scaled hidden features, as this could have led to a more complex structure of the uncertainty estimation module, which would decrease the prediction performance. We confirmed this view in Results.\n\nLoss calculation module\n\nHaving defined the structure of the backbone module \\({f}_{{{{\\rm{b}}}}}\\) and the uncertainty estimation module \\({f}_{{{{\\rm{u}}}}}\\), we need to focus on how they are jointly optimized. The total loss of the modules \\({L}_{{\\rm{total}}}\\) consists of two main components: the backbone module loss \\({L}_{{{{\\rm{b}}}}}\\) and the uncertainty estimation module loss \\({L}_{{{{\\rm{u}}}}}\\), which will be described separately below.\n\nThe output of a labeled sample \\(x\\) after the backbone module is \\(\\hat{y}={f}_{{{{\\rm{b}}}}}(x)\\). In the binary classification task, we usually use binary cross-entropy loss. It is\n\n$${L}_{{{{\\rm{b}}}}}(\\hat{y},y)=-(y\\cdot \\,\\log (\\hat{y})+(1-y)\\cdot \\,\\log (1-\\hat{y}))$$\n\n(1)\n\nWe want the output of the uncertainty estimation module to be as close as possible to the binary cross-entropy loss of the sample, so the uncertainty estimation task can be considered a regression task. In usual regression tasks, the most used metric is the mean squared error (MSE) \\({L}_{{{{\\rm{u}}}}}(\\hat{y},y)=\\frac{1}{n}{\\sum }_{i=1}^{n}{(\\hat{y}-y)}^{2}\\), but the scale of loss changes as the training progresses, so using MSE as the loss is not a sensible choice. Here, we determine the trend of uncertainty score estimation by comparing the losses of a pair of samples within a mini-batch. Assuming that the \\(k\\) th pair of samples \\(({x}_{i},{y}_{i})\\) and \\(({x}_{j},{y}_{j})\\) in the same mini-batch in the sample pool, their outputs after the uncertainty estimation module are \\({\\hat{l}}_{i}\\) and \\({\\hat{l}}_{j}\\), and the actual cross-entropy losses are \\({l}_{i}\\) and \\({l}_{j}\\), we can define the loss for this pair of samples after the uncertainty estimation module as\n\n$${L}_{{{{\\rm{u}}}}}\\left({\\hat{l}}_{{{{\\rm{batch}}}}}^{k},{l}_{{{{\\rm{batch}}}}}^{k}\\right)=\\,\\max (0,-{{{\\rm{sign}}}}({l}_{i}-{l}_{j})\\cdot ({\\hat{l}}_{i}-{\\hat{l}}_{j})+\\xi )$$\n\n(2)\n\nwhere \\({{{\\rm{sign}}}}(\\cdot )\\) is the sign function, margin \\(\\xi\\) is a very small number. Equation(2) indicates that when \\({l}_{i}-{l}_{j}\\) and \\({\\hat{l}}_{i}-{\\hat{l}}_{j}\\) have the same sign, i.e., the loss of a pair of samples shows the same trend, the value of \\({L}_{{{{\\rm{u}}}}}\\) is zero. Otherwise, the parameters of the uncertainty estimation module need to be updated by gradient descent.\n\nThus, given the size \\(B\\) of the mini-batch, the total loss of the two modules can be defined as\n\n$${L}_{{{\\rm{total}}}}=\\frac{1}{B}\\left(\\mathop{\\sum}_{(x,y)\\in B}{L}_{{{{\\rm{b}}}}}(\\hat{y},y)+2\\lambda \\cdot \\mathop{\\sum}_{({x}^{k},{y}^{k})\\in B}{L}_{{{{\\rm{u}}}}}({\\hat{l}}_{{{{\\rm{batch}}}}}^{k},{l}_{{{{\\rm{batch}}}}}^{k})\\right)$$\n\n(3)\n\nBy optimizing the total loss \\({L}_{{\\mbox{total}}}\\), we can jointly optimize the parameters of the backbone module and the uncertainty estimation module during the training process, thus estimating the uncertainty of unlabeled samples during the active learning phase. Algorithm 1 is elaborated to the algorithm logic and conceptual modeling.\n\nAlgorithm 1\n\nThe muTOX-AL framework for molecular mutagenicity prediction\n\nInput:\n\nunlabeled pool \\({{{\\mathrm{U}}}}\\)\n\nThe testing set \\({{{\\mathcal{T}}}}\\)\n\nThe number of initialized label set \\(M\\)\n\nThe number of active learning cycles \\(C\\)\n\nThe number of samples labeled in each cycle \\(K\\)\n\nThe backbone module \\({f}_{{{{\\rm{b}}}}}\\), The uncertainty estimation module \\({f}_{{{{\\rm{u}}}}}\\)\n\n1: Randomly select \\(M\\) samples from \\({{{\\mathrm{U}}}}\\) to gain initialized labeled set \\({\\mathcal L}\\)\n\n2: For c in C:\n\n3: Train the backbone module \\({f}_{{{{\\rm{b}}}}}\\) and the uncertainty estimation module \\({f}_{{{{\\rm{u}}}}}\\) using \\({\\mathcal L}\\)\n\n4: Evaluate the performance on \\({f}_{{{{\\rm{b}}}}}\\) using the testing set \\({{{\\mathcal{T}}}}\\)\n\n5: Estimate the uncertainty of the unlabeled samples \\({{{\\mathrm{U}}}}\\) by \\({f}_{{{{\\rm{b}}}}}\\) and \\({f}_{{{{\\rm{u}}}}}\\)\n\n6: Select the top K samples with the highest uncertainty\n\n7: Query their labels from the oracle to obtain \\({ {\\mathcal L} }_{K}\\)\n\n8: \\({\\mathcal L} \\leftarrow {\\mathcal L} \\cup { {\\mathcal L} }_{K}\\)\n\n9: \\(c\\leftarrow c+1\\)\n\n10: End\n\nEvaluation metrics\n\nTwo commonly evaluation metrics in classification tasks are used as evaluation criteria: accuracy and F1-score. First, we define four indicators: True Positive (TP) means that the positive sample has a positive predictive value and the prediction is correct; True Negative (TN) means that the negative sample has a negative predictive value and the prediction is correct; False Positive (FP) means that the positive sample has a positive predictive value and the prediction is wrong; False Negative means that the predicted value of the negative sample is negative and the prediction is correct.\n\nAccuracy represents the proportion of samples correctly predicted to all samples and is the most common evaluation metric in classification tasks and is defined as\n\n$${{\\rm{Accuracy}}}=\\frac{{{\\rm{TP}}}+{{\\rm{TN}}}}{{{\\rm{TP}}}+{{\\rm{TN}}}+{{\\rm{FP}}}+{{\\rm{FN}}}}$$\n\n(4)\n\nF1-score is defined in Eq. (5), which combines the Precision and Recall metrics.\n\n$${{\\rm{F1}}}{\\mbox{-}}{{\\rm{score}}}=\\frac{2 \\times {{\\rm{Precision}}} \\times {{\\rm{Recall}}}}{{{\\rm{Precision}}}+{{\\rm{Recall}}}}$$\n\n(5)\n\nwhere\n\n$${{\\rm{Precision}}}=\\frac{{{\\rm{TP}}}}{{{\\rm{TP}}}+{{\\rm{FP}}}}$$\n\n(6)\n\n$${{\\rm{Recall}}}={{\\rm{Sensitivity}}}=\\frac{{{\\rm{TP}}}}{{{\\rm{TP}}}+{{\\rm{FN}}}}$$\n\n(7)\n\nSpecificity refers to the proportion of TN samples that are correctly predicted as negative by the model, i.e., the probability of TN samples being correctly predicted as negative.\n\n$${{\\rm{Specificity}}}=\\frac{{{\\rm{TN}}}}{{{\\rm{TN}}}+{{\\rm{FP}}}}$$\n\n(8)\n\nExperimental settings\n\nAll our experiments are implemented in the PyTorch framework. We set the batch size as 128 and used a 5-fold cross-validation to increase the generalizability of the experimental results. We mainly followed the training strategy in the active learning setup, following a five-fold cross-validation strategy, where all the dataset was randomly divided into five subsets, and in each fold, four of them were selected as the total training set for the model, and the remaining one subset was used to test the model’s performance (the test set), which is not visible at all times. The whole active learning process is divided into nine cycles. At the beginning of the experiment (cycle = 0), we randomly select 200 samples from the unlabeled sample pool to train the initialized network and select 300 samples from the unlabeled pool in each active learning cycle. The backbone module is trained jointly with uncertainty estimation module. Separately, the backbone module is trained with 300 epochs, using an SGD optimizer with a learning rate of 5e-3, a momentum parameter of 0.9 and a weight decay parameter of 5e-4. The uncertainty estimation module is trained using an Adam optimizer with a learning rate of 8e-3. The margin in Eq. (2) is set to one. For each method, ten randomized replicate experiments are conducted using different initial labeled samples, and we report the mean of the ten experiments at the end. Detailed information on active learning training strategies can be found in the “Active learning training strategies in muTOX-AL” section of the Supplementary Information.\n\nActive learning methods for comparison\n\nWe have compared muTOX-AL with the following five active learning methods.\n\nRandom strategy\n\nThe random strategy is the most common active learning baseline. In each active learning cycle, the \\(K\\) samples are selected randomly from the unlabeled pool and given to the oracle for annotation.\n\nMargin-based active learning strategy35\n\nThe margin-based active learning strategy is a uncertainty-based method. It defines the uncertainty by measuring the difference between the prediction probabilities of different categories. The \\(K\\) samples with the lowest margin are added to the labeled pool. The margin is defined as\n\n$${{{\\rm{X}}}}={{\\mbox{arg}}\\,\\min }_{x\\in {{{\\mathrm{U}}}}}(P({\\hat{y}}_{1}|x)-P({\\hat{y}}_{2}|x))$$\n\n(9)\n\nEntropy-based active learning strategy36\n\nThe entropy-based active learning strategy is an uncertainty-based method. In information theory, the uncertainty of the data is higher if it has a higher entropy. Therefore, the entropy of the unlabeled samples is calculated and ranked. The \\(K\\) samples with the highest entropy are added to the labeled pool. The entropy is defined as\n\n$${{{\\rm{X}}}} = {{\\arg}\\,\\max }_{x\\in {{{\\mathrm{U}}}}} {E}_{x} = {\\arg}\\,\\min \\left\\{\\mathop{\\sum }_{i=1}^{Y} {{{\\mathrm{P}}}}({y}_{i}|x)\\times \\,\\log {{{\\mathrm{P}}}} ({y}_{i}|x)\\right\\}$$\n\n(10)\n\nTOD active learning strategy37\n\nThe temporal output discrepancy TOD active learning strategy based on temporal output discrepancy is an uncertainty-based approach. It defines the uncertainty by calculating the discrepancy of model output at different active learning cycles.\n\nCore-set active learning strategy38\n\nThe Core-set active learning strategy is a diversity-based approach which is also a common baseline in active learning trying to find a core set that makes the model’s performance on the core set and the whole dataset as close as possible.\n\nMachine learning-based mutagenicity prediction methods for comparison\n\nMIL\n\nFeeney et al.19 propose a machine learning approach based on multi-instance learning for molecular mutagenicity prediction, particularly for metabolically activated compounds like aromatic amines. By grouping metabolites and their parent compounds under a single mutagenicity label, MIL circumvents the need for individual labels, capturing the mutagenic potential through structural considerations. MIL achieved excellent performance on the mutagenicity molecular dataset, so we used it as one of the baselines for muTOX-AL.\n\nEnhanced_Representation_Mutagenicity\n\nShinada et al.18 systematically considered and evaluated combinations of structures and molecular features that have the greatest impact on model accuracy, using various classification models (including classic machine learning and deep learning models) to assess these features. We selected Structural Representation, Molecular Descriptors, and Genotoxicity Descriptors features, with the Random Forest classifier as our evaluation baseline.\n\nStatistics and reproducibility\n\nThe study employed five fold cross-validation with ten random repetitions, reporting the mean and standard deviation across these repetitions. The p-values reported in the study were calculated using independent t-tests.\n\nReporting summary\n\nFurther information on research design is available in the Nature Portfolio Reporting Summary linked to this article.",
      "# [Is LangChain losing its appeal for developers? Here's the truth by Abhijeet V Singh, Career Advice, Technology Unplugged, Leader's Speak, Editor Picks on 2025-03-05](https://content.techgig.com/technology/why-developers-are-not-using-langchain/articleshow/118705898.cms)\nDevelopers are moving away from LangChain due to its instability, frequent updates, and overly complex structure. They find better alternatives like PydanticAI and PocketFlow more reliable and user-friendly, opting to build their own stacks instead. LangChain needs significant improvements in stability, simplicity, and documentation to regain trust.\n\nLangChain was once seen as a game-changing framework for building AI apps powered by large language models (LLMs). But now, many developers are leaving it behind. Why? It’s mainly due to issues like complexity, constant updates that break things, and poor documentation. Let’s dive into why LangChain is losing its appeal.\n\nToo Complicated and Always Changing\n\nLangChain started off with a lot of promise, but soon, developers began facing big problems. The framework was unstable. Updates often broke things, and the documentation was outdated or just didn’t make sense. One developer mentioned on Reddit that the interface kept changin,g and the docs were almost always behind. This forced them to dive into the source code instead of trusting the docs.\n\nOvercomplicating Everything\n\nAnother reason developers are ditching LangChain is its complexity. The framework has too many layers of abstraction. This makes it hard to understand or modify things easily. The team at Octomind shared that when they tried to make their system more complex, LangChain’s rigid structure didn’t allow them to do so. Instead of being a helpful tool, it became a blocker.\n\nNot Great for Real Projects\n\nLangChain wasn’t built for real, production-level applications. Developers found that it added unnecessary bloat on top of APIs like OpenAI’s. It made the whole system slower and harder to manage. One team shared their frustration after building a proof-of-concept (POC) with LangChain. They couldn’t update it without major code changes. They ended up ditching it instead of upgrading it.\n\nAlternatives Are Gaining Ground\n\nWith all the problems with LangChain, developers are moving toward better alternatives. PydanticAI is gaining popularity because it offers a simpler and more Pythonic way to build LLM applications. Though it’s not perfect, it’s definitely more user-friendly than LangChain. There’s also PocketFlow, which is becoming popular for being more modular and flexible. LlamaIndex is another stable choice developers are flocking to.\n\nBuild Your Own Stack Instead\n\nKieran Klaassen, co-founder of Every Inc, summed it up best when he said: “LangChain is where good AI projects go to die.” Experienced developers now prefer building their own stack rather than wasting time with a broken framework. It’s more efficient and flexible in the long run.\n\nCan LangChain Make a Comeback?\n\nDespite all the complaints, LangChain still has some supporters. However, it needs to make some big changes to stay relevant. It might regain developer trust if it improves stability, simplifies its design, and updates its documentation. But for many developers, it’s too late. They’ve already switched to more reliable and flexible options.\n\nCheck other stories with similar interests:\n\nhttps://techgig.com/generateHttpWebService-v2.php?tgtype=SAVE_NEWS_READ_LOGS&news_id=118705898&news_title=Is LangChain losing its appeal for developers? Here's the truth&news_sec=Technology&tags=LangChain issues, software documentation problems, PydanticAI, modular AI solutions, LangChain developers, flexible AI frameworks, custom AI stack, build LLM applications, alternative to LangChain, AI applications framework, &news_url=https://content.techgig.com/technology/why-developers-are-not-using-langchain/articleshow/118705898.cms&ppuserinfo=",
      "# [New algorithm for functional protein design outperforms traditional methods by Chen Yehong on 2024-12-09](https://phys.org/news/2024-12-algorithm-functional-protein-outperforms-traditional.html)\nResearchers from the University of Science and Technology of China (USTC), led by Prof. Liu Qi, in collaboration with Harvard Medical School's Marinka Zitnik lab, have developed a novel deep generative algorithm, PocketGen. This algorithm, based on graph representation learning and protein language models, efficiently generates protein pocket sequences and spatial structures for binding small molecules. The study was published in Nature Machine Intelligence.\n\nFunctional protein design, particularly for proteins binding to small molecules such as enzymes and biosensors, is crucial for drug discovery and biomedical applications. Traditional methods based on energy optimization and template matching are time-consuming and yield low success rates.\n\nMeanwhile, deep learning models face challenges in modeling complex molecular–protein interactions and capturing sequence-structure dependencies. PocketGen addresses these issues, offering a high-efficiency and high-accuracy solution that adheres to physicochemical principles.\n\nPocketGen builds on previous works FAIR and PocketFlow and consists of two core components. First is a dual-layer graph Transformer encoder inspired by proteins' hierarchical structures. This module is designed to learn different fine-grained interaction information and to update the representations and spatial coordinates of amino acids and atoms accordingly.\n\nThe second part is a pre-trained protein language model, as illustrated in the image above, where PocketGen efficiently fine-tunes the ESM2 model to assist in amino acid sequence prediction. By selectively adapting certain parameters, PocketGen enhances sequence-structure consistency through cross-attention mechanisms.\n\nExperimental results demonstrated that PocketGen significantly outperforms traditional methods in affinity, structural plausibility, and computational efficiency, achieving over a 10-fold improvement in speed. Further, in validation tasks such as protein pocket design for small molecules like fentanyl and ibuprofen, the effectiveness of PocketGen was confirmed through comparisons with state-of-the-art generative models, including RFDiffusion and RFDiffusionAA, developed by Nobel Laureate David Baker's lab.\n\nAdditionally, the attention matrices generated by PocketGen were compared with results from first-principle-based force field simulations, demonstrating that the deep learning-based PocketGen model exhibits good interpretability.",
      "# [Why Developers are Quitting LangChain by Mohit Pandey on 2025-03-03](https://analyticsindiamag.com/ai-features/why-developers-are-quitting-langchain/)\nLangChain once held promise as a go-to framework for many developers to build applications powered by LLMs. Even then, it was not perfect and people had a lot of issues. However, a growing number of developers are now moving away from it, citing issues ranging from unnecessary complexity to unstable updates.\n\nWhile some still find value in LangChain’s features, the overall sentiment suggests that many seek alternatives such as Pydantic or LlamaIndex. One of the most common complaints among developers is LangChain’s instability. Frequent changes to the API structure, coupled with inconsistent documentation, have frustrated users.\n\nIn a Reddit discussion, a developer said, “It’s unstable, the interface constantly changes, the documentation is regularly out of date, and the abstractions are overly complicated.” Similar sentiments are echoed throughout the community. Many developers find themselves reading the source code instead of relying on the documentation.\n\n‘LangChain is Overcomplicating Things for No Reason’\n\nA few months back, the engineering team at Octomind, a software company, wrote a detailed blog on why they dropped out of LangChain. The framework’s inflexibility made it difficult to improve lower-level behaviour, and its intentional abstraction of details hindered writing lower-level code.\n\n“When we wanted to move from an architecture with a single sequential agent to something more complex, LangChain was the limiting factor,” read the blog.\n\nLangChain’s complexity has led many to question its design choices. Developers have criticised its layers of abstraction, which make it harder to understand and modify. Experienced developers like Praveer Kochhar, co-founder of Kogo Tech Labs, have questioned the framework and declared that it is not meant for production.\n\nMeanwhile, Angelina Y, the co-founder of OSCR AI, said that as time passes, more people realise that frameworks like LangChain and LlamaIndex are not good for production. “Practically becoming a versatile tool of no use! Of course, I must say that they are very good for making prototypes, especially LlamaIndex,” she added.\n\nMany feel that the framework prioritises “enterprise-level” aesthetics over practical usability.\n\nLast year, AIM also noted that there are a lot of problems with LangChain that continue to remain unresolved. It also uses the same amount of code as the original libraries of OpenAI and others, which makes it feel like bloatware on top of the original APIs, making it inefficient for production use.\n\nFor a framework that aims to help developers build reliable AI applications, many find LangChain unsuitable for production. A developer said that their team did a POC project with LangChain, and there were so many changes that they couldn’t update without major code edits. “We are going to get rid of LangChain in our code instead of upgrading it.”\n\nWhile some developers acknowledge that LangChain is still in rapid development, many feel it lacks the stability required for serious projects. While LangGraph, a related project, is stable, LangChain itself has become bloated.\n\nNo Other Alternative\n\nKieran Klaassen, co-founder of Every Inc, said, “LangChain is where good AI projects go to die.” He added that experienced developers call it “the worst library they’ve ever worked with” due to its bloated abstractions and black-box design.\n\nHe advised developers to build their own stack instead. “You’ll spend less time fighting someone else’s broken framework and more time shipping actual features that work.”\n\nGiven these challenges, many developers are exploring alternatives that are, admittedly, also not there. Even then, some prefer custom-built solutions over relying on an unstable framework.\n\nFor example, PydanticAI offers a more streamlined approach and is ‘Pythony’. This seems similar to what LangChain was known for — the PyTorch for building LLMs. However, just like LangChain, PydanticAI also faces similar issues.\n\nAnother emerging alternative is PocketFlow, which aims to provide a more modular and developer-friendly experience. Developers have also opted for LlamaIndex for a long time.\n\nWhile LangChain has its proponents, the growing dissatisfaction suggests it must address key concerns to regain developer trust. Stability, better documentation, and a focus on practical usability over unnecessary abstractions could help prevent further decline.\n\nHowever, for many, the damage may already be done. While it may still be useful for rapid prototyping, many are moving to more stable and flexible alternatives. Whether LangChain can turn things around remains to be seen. For now, however, many developers are letting it go.",
      "# [Leveraging Advanced RAG Techniques for Knowledge Management and AI Development by Nabil W, medium.com on 2024-05-01](https://medium.com/@nabilw/leveraging-advanced-rag-techniques-for-knowledge-management-and-ai-development-e442ac74ff8f)\nIntroduction: Harnessing AI for Effective Knowledge Management\n\nIn today’s digital age, data is ubiquitous, continuously generated through myriad channels including documents, emails, meetings, and more. This deluge of information presents a significant challenge for knowledge management within any organization. Traditional methods of sorting, searching, and retrieving information from such vast and diverse datasets are no longer sufficient. This is where Artificial Intelligence (AI), and more specifically, Retrieval Augmented Generation (RAG) systems, step in as game-changers.\n\nRetrieval Augmented Generation represents a cutting-edge approach in AI, leveraging the power of large language models (LLMs) to enhance the retrieval process. By dynamically pulling in relevant information from a vast database, RAG systems can provide more precise, contextually relevant responses. This capability is transformative for businesses looking to streamline their knowledge management processes, ensuring quick access to accurate and relevant information.\n\nThis blog post aims to delve deep into the world of advanced RAG techniques. We will explore how these systems are not just theoretical constructs but practical tools that can be tuned and optimized for real-world applications. From the basics of setting up a RAG system to exploring sophisticated methods like semantic chunking and dynamic query handling, this post will provide a comprehensive guide to anyone looking to understand or implement RAG in their operations.\n\nBy the end of this journey, you will have a robust understanding of how RAG systems work, how to implement them, and how to harness their full potential to revolutionize knowledge management within your organization. Let’s embark on this exploration of one of AI’s most promising frontiers.\n\nSection 1: Understanding RAG Basics\n\nRetrieval Augmented Generation (RAG) is a technique that combines the power of neural networks with traditional information retrieval methods to enhance the capabilities of language models. This hybrid approach is particularly valuable in scenarios where the language model needs to generate responses based on a vast amount of information that can’t be stored within the model itself.\n\nWhat is RAG?\n\nAt its core, RAG operates by integrating retrieval into the generative process of language models. When a query is presented, the system first retrieves relevant documents or data snippets from a large database. These retrieved contents are then used as a context by the language model to generate an informed and accurate response. This method is especially useful in handling detailed queries that require domain-specific knowledge not inherently possessed by the model.\n\nHow Does RAG Work?\n\nThe process can be broken down into several key steps:\n\nQuery Processing: The input query is processed to understand its intent and to formulate the retrieval query.\n\nDocument Retrieval: The system searches a database to find relevant documents. This retrieval can be based on various methods, including keyword search, vector search, or a hybrid approach.\n\nContext Integration: The retrieved documents are fed into the language model as an extended context.\n\nResponse Generation: The language model uses both the original query and the retrieved context to generate a coherent and contextually relevant response.\n\nBenefits of RAG\n\nEnhanced Accuracy: By using external documents to inform its responses, RAG can provide more accurate and detailed answers than a standalone language model.\n\nScalability: It allows models to handle information beyond their training data, making them applicable in more diverse scenarios.\n\nDynamic Learning: RAG systems can adapt to new information and contexts without the need for retraining, as the knowledge base can be updated independently of the model.\n\nCommon Challenges\n\nWhile RAG offers significant benefits, there are challenges in its implementation:\n\nData Quality and Relevance: The effectiveness of a RAG system is heavily dependent on the quality and relevance of the retrieved data.\n\nLatency: Retrieval operations, especially over large datasets, can introduce latency, impacting the response time of the model.\n\nComplexity: Setting up a robust RAG system involves complex integration between the retrieval database and the generative model, requiring careful tuning and optimization.\n\nRAG in Action\n\nPractical examples of RAG applications include AI chatbots that can pull information from a company’s documentation to answer customer queries, or research tools that synthesize information from scientific papers to generate summaries or answer specific questions.\n\nSection 2: Data Preparation and Advanced Parsing Techniques\n\nTo ensure the effectiveness of a Retrieval Augmented Generation (RAG) system, the input data must be meticulously prepared and accurately parsed. This section focuses on the crucial steps and technologies involved in refining data for RAG systems, ensuring that the retrieved information is both relevant and of high quality.\n\nImportance of Data Preparation\n\nIn the context of RAG, data preparation involves the processing of raw data into a format that is suitable for both retrieval and effective use by the language model. Proper data preparation not only enhances the accuracy of the retrieval process but also ensures that the generative model can synthesize responses effectively.\n\nAdvanced Parsing Techniques\n\nAdvanced parsing techniques are critical for transforming unstructured or semi-structured data into a cleaner, more structured format. Here are some key techniques and tools:\n\nPDF and PowerPoint Parsing: Tools like Llama Parts and Fire Craw are instrumental for extracting clean, usable text from formats typically rich in mixed content such as images and diagrams. Llama Parts, for instance, converts PDF files into a more AI-friendly markdown format, focusing on high accuracy in data extraction.\n\nWebsite Data Parsing: For extracting structured data from websites, tools like Fire Craw convert web pages into clean markdown formats, allowing RAG systems to process online information effectively. This is particularly useful for applications that rely on real-time data from the internet.\n\nHandling Multimodal Data: RAG systems often need to handle data that is not purely textual. Advanced parsers are capable of interpreting and structuring data from images, charts, and tables, integrating this information into the searchable text database.\n\nStructuring Data for Retrieval\n\nOnce the data is parsed, it must be structured in a way that facilitates efficient retrieval:\n\nChunking: Dividing large documents into smaller, manageable chunks helps in improving the precision of retrieval. Semantic chunking, where chunks are formed based on the inherent meaning and context, ensures that each piece contains thematically coherent information.\n\nIndexing: Proper indexing is crucial for quick retrieval. Using vector embeddings for indexing allows the system to understand the semantic relationships between different chunks, enhancing the relevance of retrieved documents.\n\nMetadata Enrichment: Adding metadata to chunks — such as titles, headers, or keywords — helps improve the contextuality of the retrieval process. This metadata acts as additional signals that guide the RAG system in fetching the most relevant content.\n\nChallenges in Data Preparation\n\nWhile advanced tools greatly enhance data preparation, challenges remain:\n\nData Quality Variance: The quality of output is directly tied to the input data’s quality. Inconsistent data quality can lead to poor system performance.\n\nComplexity in Integration: Seamlessly integrating these tools into existing data pipelines can be technically challenging and resource-intensive.\n\nScalability Issues: As the volume of data increases, maintaining efficient parsing and retrieval without significant latency becomes challenging.\n\nBest Practices\n\nRegular Updates: Keep the parsing tools and techniques updated with the latest advancements to handle new data formats effectively.\n\nQuality Assurance: Regularly test the parsed data for accuracy and relevancy to ensure the RAG system is receiving the best possible input.\n\nScalable Architectures: Design data pipelines that can scale dynamically with the increasing data volume and complexity.\n\nBy mastering these advanced data preparation and parsing techniques, developers can significantly enhance the performance and reliability of RAG systems. This groundwork is crucial for the advanced retrieval techniques discussed in the next section, where we delve deeper into optimizing the RAG framework for better performance and accuracy.\n\nSection 3: Semantic Chunking and Vector Embeddings\n\nSemantic chunking is a sophisticated technique that optimizes the segmentation of text to enhance the performance of vector embeddings used in Retrieval Augmented Generation (RAG) systems. This section explores the principles of semantic chunking, its implementation, and its impact on the efficacy of information retrieval.\n\nUnderstanding Semantic Chunking\n\nSemantic chunking involves dividing text into segments or “chunks” based on their semantic content rather than arbitrary measures like word count or character limit. This method ensures that each chunk represents a coherent idea or concept, making it more meaningful for vector-based retrieval systems.\n\nKey Benefits of Semantic Chunking\n\nImproved Retrieval Accuracy: By maintaining thematic integrity within each chunk, semantic chunking enhances the relevance of retrieved documents, leading to more accurate and contextually appropriate responses.\n\nEfficient Use of Model Capacity: Semantic chunks optimize the use of the language model’s limited context window (token limit), ensuring that every token the model considers is relevant.\n\nBetter Alignment with Query Intent: Semantic chunking aligns chunks with potential query intents, increasing the likelihood that the retrieval system will select the most relevant content in response to a user query.\n\nImplementing Semantic Chunking\n\nThe process of semantic chunking typically involves several steps and tools, including:\n\nNatural Language Processing (NLP) Techniques: Utilizing NLP tools to analyze the structure and meaning of the text, identifying natural breakpoints based on linguistic cues like topic shifts or narrative changes.\n\nVector Embeddings: Applying machine learning models to convert text chunks into vector form. These vectors capture the semantic essence of the chunks, facilitating their retrieval based on semantic similarity rather than keyword matching.\n\nDynamic Thresholding: Using algorithms to dynamically determine the optimal size of chunks based on the complexity and density of information within the text.\n\nTechnologies and Tools\n\nTools like OpenAI’s embedding models and custom NLP algorithms are essential for effective semantic chunking. These tools analyze and process text to identify segments that encapsulate complete semantic units, converting them into vector embeddings that are stored in databases such as Pinecone or Elasticsearch.\n\nChallenges in Semantic Chunking\n\nWhile powerful, semantic chunking presents several challenges:\n\nComplexity in Implementation: Developing an effective semantic chunking system requires advanced NLP knowledge and the ability to tune models for specific types of data.\n\nBalancing Chunk Size and Cohesion: Finding the right balance between chunk size and informational cohesion can be challenging, as overly broad or narrow chunks can hinder retrieval effectiveness.\n\nComputational Demands: Processing large datasets with advanced NLP models for semantic chunking can be resource-intensive, requiring significant computational power.\n\nPractical Applications\n\nSemantic chunking is particularly useful in applications such as:\n\nLegal and Medical Document Retrieval: Where precision and contextual accuracy are paramount.\n\nCustomer Support Systems: Enhancing AI-driven chatbots to retrieve and provide exact information in response to specific customer queries.\n\nConclusion\n\nSemantic chunking is a critical component in the development of sophisticated RAG systems, enabling more precise and effective information retrieval. By carefully implementing semantic chunking, organizations can significantly enhance the performance of their AI applications, leading to better decision-making and improved user experiences.\n\nSection 4: Enhancing RAG with Advanced Retrieval Techniques\n\nRetrieval Augmented Generation (RAG) systems benefit significantly from advanced retrieval techniques that enhance their ability to fetch the most relevant information quickly and accurately. This section explores various sophisticated retrieval strategies that can be integrated into RAG systems to improve their performance and scalability.\n\nIntroduction to Advanced Retrieval Techniques\n\nThe effectiveness of a RAG system heavily depends on the precision of the retrieval phase. Advanced retrieval techniques aim to optimize this phase by using smarter, more efficient methods to search through large datasets, ensuring that the language model receives the most relevant context for generating responses.\n\nVector Search\n\nVector search uses continuous vector space to represent data and leverages geometric distances to determine relevance. This method is superior to traditional keyword searches as it understands the semantic similarities between the query and the content, allowing for more nuanced and contextually appropriate retrievals.\n\nImplementing Vector Search: Tools like Faiss (Facebook AI Similarity Search) or Annoy (Approximate Nearest Neighbors Oh Yeah) are popular for implementing efficient vector search in production environments.\n\nHybrid Search\n\nHybrid search combines vector search with traditional retrieval methods like keyword search or SQL queries. This approach is beneficial for cases where precise keyword matching is crucial, such as retrieving product names in e-commerce or specific terms in legal documents.\n\nBenefits: Provides a balance between semantic relevance and keyword specificity, enhancing the accuracy and relevance of retrieved results.\n\nReranking with Machine Learning\n\nOnce the initial set of documents is retrieved, reranking them using machine learning models can further refine the results. This process involves scoring each document based on its predicted relevance to the query and reordering them accordingly.\n\nTechniques: Models like BERT or RoBERTa can be fine-tuned to act as rerankers, providing scores based on the contextual alignment between the query and the document content.\n\nAgentic Retrieval\n\nAgentic retrieval introduces an agent-based layer where AI agents dynamically decide the best retrieval paths based on the query’s context. This method is particularly useful in complex scenarios where multiple data sources or types must be considered.\n\nApplication: In customer service, an agent could decide whether to pull information from FAQs, user manuals, or product guides based on the customer’s query complexity and specificity.\n\nChallenges in Advanced Retrieval Techniques\n\nComplexity: Integrating and tuning advanced retrieval methods can be complex and resource-intensive.\n\nLatency: While more precise, these methods can introduce latency, particularly in real-time applications.\n\nData Dependencies: The success of these techniques often depends on the quality and structure of the underlying data.\n\nBest Practices for Implementation\n\nContinuous Evaluation and Tuning: Regularly assess the performance of retrieval techniques and fine-tune them based on feedback and changing data conditions.\n\nScalability Considerations: Design retrieval systems with scalability in mind, ensuring that they can handle growth in data volume and query traffic.\n\nIntegration with AI Models: Ensure seamless integration between the retrieval system and the generative models, maintaining a balance between retrieval accuracy and response generation speed.\n\nConclusion\n\nAdvanced retrieval techniques offer significant potential to enhance RAG systems by providing more accurate and contextually relevant information. By carefully selecting and implementing these methods, organizations can greatly improve the efficiency and effectiveness of their AI-driven applications.\n\nSection 5: Implementing Agentic RAG for Dynamic Query Handling\n\nAgentic Retrieval Augmented Generation (Agentic RAG) represents an evolution in RAG technology, incorporating intelligent agents that dynamically manage the retrieval process based on the complexity and specificity of queries. This section delves into how agentic RAG can be utilized to enhance dynamic query handling and adapt to diverse informational needs efficiently.\n\nWhat is Agentic RAG?\n\nAgentic RAG systems utilize AI agents that act autonomously to optimize the retrieval and response generation processes. These agents assess each query in real-time, decide the best sources for information retrieval, and dynamically adjust their actions based on the context and the evolving requirements of the task.\n\nCore Components of Agentic RAG\n\nQuery Translation and Planning: Agents translate user queries into more effective forms or break them down into sub-queries that are easier to manage and retrieve. This is especially useful for complex queries that may span multiple topics or require data from different sources.\n\nDynamic Retrieval Strategies: Depending on the query’s nature, the agent chooses between different retrieval strategies (e.g., vector search, keyword search, hybrid methods) to optimize accuracy and relevance.\n\nContextual Reranking and Synthesis: After initial retrieval, agents rerank the information based on relevance and synthesize the content to provide concise, informative answers.\n\nImplementing Agentic RAG\n\nStep 1: Agent Design and Development: Define the capabilities and decision-making processes of the agents, such as their ability to parse queries, select retrieval strategies, and perform reranking.\n\nStep 2: Integration with Retrieval Systems: Connect agents with vector databases and other retrieval systems, ensuring they can fetch and process data efficiently.\n\nStep 3: Feedback Loops: Implement mechanisms for the agents to learn from past interactions, refining their strategies and improving their performance over time.\n\nPractical Examples of Agentic RAG\n\nCustomer Support: In customer support scenarios, agents can dynamically fetch the most relevant FAQ sections or product details based on the specific issues described by the customers.\n\nResearch Assistance: For academic or professional research, agents can sift through vast digital libraries to find and synthesize information from multiple papers or reports relevant to a specific research query.\n\nChallenges and Considerations\n\nComplexity in Agent Training: Training agents to handle a wide range of queries and integrate seamlessly with RAG systems can be complex and resource-intensive.\n\nMaintaining Performance: Ensuring the system remains fast and responsive, especially as the number and complexity of queries grow.\n\nAdaptability and Scalability: Designing agents that can adapt to new types of data and scale with increasing information loads.\n\nBest Practices for Agentic RAG\n\nIterative Development: Start with basic agent functionalities and gradually introduce more complex capabilities as the system matures.\n\nUser-Centered Design: Consider the end user’s needs and expectations in the agent’s design, focusing on improving user experience and satisfaction.\n\nContinuous Monitoring and Optimization: Regularly monitor the system’s performance and user feedback to identify areas for improvement.\n\nConclusion\n\nAgentic RAG systems offer a promising advancement in AI-driven information retrieval, allowing for more sophisticated, adaptive, and user-specific responses. By leveraging the power of AI agents, organizations can enhance the efficiency and effectiveness of their knowledge management systems, providing tailored information with greater precision and relevance.\n\nSection 6: From Theory to Practice: Building a RAG Application\n\nBuilding a Retrieval Augmented Generation (RAG) application involves a series of steps that blend theoretical concepts with practical implementation. This section provides a detailed guide on how to develop a RAG system, complete with code snippets and explanations for setting up data pipelines, implementing retrieval methods, and integrating with language models.\n\nStep 1: Define the Scope and Requirements\n\nBefore coding, define the specific needs and goals of your RAG application:\n\nTarget Audience: Who will use this application?\n\nData Sources: What types of documents or data will the system retrieve information from?\n\nPerformance Metrics: How will you measure the success of your RAG system?\n\nStep 2: Data Preparation and Parsing\n\nBegin by preparing and parsing your data to ensure it is clean and structured for efficient retrieval:python\n\nfrom llama_parser import LlamaParts\n\n# Initialize the parser for PDF documents\n\npdf_parser = LlamaParts()# Parse a sample document\n\nstructured_data = pdf_parser.parse('sample_report.pdf')\n\nThis step involves using tools discussed in previous sections to convert raw data into a structured format that can be easily indexed and retrieved.\n\nStep 3: Setting Up the Retrieval System\n\nSet up a vector database to store and retrieve document embeddings:pythonCopy code\n\nfrom pinecone import Index\n\n# Initialize a Pinecone index\n\nindex = Index('your_index_name')# Index documents\n\nfor doc_id, doc_content in structured_data.items():\n\nvector = embed(doc_content)\n\nindex.upsert(id=doc_id, vector=vector)\n\nThis involves embedding documents using a pre-trained model and storing these embeddings in a vector database like Pinecone or Elasticsearch.\n\nStep 4: Implement the Retrieval Logic\n\nImplement the retrieval logic that interacts with the vector database to fetch relevant documents based on a query:pythonCopy code\n\ndef retrieve_documents(query):\n\nquery_vector = embed(query)\n\nresults = index.query(vector=query_vector, top_k=5)\n\nreturn results\n\nThis function takes a user query, converts it into an embedding, and retrieves the top 5 most semantically similar documents.\n\nStep 5: Integrate with a Language Model\n\nUse a language model to generate responses based on the retrieved documents:pythonCopy code\n\nfrom transformers import GPT3Model\n\nmodel = GPT3Model.from_pretrained('gpt3-large')def generate_response(retrieved_docs):\n\ncontext = ' '.join([doc['content'] for doc in retrieved_docs])\n\nprompt = f\"Based on the following information: {context}, answer the user's question.\"\n\nresponse = model.generate(prompt)\n\nreturn response\n\nThis step combines the retrieved content into a coherent context and prompts a large language model to generate an appropriate response.\n\nStep 6: User Interface and Feedback Loop\n\nDevelop a user interface that allows users to interact with the RAG system and provide feedback:pythonCopy code\n\nimport streamlit as st\n\nst.title('RAG System Interface')\n\nquery = st.text_input('Enter your query:')\n\nif st.button('Submit'):\n\nretrieved_docs = retrieve_documents(query)\n\nanswer = generate_response(retrieved_docs)\n\nst.write('Answer:', answer)\n\nInclude functionality for users to provide feedback on the responses, which can be used to fine-tune the system.\n\nConclusion\n\nBuilding a RAG application requires careful integration of multiple components, including data parsing, vector embedding, retrieval, and response generation. By following these steps and utilizing the provided code snippets, developers can create a powerful tool for information retrieval and knowledge management.\n\nSection 7: Testing and Optimizing RAG Systems\n\nAfter constructing a Retrieval Augmented Generation (RAG) system, it’s crucial to engage in thorough testing and continuous optimization to ensure the system meets performance standards and effectively serves its intended purpose. This section will guide you through methodologies for evaluating, testing, and refining RAG systems.\n\nTesting Methodologies\n\nUnit Testing: Begin with unit tests to validate each component of your RAG system — data parsing, indexing, retrieval, and response generation — functions as expected in isolation.\n\nimport unittest\n\nclass TestRetrievalMethods(unittest.TestCase):\n\ndef test_vector_retrieval(self):\n\n# Test the retrieval logic\n\nquery = \"What is AI?\"\n\nexpected_id = \"doc123\"\n\nresults = retrieve_documents(query)\n\nself.assertIn(expected_id, [result['id'] for result in results])\n\nif __name__ == '__main__':\n\nunittest.main()\n\nIntegration Testing: Assess the integration of different system components to ensure they work together seamlessly to produce the correct outputs.\n\nclass TestSystemIntegration(unittest.TestCase):\n\ndef test_query_to_response(self):\n\nquery = \"Explain quantum computing.\"\n\nresponse = generate_response(retrieve_documents(query))\n\nself.assertTrue(isinstance(response, str) and len(response) > 0)\n\nif __name__ == '__main__':\n\nunittest.main()\n\nSystem Testing: Perform end-to-end system tests to evaluate the RAG system’s overall functionality and performance under conditions that mimic real-world operations.\n\nPerformance Evaluation\n\nResponse Accuracy: Use metrics like precision, recall, and F1-score to measure how accurately the system retrieves relevant information and generates responses.\n\nLatency Measurements: Ensure the response time is within acceptable limits, especially for applications requiring real-time feedback.\n\nUser Satisfaction: Conduct user surveys and gather qualitative feedback to gauge the system’s effectiveness and user friendliness.\n\nOptimization Strategies\n\nFine-Tuning Retrieval Models: Continuously update and fine-tune the retrieval models to improve their understanding and handling of diverse queries.\n\n# Example of model fine-tuning from transformers\n\nimport AdamW optimizer = AdamW(model.parameters(), lr=1e-5) # Training loop here\n\nEnhancing Language Models: Regularly retrain the language models with new data or adjust their parameters to refine response generation quality.\n\nScaling and Load Balancing: Implement scalable infrastructure and load balancing to handle increased traffic and data volume without degradation in performance.\n\nContinuous Monitoring and Feedback\n\nSet up monitoring systems to track performance metrics in real-time, and establish feedback loops that allow users to report issues or inefficiencies. Use this data to make informed adjustments:\n\n# Monitoring dashboard setup example\n\nimport streamlit as st\n\nst.metric(label=\"Query Response Time\", value=\"200ms\")\n\nst.metric(label=\"User Satisfaction Score\", value=\"4.5/5\")\n\nConclusion\n\nTesting and optimizing a RAG system is an ongoing process that requires attention to detail, responsiveness to user needs, and agility in adapting to new challenges. By applying the strategies outlined above, developers can ensure their RAG systems not only meet initial expectations but also continue to evolve and improve over time.\n\nSection 8: Real-world Applications and Case Studies\n\nAdvanced Retrieval Augmented Generation (RAG) systems have transformative potential across various sectors. This section explores real-world applications and case studies that demonstrate how RAG systems enhance decision-making, improve user interactions, and solve complex information retrieval challenges.\n\nReal-world Applications\n\nHealthcare: RAG systems are instrumental in managing medical literature and patient data. Doctors use these systems to quickly access patient histories, research treatment options, and stay updated on the latest medical advancements. For instance, a RAG system can retrieve information from medical journals and clinical reports to answer specific queries about drug interactions or treatment protocols.\n\nLegal Industry: Law firms implement RAG systems to navigate vast repositories of legal documents. These systems help lawyers find relevant case laws, precedents, and statutes that are critical for building strong cases. The ability to quickly retrieve and synthesize relevant legal information can drastically reduce the time spent on legal research.\n\nCustomer Support: Companies leverage RAG systems to provide real-time, accurate customer support. By retrieving information from product manuals, FAQs, and customer databases, these systems answer inquiries efficiently, improving customer satisfaction and reducing workload on human agents.\n\nCase Studies\n\nCase Study 1: IBM Watson in Healthcare\n\nBackground: IBM Watson Health used a RAG-like system to assist medical professionals in diagnosing and treating patients.\n\nImplementation: The system parsed and retrieved information from medical journals and patient records to provide recommendations and treatment options.\n\nOutcome: Improved diagnosis accuracy and personalized treatment plans, leading to better patient outcomes and reduced healthcare costs.\n\nCase Study 2: Legal Research Firm\n\nBackground: A leading legal research firm implemented a RAG system to streamline the process of legal document retrieval and case preparation.\n\nImplementation: The system used advanced NLP techniques to understand and retrieve relevant legal texts from a database of over a million documents.\n\nOutcome: Can reduce research time significantly, allowing lawyers to focus more on case strategy and client interaction.\n\nBenefits and Impact\n\nEfficiency: RAG systems significantly cut down the time needed to find and utilize information, increasing productivity across various tasks.\n\nAccuracy: Enhanced retrieval methods ensure that the information provided is accurate and relevant, reducing errors in decision-making processes.\n\nScalability: RAG systems can handle increasing amounts of data without a proportional increase in expense or resource usage, making them scalable solutions for growing organizations.\n\nConclusion\n\nThe real-world applications and case studies of RAG systems underscore their value in transforming how organizations handle information. By automating and enhancing the retrieval and utilization of data, RAG systems empower professionals across industries to make better-informed decisions, ultimately leading to improved outcomes and efficiencies.\n\nFinal Conclusion: Harnessing the Power of RAG Systems\n\nThroughout this blog post, we’ve embarked on a comprehensive journey exploring the intricacies of Retrieval Augmented Generation (RAG) systems — from their basic principles and implementation strategies to advanced techniques and real-world applications. As we conclude, it’s important to reflect on the key insights gained and contemplate the future trajectory of RAG technologies.\n\nRecap of Key Insights\n\nFundamentals: We started by understanding the basic workings of RAG systems, highlighting their ability to enhance traditional language models by integrating dynamic retrieval capabilities.\n\nData Handling: Effective data preparation and advanced parsing techniques are foundational for optimizing the input for RAG systems, ensuring that the data is accurate, relevant, and structured.\n\nAdvanced Techniques: Techniques like semantic chunking, vector search, and agentic RAG not only improve the precision of information retrieval but also tailor the responses to be contextually relevant.\n\nPractical Applications: The exploration of real-world applications demonstrated RAG’s transformative potential across industries such as healthcare, legal, and customer service, providing tangible benefits like increased efficiency, accuracy, and user satisfaction.\n\nTesting and Optimization: Continuous testing and optimization are crucial for maintaining the efficacy of RAG systems, adapting to new data, and refining system components to meet evolving user needs.\n\nFinal Thoughts\n\nRAG systems represent a significant advancement in the way we manage and utilize information. By leveraging AI to enhance data retrieval and response generation, these systems offer a powerful tool for businesses and organizations to improve decision-making and operational efficiency. As we continue to innovate and refine these technologies, the potential for RAG to revolutionize various aspects of professional and everyday life is immense.",
      "# [starred/README.md at master · gaahrdner/starred](https://github.com/gaahrdner/starred/blob/master/README.md)\nA curated list of my GitHub stars! Generated by starred.\n\nASL\n\nASP.NET\n\nActionScript\n\nAdblock Filter List\n\nAssembly\n\nAstro\n\nBatchfile\n\nBlade\n\nBlitzBasic\n\nBro\n\nC\n\nC#\n\nC++\n\nCMake\n\nCOBOL\n\nCSS\n\nClojure\n\nCodeQL\n\nCoffeeScript\n\nCommon Lisp\n\nCrystal\n\nCuda\n\nDart\n\nDhall\n\nDockerfile\n\nElixir\n\nElm\n\nEmacs Lisp\n\nErlang\n\nFortran\n\nGAP\n\nGDScript\n\nGLSL\n\nGo\n\nGroovy\n\nHCL\n\nHTML\n\nHaskell\n\nHy\n\nIsabelle\n\nJava\n\nJavaScript\n\nJinja\n\nJsonnet\n\nJupyter Notebook\n\nJust\n\nKiCad Layout\n\nKotlin\n\nLess\n\nLua\n\nMDX\n\nMakefile\n\nMarkdown\n\nMathematica\n\nMeson\n\nNim\n\nNix\n\nOCaml\n\nObjective-C\n\nObjective-C++\n\nOpen Policy Agent\n\nOpenSCAD\n\nOthers\n\nPHP\n\nPLpgSQL\n\nPascal\n\nPerl\n\nPostScript\n\nPowerShell\n\nProcessing\n\nProlog\n\nPuppet\n\nPureBasic\n\nPureScript\n\nPython\n\nQML\n\nR\n\nRich Text Format\n\nRoff\n\nRuby\n\nRust\n\nSCSS\n\nScala\n\nShell\n\nSolidity\n\nStarlark\n\nSvelte\n\nSwift\n\nTLA\n\nTeX\n\nTypeScript\n\nV\n\nVHDL\n\nVim Script\n\nVue\n\nXSLT\n\nYAML\n\nYARA\n\nZeek\n\nprofzei/Matebook-X-Pro-2018 - 💻 Latest macOS on Huawei Matebook X Pro 2018\n\nASP.NET\n\nYuhangSong/Arena-Baselines - Arena: A General Evaluation Platform and Building Toolkit for Single/Multi-Agent Intelligence. AAAI 2020.\n\nTerryCavanagh/VVVVVV - The source code to VVVVVV! http://thelettervsixtim.es/\n\nAdblock Filter List\n\nmigueldemoura/ublock-umatrix-rulesets - Hosts and uBlock Rulesets\n\nosresearch/airbreak - CPAP jailbreak to allow it to be used as a temporary ventilator\n\ncromulencellc/hackasat-qualifier-2020 - Open source release of challenges and other code used in the Hack-A-Sat Qualifier in 2020.\n\nVitorVilela7/wide-snes - Super Mario World (SNES) Widescreen Project\n\nvxunderground/MalwareSourceCode - Collection of malware source code for a variety of platforms in an array of different programming languages.\n\nRandalLinden/DOOM-FX - Doom/FX for Super Nintendo with SuperFX GSU2A\n\nchrislgarry/Apollo-11 - Original Apollo 11 Guidance Computer (AGC) source code for the command and lunar modules.\n\nmicrosoft/MS-DOS - The original sources of MS-DOS 1.25, 2.0, and 4.0 for reference purposes\n\nKo-/aes-armcortexm - Fast, constant-time and masked AES assembly implementations for ARM Cortex-M3 and M4\n\nbitdump/BLHeli - BLHeli for brushless ESC firmware\n\nLissy93/awesome-privacy - 🦄 A curated list of privacy & security-focused software and services\n\nmassgravel/Microsoft-Activation-Scripts - Open-source Windows and Office activator featuring HWID, Ohook, TSforge, KMS38, and Online KMS activation methods, along with advanced troubleshooting.\n\ngrocy/grocy - ERP beyond your fridge - Grocy is a web-based self-hosted groceries & household management solution for your home\n\n1N3/IntruderPayloads - A collection of Burpsuite Intruder payloads, BurpBounty payloads, fuzz lists, malicious file uploads and web pentesting methodologies and checklists.\n\nantipatico/zeek-dronebl-dnsbl - A Zeek (ex Bro) script to query the DroneBL's DNSBL database.\n\nspitfire55/MegaDev - Bro IDS + ELK Stack to detect and block data exfiltration\n\nh2o/h2o - H2O - the optimized HTTP/1, HTTP/2, HTTP/3 server\n\ncilium/tetragon - eBPF-based Security Observability and Runtime Enforcement\n\nhgarrereyn/GraphFuzz - GraphFuzz is an experimental framework for building structure-aware, library API fuzzers.\n\noracle/bpftune - bpftune uses BPF to auto-tune Linux systems\n\nhanatos/sioux - sioux is not comanche 3\n\ncepa/aegir-gps-tracker - Aegir GPS/LTE/Iridium Tracker\n\nnewaetech/chipshouter-picoemp - Why not run micropython on your EMFI tool?\n\nxroche/httrack - HTTrack Website Copier, copy websites to your computer (Official repository)\n\nbvschaik/julius - An open source re-implementation of Caesar III\n\nmikex86/LibreCuda -\n\npgvector/pgvector - Open-source vector similarity search for Postgres\n\nvalkey-io/valkey - A flexible distributed key-value datastore that is optimized for caching and other realtime workloads.\n\nn0xa/m5stick-nemo - M5 Stick C firmware for high-tech pranks\n\nanfractuosity/ramrecovery - Simple demo illustrating remanence of data in RAM (see Cold boot attack) using a Raspberry Pi. Loads many images of the Mona Lisa into RAM and recovers after powering off/on again.\n\nrisolvipro/playdate-mode7 - A Mode 7 library for Playdate.\n\ndebauchee/barrier - Open-source KVM software\n\ntoverainc/willow - Open source, local, and self-hosted Amazon Echo/Google Home competitive Voice Assistant alternative\n\nimatix/openamq - Full history of the first AMQP implementation 2004-2009\n\ntrholding/llama2.c - Llama 2 Everywhere (L2E)\n\nam0nsec/HellsGate - Original C Implementation of the Hell's Gate VX Technique\n\ngetanteon/alaz - Alaz: Advanced eBPF Agent for Kubernetes Observability – Effortlessly monitor K8s service interactions and performance metrics in your K8s environment. Gain in-depth insights with service maps, metric\n\nkarpathy/llama2.c - Inference Llama 2 in one file of pure C\n\nbartobri/no-more-secrets - A command line tool that recreates the famous data decryption effect seen in the 1992 movie Sneakers.\n\nldpreload/BlackLotus - BlackLotus UEFI Windows Bootkit\n\nSpritetm/picframe_colepd - A WiFi picture frame allowing for remote photo uploads, using an ESP32-C3 and a 5.6\" color E-ink display\n\nskuep/AIOC - Ham Radio All-in-one-Cable\n\ntrzy/ChatARKit - Using ChatGPT to create AR experiences with natural language.\n\ngojue/ecapture - Capturing SSL/TLS plaintext without a CA certificate using eBPF. Supported on Linux/Android kernels for amd64/arm64.\n\nPurpleVsGreen/beacown -\n\nravynsoft/ravynos - A BSD-based OS project that aims to provide source and binary compatibility with macOS® and a similar user experience.\n\nRogueMaster/awesome-flipperzero-withModules - A collection of awesome resources & modules for the Flipper Zero device. Best used with Rogue Master Flipper Zero Custom Firmware.\n\ndakhnod/FakeTag - firmware for nRF51 chips that is coincidentally compatible with the FindMy (AirTag) ecosystem\n\nHarbourMasters/Shipwright -\n\nDarkFlippers/unleashed-firmware - Flipper Zero Unleashed Firmware\n\nsynthetik-technologies/blastfoam - A CFD solver for multi-component compressible flow with application to high-explosive detonation, explosive safety and air blast\n\nczekster/markov - Materials for book: \"Markov Chains for programmers\"\n\nnuvious/pam-duress - A Pluggable Authentication Module (PAM) which allows the establishment of alternate passwords that can be used to perform actions to clear sensitive data, notify IT/Security staff, close off sensitive\n\nunikraft/unikraft - A next-generation cloud native kernel designed to unlock best-in-class performance, security primitives and efficiency savings.\n\ncloudflare/cloudflare-blog - Cloudflare Blog code samples\n\nsolo-io/bumblebee - Get eBPF programs running from the cloud to the kernel in 1 line of bash\n\nosresearch/papercraft - Unfolding STL models to make laser cut patterns\n\nyandex/odyssey - Scalable PostgreSQL connection pooler\n\nDualCoder/vgpu_unlock - Unlock vGPU functionality for consumer grade GPUs.\n\nARM-software/arm-trusted-firmware - Read-only mirror of Trusted Firmware-A\n\ngoogle/AFL - american fuzzy lop - a security-oriented fuzzer\n\ngoogle/honggfuzz - Security oriented software fuzzer. Supports evolutionary, feedback-driven fuzzing based on code coverage (SW and HW based)\n\nyugabyte/yugabyte-db - YugabyteDB - the cloud native distributed SQL database for mission-critical applications.\n\ncromulencellc/hackasat-final-2020 - Open source release of challenges and other code used in the 2020 Hack-a-Sat Final.\n\ncariboulabs/cariboulite - CaribouLite turns any 40-pin Raspberry-Pi into a Tx/Rx 6GHz SDR\n\ncoreos/rpm-ostree - ⚛📦 Hybrid image/package system with atomic upgrades and package layering\n\npathtofile/SealighterTI - Combining Sealighter with unpatched exploits to run the Threat-Intelligence ETW Provider\n\niovisor/gobpf - Go bindings for creating BPF programs.\n\nrisinek/esp32-wifi-penetration-tool - Exploring possibilities of ESP32 platform to attack on nearby Wi-Fi networks.\n\nhackerschoice/gsocket - Connect like there is no firewall. Securely.\n\nr4j0x00/exploits -\n\nSpritetm/minimacplus - Source code, PCB artwork and firmware for a tiny Macintosh Plus\n\ndsnezhkov/zombieant - Zombie Ant Farm: Primitives and Offensive Tooling for Linux EDR evasion.\n\nwillfindlay/bpfbox - 🐝 BPFBox 📦 Exploring process confinement in eBPF\n\ncaptain-amygdala/pistorm - 68k Hardware Emulator\n\ncriblio/appscope - Gain observability into any Linux command or application with no code modification\n\nvanhoefm/krackattacks-scripts -\n\nRfidResearchGroup/proxmark3 - Iceman Fork - Proxmark3\n\nintel/kernel-fuzzer-for-xen-project - Kernel Fuzzer for Xen Project (KF/x) - Hypervisor-based fuzzing using Xen VM forking, VMI & AFL\n\nvxunderground/VXUG-Papers - Research code & papers from members of vx-underground.\n\nrizinorg/rizin - UNIX-like reverse engineering framework and command-line toolset.\n\ncnlohr/channel3 - ESP8266 Analog Broadcast Television Interface\n\nsiemens/jailhouse - Linux-based partitioning hypervisor\n\nopenwall/john - John the Ripper jumbo - advanced offline password cracker, which supports hundreds of hash and cipher types, and runs on many operating systems, CPUs, GPUs, and even some FPGAs\n\nhackerhouse-opensource/exploits - exploits and proof-of-concept vulnerability demonstration files from the team at Hacker House\n\nbootleg/ret-sync - ret-sync is a set of plugins that helps to synchronize a debugging session (WinDbg/GDB/LLDB/OllyDbg2/x64dbg) with IDA/Ghidra/Binary Ninja disassemblers.\n\nhaad/proxychains - proxychains - a tool that forces any TCP connection made by any given application to follow through proxy like TOR or any other SOCKS4, SOCKS5 or HTTP(S) proxy. Supported auth-types: \"user/pass\" for\n\nsandboxie-plus/Sandboxie - Sandboxie Plus & Classic\n\njsitnicki/ebpf-summit-2020 - Steering connections to sockets with BPF socket lookup hook (eBPF Summit 2020)\n\nP403n1x87/austin - Python frame stack sampler for CPython\n\nLloydLabs/wsb-detect - wsb-detect enables you to detect if you are running in Windows Sandbox (\"WSB\")\n\noutflanknl/Zipper - Zipper, a CobaltStrike file and folder compression utility.\n\ngreatscottgadgets/ubertooth - Software, firmware, and hardware designs for Ubertooth\n\ndog-qiuqiu/MobileNet-Yolo - MobileNetV2-YoloV3-Nano: 0.5BFlops 3MB HUAWEI P40: 6ms/img, YoloFace-500k:0.1Bflops 420KB:fire::fire::fire:\n\nF5OEO/rpitx - RF transmitter for Raspberry Pi\n\nHamlib/Hamlib - Ham radio control library for rigs, rotators, tuners, and amplifiers\n\nCESNET/UltraGrid - UltraGrid low-latency audio and video network transmission system\n\nsmeinecke/nylon - nylon is a lightweight proxy framework, currently supporting SOCKS4/5 and a services mirror mode.\n\nmartinmarinov/TempestSDR - Remote video eavesdropping using a software-defined radio platform\n\nkernelslacker/trinity - Linux system call fuzzer\n\nEngineOwningSoftware/pcileech-webradar - CS:GO DMA Cheat (caution, seems to be detected by ESEA and FaceIt)\n\nufrisk/pcileech - Direct Memory Access (DMA) Attack Software\n\ncoturn/coturn - coturn TURN server project\n\nExistentialAudio/BlackHole - BlackHole is a modern macOS audio loopback driver that allows applications to pass audio to other applications with zero additional latency.\n\ngoogle/sanitizers - AddressSanitizer, ThreadSanitizer, MemorySanitizer\n\nAFLplusplus/AFLplusplus - The fuzzer afl++ is afl with community patches, qemu 5.1 upgrade, collision-free coverage, enhanced laf-intel & redqueen, AFLfast++ power schedules, MOpt mutators, unicorn_mode, and a lot more!\n\nstr8outtaheap/heapwn - Linux Heap Exploitation Practice\n\nwapiflapi/exrs - Exercises for learning Reverse Engineering and Exploitation.\n\nrieck/harry - A Tool for Measuring String Similarity\n\nzeustrojancode/Zeus - NOT MY CODE! Zeus trojan horse - leaked in 2011, I am not the author. This repository is for study purposes only, do not message me about your lame hacking attempts.\n\ngen2brain/raylib-go - Go bindings for raylib, a simple and easy-to-use library to enjoy videogames programming.\n\nnccgroup/phantap - Phantom Tap (PhanTap) - an ‘invisible’ network tap aimed at red teams\n\nmerbanan/rtl_433 - Program to decode radio transmissions from devices on the ISM bands (and other frequencies)\n\nsailay1996/UAC_Bypass_In_The_Wild - Windows 10 UAC bypass for all executable files which are autoelevate true .\n\nosmocom/gr-fosphor - GNURadio block for spectrum visualization using GPU; mirror of https://gitea.osmocom.org/sdr/gr-fosphor\n\nosqzss/gps-sdr-sim - Software-Defined GPS Signal Simulator\n\nt6x/reaver-wps-fork-t6x -\n\nzmap/zmap - ZMap is a fast single packet network scanner designed for Internet-wide network surveys.\n\nnwork/jellyfish - GPU rootkit PoC by Team Jellyfish\n\ntrailofbits/krf - A kernelspace syscall interceptor and randomized faulter\n\nRalim/IronOS - Open Source Soldering Iron firmware\n\nImVexed/muon - GPU based Electron on a diet\n\ngoogle/walk - Plan 9 style utilities to replace find(1)\n\nfulldecent/system-bus-radio - Transmits AM radio on computers without radio transmitting hardware.\n\nA2nkF/macOS-Kernel-Exploit - macOS Kernel Exploit for CVE-2019-8781.\n\nMatheus-Garbelini/esp32_esp8266_attacks - Proof of Concept of ESP32/8266 Wi-Fi vulnerabilties (CVE-2019-12586, CVE-2019-12587, CVE-2019-12588)\n\nnmap/ncrack - Ncrack network authentication tool\n\ns0lst1c3/eaphammer - Targeted evil twin attacks against WPA2-Enterprise networks. Indirect wireless pivots using hostile portal attacks.\n\ntelekom-security/tpotce - 🍯 T-Pot - The All In One Multi Honeypot Platform 🐝\n\nradareorg/radare2 - UNIX-like reverse engineering framework and command-line toolset\n\nGenymobile/scrcpy - Display and control your Android device\n\ntaviso/ctftool - Interactive CTF Exploration Tool\n\nkoute/bytehound - A memory profiler for Linux.\n\ntwitter/pelikan - Pelikan is Twitter's unified cache backend\n\nlz4/lz4 - Extremely Fast Compression algorithm\n\nTheWover/donut - Generates x86, x64, or AMD64+x86 position-independent shellcode that loads .NET Assemblies, PE files, and other Windows payloads from memory and runs them with parameters\n\narea9innovation/flow9 - Platform for safe, easy and productive programming of complex, multi-platform apps with a modern user interface\n\nSpacehuhnTech/esp8266_deauther - Affordable WiFi hacking platform for testing and learning\n\nVirusTotal/yara - The pattern matching swiss knife\n\netlegacy/etlegacy-deprecated - Archived repository. For current repo, see: https://github.com/etlegacy/etlegacy\n\naymanbagabas/Huawei-WMI - Huawei WMI laptop extras linux driver\n\nklaussilveira/qengine - Retro game engine for creating games like it's 1997\n\nfwupd/fwupd - A system daemon to allow session software to update firmware\n\nchris408/digispark-usbkey-board - Digispark ATtiny85 USB key \"rubber ducky\" clone\n\nmoehriegitt/hob3l - 100x Faster Slicing of SCAD Files for 3D Printing\n\nbbbrumley/portsmash -\n\nscumjr/dirtycow-vdso - PoC for Dirty COW (CVE-2016-5195)\n\nvideogamepreservation/descent - Descent (1995) by Parallax Software Corp.\n\nihucos/plash - Build and run layered root filesystems.\n\nwb2osz/direwolf - Dire Wolf is a software \"soundcard\" AX.25 packet modem/TNC and APRS encoder/decoder. It can be used stand-alone to observe APRS traffic, as a tracker, digipeater, APRStt gateway, or Internet Gateway (\n\ntimescale/timescaledb - A time-series database for high-performance real-time analytics packaged as a Postgres extension\n\nallinurl/goaccess - GoAccess is a real-time web log analyzer and interactive viewer that runs in a terminal in *nix systems or through your browser.\n\nwekillpeople/browser-dumpwd - Dump browser passwords(chrome, firefox) with sqlite3 lib.\n\nnleseul/obs-shaderfilter - OBS Studio filter for applying an arbitrary shader to a source.\n\nredcanaryco/atomic-red-team - Small and highly portable detection tests based on MITRE's ATT&CK.\n\ngithub/glb-director - GitHub Load Balancer Director and supporting tooling.\n\nshadowsocks/simple-obfs - A simple obfuscating tool (Deprecated)\n\nopenai/retro - Retro Games in Gym\n\niliasam/OpenSimpleLidar - Open Source scanning laser rangefinder\n\ndavatorium/rofi - Rofi: A window switcher, application launcher and dmenu replacement\n\ngentilkiwi/mimikatz - A little tool to play with Windows security\n\nninia/jep - Embed Python in Java\n\nSecWiki/linux-kernel-exploits - linux-kernel-exploits Linux平台提权漏洞集合\n\nbaskerville/bspwm - A tiling window manager based on binary space partitioning\n\nsqueaky-pl/japronto - Screaming-fast Python 3.5+ HTTP toolkit integrated with pipelining HTTP server based on uvloop and picohttpparser.\n\nfabianhu/SIP-Pi - SIP answering machine running on Raspberry Pi\n\ngo-gl/glfw - Go bindings for GLFW 3\n\nnbs-system/naxsi - NAXSI is an open-source, high performance, low rules maintenance WAF for NGINX\n\nnetdata/netdata - X-Ray Vision for your infrastructure!\n\nyarrick/iodine - Official git repo for iodine dns tunnel\n\nopenresty/openresty - High Performance Web Platform Based on Nginx and LuaJIT\n\nconorpp/u2f-zero - U2F USB token optimized for physical security, affordability, and style\n\nrobertdavidgraham/masscan - TCP port scanner, spews SYN packets asynchronously, scanning entire Internet in under 5 minutes.\n\nsamyk/magspoof - A portable device that can spoof/emulate any magnetic stripe, credit card or hotel card \"wirelessly\", even on standard magstripe (non-NFC/RFID) readers. It can disable Chip&PIN and predict AMEX card n\n\nandybarry/flight - Flight code for MIT CSAIL Robot Locomotion Group flying-through-forests project\n\ntwitter/twemproxy - A fast, light-weight proxy for memcached and redis\n\nopenLRSng/openLRSng - Configurable firmware for openLRS compatible TX/RX systems\n\n2Retr0/GodotOceanWaves - FFT-based ocean-wave rendering, implemented in Godot\n\nStability-AI/StableSwarmUI - StableSwarmUI, A Modular Stable Diffusion Web-User-Interface, with an emphasis on making powertools easily accessible, high performance, and extensibility.\n\nfiddyschmitt/File-Tunnel - Tunnel TCP connections through a file\n\nwolfgarbe/PruningRadixTrie - PruningRadixTrie - 1000x faster Radix trie for prefix search & auto-complete\n\nhuggingface/unity-api -\n\nmicrosoft/semantic-kernel - Integrate cutting-edge LLM technology quickly and easily into your apps\n\npeass-ng/PEASS-ng - PEASS - Privilege Escalation Awesome Scripts SUITE (with colors)\n\nReadarr/Readarr - Book Manager and Automation (Sonarr for Ebooks)\n\nProwlarr/Prowlarr - Prowlarr is an indexer manager/proxy built on the popular *arr .net/reactjs base stack to integrate with your various PVR apps, supporting management of both Torrent Trackers and Usenet Indexers.\n\nBnuuySolutions/OculusKiller - Completely kill the Oculus Dash and auto-launch SteamVR.\n\nShogan/kube-chaos - A chaos engineering style game where you seek out and destroy Kubernetes pods, twinstick shmup style.\n\nmatterpreter/DefenderCheck - Identifies the bytes that Microsoft Defender flags on.\n\nlyuma/Av3Emulator - Emulator for VRChat's Avatars 3.0 system, built on the Unity PlayableGraph API\n\nViralmaniar/BigBountyRecon - BigBountyRecon tool utilises 58 different techniques using various Google dorks and open source tools to expedite the process of initial reconnaissance on the target organisation.\n\nUnityTechnologies/open-project-1 - Unity Open Project #1: Chop Chop\n\ncobbr/Covenant - Covenant is a collaborative .NET C2 framework for red teamers.\n\nmandiant/SharPersist -\n\nharleyQu1nn/AggressorScripts - Collection of Aggressor scripts for Cobalt Strike 3.0+ pulled from multiple sources\n\nmdsecactivebreach/RegistryStrikesBack -\n\nmdsecactivebreach/CloneVault -\n\nrxwx/chlonium - Chromium Cookie import / export tool\n\nmicrosoft/onefuzz - A self-hosted Fuzzing-As-A-Service platform\n\nFlangvik/BetterSafetyKatz - Fork of SafetyKatz that dynamically fetches the latest pre-compiled release of Mimikatz directly from gentilkiwi GitHub repo, runtime patches signatures and uses SharpSploit DInvoke to PE-Load into me\n\nGhostPack/SafetyKatz - SafetyKatz is a combination of slightly modified version of @gentilkiwi's Mimikatz project and @subtee's .NET PE Loader\n\nmicrosoft/ApplicationInspector - A source code analyzer built for surfacing features of interest and other characteristics to answer the question 'What's in the code?' quickly using static analysis with a json based rules engine. Ide\n\nNoelFB/Celeste - Celeste Bugs & Issue Tracker + some Source Code\n\ntevora-threat/SharpView - C# implementation of harmj0y's PowerView\n\nx41sec/browser-security-whitepaper-2017 - X41 Browser Security White Paper - Tools and PoCs\n\nHunnicCyber/SharpSniper - Find specific users in active directory via their username and logon IP address\n\njellyfin/jellyfin - The Free Software Media System - Server Backend & API\n\noutflanknl/EvilClippy - A cross-platform assistant for creating malicious MS Office documents. Can hide VBA macros, stomp VBA code (via P-Code) and confuse macro analysis tools. Runs on Linux, OSX and Windows.\n\nTheBerkin/rant3 - (Obsolete) Archive of Rant 3.x.\n\nUnity-Technologies/ml-agents - The Unity Machine Learning Agents Toolkit (ML-Agents) is an open-source project that enables games and simulations to serve as environments for training intelligent agents using deep reinforcement lea\n\nIainMNorman/aoc2018 -\n\nsugi-cho/FlowingParticles - パーティクルをテクスチャで制御する\n\nLidarr/Lidarr - Looks and smells like Sonarr but made for music.\n\nmdjarv/JoystickVisualizer - Joystick Visualizer software, currently made for the Thrustmaster Warthog\n\nmxgmn/WaveFunctionCollapse - Bitmap & tilemap generation from a single example with the help of ideas from quantum mechanics\n\nOmbi-app/Ombi - Want a Movie or TV Show on Plex/Emby/Jellyfin? Use Ombi!\n\nJackett/Jackett - API Support for your favorite torrent trackers\n\nRadarr/Radarr - Movie organizer/manager for usenet and torrent users.\n\nValveSoftware/source-sdk-2013 - The 2013 edition of the Source SDK\n\ndjyt/cannonball - Cannonball: An Enhanced OutRun Engine\n\nsrsran/srsRAN_Project - Open source O-RAN 5G CU/DU solution from Software Radio Systems (SRS) https://docs.srsran.com/projects/project\n\nlibriscv/drogon-sandbox -\n\nRamboRogers/rfhunter - RFHunter is a device to find hidden Cameras at AirBNBs\n\nmicrosoft/BitNet - Official inference framework for 1-bit LLMs\n\nBlueforcer/awtrix3 - Custom firmware for the Ulanzi Smart Pixel clock or self made awtrix. Getting started is easy as 1-2-3\n\nkevmo314/scuda - SCUDA is a GPU over IP bridge allowing GPUs on remote machines to be attached to CPU-only machines.\n\nremipch/solar_concentrator - Homemade automated solar concentrator 🔧 ☀️ 🔎\n\nk2-fsa/sherpa-onnx - Speech-to-text, text-to-speech, speaker diarization, speech enhancement, and VAD using next-gen Kaldi with onnxruntime without Internet connection. Support embedded systems, Android, iOS, HarmonyOS, R\n\njrouwe/JoltPhysics - A multi core friendly rigid body physics and collision detection library. Written in C++. Suitable for games and VR applications. Used by Horizon Forbidden West.\n\ntrailofbits/multiplier - Code auditing productivity multiplier.\n\nAdriankhl/godot-llm - LLM in Godot\n\nalexbatalov/fallout1-ce - Fallout for modern operating systems\n\nsnap-stanford/snap - Stanford Network Analysis Platform (SNAP) is a general purpose network analysis and graph mining library.\n\ngoogle/gemma.cpp - lightweight, standalone C++ inference engine for Google's Gemma models.\n\nNVIDIA/TensorRT-LLM - TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficientl\n\ncifertech/ESP32-DIV - Packet Monitor, WiFi Analyzer, Beacon Spam, Deauth Detector\n\nml-explore/mlx - MLX: An array framework for Apple silicon\n\nMozilla-Ocho/llamafile - Distribute and run LLMs with a single file.\n\nhyprwm/Hyprland - Hyprland is an independent, highly customizable, dynamic tiling Wayland compositor that doesn't sacrifice on its looks.\n\ngoogle/graph-mining -\n\napache/arrow - Apache Arrow is the universal columnar format and multi-language toolbox for fast data interchange and in-memory analytics\n\nduckdb/duckdb - DuckDB is an analytical in-process SQL database management system\n\nvalhalla/valhalla - Open Source Routing Engine for OpenStreetMap\n\nYavorGIvanov/sam.cpp -\n\nvietanhdev/open-adas - An open source advanced driver assistance system (ADAS) that uses Jetson Nano as the hardware. Features: Traffic sign detection, Forward collision warning, Lane departure warning.\n\nDoubangoTelecom/ultimateALPR-SDK - World's fastest ANPR / ALPR implementation for CPUs, GPUs, VPUs and NPUs using deep learning (Tensorflow, Tensorflow lite, TensorRT, OpenVX, OpenVINO). Multi-Charset (Latin, Korean, Chinese) & Multi-O\n\nvitoplantamura/OnnxStream - Lightweight inference library for ONNX files, written in C++. It can run Stable Diffusion XL 1.0 on a RPI Zero 2 (or in 298MB of RAM) but also Mistral 7B on desktops and servers. ARM, x86, WASM, RISC-\n\nasg017/sqlite-vss - A SQLite extension for efficient vector search, based on Faiss!\n\nSvxy/The-Simpsons-Hit-and-Run - Stolen (and slightly cleaned up) version of The Simpsons: Hit & Run original source code from 2003\n\nGDRETools/gdsdecomp - Godot reverse engineering tools\n\nszabolcsdombi/optimization-demo - ⚡ Optimizing Python code by implementing a C++ extension\n\nSysSec-KAIST/LTESniffer - An Open-source LTE Downlink/Uplink Eavesdropper\n\nazerothcore/azerothcore-wotlk - Complete Open Source and Modular solution for MMO\n\nnomic-ai/gpt4all-chat - gpt4all-j chat\n\nRWKV/rwkv.cpp - INT4/INT5/INT8 and FP16 inference on CPU for RWKV language model\n\nnomic-ai/gpt4all - GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.\n\nggml-org/llama.cpp - LLM inference in C/C++\n\nggerganov/whisper.cpp - Port of OpenAI's Whisper model in C/C++\n\nfunction3d/petalot - PET Bottle To 3D Filament\n\ntopjohnwu/Magisk - The Magic Mask for Android\n\nquinndiggity/hacking_slot_machines - Hacking slot machines.\n\nfacebook/watchman - Watches files and records, or triggers actions, when they change.\n\ncloudflare/workerd - The JavaScript / Wasm runtime that powers Cloudflare Workers\n\ngodotengine/godot - Godot Engine – Multi-platform 2D and 3D game engine\n\nHaxHeadroom/HaxHeadroom-FlipperZero-Goodies - Collection of scripts, guides and resources for your FlipperZero - 𝙷𝚊𝙺𝙲𝚎𝚍 𝚠𝚒𝚝𝚑 𝟸𝟹'𝚜\n\npixie-io/pixie - Instant Kubernetes-Native Application Observability\n\nrathena/rathena - rAthena is an open-source cross-platform MMORPG server.\n\nCleverRaven/Cataclysm-DDA - Cataclysm - Dark Days Ahead. A turn-based survival game set in a post-apocalyptic world.\n\ndragonflydb/dragonfly - A modern replacement for Redis and Memcached\n\nggerganov/kbd-audio - 🎤⌨️ Acoustic keyboard eavesdropping\n\nprojectM-visualizer/projectm - projectM - Cross-platform Music Visualization Library. Open-source and Milkdrop-compatible.\n\nmicrosoft/IoT-For-Beginners - 12 Weeks, 24 Lessons, IoT for All!\n\nchrxh/alien - ALIEN is a CUDA-powered artificial life simulation program.\n\nehbar/evol - Evol: The non-life evolution simulator\n\nsystem-pclub/GCatch - Statically Detecting Go Concurrency Bugs\n\nopenframeworks/openFrameworks - openFrameworks is a community-developed cross platform toolkit for creative coding in C++.\n\nfinos/perspective - A data visualization and analytics component, especially well-suited for large and/or streaming datasets.\n\ngoogle/nsjail - A lightweight process isolation tool that utilizes Linux namespaces, cgroups, rlimits and seccomp-bpf syscall filters, leveraging the Kafel BPF language for enhanced security.\n\nhasherezade/pe-sieve - Scans a given process. Recognizes and dumps a variety of potentially malicious implants (replaced/injected PEs, shellcodes, hooks, in-memory patches).\n\nsleuthkit/sleuthkit - The Sleuth Kit® (TSK) is a library and collection of command line digital forensics tools that allow you to investigate volume and file system data. The library can be incorporated into larger digital\n\nrizinorg/rz-ghidra - Deep ghidra decompiler and sleigh disassembler integration for rizin\n\nsolemnwarning/rehex - Reverse Engineers' Hex Editor\n\nComodoSecurity/openedr - Open EDR public repository\n\nrtl-airband/RTLSDR-Airband - Multichannel AM/NFM demodulator\n\nTrunkRecorder/trunk-recorder - Records calls from a Trunked Radio System (P25 & SmartNet)\n\ndanbev/learning-v8 - Project for learning V8 internals\n\ncrossroadsfpga/pigasus - 100Gbps Intrusion Detection and Prevention System\n\ncmu-db/noisepage - Self-Driving Database Management System from Carnegie Mellon University\n\nsepfy/xiaopi - An Open Source Home Security Camera For Raspberry Pi\n\ncatboost/catboost - A fast, scalable, high performance Gradient Boosting on Decision Trees library, used for ranking, classification, regression and other machine learning tasks for Python, R, Java, C++. Supports computa\n\nCyberForce/Pesidious - Malware Mutation Using Reinforcement Learning and Generative Adversarial Networks\n\naseprite/aseprite - Animated sprite editor & pixel art tool (Windows, macOS, Linux)\n\nNeo23x0/Raccine - A Simple Ransomware Vaccine\n\ngoogle/makani - Makani was a project to develop a commercial-scale airborne wind turbine, culminating in a flight test of the Makani M600 off the coast of Norway. All Makani software has now been open-sourced. This r\n\npmarks-net/ac - Wireless A/C controller\n\nohpe/juicy-potato - A sugared version of RottenPotatoNG, with a bit of juice, i.e. another Local Privilege Escalation tool, from a Windows Service Accounts to NT AUTHORITY\\SYSTEM.\n\nHackerPoet/NonEuclidean - A Non-Euclidean Rendering Engine for 3D scenes.\n\nmicrosoft/ALEX - A library for building an in-memory, Adaptive Learned indEX\n\nmicrosoft/winget-cli - WinGet is the Windows Package Manager. This project includes a CLI (Command Line Interface), PowerShell modules, and a COM (Component Object Model) API (Application Programming Interface).\n\nkhalladay/render-with-notepad - A series of programs demonstrating the basics of Memory Scanning, Api Hooking and DLL Injection. The high point is using Notepad.exe as a render target, and playing snake in a notepad window\n\ngit-artes/gr-tempest - An implementation of TEMPEST en GNU Radio\n\nStream-AD/MIDAS - Anomaly Detection on Dynamic (time-evolving) Graphs in Real-time and Streaming manner. Detecting intrusions (DoS and DDoS attacks), frauds, fake rating anomalies.\n\ny-x-c/wearable-microphone-jamming - Repository for our paper Wearable Microphone Jamming\n\ntstack/lnav - Log file navigator\n\nmit-nlp/MITIE - MITIE: library and tools for information extraction\n\nsimdjson/simdjson - Parsing gigabytes of JSON per second : used by Facebook/Meta Velox, the Node.js runtime, ClickHouse, WatermelonDB, Apache Doris, Milvus, StarRocks\n\nalibaba/MNN - MNN is a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba. Full multimodal LLM Android App:[MNN-LLM-Android](./apps/Android/MnnLlmChat/README.\n\nEQuiw/code-imitator -\n\n0xZ0F/Z0FCourse_ReverseEngineering - Reverse engineering focusing on x64 Windows.\n\nalicevision/AliceVision - Photogrammetric Computer Vision Framework\n\nleozide/leocad - A CAD application for creating virtual LEGO models\n\nninja-build/ninja - a small build system with a focus on speed\n\nspacehuhn/WiFiSatellite - WiFi Satellite Project - as seen on the Chaos Communication Congress\n\ngoogle/path-auditor -\n\nCoatiSoftware/Sourcetrail - Sourcetrail - free and open-source interactive source explorer\n\nsebastianstarke/AI4Animation - Bringing Characters to Life with Computer Brains in Unity\n\ncpetrich/counterfeit_DS18B20 - How to tell original from fake DS18B20 temperature sensors.\n\npolybar/polybar - A fast and easy-to-use status bar\n\nrizinorg/cutter - Free and Open Source Reverse Engineering Platform powered by rizin\n\nWithSecureLabs/C3 - Custom Command and Control (C3). A framework for rapid prototyping of custom C2 channels, while still providing integration with existing offensive toolkits.\n\ngoogle-ai-edge/mediapipe - Cross-platform, customizable ML solutions for live and streaming media.\n\ngoogle/safeside - Understand and mitigate software-observable side-channels\n\njmoon018/PacVim -\n\nwazuh/wazuh - Wazuh - The Open Source Security Platform. Unified XDR and SIEM protection for endpoints and cloud workloads.\n\nespotek-org/Labrador - EspoTek Labrador is a USB device that transforms your PC or smartphone into a fully-featured electronics lab. This repo holds all of the source code!\n\nSerenityOS/serenity - The Serenity Operating System 🐞\n\ninterpretml/interpret - Fit interpretable models. Explain blackbox machine learning.\n\nShiqiYu/libfacedetection - An open source library for face detection in images. The face detection speed can reach 1000FPS.\n\nolive-editor/olive - Free open-source non-linear video editor\n\nexploitagency/ESPloitV2 - WiFi Keystroke Injection Tool designed for an Atmega 32u4/ESP8266 Paired via Serial (Cactus WHID Firmware). Also features Serial, HTTP, and PASV FTP exfiltration methods and an integrated Credential\n\nssloy/tinyraycaster - 486 lines of C++: old-school FPS in a weekend\n\nssloy/tinyraytracer - A brief computer graphics / rendering course\n\nssloy/tinykaboom - A brief computer graphics / rendering course\n\nschlae/snark-barker - A 100% compatible replica of the famed SB 1.0 sound card\n\nseenaburns/dex-ui - A science fiction desktop running on Linux. Awesome.\n\nflashlight/wav2letter - Facebook AI Research's Automatic Speech Recognition Toolkit\n\nucbrise/confluo - Real-time Monitoring and Analysis of Data Streams\n\ngoogle/filament - Filament is a real-time physically based rendering engine for Android, iOS, Windows, Linux, macOS, and WebGL2\n\napple/foundationdb - FoundationDB - the open source, distributed, transactional key-value store\n\nDistroAV/DistroAV - DistroAV (formerly OBS-NDI): NDI integration for OBS Studio\n\nenvoyproxy/envoy - Cloud-native high-performance edge/middle/service proxy\n\nValveSoftware/Proton - Compatibility tool for Steam Play based on Wine and additional components\n\nClickHouse/ClickHouse - ClickHouse® is a real-time analytics database management system\n\nwebcamoid/webcamoid - Webcamoid is a full featured and multiplatform webcam suite.\n\nmrayy/UnityCam - Unity3D Virtual webcam plugin, streams unity viewport contents to other applications as virtual camera\n\nstreamlabs/facemask-plugin - (sl)obs filter plug-in for detecting faces and drawing masks on them\n\nalatsombath/Eye-of-the-Storm - A music visualizer for Rainmeter\n\nVhonowslend/StreamFX-Public - StreamFX is a plugin for OBS® Studio which adds many new effects, filters, sources, transitions and encoders! Be it 3D Transform, Blur, complex Masking, or even custom shaders, you'll find it all here\n\nnasa/europa -\n\nXiaoMi/mace - MACE is a deep learning inference framework optimized for mobile heterogeneous computing platforms.\n\nexcamera/alfalfa - Purely functional video codec, used for ExCamera and Salsify\n\ntrapexit/mergerfs - a featureful union filesystem\n\nscylladb/scylladb - NoSQL data store using the Seastar framework, compatible with Apache Cassandra and Amazon DynamoDB\n\nctubio/Krypto-trading-bot - Self-hosted crypto trading bot (automated high frequency market making) written in C++\n\ncarla-simulator/carla - Open-source simulator for autonomous driving research.\n\nOpenGenus/cosmos - World's largest Contributor driven code dataset | Used in Quark Search Engine, @OpenGenus IQ, OpenGenus Visual Project\n\nJamesP6000/WsprryPi - Raspberry Pi WSPR transmitter using NTP based frequency calibration\n\nrobin7331/IKEA-Hackant -\n\ntensorflow/tensorflow - An Open Source Machine Learning Framework for Everyone\n\nprusa3d/PrusaSlicer - G-code generator for 3D printers (RepRap, Makerbot, Ultimaker etc.)\n\nherbstluftwm/herbstluftwm - A manual tiling window manager for X11\n\nmaxritter/diy-thermocam - A do-it-yourself thermal imager, compatible with the FLIR Lepton 2.5, 3.1R and 3.5 sensor with Arduino firmware\n\nptrkrysik/gr-gsm - Gnuradio blocks and tools for receiving GSM transmissions\n\nfacebookarchive/beringei - Beringei is a high performance, in-memory storage engine for time series data.\n\nvisualfc/liteide - LiteIDE is a simple, open source, cross-platform Go IDE.\n\nmanupap1/libzoneminder-plugin-openalpr - libzoneminder-plugin-openalpr is a free, open source Licence Plate Recognition plugin for the ZoneMinder CCTV sofware (https://github.com/ZoneMinder/ZoneMinder). It is based on openalpr library (https\n\nopenalpr/openalpr - Automatic License Plate Recognition library\n\nsheaivey/rx5808-pro-diversity - DIY project to create your own 5.8ghz FPV diversity basestation - based off the rx5808 receiver module. Project includes basic Arduino Nano implementation to advanced custom PCB board and introduction\n\nUSU-Security/oip - \"organicip\" visualizer - uses libpcap and SDL to visualize IP traffic between endpoints\n\ndockcross/dockcross - Cross compiling toolchains in Docker images\n\nptrkrysik/multi-rtl - Multi-channel receiver with use of RTL-SDR dongles\n\nmeyfa/CobolCraft - A Minecraft server written in COBOL\n\ncocktailpeanut/dalai - The simplest way to run LLaMA on your local machine\n\nlethain/staff-eng - Collection of stories of how folks have reached Staff-plus roles in technology.\n\nassetnote/wordlists - Automated & Manual Wordlists provided by Assetnote\n\nsyphon1c/Threatelligence - Threatelligence is a simple cyber threat intelligence feed collector, using Elasticsearch, Kibana and Python to automatically collect intelligence from custom or public sources. Automatically updates\n\nryanoasis/nerd-fonts - Iconic font aggregator, collection, & patcher. 3,600+ icons, 50+ patched fonts: Hack, Source Code Pro, more. Glyph collections: Font Awesome, Material Design Icons, Octicons, & more\n\nvaibhawvipul/First-steps-towards-Deep-Learning - This is an open sourced book on deep learning.\n\ncssanimation/css-animation-101 - Learn how to bring animation to your web projects\n\nnecolas/normalize.css - A modern alternative to CSS resets\n\ntachyons-css/tachyons - Functional css for humans\n\njbtronics/CrookedStyleSheets - Webpage tracking only using CSS (and no JS)\n\nadapta-project/adapta-gtk-theme - An adaptive Gtk+ theme based on Material Design Guidelines\n\nhorst3180/arc-theme - A flat theme with transparent elements\n\naftertheflood/sparks - A typeface for creating sparklines in text without code.\n\ndamn/moon - RPG Maker & Engine\n\ninstantdb/instant - Instant is a modern Firebase. We make you productive by giving your frontend a real-time database.\n\njepsen-io/maelstrom - A workbench for writing toy implementations of distributed systems.\n\nkiranshila/Doplarr - An *arr request bot for Discord\n\npenpot/penpot - Penpot: The open-source design tool for design and code collaboration\n\nathensresearch/athens - Athens is no longer maintainted. Athens was an open-source, collaborative knowledge graph, backed by YC W21\n\nmetabase/metabase - The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data 📊\n\njepsen-io/jepsen - A framework for distributed systems verification, with fault injection\n\ngithub/vscode-codeql-starter - Starter workspace to use with the CodeQL extension for Visual Studio Code.\n\nPagedraw/pagedraw - a UI builder for React web apps\n\nflosse/sloc - simple tool to count SLOC (source lines of code)\n\nCommon Lisp\n\nkaveh808/kons-9 - Common Lisp 3D Graphics Project\n\nvitobotta/hetzner-k3s - The easiest and fastest way to create and manage Kubernetes clusters in Hetzner Cloud using the lightweight distribution k3s by Rancher.\n\nluckyframework/lucky - A full-featured Crystal web framework that catches bugs for you, runs incredibly fast, and helps you write code that lasts.\n\ndeepseek-ai/DeepEP - DeepEP: an efficient expert-parallel communication library\n\ndagmawibabi/ScholarXIV - ScholArxiv is an open-source, aesthetic, minimal and AI powered app that allows users to search, read, bookmark, share, download and view summaries of academic papers from the arXiv repository.\n\nente-io/ente - End-to-end encrypted, FOSS cloud for Photos, 2FA secrets and more!\n\nKRTirtho/spotube - 🎧 Open source Spotify client that doesn't require Premium nor uses Electron! Available for both desktop & mobile!\n\nAppFlowy-IO/AppFlowy - Bring projects, wikis, and teams together with AI. AppFlowy is the AI collaborative workspace where you achieve more without losing control of your data. The leading open source Notion alternative.\n\njmshrv/finamp - A Jellyfin music client for mobile\n\nkodecocodes/flta-materials - The projects and the materials that accompany the Flutter Apprentice book\n\nchuabingquan/helm - 💪 Helm is an app that gamifies stress/anxiety/depression management in an actionable manner to provide relief.\n\nflutter/flutter - Flutter makes it easy and fast to build beautiful apps for mobile and beyond\n\nSolido/awesome-flutter - An awesome list that curates the best Flutter libraries, tools, tutorials, articles and more.\n\ndhall-lang/dhall-kubernetes - Typecheck, template and modularize your Kubernetes definitions with Dhall\n\nOWASP/API-Security - OWASP API Security Project\n\nHacking-the-Cloud/hackingthe.cloud - An encyclopedia for offensive and defensive security knowledge in cloud native technologies.\n\nlinuxserver/docker-calibre -\n\nposzu/godot-servers-k8s -\n\ngrocy/grocy-docker - ERP beyond your fridge - now containerized - this is the docker repo of https://github.com/grocy/grocy\n\noxsecurity/megalinter - 🦙 MegaLinter analyzes 50 languages, 22 formats, 21 tooling formats, excessive copy-pastes, spelling mistakes and security issues in your repository sources with a GitHub Action, other CI tools or loca\n\nhexops-graveyard/dockerfile - Dockerfile best-practices for writing production-worthy Docker images.\n\nOWASP/wstg - The Web Security Testing Guide is a comprehensive Open Source guide to testing the security of web applications and web services.\n\nandrewbeard/broworkshop - Materials for the BSides NoVA/Charleston 2018 Bro Workshop\n\nAlexisAhmed/BugBountyToolkit - A multi-platform bug bounty toolkit that can be installed on Debian/Ubuntu or set up with Docker.\n\nvulhub/vulhub - Pre-Built Vulnerable Environments Based on Docker-Compose\n\nJetBrains/teamcity-docker-agent - TeamCity agent docker image sources\n\nkelseyhightower/nocode - The best way to write secure and reliable applications. Write nothing; deploy nowhere.\n\npgorczak/srslte-docker-emulated - Minimal end-to-end LTE. Dockerized and emulated radio over shared memory.\n\ngoldbergyoni/nodebestpractices - ✅ The Node.js best practices list (July 2024)\n\nelectric-sql/electric - Real-time sync for Postgres.\n\nelixir-nx/nx - Multi-dimensional arrays (tensors) and numerical definitions for Elixir\n\nlivebook-dev/livebook - Automate code & data workflows with interactive Elixir notebooks\n\nelixir-explorer/explorer - Series (one-dimensional) and dataframes (two-dimensional) for fast and elegant data exploration in Elixir\n\nelixir-nx/scholar - Traditional machine learning on top of Nx\n\nelixir-nx/axon - Nx-powered Neural Networks\n\nstandard-webhooks/standard-webhooks - The Standard Webhooks specification\n\nwoutdp/live_svelte - Svelte inside Phoenix LiveView with seamless end-to-end reactivity\n\nhappycodrz/phoenix-apps -\n\nelixir-nx/bumblebee - Pre-trained Neural Network models in Axon (+ 🤗 Models integration)\n\nsupabase/realtime - Broadcast, Presence, and Postgres Changes via WebSockets\n\nGoogleCloudPlatform/elixir-samples - A collection of samples on using Elixir with Google Cloud Platform.\n\nScenicFramework/scenic - Core Scenic library\n\nh4cc/awesome-elixir - A curated list of amazingly awesome Elixir and Erlang libraries, resources and shiny things. Updates:\n\nrtfeldman/elm-spa-example - A Single Page Application written in Elm\n\nEmacs Lisp\n\nkubernetes-el/kubernetes-el - Manage Kubernetes clusters with Emacs.\n\nhappi/theBeamBook - A description of the Erlang Runtime System ERTS and the virtual Machine BEAM.\n\nprocessone/tsung - Tsung is a high-performance benchmark framework for various protocols including HTTP, XMPP, LDAP, etc.\n\nmom-ocean/MOM6 - Modular Ocean Model\n\nFreddieHong19/Open5x - This is a Github repository for 5-axis 3D printing\n\nlukky-nl/Pocket-Godot - Starter Kit for mobile game development using Godot\n\nKenneyNL/Starter-Kit-FPS -\n\nKenneyNL/Starter-Kit-City-Builder -\n\nJamsers/Bistro-Demo-Tweaked - Bistro demo for Godot showcasing lighting and high quality assets.\n\ndrwhut/tabletop-club - An open-source platform for playing tabletop games in a physics-based 3D environment for Windows, macOS, and Linux! Made with the Godot Engine.\n\nHaidra-Org/AI-Horde-Godot-Addon - A Godot addon for using Stable Horde\n\nOrama-Interactive/Pixelorama - Unleash your creativity with Pixelorama, a powerful and accessible open-source pixel art multitool. Whether you want to create sprites, tiles, animations, or just express yourself in the language of p\n\ngdquest-demos/godot-shaders - A large library of free and open-source shaders for the Godot game engine. Here, you'll get 2D and 3D shaders with playable demos.\n\nekzhang/graphics-workshop - Learn computer graphics by writing GPU shaders!\n\nZouuup/landrun - Run any Linux process in a secure, unprivileged sandbox using Landlock. Think firejail, but lightweight, user-friendly, and baked into the kernel.\n\nteivah/100-go-mistakes - 📖 100 Go Mistakes and How to Avoid Them\n\nrudransh61/Physix-go - A simple Physics engine in GoLang\n\nikemen-engine/Ikemen-GO - An open-source fighting game engine that supports MUGEN resources.\n\ngrpc-ecosystem/grpc-gateway - gRPC to JSON proxy generator following the gRPC HTTP spec\n\n9elements/firmware-action - Build system for open source firmware (coreboot, linux, EDK2, ...) with unified builds across development and CI environments.\n\ntakara-ai/go-attention - A full attention mechanism and transformer in pure go.\n\nyusuf-musleh/mmar - mmar is a zero-dependency, self-hostable, cross-platform HTTP tunnel that exposes your localhost to the world on a public URL. Written in Go.\n\nDeepSourceCorp/globstar - Globstar is a fast, feature-rich, and open-source static analysis toolkit for writing and running code checkers. Based on tree-sitter.\n\nnoperator/raink - Bleeding-edge fork of raink 🩸\n\nkubenetworks/kubevpn - KubeVPN offers a Cloud Native Dev Environment that connects to kubernetes cluster network.\n\ntesserato/CodeWeaver - Weave your codebase into a single, navigable Markdown document\n\nleg100/pug - Drive terraform at terminal velocity.\n\nsoub4i/kubestatus-operator - kubestatus operator\n\nIceWhaleTech/CasaOS - CasaOS - A simple, easy-to-use, elegant open-source Personal Cloud system.\n\ncyclops-ui/cyclops - Developer Friendly Kubernetes 👁️\n\nzasper-io/zasper - 4X Better IDE than Jupyterlab\n\nget-glu/glu - A deployment pipeline framework that sticks\n\nchenquan/sqltrace - A low-code intrusion library that provides SQL tracing capabilities, suitable for any relational database (Sqlite3, MySQL, Oracle, SQL Server, PostgreSQL, TiDB, TDengine, etc.) and ORM libraries for v\n\nfergusstrange/embedded-postgres - Run a real Postgres database locally on Linux, OSX or Windows as part of another Go application or test\n\nariga/atlas - Manage your database schema as code\n\nsqldef/sqldef - Idempotent schema management for MySQL, PostgreSQL, and more\n\ncloudprober/cloudprober - An active monitoring software to detect failures before your customers do.\n\nperiskop-dev/periskop - Exception Monitoring Service\n\nsinkingpoint/clogger - A Logging Daemon\n\ndsnet/try - Simplified error handling in Go\n\nsuborbital/vektor - Opinionated production-grade HTTP server framework for Go\n\nfatih/semgroup - Like errgroup/waitgroup, but only runs a maximum of tasks at any time.\n\ntmrts/go-patterns - Curated list of Go design patterns, recipes and idioms\n\neldadru/ksniff - Kubectl plugin to ease sniffing on kubernetes pods using tcpdump and wireshark\n\nstefanprodan/podinfo - Go microservice template for Kubernetes\n\ngetseabird/seabird - Native Kubernetes desktop IDE designed for seamless cluster exploration\n\nrancher/k3os - Purpose-built OS for Kubernetes, fully managed by Kubernetes.\n\nstefanprodan/timoni - Timoni is a package manager for Kubernetes, powered by CUE and inspired by Helm.\n\nnetobserv/network-observability-operator - An OpenShift / Kubernetes operator for network observability\n\nedgelesssys/constellation - Constellation is the first Confidential Kubernetes. Constellation shields entire Kubernetes clusters from the (cloud) infrastructure using confidential computing.\n\nkubeshark/kubeshark - The API traffic analyzer for Kubernetes providing real-time K8s protocol-level visibility, capturing and monitoring all traffic and payloads going in, out and across containers, pods, nodes and cluste\n\nclusterpedia-io/clusterpedia - The Encyclopedia of Kubernetes clusters\n\nmerbridge/merbridge - Use eBPF to speed up your Service Mesh like crossing an Einstein-Rosen Bridge.\n\nNimbleArchitect/kubectl-ice - Kubectl-ice is an open-source tool for Kubernetes users to monitor and optimize container resource usage. Features include usage breakdowns for pods and containers, making scaling and optimization eas\n\nchrisns/kubectl-passman - kubectl plugin that provides the missing link/glue between common password managers and kubectl\n\ngravitl/netmaker - Netmaker makes networks with WireGuard. Netmaker automates fast, secure, and distributed virtual networks.\n\niovisor/kubectl-trace - Schedule bpftrace programs on your kubernetes cluster using the kubectl\n\ncugu/gocap - List your dependencies capabilities and monitor if updates require more capabilities.\n\nyuuki/shawk - [PoC] A socket-based tracing system for discovering network service dependencies. (renamed from transtracer)\n\nanchore/grype - A vulnerability scanner for container images and filesystems\n\nprojectdiscovery/uncover - Quickly discover exposed hosts on the internet using multiple search engines.\n\nulfox/nettrust - Dynamic Outbound Firewall Authorizer\n\nalphasoc/flightsim - A utility to safely generate malicious network traffic patterns and evaluate controls.\n\ndevploit/nomore403 - Tool to bypass 403/40X response codes.\n\ntofuutils/tenv - OpenTofu / Terraform / Terragrunt and Atmos version manager\n\nlxc/incus - Powerful system container and virtual machine manager\n\ntsenart/kth - Fast selection algorithms for Go\n\nkelindar/search - Go library for embedded vector search and semantic embeddings using llama.cpp\n\nnaughtygopher/pocache - Pocache is a minimal cache package which focuses on a preemptive optimistic caching strategy\n\nadamdecaf/deadcheck - dead mans switch without reliance on your system\n\nandrearaponi/dito - an advanced reverse proxy server written in Go\n\ntjb/gofaux - versatile cli tool that captures and stores json requests, allowing you to replay them as needed.\n\nTelemaco019/kubesafe - Safely manage multiple Kubernetes clusters by defining safe contexts and protected commands.\n\nsatmihir/fair - A Go library for serving resources fairly\n\nergo-services/ergo - An actor-based Framework with network transparency for creating event-driven architecture in Golang. Inspired by Erlang. Zero dependencies.\n\nkeisku/gmon - An eBPF tool monitoring a goroutine\n\ngorgonia/gorgonia - Gorgonia is a library that helps facilitate machine learning in Go.\n\nthejerf/suture - Supervisor trees for Go.\n\nrunZeroInc/sshamble - SSHamble: Unexpected Exposures in SSH\n\ngazette/core - Build platforms that flexibly mix SQL, batch, and stream processing paradigms\n\nxvzc/SpoofDPI - A simple and fast anti-censorship tool written in Go\n\nnlewo/comin - GitOps For NixOS Machines\n\nmiekg/gitopper - Gitops for non-Kubernetes folks\n\nmyzie/burrow - Burrow is a globally distributed HTTP proxy via AWS Lambda\n\narunsupe/semantic-grep - grep for words with similar meaning to the query\n\nquackduck/devzat - The devs are over here at devzat, chat over SSH!\n\ndrakkan/sftpgo - Full-featured and highly configurable SFTP, HTTP/S, FTP/S and WebDAV server - S3, Google Cloud Storage, Azure Blob\n\ncharmbracelet/bubbletea - A powerful little TUI framework 🏗\n\ncharmbracelet/wish - Make SSH apps, just like that! 💫\n\ncharmbracelet/bubbles - TUI components for Bubble Tea 🫧\n\ndanielmiessler/fabric - fabric is an open-source framework for augmenting humans using AI. It provides a modular framework for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.\n\nsyntaqx/cookie - Cookies, but with structs, for happiness.\n\npoundifdef/smoothmq - An improved drop-in replacement for SQS\n\ncruise-automation/isopod - An expressive DSL and framework for Kubernetes configuration without YAML\n\nglasskube/glasskube - 🧊 The next generation Package Manager for Kubernetes 📦 Featuring a GUI and a CLI. Glasskube packages are dependency aware, GitOps ready and can get automatic updates via a central public package repos\n\nstripe/skycfg - Skycfg is an extension library for the Starlark language that adds support for constructing Protocol Buffer messages.\n\nanchore/syft - CLI tool and library for generating a Software Bill of Materials from container images and filesystems\n\nedgelesssys/contrast - Deploy and manage confidential containers on Kubernetes\n\nNHAS/wag - Simple Wireguard 2FA\n\nplandex-ai/plandex - Open source AI coding agent. Designed for large projects and real world tasks.\n\ndaytonaio/daytona - Daytona is a Secure and Elastic Infrastructure for Running AI-Generated Code.\n\nknl/pulley - A service to expose Prometheus metrics of your CI’s validation of Pull Requests, using GitHub webhooks.\n\nxrstf/github_exporter - Prometheus GitHub exporter with a focus on Pull Request/Issue/Milestone metrics\n\nchaspy/github-pr-prometheus-exporter - Prometheus Exporter for GitHub Pull Requests\n\njmartin82/mkpis - Measuring the development process for Gitflow managed projects.\n\namlweems/xzbot - notes, honeypot, and exploit demo for the xz backdoor (CVE-2024-3094)\n\npojntfx/weron - Overlay networks based on WebRTC.\n\ngravitational/gha-exporter - GitHub Actions metrics exporter for Prometheus\n\nfailsafe-go/failsafe-go - Fault tolerance and resilience patterns for Go\n\na-h/templ - A language for writing HTML user interfaces in Go.\n\nmercari/tortoise - Tortoise: Shell-Shockingly-Good Kubernetes Autoscaling\n\nSuperPaintman/the-evolution-of-a-go-programmer - The Evolution of a Go Programmer\n\njovandeginste/workout-tracker - A workout tracking web application for personal use (or family, friends), geared towards running and other GPX-based activities\n\nfullstorydev/grpcurl - Like cURL, but for gRPC: Command-line tool for interacting with gRPC servers\n\nhlfshell/coppermind - Instruction based LLM contextual memory manager to power custom AI personalities and chatbots\n\nzitadel/passwap - Package passwap provides a unified implementation between different password hashing algorithms. It allows for easy swapping between algorithms, using the same API for all of them.\n\nlunarway/shuttle - CLI for handling shared build and deploy tools between projects no matter what technologies the projects are using\n\napernet/OpenGFW - OpenGFW is a flexible, easy-to-use, open source implementation of GFW (Great Firewall of China) on Linux\n\nint128/argocd-commenter - Notify ArgoCD Application status via Pull Request comment or GitHub Deployment API\n\nFairwindsOps/rbac-manager - A Kubernetes operator that simplifies the management of Role Bindings and Service Accounts.\n\ngregoryv/uncover - Generate coverage reports from cover profiles\n\nyannh/kubeconform - A FAST Kubernetes manifests validator, with support for Custom Resources!\n\noverflowy/spongebob-cli - SpongeBob delivered straight from your terminal\n\ncasibase/casibase - ⚡️AI Cloud OS: Open-source enterprise-level AI knowledge base and Manus-like agent management platform with admin UI, user management and Single-Sign-On⚡️, supports ChatGPT, Claude, DeepSeek R1, Llama\n\nopenbao/openbao - OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys.\n\nuber-go/nilaway - Static analysis tool to detect potential nil panics in Go code\n\nbazel-contrib/bazel-gazelle - Gazelle is a Bazel build file generator for Bazel projects. It natively supports Go and protobuf, and it may be extended to support new languages and custom rule sets.\n\nuber-go/automaxprocs - Automatically set GOMAXPROCS to match Linux container CPU quota.\n\nIeooo/clash - fork from clash\n\napache/answer - A Q&A platform software for teams at any scales. Whether it's a community forum, help center, or knowledge management platform, you can always count on Apache Answer.\n\njackc/pgx - PostgreSQL driver and toolkit for Go\n\nzeromicro/go-zero - A cloud-native Go microservices framework with cli tool for productivity.\n\nflipt-io/cup - Git Contribution Automation\n\ngetzep/zep - Zep | The Memory Foundation For Your AI Stack\n\n0xERR0R/blocky - Fast and lightweight DNS proxy as ad-blocker for local network with many features\n\nsix-ddc/plow - A high-performance HTTP benchmarking tool that includes a real-time web UI and terminal display\n\nF1bonacc1/process-compose - Process Compose is a simple and flexible scheduler and orchestrator to manage non-containerized applications.\n\njesseduffield/horcrux - Split your file into encrypted fragments so that you don't need to remember a passcode\n\nmrusme/superhighway84 - USENET-inspired, uncensorable, decentralized internet discussion system running on IPFS & OrbitDB\n\napernet/hysteria - Hysteria is a powerful, lightning fast and censorship resistant proxy.\n\napecloud/kubeblocks - KubeBlocks is an open-source control plane software that runs and manages databases, message queues and other stateful applications on K8s.\n\nosteele/gojekyll - A fast Go implementation of the Jekyll blogging engine\n\nIBM/fp-go - functional programming library for golang\n\nsuperfly/litefs - FUSE-based file system for replicating SQLite databases across a cluster of machines\n\nzknill/sqledge - Replicate postgres to SQLite on the edge\n\nollama/ollama - Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, and other large language models.\n\ngorse-io/gorse - Gorse open source recommender system engine\n\nGRVYDEV/S.A.T.U.R.D.A.Y - A toolbox for working with WebRTC, Audio and AI\n\nglycerine/zygomys - Zygo is a Lisp interpreter written in 100% Go. Central use case: dynamically compose Go struct trees in a zygo script, then invoke compiled Go functions on those trees. Makes Go reflection easy.\n\njetify-com/typeid - Type-safe, K-sortable, globally unique identifier inspired by Stripe IDs\n\ndiggerhq/digger - Digger is an open source IaC orchestration tool. Digger allows you to run IaC in your existing CI pipeline ⚡️\n\nMatthewJamesBoyle/golang-interview-prep -\n\nhelmfile/helmfile - Declaratively deploy your Kubernetes manifests, Kustomize configs, and Charts as Helm releases. Generate all-in-one manifests for use with ArgoCD.\n\nargoproj-labs/argocd-autopilot - Argo-CD Autopilot\n\nrelease-argus/Argus - Argus is a lightweight monitor to notify of new software releases via Gotify/Slack/other messages and/or WebHooks.\n\ndwisiswant0/siml - siml is a CLI tool for discovering similar, related to, competitive, or alternative options to a given site.\n\nMrIceman/go-uml - A tool written in Go to build Sequence Diagrams and more UML - in Go\n\nmoul/quicssh - SSH over QUIC\n\naws/karpenter-provider-aws - Karpenter is a Kubernetes Node Autoscaler built for flexibility, performance, and simplicity.\n\ngithubexporter/github-exporter - Prometheus exporter for github metrics\n\npojntfx/go-nbd - Pure Go NBD server and client library.\n\nfafrd/aquarium - AI-controlled Linux Containers\n\nauthzed/controller-idioms - Generic libraries for building idiomatic Kubernetes controllers\n\nwailsapp/wails - Create beautiful applications using Go\n\nThreeDotsLabs/wild-workouts-go-ddd-example - Go DDD example application. Complete project to show how to apply DDD, Clean Architecture, and CQRS by practical refactoring.\n\nbebop/poly - A Go package for engineering organisms.\n\nebitengine/purego -\n\ngrafana/k6-operator - An operator for running distributed k6 tests.\n\nopencost/opencost - Cost monitoring for Kubernetes workloads and cloud costs\n\nalpkeskin/mosint - An automated e-mail OSINT tool\n\nmakew0rld/didder - An extensive, fast, and accurate command-line image dithering tool.\n\nacheong08/ChatGPT-API-server - API server for ChatGPT\n\npocketbase/pocketbase - Open Source realtime backend in 1 file\n\ntetratelabs/wazero - wazero: the zero dependency WebAssembly runtime for Go developers\n\nu-root/u-root - A fully Go userland with Linux bootloaders! u-root can create a one-binary root file system (initramfs) containing a busybox-like set of tools written in Go.\n\nminiflux/v2 - Minimalist and opinionated feed reader\n\ntailscale/golink - A private shortlink service for tailnets\n\nthangchung/go-coffeeshop - ☕ A practical event-driven microservices demo built with Golang. Nomad, Consul Connect, Vault, and Terraform for deployment\n\ngoogle/mangle -\n\nloxilb-io/loxilb - eBPF based cloud-native load-balancer for Kubernetes|Edge|Telco|IoT|XaaS.\n\nPerimeterX/marshmallow - Marshmallow provides a flexible and performant JSON unmarshalling in Go. It specializes in dealing with unstructured struct - when some fields are known and some aren't, with zero performance overhead\n\nFairwindsOps/goldilocks - Get your resource requests \"Just Right\"\n\ndailymotion-oss/octopilot - Automate your Gitops workflow, by automatically creating/merging GitHub Pull Requests\n\ngolang-migrate/migrate - Database migrations. CLI and Golang library.\n\ninancgumus/learngo - ❤️ 1000+ Hand-Crafted Go Examples, Exercises, and Quizzes. 🚀 Learn Go by fixing 1000+ tiny programs.\n\nmicro/services - Real World Micro Services\n\ncoroot/coroot - Coroot is an open-source APM & Observability tool, a DataDog and NewRelic alternative. Metrics, logs, traces, continuous profiling, and SLO-based alerting, supercharged with predefined dashboards and\n\nvolution/kawipiko - kawipiko -- blazingly fast static HTTP server -- focused on low latency and high concurrency, by leveraging Go, fasthttp and the CDB embedded database\n\nkedacore/keda - KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes\n\nSagerNet/sing-box - The universal proxy platform\n\nzincsearch/zincsearch - ZincSearch . A lightweight alternative to elasticsearch that requires minimal resources, written in Go.\n\naquasecurity/tracee - Linux Runtime Security and Forensics using eBPF\n\ndominikbraun/graph - A library for creating generic graph data structures and modifying, analyzing, and visualizing them.\n\nearthly/earthly - Super simple build framework with fast, repeatable builds and an instantly familiar syntax – like Dockerfile and Makefile had a baby.\n\nkerbyj/goLazagne - Go library for credentials recovery\n\nvyrus001/msflib - A golang library designed to interact with Metasploit\n\naus/gopherheaven - Go implementation of the Heaven's Gate technique\n\noptiv/ScareCrow - ScareCrow - Payload creation framework designed around EDR bypass.\n\nBinject/universal - Universal Shared Library User-space Loader\n\naudibleblink/holeysocks - Cross-Platform Reverse Socks Proxy in Go\n\nsysdream/chashell - Chashell is a Go reverse shell that communicates over DNS. It can be used to bypass firewalls or tightly restricted networks.\n\ngoretk/redress - Redress - A tool for analyzing stripped Go binaries\n\nburrowers/garble - Obfuscate Go builds\n\nsassoftware/relic - Relic is a service and a tool for adding digital signatures to operating system packages for Linux and Windows\n\nslok/agebox - Age based repository file encryption gitops tool\n\ncycloidio/terracognita - Reads from existing public and private cloud providers (reverse Terraform) and generates your infrastructure as code on Terraform configuration\n\ndagger/dagger - An open-source runtime for composable workflows. Great for AI agents and CI/CD.\n\nliqotech/liqo - Enable dynamic and seamless Kubernetes multi-cluster topologies\n\nplexsystems/konstraint - A policy management tool for interacting with Gatekeeper\n\ndevtron-labs/devtron - The only Kubernetes dashboard you need\n\nkeploy/keploy - Unit, API & Integration Testing Agent for Developers. Generate tests, mocks/stubs for your APIs that actually work!\n\nsethvargo/ratchet - A tool for securing CI/CD workflows with version pinning.\n\naquasecurity/chain-bench - An open-source tool for auditing your software supply chain stack for security compliance based on a new CIS Software Supply Chain benchmark.\n\nFairwindsOps/pluto - A cli tool to help discover deprecated apiVersions in Kubernetes\n\ncoder/coder - Provision remote development environments via Terraform\n\nsqlc-dev/sqlc - Generate type-safe code from SQL\n\njackc/tern - The SQL Fan's Migrator\n\nknadh/dns.toys - A DNS server that offers useful utilities and services over the DNS protocol. Weather, world time, unit conversion etc.\n\nory/kratos - Headless cloud-native authentication and identity management written in Go. Scales to a billion+ users. Replace Homegrown, Auth0, Okta, Firebase with better UX and DX. Passkeys, Social Sign In, OIDC,\n\ndosco/graphjin - GraphJin - Build NodeJS / GO APIs in 5 minutes not weeks\n\nexternal-secrets/external-secrets - External Secrets Operator reads information from a third-party service like AWS Secrets Manager and automatically injects the values as Kubernetes Secrets.\n\ncyberark/summon-conjur - CyberArk Conjur provider for Summon\n\ncyberark/secretless-broker - Secure your apps by making them Secretless\n\nsigstore/gitsign - Keyless Git signing using Sigstore\n\nsalesforce/sloop - Kubernetes History Visualization\n\nFairwindsOps/nova - Find outdated or deprecated Helm charts running in your cluster.\n\nrancher/opni - Multi Cluster Observability with AIOps\n\nrancher/kim - In ur kubernetes, buildin ur imagez\n\nepinio/epinio - Opinionated platform that runs on Kubernetes, that takes you from App to URL in one step.\n\nenvoyproxy/gateway - Manages Envoy Proxy as a Standalone or Kubernetes-based Application Gateway\n\nevrone/go-clean-template - Clean Architecture template for Golang services\n\ninfracost/infracost - Cloud cost estimates for Terraform in pull requests💰📉 Shift FinOps Left!\n\nitaysk/kubectl-neat - Clean up Kubernetes yaml and json output to make it readable\n\nAnalogJ/scrutiny - Hard Drive S.M.A.R.T Monitoring, Historical Trends & Real World Failure Thresholds\n\nwangkechun/go-by-example -\n\ngreenpau/caddy-security - 🔐 Authentication, Authorization, and Accounting (AAA) App and Plugin for Caddy v2. 💎 Implements Form-Based, Basic, Local, LDAP, OpenID Connect, OAuth 2.0 (Github, Google, Facebook, Okta, etc.), SAML A\n\nnavidrome/navidrome - 🎧☁️ Your Personal Streaming Service\n\nbinwiederhier/ntfy - Send push notifications to your phone or desktop using PUT/POST\n\namir20/dozzle - Realtime log viewer for docker containers.\n\ngoogle/cadvisor - Analyzes resource usage and performance characteristics of running containers.\n\ntxn2/kubefwd - Bulk port forwarding Kubernetes services for local development.\n\nfirefart/stunner - Stunner is a tool to test and exploit STUN, TURN and TURN over TCP servers.\n\nstakater/Reloader - A Kubernetes controller to watch changes in ConfigMap and Secrets and do rolling upgrades on Pods with their associated Deployment, StatefulSet, DaemonSet and DeploymentConfig – [✩Star] if you're usin\n\nfalcosecurity/driverkit - Kit for building Falco drivers: kernel modules or eBPF probes\n\ndeepfence/PacketStreamer - ⭐ ⭐ Distributed tcpdump for cloud native environments ⭐ ⭐\n\nwhyvl/wireproxy - Wireguard client that exposes itself as a socks5 proxy\n\nkadeessh/kadeessh - Kadeessh (formerly Caddy-SSH) is a general-purpose, extensible, modular, memory-safe SSH server built in Go\n\nosrg/gobgp - BGP implemented in the Go Programming Language\n\nTomWright/dasel - Select, put and delete data from JSON, TOML, YAML, XML and CSV files with a single tool. Supports conversion between formats and can be used as a Go package.\n\nsamber/lo - 💥 A Lodash-style Go library based on Go 1.18+ Generics (map, filter, contains, find...)\n\narriven/db1000n -\n\nwasmerio/wasmer-go - 🐹🕸️ WebAssembly runtime for Go\n\nbinxio/simple-iap-proxy - Simple proxy for accessing private GKE master endpoints and other services behind a Google Identity Aware Proxy\n\nGoogleCloudPlatform/secrets-store-csi-driver-provider-gcp - Google Secret Manager provider for the Secret Store CSI Driver.\n\nDataDog/stratus-red-team - ☁️ ⚡ Granular, Actionable Adversary Emulation for the Cloud\n\nhahwul/authz0 - 🔑 Authz0 is an automated authorization test tool. Unauthorized access can be identified based on URLs and Roles & Credentials.\n\ncaddyserver/ingress - WIP Caddy 2 ingress controller for Kubernetes\n\nmholt/archiver - DEPRECATED. Please use mholt/archives instead.\n\ns1ntaxe770r/terraform-provider-planetscale - Unofficial Terraform provider for planetscale\n\nminamijoyo/tfmigrate - A Terraform / OpenTofu state migration tool for GitOps\n\nava-labs/avalanchego - Go implementation of an Avalanche node.\n\nkubernetes-sigs/secrets-store-csi-driver - Secrets Store CSI driver for Kubernetes secrets - Integrates secrets stores with Kubernetes via a CSI volume.\n\nclusternet/clusternet - [CNCF Sandbox Project] Managing your Kubernetes clusters (including public, private, edge, etc.) as easily as visiting the Internet\n\ntrufflesecurity/driftwood - Private key usage verification\n\niangcarroll/cookiemonster - 🍪 CookieMonster helps you detect and abuse vulnerable implementations of stateless sessions.\n\neatonphil/dbcore - Generate applications powered by your database.\n\nxelalexv/dregsy - Keep container registries in sync\n\nsenthilrch/kube-fledged - A kubernetes operator for creating and managing a cache of container images directly on the cluster worker nodes, so application pods start almost instantly\n\nShopify/toxiproxy - ⏰ 🔥 A TCP proxy to simulate network and system conditions for chaos and resiliency testing\n\ngetoutreach/localizer - ⛵ A no-frills local development tool for service developers working in Kubernetes\n\ntelepresenceio/telepresence - Local development against a remote Kubernetes or OpenShift cluster\n\nhashicorp/boundary - Boundary enables identity-based access management for dynamic infrastructure.\n\nevmos/ethermint - Ethermint is a Cosmos SDK library for running scalable and interoperable EVM chains\n\nsundowndev/phoneinfoga - Information gathering framework for phone numbers\n\nauthzed/spicedb - Open Source, Google Zanzibar-inspired database for scalably storing and querying fine-grained authorization data\n\ndivan/txqr - Transfer data via animated QR codes\n\naquasecurity/fanal - Static Analysis Library for Containers\n\naquasecurity/postee - Notice: Postee is no longer under active development or maintenance.\n\naquasecurity/cloud-metadata - Common metadata repository for CSPM and TFSec checks\n\nim2nguyen/rover - Interactive Terraform visualization. State and configuration explorer.\n\njuanfont/headscale - An open source, self-hosted implementation of the Tailscale control server\n\nRyanSiu1995/gcb-visualizer - Cloudbuild pipeline visualizer with graphviz\n\nmmcloughlin/md4 - Assembly-optimized MD4 hash algorithm in Go\n\ng3n/engine - Go 3D Game Engine (http://g3n.rocks)\n\nzimmski/go-mutesting - Mutation testing for Go source code\n\naaw/histosketch - A golang streaming histogram sketch. Fast quantiles and counts below a threshold.\n\ncloudwego/kitex - Go RPC framework with high-performance and strong-extensibility for building micro-services.\n\nschollz/duct - Inspired by patchbay.pub\n\ngrafana/pyroscope - Continuous Profiling Platform. Debug performance issues down to a single line of code\n\niwpnd/sectr - Build a circular sector polygon feature spanning the angle between two given bearings, a center point and a radius. A pizza piece! 🍕\n\nhelmfile/vals - Helm-like configuration values loader with support for various sources\n\nmumoshu/variant2 - Turn your bash scripts into a modern, single-executable CLI app today\n\nanacrolix/dht - dht is used by anacrolix/torrent, and is intended for use as a library in other projects both torrent related and otherwise\n\ngokrazy/rsync - rsync in Go! implements client and server, which can send or receive files (upload, download, all directions supported)\n\nlayeh/radius - a Go (golang) RADIUS client and server implementation\n\nprojectdiscovery/wappalyzergo - A high performance go implementation of Wappalyzer Technology Detection Library\n\nfrigus02/kyml - A CLI, which helps you to work with and deploy plain Kubernetes YAML files.\n\nghostunnel/ghostunnel - A simple SSL/TLS proxy with mutual authentication for securing non-TLS services.\n\nkubescape/kubescape - Kubescape is an open-source Kubernetes security platform for your IDE, CI/CD pipelines, and clusters. It includes risk analysis, security, compliance, and misconfiguration scanning, saving Kubernetes\n\naquasecurity/btfhub - BTFhub, in collaboration with the BTFhub Archive repository, supplies BTF files for all published kernels that lack native support for embedded BTF. This joint effort ensures that even kernels without\n\nd5/tengo - A fast script language for Go\n\narl/statsviz - 🚀 Visualise your Go program runtime metrics in real time in the browser\n\nklauspost/compress - Optimized Go Compression Packages\n\nFahrj/reverse-ssh - Statically-linked ssh server with reverse shell functionality for CTFs and such\n\nnicocha30/ligolo-ng - An advanced, yet simple, tunneling/pivoting tool that uses a TUN interface.\n\nbridgecrewio/yor - Extensible auto-tagger for your IaC files. The ultimate way to link entities in the cloud back to the codified resource which created it.\n\nSkyscanner/turbolift - A simple tool to help apply changes across many GitHub repositories simultaneously\n\ndoitintl/kubeip - Assign static public IPs to Kubernetes nodes (GKE, EKS)\n\nsigstore/cosign - Code signing and transparency for containers and binaries\n\ndanopstech/starlink_exporter - 📡 Prometheus exporter that exposes metrics from SpaceX Starlink Dish\n\nplanetlabs/draino - Automatically cordon and drain Kubernetes nodes based on node conditions\n\nkubernetes/node-problem-detector - This is a place for various problem detectors running on the Kubernetes nodes.\n\nkubereboot/kured - Kubernetes Reboot Daemon\n\nnikolaydubina/go-recipes - 🦩 Tools for Go projects\n\nthoughtworks/talisman - Using a pre-commit hook, Talisman validates the outgoing changeset for things that look suspicious — such as tokens, passwords, and private keys.\n\nnetbirdio/netbird - Connect your devices into a secure WireGuard®-based overlay network with SSO, MFA and granular access controls.\n\nirsl/gcp-dhcp-takeover-code-exec - Google Compute Engine (GCE) VM takeover via DHCP flood - gain root access by getting SSH keys added by google_guest_agent\n\nawgh/ratnet - Ratnet is a prototype anonymity network for mesh routing and embedded scenarios.\n\nmarcosnils/bin - Effortless binary manager\n\nShivam010/bypass-cors - a proxy server to bypass CORS enabled servers\n\naojea/netkat - netcat using netstack userspace library and eBPF\n\nalexellis/arkade - Open Source Marketplace For Developer Tools\n\nevilsocket/islazy - A Go library containing a set of opinionated packages, objects, helpers and functions implemented with the KISS principle in mind.\n\nnanmu42/orly - 🏈 Generate your own O'RLY animal book cover to troll your colleagues | 生成你自己的O'RLY动物书封面，让你的同事惊掉下巴\n\nfunction61/hautomo - Home automation hub fully built in Go, super simple to deploy\n\nyomorun/yomo - 🦖 Stateful Serverless Framework for Geo-distributed Edge AI Infra. with function calling support, write once, run on any model.\n\nmuchobien/tailscale-ui - Tailscale UI for Ubuntu\n\nhack-pad/hackpad - The in-browser IDE for Go\n\neasegress-io/easegress - A Cloud Native traffic orchestration system\n\nteamlint/ardan - web development framework\n\ndundee/gdu - Fast disk usage analyzer with console interface written in Go\n\nalexrios/lbucket - An idiomatic Go implementation of Leaky bucket.\n\njacobsa/fuse - A Go package for implementing a FUSE file system.\n\nhashicorp/terraform-ls - Terraform Language Server\n\nk8gb-io/k8gb - A cloud native Kubernetes Global Balancer\n\nvirtual-kubelet/systemk - Systemk is a systemd backend for the virtual-kubelet. Instead of starting containers, you start systemd units.\n\ngoogle/gousb - gousb provides low-level interface for accessing USB devices\n\nkevinburke/rest - Go REST helpers\n\npsanford/wormhole-william - End-to-end encrypted file transfer. A magic wormhole CLI and API in Go (golang).\n\nobservIQ/stanza - Fast and lightweight log transport and processing.\n\nlima-vm/lima - Linux virtual machines, with a focus on running containers\n\nbradleyjkemp/abwhose - The simplest way to find how to report abusive domains\n\nnodauf/Swego - Swiss army knife Webserver in Golang. Keep simple like the python SimpleHTTPServer but with many features\n\nkube-burner/kube-burner - Kubernetes performance and scale test orchestration framework written in golang\n\ntrivago/gollum - An n:m message multiplexer written in Go\n\n99designs/keyring - Go library providing a uniform interface across a range of secure credential stores\n\nqax-os/excelize - Go language library for reading and writing Microsoft Excel™ (XLAM / XLSM / XLSX / XLTM / XLTX) spreadsheets\n\nFlaque/filet - 🍖 A small temporary file utility for Go testing.\n\nbouk/monkey - Monkey patching in Go\n\ncorona10/goimagehash - Go Perceptual image hashing package\n\nkarmada-io/karmada - Open, Multi-Cloud, Multi-Cluster Kubernetes Orchestration\n\nNetflix/weep - The ConsoleMe CLI utility\n\nbenjojo/bgp-zerowindow-test - A malicious BGP daemon that forces a TCP zero window edge case\n\nkovetskiy/mark - Sync your markdown files with Confluence pages.\n\nv-byte-cpu/sx - 🖖 Fast, modern, easy-to-use network scanner\n\nfynelabs/notes - A simple notes app using Fyne\n\nGoogleCloudPlatform/microservices-demo - Sample cloud-first application with 10 microservices showcasing Kubernetes, Istio, and gRPC.\n\nsnyk/driftctl - Detect, track and alert on infrastructure drift\n\nropnop/kerbrute - A tool to perform Kerberos pre-auth bruteforcing\n\ncrosbymichael/boss - Run containers like a ross\n\nliamg/traitor - ⬆️ ☠️ 🔥 Automatic Linux privesc via exploitation of low-hanging fruit e.g. gtfobins, pwnkit, dirty pipe, +w docker.sock\n\ncortexproject/cortex - A horizontally scalable, highly available, multi-tenant, long term Prometheus.\n\nbenbjohnson/immutable - Immutable collections for Go\n\nevilsocket/shieldwall - zero-trust remote firewall instrumentation\n\nBishopFox/dufflebag - Search exposed EBS volumes for secrets\n\nflyteorg/flyte - Scalable and flexible workflow orchestration platform that seamlessly unifies data, ML and analytics stacks.\n\niann0036/iamlive - Generate an IAM policy from AWS, Azure, or Google Cloud (GCP) calls using client-side monitoring (CSM) or embedded proxy\n\ncarltheperson/10-things-linux - Getting better at Linux with 10 mini-projects.\n\nanatol/booster - Fast and secure initramfs generator\n\nbenbjohnson/litestream - Streaming replication for SQLite.\n\ntryffel/meilindex - Fast full text search for email\n\nstripe-archive/safesql - Static analysis tool for Golang that protects against SQL injections\n\njpillora/go-tld - TLD Parser in Go\n\nevilsocket/ditto - A tool for IDN homograph attacks and detection.\n\nmatryer/crunchcrunchcrunchstack - This repo is a starting point for a Go + Svelte.js + TailwindCSS project.\n\nflorianl/tc-skeleton - Simple project to demonstrate the loading of eBPF programs via florianl/go-tc.\n\nbenbjohnson/wtf - WTF Dial is an example web application written in Go.\n\nrqlite/rqlite - The lightweight, user-friendly, distributed relational database built on SQLite.\n\nBinject/shellcode - Shellcode library as a Go package\n\nBinject/go-donut - Donut Injector ported to pure Go. For use with https://github.com/TheWover/donut\n\nBinject/backdoorfactory - A from-scratch rewrite of The Backdoor Factory - a MitM tool for inserting shellcode into all types of binaries on the wire.\n\njuicedata/juicefs - JuiceFS is a distributed POSIX file system built on top of Redis and S3.\n\ntailscale/tailetc - total-memory-cache etcd v3 client\n\nevilsocket/uroboros - A GNU/Linux monitoring and profiling tool focused on single processes.\n\ngoogle/gopacket - Provides packet processing capabilities for Go\n\nwillscott/go-nfs - golang NFSv3 server\n\njordanlewis/gcassert - Assert your Go code is inlined and bounds-check eliminated\n\ngoogle/safehtml - Safe HTML for Go\n\nforensicanalysis/artifactcollector - 🧭 The artifactcollector is a customizable agent to collect forensic artifacts on any Windows, macOS or Linux system\n\nmfbx9da4/brightpath-backend - Find the safest well lit walking path between two locations on earth.\n\nowncast/owncast - Take control over your live stream video by running it yourself. Streaming + chat out of the box.\n\ngoogle/wire - Compile-time Dependency Injection for Go\n\ncloudquery/cloudquery - The developer first cloud governance platform\n\nossf/criticality_score - Gives criticality score for an open source project\n\nstephenlacy/daz - Composable HTML components in Golang\n\ncontainerd/nerdctl - contaiNERD CTL - Docker-compatible CLI for containerd, with support for Compose, Rootless, eStargz, OCIcrypt, IPFS, ...\n\nmmcloughlin/ec3 - Elliptic Curve Cryptography Compiler: an incomplete experiment in code-generation for elliptic curves in Go\n\nmeyskens/tls-ping-pong - TLS ping ping example of https://github.com/jetstack/cert-manager-nginx-plus-lab\n\neiginn/nftrace - Easier tracing of packets through iptables\n\nFiloSottile/yubikey-agent - yubikey-agent is a seamless ssh-agent for YubiKeys.\n\nliggitt/audit2rbac - Autogenerate RBAC policies based on Kubernetes audit logs\n\nIce3man543/SubOver - A Powerful Subdomain Takeover Tool\n\nassetnote/commonspeak2 - Leverages publicly available datasets from Google BigQuery to generate content discovery and subdomain wordlists\n\nlobuhi/byp4xx - 40X/HTTP bypasser in Go. Features: Verb tampering, headers, #bugbountytips, User-Agents, extensions, default credentials...\n\nzmap/zgrab2 - Fast Application Layer Scanner\n\nlibp2p/go-libp2p - libp2p implementation in Go\n\nfhmq/hmq - High performance mqtt broker\n\nredcode-labs/Coldfire - Golang malware development library\n\nredcode-labs/neurax - A framework for constructing self-spreading binaries\n\ngrafana/k6 - A modern load testing tool, using Go and JavaScript - https://k6.io\n\nmarkbates/goth - Package goth provides a simple, clean, and idiomatic way to write authentication packages for Go web applications.\n\ndarkr4y/geacon - Practice Go programming and implement CobaltStrike's Beacon in Go\n\nfoxcpp/maddy - ✉️ Composable all-in-one mail server.\n\nattic-labs/noms - The versioned, forkable, syncable database\n\nprojectdiscovery/nuclei - Nuclei is a fast, customizable vulnerability scanner powered by the global security community and built on a simple YAML-based DSL, enabling collaboration to tackle trending vulnerabilities on the int\n\nprojectdiscovery/subfinder - Fast passive subdomain enumeration tool.\n\nprojectdiscovery/dnsx - dnsx is a fast and multi-purpose DNS toolkit allow to run multiple DNS queries of your choice with a list of user-supplied resolvers.\n\nprojectdiscovery/notify - Notify is a Go-based assistance package that enables you to stream the output of several tools (or read from a file) and publish it to a variety of supported platforms.\n\ncrowdsecurity/crowdsec - CrowdSec - the open-source and participative security solution offering crowdsourced protection against malicious IPs and access to the most advanced real-world CTI.\n\namacneil/dbmate - 🚀 A lightweight, framework-agnostic database migration tool.\n\nhashicorp/hil - HIL is a small embedded language for string interpolations.\n\norijtech/structslop - structslop is a static analyzer for Go that recommends struct field rearrangements to provide for maximum space/allocation efficiency.\n\nvladimirvivien/automi - A stream processing API for Go (alpha)\n\nJonCooperWorks/go-tdameritrade - go client for the tdameritrade api\n\nJonCooperWorks/judas -\n\ntarget/portauthority - API that leverages Clair to scan Docker Registries and Kubernetes Clusters for vulnerabilities\n\ntarget/flottbot - A chatbot framework written in Go. All configurations are made in YAML files, or inside scripts written in your favorite language.\n\njuicedata/juicesync - A tool to move your data between any clouds or regions.\n\nsaljam/webwormhole - Peer authenticated WebRTC.\n\ncloudflare/lockbox - Offline encryption of Kubernetes Secrets\n\nDQNEO/minigo - minigo🐥is a small Go compiler made from scratch. It can compile itself.\n\nchuot/rdio-scanner - Rdio Scanner is an open source software that ingest and distribute audio files generated by various software-defined radio recorders. Its interface tries to reproduce the user experience of a real pol\n\nbrendanporter/duck - Reference implementation of Quack\n\nstephank/lazyssh - A jump-host SSH server that starts machines on-demand\n\nTwiN/gatus - ⛑ Automated developer-oriented status page\n\nFiloSottile/captive-browser - A dedicated Chrome instance to log into captive portals without messing with DNS settings.\n\ngo-rod/rod - A Chrome DevTools Protocol driver for web automation and scraping.\n\nossf/scorecard - OpenSSF Scorecard - Security health metrics for Open Source\n\nbradleyjkemp/sigma-go - A Go implementation and parser for Sigma rules.\n\nfleetdm/fleet - Open-source platform for IT, security, and infrastructure teams. (Linux, macOS, Chrome, Windows, cloud, data center)\n\nmna/redisc - A Go redis cluster client built on top of redigo.\n\nredcode-labs/SNOWCRASH - A polyglot payload generator\n\nredcode-labs/GoSH - Golang reverse/bind shell generator\n\nredcode-labs/Sammler - A tool to extract useful data from documents\n\nlikexian/whois-parser - Whois parser for domain whois information parsing in Go(Golang).\n\nlunixbochs/struc - Better binary packing for Go\n\nsumup-oss/gocat - 21st century, multi-purpose relay from source to destination\n\nonsi/ginkgo - A Modern Testing Framework for Go\n\nhakluke/hakrawler - Simple, fast web crawler designed for easy, quick discovery of endpoints and assets within a web application\n\nNe0nd0g/go-shellcode - A repository of Windows Shellcode runners and supporting utilities. The applications load and execute Shellcode using various API calls or techniques.\n\ncloudevents/sdk-go - Go SDK for CloudEvents\n\nkinvolk/lokomotive - 🪦 DISCONTINUED Further Lokomotive development has been discontinued. Lokomotive is a 100% open-source, easy to use and secure Kubernetes distribution from the volks at Kinvolk\n\ngrafana/tempo - Grafana Tempo is a high volume, minimal dependency distributed tracing backend.\n\nadammck/terraform-inventory - Terraform State → Ansible Dynamic Inventory\n\nmuesli/kmeans - k-means clustering algorithm implementation written in Go\n\nkkdai/youtube - Download Youtube Video in Golang\n\ngo-echarts/go-echarts - 🎨 The adorable charts library for Golang.\n\nsensepost/gowitness - 🔍 gowitness - a golang, web screenshot utility using Chrome Headless\n\nj3ssie/osmedeus - A Workflow Engine for Offensive Security\n\nj3ssie/metabigor - OSINT tools and more but without API key\n\njaeles-project/jaeles - The Swiss Army knife for automated Web Application Testing\n\nfogleman/nes - NES emulator written in Go.\n\nicexin/eggos - A Go unikernel running on x86 bare metal\n\nrobpike/lisp - Toy Lisp 1.5 interpreter\n\nshopspring/decimal - Arbitrary-precision fixed-point decimal numbers in Go\n\nShaileshSurya/hammer -\n\nblushft/go-diagrams - Create beautiful system diagrams with Go\n\nschollz/pake - PAKE library for generating a strong secret between parties over an insecure channel\n\nschollz/croc - Easily and securely send things from one computer to another 🐊 📦\n\ntidwall/uhaha - High Availability Raft Framework for Go\n\nmarkbates/pkger - Embed static files in Go binaries (replacement for gobuffalo/packr)\n\nletsencrypt/boulder - An ACME-based certificate authority, written in Go.\n\nletsencrypt/pebble - A miniature version of Boulder, Pebble is a small RFC 8555 ACME test server not suited for a production certificate authority.\n\ngoogle/winops - Small scripts and libraries for managing Windows in a corporate environment.\n\nprojectdiscovery/httpx - httpx is a fast and multi-purpose HTTP toolkit that allows running multiple probes using the retryablehttp library.\n\nwallix/triplestore - Nifty library to manage, query and store RDF triples. Make RDF great again!\n\nstefanoj3/dirstalk - Modern alternative to dirbuster/dirb\n\ngruntwork-io/terragrunt - Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.\n\nbetty200744/ultimate-go - This repo contains my notes on working with Go and computer systems.\n\nalecthomas/kong - Kong is a command-line parser for Go\n\njawher/mow.cli - A versatile library for building CLI applications in Go\n\ncloudflare/tls-tris - crypto/tls, now with 100% more 1.3. THE API IS NOT STABLE AND DOCUMENTATION IS NOT GUARANTEED.\n\nahhh/godns - a simple client lib for doing dns over http\n\nSixGenInc/Noctilucent - Using TLS 1.3 to evade censors, bypass network defenses, and blend in with the noise\n\nunstppbl/gowap - Wappalyzer implementation in Go\n\njorgelbg/cloudflare-access-grafana - Small proxy for automatically log in users from Cloudflare Access into Grafana\n\ncilium/cilium - eBPF-based Networking, Security, and Observability\n\nlwolf/konsumerator - Kafka Consumer Operator. Kubernetes operator to manage consumers of unbalanced kafka topics with per-partition vertical autoscaling based on Prometheus metrics\n\nmagisterquis/toyransomware - Toy Ransomware, useful for seeing if whiz-bang ransomware defenses work\n\ncycloidio/inframap - Read your tfstate or HCL to generate a graph specific for each provider, showing only the resources that are most important/relevant.\n\ndropbox/llama - Library for testing and measuring network loss and latency between distributed endpoints.\n\nskydive-project/skydive - An open source real-time network topology and protocols analyzer\n\ngoodwithtech/dockle - Container Image Linter for Security, Helping build the Best-Practice Docker Image, Easy to start\n\nmergestat/mergestat-lite - Query git repositories with SQL. Generate reports, perform status checks, analyze codebases. 🔍 📊\n\nlesovsky/noisia - Harmful workload generator for PostgreSQL\n\ngoplus/gop - The Go+ programming language is designed for engineering, STEM education, and data science. Our vision is to enable everyone to become a builder of the digital world.\n\ncloudflare/utahfs - UtahFS is an encrypted storage system that provides a user-friendly FUSE drive backed by cloud storage.\n\nchai2010/go-ast-book - 📚 《Go语言定制指南》(原名：Go语法树入门/开源免费图书/Go语言进阶/掌握抽象语法树/Go语言AST)\n\nstatus-im/doubleratchet - The Double Ratchet Algorithm implementation in Go\n\ndustin/go-humanize - Go Humans! (formatters for units to human friendly sizes)\n\nThePrimeagen/vim-with-me -\n\nfree5gc/free5gc - Open source 5G core network based on 3GPP R15\n\nzyedidia/micro - A modern and intuitive terminal-based text editor\n\nphua/ddclassify - Dewey Decimal Classifier\n\nFiloSottile/age - A simple, modern and secure encryption tool (and Go library) with small explicit keys, no config options, and UNIX-style composability.\n\nKyleBanks/goodreads - Goodreads API client written in Go.\n\nusbarmory/tamago-example - TamaGo - example application\n\nanasinnyk/terraform-provider-onepassword - Terraform provider for 1Password\n\nkeys-pub/keys - Key management is hard\n\nvmware/govmomi - Go library for the VMware vSphere API\n\n99designs/gqlgen - go generate based graphql server library\n\nnektos/act - Run your GitHub Actions locally 🚀\n\nsysdream/ligolo - Reverse Tunneling made easy for pentesters, by pentesters https://sysdream.com/\n\nTheAlgorithms/Go - Algorithms and Data Structures implemented in Go for beginners, following best practices.\n\nmmcloughlin/addchain - Cryptographic Addition Chain Generation in Go\n\nAbGuthrie/goquery - Provide a shell like interface by utilizing osquery's distributed API\n\nduythinht/dbml-go - DBML parser and tools for Go\n\ngo-bindata/go-bindata - Turn data file into go code.\n\nyolossn/Prometheus-Basics - Prometheus-Basics is part of Prometheus Docs now, checkout 👇\n\nassafmo/xioc - Extract indicators of compromise from text, including \"escaped\" ones.\n\nbrompwnie/botb - A container analysis and exploitation tool for pentesters and engineers.\n\nhoanhan101/algo - 101+ coding interview problems in Go\n\ndeoxxa/hl7 -\n\nsteve0hh/midas - Go implementation of MIDAS: Microcluster-Based Detector of Anomalies in Edge Streams\n\nshomali11/go-interview - Collection of Technical Interview Questions solved with Go\n\nmulbc/botanist - Botanist is a bot to alert you interactively about Prometheus alerts.\n\ntxthinking/socks5 - SOCKS Protocol Version 5 Library in Go. Full TCP/UDP and IPv4/IPv6 support\n\nlanrat/czds - simple golang API and tools to interact with czds.icann.org\n\nesimov/pigo - Fast face detection, pupil/eyes localization and facial landmark points detection library in pure Go.\n\nblendle/zapdriver - Blazing fast, Zap-based Stackdriver logging.\n\nbvwells/go-patterns - Design patterns for the Go programming language\n\ndanicat/pacgo - A Pac Man clone written in Go (with emojis!)\n\ngliderlabs/ssh - Easy SSH servers in Golang\n\nsnwfdhmp/efs - Encrypted File System over HTTP (using Ed25519 HMAC auth and AES-256 encryption).\n\ntherecipe/qt - Qt binding for Go (Golang) with support for Windows / macOS / Linux / FreeBSD / Android / iOS / Sailfish OS / Raspberry Pi / AsteroidOS / Ubuntu Touch / JavaScript / WebAssembly\n\nrhaidiz/broxy - An HTTP/HTTPS intercept proxy written in Go.\n\ngofiber/fiber - ⚡️ Express inspired web framework written in Go\n\nUllaakut/astrolab - The server which receives and stores Astronomer trust reports, and provides an endpoint to generate GitHub badges.\n\nUllaakut/Gorsair - Gorsair gives root access on remote docker containers that expose their APIs\n\nUllaakut/astronomer - A tool to detect illegitimate stars from bot accounts on GitHub projects\n\nUllaakut/camerattack - An attack tool designed to remotely disable CCTV camera streams (like in spy movies)\n\nPuerkitoBio/goquery - A little like that j-thing, only in Go.\n\nvbauerster/mpb - multi progress bar for Go cli applications\n\nUllaakut/disgo - 🕺🏽Simple output library for go CLIs.\n\nPacktPublishing/Hands-On-Software-Engineering-with-Golang - Hands-On Software Engineering with Golang, published by Packt\n\ncostela/wesher - wireguard overlay mesh network manager\n\nPentestPad/subzy - Subdomain takeover vulnerability checker\n\ncloudflare/slirpnetstack - slirp4netns implementation using gvisor/netstack\n\nfwessels/simdjson-go - Golang port of simdjson\n\nrverton/webanalyze - Port of Wappalyzer (uncovers technologies used on websites) to automate mass scanning.\n\nhaccer/subjack - Subdomain Takeover tool written in Go\n\nanshumanbh/tko-subs - A tool that can help detect and takeover subdomains with dead DNS records\n\nsubmariner-io/submariner - Networking component for interconnecting Pods and Services across Kubernetes clusters.\n\nprojectdiscovery/naabu - A fast port scanner written in go with a focus on reliability and simplicity. Designed to be used in combination with other tools for attack surface discovery in bug bounties and pentests\n\nsegmentio/ctlstore - Control Data Store\n\nTimothyYe/skm - A simple and powerful SSH keys manager\n\npomerium/pomerium - Pomerium is an identity and context-aware access proxy.\n\nsanbornm/go-selfupdate - Enable your Go applications to self update\n\ngo-furnace/go-furnace - Go Hosting Solution for AWS, Google Cloud and Digital Ocean\n\nThreeDotsLabs/watermill - Building event-driven applications the easy way in Go.\n\nslack-go/slack - Slack API in Go\n\nperkeep/perkeep - Perkeep (née Camlistore) is your personal storage system for life: a way of storing, syncing, sharing, modelling and backing up content.\n\nbufbuild/buf - The best way of working with Protocol Buffers.\n\nbxcodec/faker - Go (Golang) Fake Data Generator for Struct. [Notes]This repository is archived, moved to the new repository https://github.com/go-faker/faker\n\neduncan911/mspec - BDD-style Specifications for Go\n\neduncan911/podcast - iTunes and RSS 2.0 Podcast Generator in Golang\n\ndvassallo/s3-benchmark - Measure Amazon S3's performance from any location.\n\nhajimehoshi/ebiten - Ebitengine - A dead simple 2D game engine for Go\n\nchaos-mesh/chaos-mesh - A Chaos Engineering Platform for Kubernetes.\n\ncelrenheit/sandflake - Decentralized, sequential, lexicographically sortable unique id\n\nciehanski/libgen-cli - A CLI tool to access the Library Genesis dataset; written in Go.\n\nusbarmory/tamago - TamaGo - bare metal Go\n\nuber-go/goleak - Goroutine leak detector\n\nallegro/bigcache - Efficient cache for gigabytes of data written in Go.\n\nseiflotfy/cuckoofilter - Cuckoo Filter: Practically Better Than Bloom\n\ncrawlab-team/crawlab - Distributed web crawler admin platform for spiders management regardless of languages and frameworks. 分布式爬虫管理平台，支持任何语言和框架\n\nsegmentio/chamber - CLI for managing secrets\n\nrobfig/cron - a cron library for go\n\ntarget/goalert - Open source on-call scheduling, automated escalations, and notifications so you never miss a critical alert\n\nslimtoolkit/slim - Slim(toolkit): Don't change anything in your container image and minify it by up to 30x (and for compiled languages even more) making it secure too! (free and open source)\n\nalexellis/go-execute - Automate CLI commands with Go\n\ncbroglie/mustache - The mustache template language in Go\n\nsimilarweb/finala - Finala is an open-source resource cloud scanner that analyzes, discloses, presents and notifies about wasteful and unused resources.\n\njessfraz/gmailfilters - A tool to sync Gmail filters from a config file to your account.\n\nphotonlines/Go-Web-Server - A Go web server with built in logging, tracing, health check, and graceful shutdown. It also includes a few demo applications showing the Go HTML temple functionality.\n\ngogo/protobuf - [Deprecated] Protocol Buffers for Go with Gadgets\n\nDATA-DOG/go-sqlmock - Sql mock driver for golang to test database interactions\n\nopenshift/origin - Conformance test suite for OpenShift\n\nhashicorp/terraform-provider-google - Terraform Provider for Google Cloud Platform\n\npquerna/ffjson - faster JSON serialization for Go\n\ntidwall/gjson - Get JSON values quickly - JSON parser for Go\n\nsegmentio/encoding - Go package containing implementations of efficient encoding, decoding, and validation APIs.\n\nzxsecurity/glugger - The fastest (and least featureful) DNS bruteforcer in the South\n\nquic-go/quic-go - A QUIC implementation in pure Go\n\nrs/rest-layer - REST Layer, Go (golang) REST API framework\n\nslackhq/nebula - A scalable overlay networking tool with a focus on performance, simplicity and security\n\nhypermodeinc/dgraph - high-performance graph database for real-time use cases\n\nguregu/null - reasonable handling of nullable values\n\njpillora/opts - A Go (golang) package for building frictionless command-line interfaces\n\nspf13/pflag - Drop-in replacement for Go's flag package, implementing POSIX/GNU-style --flags.\n\nesimov/diagram - CLI app to convert ASCII arts into hand drawn diagrams.\n\nfatedier/frp - A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.\n\npingcap/tidb - TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.\n\nspf13/viper - Go configuration with fangs\n\nginuerzh/gost - GO Simple Tunnel - a simple tunnel written in golang\n\nhyperledger/fabric - Hyperledger Fabric is an enterprise-grade permissioned distributed ledger framework for developing solutions and applications. Its modular and versatile design satisfies a broad range of industry use\n\njesseduffield/lazydocker - The lazier way to manage everything docker\n\nldsec/drynx - Decentralized, Secure, Verifiable System for Statistical Queries and Machine Learning on Distributed Datasets\n\ndedis/cothority - Scalable collective authority\n\naquasecurity/tfsec - Tfsec is now part of Trivy\n\ngo-playground/validator - 💯Go Struct and Field validation, including Cross Field, Cross Struct, Map, Slice and Array diving\n\nchai2010/advanced-go-programming-book - 📚 《Go语言高级编程》开源图书，涵盖CGO、Go汇编语言、RPC实现、Protobuf插件实现、Web框架实现、分布式系统等高阶主题(完稿)\n\nOpenDiablo2/OpenDiablo2 - An open source re-implementation of Diablo 2\n\nslackhq/go-audit - go-audit is an alternative to the auditd daemon that ships with many distros\n\ngoogle/mtail - extract internal monitoring data from application logs for collection in a timeseries database\n\nmagefile/mage - a Make/rake-like dev tool using Go\n\ntuneinsight/lattigo - A library for lattice-based multiparty homomorphic encryption",
      "# [The Collective](https://tympanus.net/codrops/news/)\nThe best new app for newsletter reading\n\nMeco is a distraction-free space for reading and discovering newsletters, separate from the inbox. Add your newsletters in seconds and liberate your inbox today!\n\nBuild a Product Card with Tailwind CSS\n\nDiscover intermediate and advanced styling techniques using Tailwind CSS and craft a fully responsive, professional product card for a web store in this Scrimba course. Codrops readers get 20% off Pro plans!\n\nTake This On-Call Rotation and Shove It\n\nA deeply personal, richly detailed critique of unpaid and exploitative on-call practices in tech, arguing that 24/7 availability should be compensated and reconsidered.\n\nLuis Bizarro Portfolio\n\nLuis Bizarro has open-sourced the code behind his personal portfolio.\n\nNavigate\n\nResn launches NVG8: a sleek, scroll-driven Web3 experience that gamifies data contribution through immersive motion and futuristic UI.\n\nCheck out the latest websites.\n\nUI Algorithms: A Tiny Undo Stack\n\nJulik Tarkhanov shares a robust JavaScript undo/redo stack using dual arrays and structured cloning—avoiding common indexing pitfalls with a clean API.\n\nShaderGPT Explore Page\n\nShaderGPT introduces a new Explore Page, allowing users to search, filter, and vote on AI-generated GLSL shaders, helping surface the most popular results.\n\nAI bots are destroying Open Access\n\nAI scraping bots are overwhelming open-access sites, threatening the sustainability of libraries, archives, and scholarly platforms online.\n\nCowardly Defaults and Courageous Overrides with Modern CSS\n\nModern CSS features like :where() and cascade layers enable cleaner, conflict-free utility classes—no more specificity battles or !important hacks.\n\nRevisiting CSS border-image\n\nA deep dive into CSS border-image and how it enables creative, performant designs through slicing, repeating, and styling with images or gradients.\n\nYou should know this before choosing Next.js\n\nWhat to consider before choosing Next.js—framework limitations, portability issues, and transparency concerns.\n\nHardware-Aware Coding: CPU Architecture Concepts Every Developer Should Know\n\nA deep dive into CPU architecture concepts showing how developers can boost code performance by aligning with hardware behavior.\n\nThe case for “old school” CSS\n\nRediscover the joy of writing old-school CSS with Drupal 10 theming—flex layouts, Twig magic, and a mobile menu, all built from scratch!\n\nThe ‹select› element can now be customized with CSS\n\nChrome 135 adds support for fully customizable <select> elements using appearance: base-select, enabling rich content and styling via CSS.\n\nBrowse No More\n\nA thoughtful critique of AI answer engines and how they're changing (and diminishing) the experience of browsing the web.\n\nPassing Data into SVG: Linked Parameters Workaround\n\nAn experimental workaround for passing data like colors from CSS into SVGs used as images, exploiting SVG sizing and modern CSS features.\n\nMinding the gaps: A new way to draw separators in CSS\n\nAn article by the Microsoft team on techniques for drawing separators in CSS, and a new proposal called \"CSS gap decorations\".\n\nAI Blindspots\n\nEdward Z. Yang shares \"blindspots\" in LLMs he has noticed while AI coding.\n\ndaylight\n\nA command-line program for tracking sunrise and sunset times (Mac/Linux).\n\nDoes vibe coding work?\n\nDavid Lindkvist tests building a UI with only AI-generated code—fast, but messy. Cursor + Claude sped things up, but control and polish suffered.\n\nMatching drop shadows across CSS, Android, iOS, Figma, and Sketch\n\nA quick explanation of why drop shadows look different across platforms—and how to fix it.\n\nOpenAI.fm\n\nOpenAI.fm is an interactive demo for testing the new text-to-speech voices in the OpenAI API\n\nAnnouncing WordPress Export to Markdown v3\n\nWordPress Export to Markdown v3 adds a smoother wizard, draft post support, and CLI options for static site migrations. Source code here.\n\nCarousels with CSS\n\nCSS-only carousels are now possible with Chrome 135 and the CSS Overflow 5 spec. Adam Argyle showcases scroll buttons, markers, snapping, and more—no JS required.\n\nSplash\n\nThe latest step in Matsuoka’s WebGPU fluid sim work—now with smoother surfaces, raymarched shadows, and more interactivity. Source code here.\n\nCheck out the latest demos.\n\nReal-world uses of TypeScript’s utility types\n\nSam Rose shares real-world examples of TypeScript utility types like Partial, Omit, and ReturnType.\n\nCSS Animation with offset-path\n\nChuan demonstrates how to recreate motion patterns using offset-path in CSS, showcasing polygon-based paths and animated sequences.\n\nLLM Agents are simply Graph — Tutorial For Dummies\n\nA beginner-friendly tutorial demystifying LLM agents, explaining them as simple graphs with decision loops, using PocketFlow for clear, hands-on learning.\n\nCSS view-timeline shine effect\n\nRyan Mulligan’s demo showcases a CSS view-timeline shine effect using animation-timeline: view(), animating elements based on scroll position.\n\nCheck out the latest demos.\n\nSelf Gap\n\nAhmad Shadeed explores ways to control spacing between flex and grid items, discussing current CSS solutions and proposing a new gap-self property.\n\nCascii v1.0.1 (beta)\n\nA web-based ASCII and Unicode diagram builder written in vanilla JavaScript with zero dependencies. Repo here\n\nOscura\n\nA VS Code theme by Fey, inspired by hacker terminals and designed for a sleek, minimal coding experience with curated colors and balanced contrast.\n\nA fluid CSS methodology\n\nWilly Brauner explores a fluid CSS methodology using viewport-based calculations for responsive, scalable, and maintainable layouts.\n\nAnon Code\n\nA terminal-based AI coding tool that integrates with any model supporting the OpenAI-style API.\n\nA Bear Case: My Predictions Regarding AI Progress\n\nThane Ruthenis discusses his bearish predictions for AI progress, arguing that scaling current models like LLMs won't lead to AGI anytime soon.\n\nGoravel\n\nGoravel is a web application framework designed for Gophers, offering complete functionality and scalability, inspired by Laravel.\n\nSuspicious Vial\n\nFrank Reitberger's Three.js demo uses custom shaders and ping-pong buffers to create realistic fluid sloshing inside a glass-like vessel.\n\nKill your Feeds\n\nTom Usher discusses how social media algorithms manipulate our attention and beliefs, urging readers to regain control over their online experience.\n\nLet the stagger experiments begin\n\nNew CSS features sibling-index() and sibling-count() reduce boilerplate and simplify staggered animations. Now available in Chrome Canary.\n\n“Wait, not like that”: Free and open access in the age of generative AI\n\nMolly White explores how AI companies exploit open knowledge, the risks to freely licensed content, and potential solutions to sustain the commons.\n\nPowering Search With Astro Actions and Fuse.js\n\nBryan Robinson explores using Astro Actions and Fuse.js to add dynamic search to static sites while maintaining performance and flexibility.\n\nBubbles\n\nBubbles is a new dependency-free game from the creator of Lander. Play, set high scores, and build custom levels with the builder tool here.\n\nHow to write exceptional documentation\n\nA guide to writing effective developer documentation, covering quickstarts, tutorials, API references, and more. Focuses on clarity, usability, and iteration.",
      "# [Make Your Day](https://www.tiktok.com/discover/how-to-make-notice-on-absa-app)\n",
      "# [awesome-azure-openai-llm/README_all_in_one.md at main · kimtth/awesome-azure-openai-llm](https://github.com/kimtth/awesome-azure-openai-llm/blob/main/README_all_in_one.md)\nSkip to content\n\nNavigation Menu",
      "# [texts · Datasets at Hugging Face](https://huggingface.co/datasets/h1alexbel/sr-texts/viewer/default/train?p=1)\ncloudnative-pg/cloudnative-pg;Welcome to the CloudNativePG project! CloudNativePG is a comprehensive open source platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance. The main component is the CloudNativePG operator. CloudNativePG was originally built and sponsored by EDB . Table of content Code of conduct Governance policies Contributing Adopters License Getting Started The best way to get started is with the \"Quickstart\" section in the documentation. Scope The goal of CloudNativePG is to increase the adoption of PostgreSQL, one of the most loved DBMS in traditional VM and bare metal environments, inside Kubernetes, thus making the database an integral part of the development process and GitOps CI/CD automated pipelines. In scope CloudNativePG has been designed by Postgres experts with Kubernetes administrators in mind. Put simply, it leverages Kubernetes by extending its controller and by defining, in a programmatic way, all the actions that a good DBA would normally do when managing a highly available PostgreSQL database cluster. Since the inception, our philosophy has been to adopt a Kubernetes native approach to PostgreSQL cluster management, making incremental decisions that would answer the fundamental question: \"What would a Kubernetes user expect from a Postgres operator?\". The most important decision we made is to have the status of a PostgreSQL cluster directly available in the Cluster resource, so to inspect it through the Kubernetes API. We've fully embraced the operator pattern and eventual consistency, two of the core principles upon which Kubernetes is built for managing complex applications. As a result, the operator is responsible for managing the status of the Cluster resource, keeping it up to date with the information that each PostgreSQL instance manager regularly reports back through the API server. Changes to the cluster status might trigger, for example, actions like: a PostgreSQL failover where, after an unexpected failure of a cluster's primary instance, the operator itself elects the new primary, updates the status, and directly coordinates the operation through the reconciliation loop, by relying on the instance managers scaling up or down the number of read-only replicas, based on a positive or negative variation in the number of desired instances in the cluster, so that the operator creates or removes the required resources to run PostgreSQL, such as persistent volumes, persistent volume claims, pods, secrets, config maps, and then coordinates cloning and streaming replication tasks updates of the endpoints of the PostgreSQL services that applications rely on to interact with the database, as Kubernetes represents the single source of truth and authority updates of container images in a rolling fashion, following a change in the image name, by first updating the pods where replicas are running, and then the primary, issuing a switchover first The latter example is based on another pillar of CloudNativePG: immutable application containers - as explained in the blog article \"Why EDB Chose Immutable Application Containers\" . The above list can be extended. However, the gist is that CloudNativePG exclusively relies on the Kubernetes API server and the instance manager to coordinate the complex operations that need to take place in a business continuity PostgreSQL cluster, without requiring any assistance from an intermediate management tool responsible for high availability and failover management like similar open source operators. CloudNativePG also manages additional resources to help the Cluster resource manage PostgreSQL - currently Backup , ClusterImageCatalog , ImageCatalog , Pooler , and ScheduledBackup . Fully embracing Kubernetes means adopting a hands-off approach during temporary failures of the Kubernetes API server. In such instances, the operator refrains from taking action, deferring decisions until the API server is operational again. Meanwhile, Postgres instances persist, maintaining operations based on the latest known state of the cluster. Out of scope CloudNativePG is exclusively focused on the PostgreSQL database management system maintained by the PostgreSQL Global Development Group (PGDG). We are not currently considering adding to CloudNativePG extensions or capabilities that are included in forks of the PostgreSQL database management system, unless in the form of extensible or pluggable frameworks. CloudNativePG doesn't intend to pursue database independence (e.g. control a MariaDB cluster). Communications Slack Channel Github Discussions Twitter Resources Roadmap Website FAQ Blog Adopters A list of publicly known users of the CloudNativePG operator is in ADOPTERS.md . Help us grow our community and CloudNativePG by adding yourself and your organization to this list! CloudNativePG at KubeCon March 21 2024, KubeCon Europe 2024 in Paris: \"Scaling Heights: Mastering Postgres Database Vertical Scalability with Kubernetes Storage Magic\" (Gari Singh, Google & Gabriele Bartolini, EDB) March 19 2024, Data on Kubernetes Day at KubeCon Europe 2024 in Paris: \"From Zero to Hero: Scaling Postgres in Kubernetes Using the Power of CloudNativePG\" (Gabriele Bartolini, EDB) 7 November 2023, KubeCon North America 2023 in Chicago: \"Disaster Recovery with Very Large Postgres Databases (in Kubernetes)\" (Michelle Au, Google & Gabriele Bartolini, EDB) 27 October 2022, KubeCon North America 2022 in Detroit: \"Data On Kubernetes, Deploying And Running PostgreSQL And Patterns For Databases In a Kubernetes Cluster\" (Chris Milsted, Ondat & Gabriele Bartolini, EDB) Useful links Data on Kubernetes (DoK) Community \"How to migrate your PostgreSQL database in Kubernetes with ~0 downtime from anywhere\" by Gabriele Bartolini (March 2024) \"Maximizing Microservice Databases with Kubernetes, Postgres, and CloudNativePG\" by Gabriele Bartolini (February 2024) \"Recommended Architectures for PostgreSQL in Kubernetes\" by Gabriele Bartolini (September 2023) \"The Current State of Major PostgreSQL Upgrades with CloudNativePG\" by Gabriele Bartolini (August 2023) \"The Rise of the Kubernetes Native Database\" by Jeff Carpenter (December 2022) \"Why Run Postgres in Kubernetes?\" by Gabriele Bartolini (May 2022) \"Shift-Left Security: The Path To PostgreSQL On Kubernetes\" by Gabriele Bartolini (April 2021) \"Local Persistent Volumes and PostgreSQL usage in Kubernetes\" by Gabriele Bartolini (June 2020) Star History Trademarks Postgres, PostgreSQL and the Slonik Logo are trademarks or registered trademarks of the PostgreSQL Community Association of Canada, and used with their permission.;CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance;postgres,postgresql,kubernetes,k8s,database,sql,operator,database-management,high-availability,self-healing\n\ncloudnative-pg/cloudnative-pg\n\nDGP-Studio/Snap.Hutao;胡桃工具箱是一款以 MIT 协议开源的原神工具箱，专为现代化 Windows 平台设计，旨在改善桌面端玩家的游戏体验。通过将既有的官方资源与开发团队设计的全新功能相结合，提供了一套完整且实用的工具集，且无需依赖任何移动设备。它不对游戏客户端进行任何破坏性修改以确保工具箱的安全性 Snap Hutao is an open-source Genshin Impact toolkit under MIT license, designed for modern Windows platform to improve the gaming experience for desktop players. By combining existing official resources with new features designed by the development team, it provides a complete and useful set of tools without the need to rely on mobile devices. Snap Hutao does not take any destructive modification to the game client to ensure the security of the toolkit. 安装 / Installation 你可以按照 快速开始 文档中提供的流程安装并设置 Snap Hutao。 You can follow the instructions in the Quick Start document to install and set up Snap Hutao. 本地化翻译 / Localization Snap Hutao 使用 Crowdin 作为客户端文本翻译平台，在该平台上你可以为你熟悉的语言提交翻译文本。我们感谢每一个为 Snap Hutao 做出贡献的社区成员，并且欢迎更多的朋友能参与到这个项目中。 Snap Hutao uses Crowdin as a client text translation platform where you can submit translated text for languages you are familiar with. We are grateful to every community member who has contributed to Snap Hutao and welcome more friends to participate in this project. 社区 / Community 贡献 / Contribute 向我们提交 PR / Make Pull Requests 为我们更新文档 / Enhance our Document 特别感谢 / Special Thanks HolographicHat UIGF organization 特定的原神项目 / Specific Genshin-related Projects Scighost/Starward 使用的技术栈 / Tech Stack CommunityToolkit/dotnet CommunityToolkit/Labs-Windows CommunityToolkit/Windows dotnet/efcore dotnet/runtime DotNetAnalyzers/StyleCopAnalyzers microsoft/vs-validation microsoft/WindowsAppSDK microsoft/microsoft-ui-xaml quartznet/quartznet 支撑项目 / Supporter Project Snap.Hutao.Server Snap.Metadata 赞助商 / Sponsorship Snap Hutao is currently using sponsored software from the following service providers. | | | | | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | | | | | | | | | Netlify provides document and home page hosting service for Snap Hutao Crowdin provides its SaaS platform to help Snap Hutao's localization Jihu GitLab (极狐) provides Git repository and CI/CD SaaS service for Snap Hutao in China Free code signing provided by SignPath.io , certificate by SignPath Foundation 1Password provides Snap Hutao development team with their amazing password management software DigitalOcean provides reliable cloud database for Snap Hutao database backup Ducalis.io provides Snap Hutao project with a complete decision-making toolkit for project management Jetbrains provides powerful IDE for Snap Hutao infrastructure services coding 开发 / Development;实用的开源多功能原神工具箱 🧰 / Multifunctional Open-source Genshin Impact Toolkit 🧰;genshin-impact,yuanshen,genshin,hoyoverse,hutao,mihoyo,dotnet,windows,snap-hutao,winui3\n\nDGP-Studio/Snap.Hutao\n\nhuggingface/deep-rl-class;The Hugging Face Deep Reinforcement Learning Course 🤗 (v2.0) If you like the course, don't hesitate to ⭐ star this repository. This helps us 🤗 . This repository contains the Deep Reinforcement Learning Course mdx files and notebooks. The website is here : https://huggingface.co/deep-rl-course/unit0/introduction?fw=pt The syllabus 📚: https://simoninithomas.github.io/deep-rl-course The course 📚: https://huggingface.co/deep-rl-course/unit0/introduction?fw=pt Sign up here ➡️➡️➡️ http://eepurl.com/ic5ZUD Citing the project To cite this repository in publications: bibtex @misc{deep-rl-course, author = {Simonini, Thomas and Sanseviero, Omar}, title = {The Hugging Face Deep Reinforcement Learning Class}, year = {2023}, publisher = {GitHub}, journal = {GitHub repository}, howpublished = {\\url{https://github.com/huggingface/deep-rl-class}}, };This repo contains the syllabus of the Hugging Face Deep Reinforcement Learning Course.;deep-reinforcement-learning,reinforcement-learning,reinforcement-learning-excercises,deep-learning\n\nhuggingface/deep-rl-class\n\nmicrosoft/Microsoft-3D-Movie-Maker;Microsoft 3D Movie Maker Released in 1995, this is the original source code to the Microsoft 3D Movie Maker project, now released under the MIT license as open source. Building instructions This project is unlikely to build successfully under modern hardware/software, but you can get started with compilation and get partial completed binaries. Here's what will get you going. Thanks to Mac Sample for their work on getting this far! Make sure this repo is checked out to a folder with a short name, ideally right on the root of a drive (i.e. C:\\3d). You will need Visual C++ 2.0's dev tools (located under MSVC20\\BIN on its installer disk) on your path. Modern compilers dislike some of the pre C++98 conventions. From the root of this repo, run setvars.bat you can change the values in this script to change what your build will target. Locate and place font files (see FONTS.md ) Run nmake and you'll begin building 3d Movie Maker. Contributing The source files in this repo are for historical reference and will be kept static, and this repository will be archived. Feel free to fork this repo and experiment. Code cleanup This code was restored from the Microsoft corporate archives and cleared for release. Developer names and aliases were removed, with the exception of current employees who worked on the original release who consented to keeping their names in place The archive consisted of several CDs, some of which were for alternate builds or products, and have been excluded The code does not build with today's engineering tools, and is released as-is. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines . Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies. This repo includes a build from 1995 of BRender from Argonaut software. Approval to open source BRender as MIT was given in an email from Jez San, former CEO of Argonaut. Other versions of BRender exist at https://github.com/foone/BRender-v1.3.2 and https://github.com/foone/BRender-1997 Thanks to Jez and the whole BRender team for their hard work on this amazing engine. A full historical list of BRender contributors is available at https://github.com/foone/BRender-v1.3.2/blob/main/README.md This repo does NOT include the SoftImage SDK \"./DKIT\" from 1992. Jez also offered this interesting BRender anecdote in an email: When Sam Littlewood designed BRender, he didn’t write the code. And then document it. The way most things were built at the time. First, he wrote the manual. The full documentation That served as the spec. Then the coding started.;This is the source code for the original Microsoft 3D Movie Maker released in 1995. This is not supported software.;[]\n\nmicrosoft/Microsoft-3D-Movie-Maker\n\ncirruslabs/tart;Tart is a virtualization toolset to build, run and manage macOS and Linux virtual machines (VMs) on Apple Silicon. Built by CI engineers for your automation needs. Here are some highlights of Tart: Tart uses Apple's own Virtualization.Framework for near-native performance . Push/Pull virtual machines from any OCI-compatible container registry. Use Tart Packer Plugin to automate VM creation. Easily integrates with any CI system. Tart powers Cirrus Runners service — a drop-in replacement for the standard GitHub-hosted runners, offering 2-3 times better performance for a fraction of the price. Many companies are using Tart in their internal setups. Here are a few of them: Note: If your company or project is using Tart please consider adding yourself to the list above . Usage Try running a Tart VM on your Apple Silicon device running macOS 13.0 (Ventura) or later (will download a 25 GB image): bash brew install cirruslabs/cli/tart tart clone ghcr.io/cirruslabs/macos-sonoma-base:latest sonoma-base tart run sonoma-base Please check the official documentation for more information and/or feel free to use discussions for remaining questions.;macOS and Linux VMs on Apple Silicon to use in CI and other automations;automation,macos,tart,virtualization,virtualization-framework,apple-silicon,ci\n\ncirruslabs/tart\n\nGiskard-AI/giskard;The Evaluation & Testing framework for LLMs & ML models Control risks of performance, bias and security issues in AI models [![GitHub release](https://img.shields.io/github/v/release/Giskard-AI/giskard)](https://github.com/Giskard-AI/giskard/releases) [![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://github.com/Giskard-AI/giskard/blob/main/LICENSE) [![CI](https://github.com/Giskard-AI/giskard/actions/workflows/build-python.yml/badge.svg?branch=main)](https://github.com/Giskard-AI/giskard/actions/workflows/build-python.yml?query=branch%3Amain) [![Sonar](https://sonarcloud.io/api/project_badges/measure?project=giskard&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=giskard) [![Giskard on Discord](https://img.shields.io/discord/939190303397666868?label=Discord)](https://gisk.ar/discord) Docs • Blog • Website • Discord Install Giskard 🐢 Install the latest version of Giskard from PyPi using pip: sh pip install \"giskard[llm]\" -U We officially support Python 3.9, 3.10 and 3.11. Try in Colab 📙 Open Colab notebook Giskard is an open-source Python library that automatically detects performance, bias & security issues in AI applications . The library covers LLM-based applications such as RAG agents, all the way to traditional ML models for tabular data. Scan: Automatically assess your LLM-based agents for performance, bias & security issues ⤵️ Issues detected include: - Hallucinations - Harmful content generation - Prompt injection - Robustness issues - Sensitive information disclosure - Stereotypes & discrimination - many more... RAG Evaluation Toolkit (RAGET): Automatically generate evaluation datasets & evaluate RAG application answers ⤵️ If you're testing a RAG application, you can get an even more in-depth assessment using RAGET , Giskard's RAG Evaluation Toolkit. RAGET can generate automatically a list of question , reference_answer and reference_context from the knowledge base of the RAG. You can then use this generated test set to evaluate your RAG agent. RAGET computes scores for each component of the RAG agent . The scores are computed by aggregating the correctness of the agent’s answers on different question types. Here is the list of components evaluated with RAGET : Generator : the LLM used inside the RAG to generate the answers Retriever : fetch relevant documents from the knowledge base according to a user query Rewriter : rewrite the user query to make it more relevant to the knowledge base or to account for chat history Router : filter the query of the user based on his intentions Knowledge Base : the set of documents given to the RAG to generate the answers Giskard works with any model, in any environment and integrates seamlessly with your favorite tools ⤵️ Contents 🤸‍♀️ Quickstart 1 . 🏗️ Build a LLM agent 2 . 🔎 Scan your model for issues 3 . 🪄 Automatically generate an evaluation dataset for your RAG applications 👋 Community 🤸‍♀️ Quickstart 1. 🏗️ Build a LLM agent Let's build an agent that answers questions about climate change, based on the 2023 Climate Change Synthesis Report by the IPCC. Before starting let's install the required libraries: sh pip install langchain tiktoken \"pypdf<=3.17.0\" ```python from langchain import OpenAI, FAISS, PromptTemplate from langchain.embeddings import OpenAIEmbeddings from langchain.document_loaders import PyPDFLoader from langchain.chains import RetrievalQA from langchain.text_splitter import RecursiveCharacterTextSplitter Prepare vector store (FAISS) with IPPC report text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True) loader = PyPDFLoader(\"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\") db = FAISS.from_documents(loader.load_and_split(text_splitter), OpenAIEmbeddings()) Prepare QA chain PROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard. Your task is to answer common questions on climate change. You will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023). Please provide short and clear answers based on the provided context. Be polite and helpful. Context: {context} Question: {question} Your answer: \"\"\" llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0) prompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"]) climate_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt) ``` 2. 🔎 Scan your model for issues Next, wrap your agent to prepare it for Giskard's scan: ```python import giskard import pandas as pd def model_predict(df: pd.DataFrame): \"\"\"Wraps the LLM call in a simple Python function. The function takes a pandas.DataFrame containing the input variables needed by your model, and must return a list of the outputs (one for each row). \"\"\" return [climate_qa_chain.run({\"query\": question}) for question in df[\"question\"]] Don’t forget to fill the name and description : they are used by Giskard to generate domain-specific tests. giskard_model = giskard.Model( model=model_predict, model_type=\"text_generation\", name=\"Climate Change Question Answering\", description=\"This model answers any question about climate change based on IPCC reports\", feature_names=[\"question\"], ) ``` ✨✨✨Then run Giskard's magical scan✨✨✨ python scan_results = giskard.scan(giskard_model) Once the scan completes, you can display the results directly in your notebook: ```python display(scan_results) Or save it to a file scan_results.to_html(\"scan_results.html\") ``` If you're facing issues, check out our docs for more information. 3. 🪄 Automatically generate an evaluation dataset for your RAG applications If the scan found issues in your model, you can automatically extract an evaluation dataset based on the issues found: python test_suite = scan_results.generate_test_suite(\"My first test suite\") By default, RAGET automatically generates 6 different question types (these can be selected if needed, see advanced question generation). The total number of questions is divided equally between each question type. To make the question generation more relevant and accurate, you can also provide a description of your agent. ```python from giskard.rag import generate_testset, KnowledgeBase Load your data and initialize the KnowledgeBase df = pd.read_csv(\"path/to/your/knowledge_base.csv\") knowledge_base = KnowledgeBase.from_pandas(df, columns=[\"column_1\", \"column_2\"]) Generate a testset with 10 questions & answers for each question types (this will take a while) testset = generate_testset( knowledge_base, num_questions=60, language='en', # optional, we'll auto detect if not provided agent_description=\"A customer support chatbot for company X\", # helps generating better questions ) ``` Depending on how many questions you generate, this can take a while. Once you’re done, you can save this generated test set for future use: ```python Save the generated testset testset.save(\"my_testset.jsonl\") ``` You can easily load it back ```python from giskard.rag import QATestset loaded_testset = QATestset.load(\"my_testset.jsonl\") Convert it to a pandas dataframe df = loaded_testset.to_pandas() ``` Here’s an example of a generated question: | question | reference_context | reference_answer | metadata | |----------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|-------------------------------------------------------| | For which countries can I track my shipping? | Document 1: We offer free shipping on all orders over $50. For orders below $50, we charge a flat rate of $5.99. We offer shipping services to customers residing in all 50 states of the US, in addition to providing delivery options to Canada and Mexico. Document 2: Once your purchase has been successfully confirmed and shipped, you will receive a confirmation email containing your tracking number. You can simply click on the link provided in the email or visit our website’s order tracking page. | We ship to all 50 states in the US, as well as to Canada and Mexico. We offer tracking for all our shippings. | {\"question_type\": \"simple\", \"seed_document_id\": 1, \"topic\": \"Shipping policy\"} | Each row of the test set contains 5 columns: question : the generated question reference_context : the context that can be used to answer the question reference_answer : the answer to the question (generated with GPT-4) conversation_history : not shown in the table above, contain the history of the conversation with the agent as a list, only relevant for conversational question, otherwise it contains an empty list. metadata : a dictionary with various metadata about the question, this includes the question_type, seed_document_id the id of the document used to generate the question and the topic of the question 👋 Community We welcome contributions from the AI community! Read this guide to get started, and join our thriving community on Discord . 🌟 Leave us a star , it helps the project to get discovered by others and keeps us motivated to build awesome open-source tools! 🌟 ❤️ If you find our work useful, please consider sponsoring us on GitHub. With a monthly sponsoring, you can get a sponsor badge, display your company in this readme, and get your bug reports prioritized. We also offer one-time sponsoring if you want us to get involved in a consulting project, run a workshop, or give a talk at your company.;🐢 Open-Source Evaluation & Testing for LLMs and ML models;mlops,ml-validation,ml-testing,ai-testing,ai-safety,ml-safety,llmops,ethical-artificial-intelligence,responsible-ai,fairness-ai\n\nGiskard-AI/giskard\n\nVonHeikemen/lsp-zero.nvim;LSP Zero Collection of functions that will help you setup Neovim's LSP client, so you can get IDE-like features with minimum effort. Out of the box it will help you integrate nvim-cmp (an autocompletion plugin) and nvim-lspconfig (a collection of configurations for various language servers). So a minimal config can look like this. lua require('lsp-zero') require('lspconfig').intelephense.setup({}) With this code when intelephense (a language server for PHP) is active you'll get all the features Neovim offers by default plus autocompletion. See demo in asciinema . How to get started If you are new to Neovim and you don't have a configuration file ( init.lua ) follow this step by step tutorial . If you know how to configure Neovim go to the Getting started page in the documentation. Also consider nvim-lspconfig works fine without lsp-zero. And you can setup nvim-cmp by yourself. I wrote a blog post that shows how to do it: You might not need lsp-zero . Documentation You can browse the documentation at lsp-zero.netlify.app/v3.x Installation and basic usage LSP configuration Autocompletion Frequent Questions Expand: More Documentation Links * Integrations * [Integrate with mason.nvim](https://lsp-zero.netlify.app/v3.x/guide/integrate-with-mason-nvim.html) * [Enable folds with nvim-ufo](https://lsp-zero.netlify.app/v3.x/guide/quick-recipes.html#enable-folds-with-nvim-ufo) * [Setup copilot.lua + nvim-cmp](https://lsp-zero.netlify.app/v3.x/guide/setup-copilot-lua-plus-nvim-cmp.html) * [Setup with nvim-jdtls](https://lsp-zero.netlify.app/v3.x/guide/setup-with-nvim-jdtls.html) * [Setup lsp-inlayhints.nvim](https://lsp-zero.netlify.app/v3.x/guide/quick-recipes.html#enable-inlay-hints-with-lsp-inlayhints-nvim) * [Setup with nvim-navic](https://lsp-zero.netlify.app/v3.x/guide/quick-recipes.html#setup-with-nvim-navic) * [Setup with rustaceanvim](https://lsp-zero.netlify.app/v3.x/guide/quick-recipes.html#setup-with-rustaceanvim) * [Setup with flutter-tools](https://lsp-zero.netlify.app/v3.x/guide/quick-recipes.html#setup-with-flutter-tools) * [Setup with nvim-metals](https://lsp-zero.netlify.app/v3.x/guide/quick-recipes.html#setup-with-nvim-metals) * [Setup with haskell-tools](https://lsp-zero.netlify.app/v3.x/guide/quick-recipes.html#setup-with-haskell-tools) * Guides * [What to do when the language server doesn't start?](https://lsp-zero.netlify.app/v3.x/guide/what-to-do-when-lsp-doesnt-start.html) * [Lazy loading with lazy.nvim](https://lsp-zero.netlify.app/v3.x/guide/lazy-loading-with-lazy-nvim.html) * [lua_ls for Neovim](https://lsp-zero.netlify.app/v3.x/guide/neovim-lua-ls.html) * [Configure Volar 2.0 (with typescript support)](https://lsp-zero.netlify.app/v3.x/guide/configure-volar-v2.html) * [Migrate from v2.x to v3.x](https://lsp-zero.netlify.app/v3.x/guide/migrate-from-v2-branch.html) * [Migrate from v1.x to v3.x](https://lsp-zero.netlify.app/v3.x/guide/migrate-from-v1-branch.html) * API * [Commands](https://lsp-zero.netlify.app/v3.x/reference/commands.html) * [Variables](https://lsp-zero.netlify.app/v3.x/reference/variables.html) * [Lua API](https://lsp-zero.netlify.app/v3.x/guide/what-to-do-when-lsp-doesnt-start.html) * Blog posts * [You might not need lsp-zero](https://lsp-zero.netlify.app/v3.x/blog/you-might-not-need-lsp-zero.html) * [lsp-zero under the hood](https://lsp-zero.netlify.app/v3.x/blog/under-the-hood.html) * [require lsp-zero](https://lsp-zero.netlify.app/v3.x/blog/what-require-lsp-zero-does.html) * [ThePrimeagen 0 to LSP config](https://lsp-zero.netlify.app/v3.x/blog/theprimeagens-config-from-2022.html) If you need any help Feel free to open a new discussion in this repository. Or join the chat #lsp-zero-nvim:matrix.org . If you have problems with a language server read this guide: What to do when the language server doesn't start? If you want to migrate from a previous version to the v3.x branch, follow one of these guides: Migrate from v2.x to v3.x Migrate from v1.x to v3.x When asking for help for a specific language One thing you should know when asking for help online: asking the question \"how to configure [random language] with lsp-zero?\" is not going to give you the results you want. You probably want to ask \"how to configure the language server for [random language] using nvim-lspconfig ?\" That will give you better results because nvim-lspconfig is the plugin that configures the language servers. Quickstart (for the impatient) If you are not that impatient, I recommend reading the Getting started page. But for those of you that just want to copy/paste, here are some templates you can use. Lua template configuration Vimscript template configuration ThePrimeagen's \"0 to LSP\" config updated Support If you find this tool useful and want to support my efforts, buy me a coffee ☕ .;A starting point to setup some lsp related features in neovim.;neovim,nvim,lsp,language-server-protocol\n\nVonHeikemen/lsp-zero.nvim\n\nLibrum-Reader/Librum;Librum Librum is an application designed to make reading enjoyable and straightforward for everyone. It's not just an e-book reader. With Librum, you can manage your own online library and access it from any device anytime, anywhere. It has features like note-taking, AI tooling, and highlighting, while offering customization to make it as personal as you want! Librum also provides free access to over 70,000 books and personal reading statistics while being free and completely open source. Join us on Discord Preview Setup and manage your own online library A simple and modern interface Add your books to collections, tag them, and sort them in any way you want Customize Librum to make it personal to you Where can I get Librum? Simply go to https://librumreader.com to download Librum. If you want to build Librum from source, follow the instructions here . Contact For questions, you can reach us under: help@librumreader.com For business related contact, reach out to us here: contact@librumreader.com Donations Donations make it possible for us to cover our server costs and allow us to make investments into new areas of development. If you would like to support us, check out: https://librumreader.com/contribute/donate or become a Github sponsor! As a team of opensource developers we rely on donations to continue working on projects like Librum. Your help is greatly appreciated. Translations Librum is currently available in: - English - German - Russian - Ukrainian - Indonesian - Italian - Korean - Portuguese - Mandarin If you want to translate Librum to another language, follow the steps below: - Download this file - Rename the file to contain your language's suffix, e.g. \"librum_ru.ts\" for Russian or \"librum_de.ts\" for German - Download the translation software (Qt Linguist) either for Windows from here or using the Qt Installer - Now start Qt Linguist, open the downloaded file, set the target language to the language you want to translate to and start translating. (Check out this guide for a quick overview of Qt Linguist) Once you are done, create a pull request or open up an issue with your new translation file! If you run into any problems, need guidance or have questions, feel free to reach out to us at: contact@librumreader.com Notes: - Make sure that your translations are approximately the same length as the original text - Please carefully check for spelling mistakes (including punctuation and capitalization) Documentation For documentation go to Librum's GitHub-wiki Contributing If you'd like to contribute, check out: https://librumreader.com/contribute If you are interested in contributing, feel free to contact us on either: 1. Discord (m_david#0631) 2. Email (contact@librumreader.com) We are following a pull request workflow where every contribution is sent as a pull request and merged into the dev/develop branch for testing. Please make sure to run clang format, keep to the conventions used throughout the application and ensure that all tests pass, before submitting any pull request. Self-hosting To self-host Librum you need to run Librum-Server locally (instructions can be found here ) and tell the client to use your self-hosted server by: - (Linux) Editing ~/.config/Librum-Reader/Librum.conf and setting selfHosted=true and serverHost to your server's url (e.g. serverHost=https://127.0.0.1:5001 ) - (Windows) Opening the registry editor (Press Win + R and search for regedit ), navigating to HKEY_CURRENT_USER\\Software\\Librum-Reader\\Librum and setting selfHosted=true and serverHost to your server's url Make sure to run the application before following the steps above, to generate the required files. Details Supported platforms Part of Librum's aim is to work on any platform. No matter where you are or which device you use, you can always continue your book with Librum, as it is cross platform . We support: - Windows - GNU/Linux - MacOS - IOS (Coming Soon) - Android (Coming Soon) Supported formats Librum is the best choice for all kinds of books, since Librum supports all major book formats including: - PDF - EPUB - CBZ (Comic books) - FB2 - TIFF - Mobi - XPS - Images And many more! Features Librum's objective is to make your reading more productive ; to that end, we provide you with a variety of features that you can access via a simple and straightforward interface. These features include: - A modern e-reader - A personalized and customizable online library - Book meta-data editing - A free in-app bookstore with more than 70,000 books - Book syncing across all of your devices - Highlighting - Bookmarking - Text search - Unlimited customization - Fine-grained organization through Librum's folder system - Note-taking (Coming Soon) - TTS (Coming Soon) - Personalized reading statistics (Coming Soon) Want a new feature? Feel free to leave a feature request ticket! Build Guide Follow this guide to build Librum from source. For GNU/Linux Prerequisites cmake (https://cmake.org/download) make (http://ftp.gnu.org/gnu/make) g++ (https://gcc.gnu.org) python3-venv (on ubuntu use sudo apt install python3-venv ) Qt 6.5 (https://www.qt.io/download-open-source) Installation The installation is straight forward, just follow the steps below: Clone the repository. sh git clone https://github.com/Librum-Reader/Librum.git --recursive Step into the cloned project folder. sh cd Librum Create the build folder and step into it. sh mkdir build-Release cd build-Release Run cmake. sh cmake -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<path/to/Qt> .. Set CMAKE_PREFIX_PATH to your Qt installation path. Installing Qt via the online installer usually installs it to /home/<name>/Qt/<version>/gcc_64 Build the project sh cmake --build . -j $(nproc) Install Librum sh cmake --install . Troubleshooting Here are solutions to some common errors. If your error is not listed here, please open an issue. Error: Failed to find required Qt component \"Quick\". Solution: Install the libGL mesa dev package, on ubuntu its sudo apt install libgl1-mesa-dev and on fedora its sudo dnf install mesa-libGL-devel . Error: Could not load the qt platform plugin \"xcb\" even though it was found Solution: Install the libxcb-cursor-dev, on ubuntu its sudo apt install libxcb-cursor-dev For Windows Prerequisites cmake (https://cmake.org/download) Visual Studio 19 (https://visualstudio.microsoft.com/de/vs/older-downloads) Python (https://www.python.org/downloads) Qt 6.5 (https://www.qt.io/download-open-source) Installation To build Librum on windows, run the following commands in the Powershell: Clone the repository. sh git clone https://github.com/Librum-Reader/Librum.git --recursive Step into the cloned project folder. sh cd Librum Create the build folder and step into it. sh mkdir build cd build Run cmake. sh cmake -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<path/to/qt> .. Set CMAKE_PREFIX_PATH to your Qt installation path. Installing Qt via the online installer usually installs it to <Drive>\\\\Qt\\\\<version>\\\\msvc2019_64 Build the project sh cmake --build . --config Release Run the app sh ./librum Additional Info Here are some things to keep in mind during the build process. Make sure to add cmake and the Qt binaries to the PATH environment variable You need Visual Studio 2019, newer versions will not work For the Qt installation, you only need to choose \"MSVC 2019 64-bit\", you can untick everything else to reduce the download size For MacOS Prerequisites cmake (https://cmake.org/download) make (http://ftp.gnu.org/gnu/make) g++ (https://gcc.gnu.org) python3 (https://www.python.org/downloads) Qt 6.5 (https://www.qt.io/download-open-source) Installation The installation is straight forward, just follow the steps below: Clone the repository. sh git clone https://github.com/Librum-Reader/Librum.git --recursive Step into the cloned project folder. sh cd Librum Create the build folder and step into it. sh mkdir build-Release cd build-Release Run cmake. sh cmake -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<path/to/Qt> .. Set CMAKE_PREFIX_PATH to your Qt installation path. Installing Qt via the online installer usually installs it to /Users/<name>/Qt/<version>/macos Build the project sh cmake --build . -j $(nproc) Install Librum sh cmake --install Note: Make sure to add /usr/local/lib to your DYLIB path, for MacOS to find the installed libraries by exporting DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:/usr/local/lib .;The Librum client application;cmake,cpp,qml,qt,ebook-reader,ebooks,library-management,reader,linux,qt6\n\nLibrum-Reader/Librum\n\nopen-duelyst/duelyst;OpenDuelyst This is the source code for Duelyst, a digital collectible card game and turn-based strategy hybrid developed by Counterplay Games and released in 2016. Running the Game Locally If you'd like to run the game locally or contribute to OpenDuelyst, check out our Documentation , especially the Roadmap and Contributor Guide . You can also join the OpenDuelyst developer Discord server here . This Discord server is focused on the development of OpenDuelyst, and has channels for frontend, backend, and infrastructure discussions, but it is open for anyone to join. Downloading the Desktop Clients Desktop clients for Windows, Mac, and Linux can be downloaded on the Releases page. They can be used against your local environment. Playing on Android or iOS We have basic support for playing on mobile web currently. To hide the status/navigation bar in Chrome or Safari, open the game and select \"Add to Home Screen\". When you open the game from the home screen, the status bar will be hidden. Filing Issues and Reporting Bugs If you encounter a bug and would like to report it, first check the Open Issues to see if the bug has already been reported. If not, feel free to create a new issue with the bug label. If you would like to request a technical feature or enhancement to the code, you can create a new issue with the enhancement label. Since OpenDuelyst is currently focused on recreating the game as it last existed in v1.96.17, please avoid creating feature requests related to balance changes. Localization The game currently includes English and German localization. If you'd like to contribute translations for another language, take a look at the app/localization/locales directory. You can copy the en folder and start updating strings for the new language, then submit a Pull Request with your contribution. There are about 4,500 localized strings, so this can also be done a little bit at a time. Once the translations are in, we can help get the language included in the game. License OpenDuelyst is licensed under the Creative Commons Zero v1.0 Universal license. You can see a copy of the license here .;Duelyst is a digital collectible card game and turn-based strategy hybrid, developed by Counterplay Games.;[]\n\nopen-duelyst/duelyst\n\nsofn-xyz/mailing;packages/cli/README.md;Build, test, send emails with React;[]\n\nsofn-xyz/mailing\n\nalibaba/fastjson2;📖 English Documentation | 📖 中文文档 本项目的Issues会被同步沉淀至 阿里云开发者社区 FASTJSON v2 FASTJSON 2 是一个性能极致并且简单易用的Java JSON库。 FASTJSON 2 是 FASTJSON 项目的重要升级，和FASTJSON 1相比，性能有非常大的提升，解决了autoType功能因为兼容和白名单的安全性问题。 性能极致，性能远超过其他流行JSON库，包括jackson/gson/org.json，性能数据: https://github.com/alibaba/fastjson2/wiki/fastjson_benchmark 支持JDK新特性，包括 JDK 11 / JDK 17 ，针对 compact string 优化，支持Record，支持 GraalVM Native-Image 完善的 JSONPath 支持，支持 SQL:2016 的JSONPath语法 支持 Android 8+ ，客户端和服务器一套API 支持 Kotlin https://alibaba.github.io/fastjson2/kotlin_cn 支持 JSON Schema https://alibaba.github.io/fastjson2/json_schema_cn 新增加支持二进制格式JSONB https://alibaba.github.io/fastjson2/jsonb_format_cn 1. 使用准备 1.1 添加依赖 在 fastjson v2 中， groupId 和 1.x 不一样，是 com.alibaba.fastjson2 ： Maven : xml <dependency> <groupId>com.alibaba.fastjson2</groupId> <artifactId>fastjson2</artifactId> <version>2.0.51</version> </dependency> Gradle : groovy dependencies { implementation 'com.alibaba.fastjson2:fastjson2:2.0.51' } 可以在 maven.org 查看最新可用的版本。 1.2 其他模块 Fastjson v1 兼容模块 如果原来使用 fastjson 1.2.x 版本，可以使用兼容包，兼容包不能保证100%兼容，请仔细测试验证，发现问题请及时反馈。 Maven : xml <dependency> <groupId>com.alibaba</groupId> <artifactId>fastjson</artifactId> <version>2.0.51</version> </dependency> Gradle : groovy dependencies { implementation 'com.alibaba:fastjson:2.0.51' } Fastjson Kotlin 集成模块 如果项目使用 Kotlin ，可以使用 fastjson-kotlin 模块，使用方式上采用 kotlin 的特性。 Maven : xml <dependency> <groupId>com.alibaba.fastjson2</groupId> <artifactId>fastjson2-kotlin</artifactId> <version>2.0.51</version> </dependency> 酌情添加标准库(kotlin-stdlib)、反射库(kotlin-reflect)， 其中若使用数据类(data class)、通过构造函数传入参数则添加反射库。 ```xml org.jetbrains.kotlin kotlin-stdlib ${kotlin-version} org.jetbrains.kotlin kotlin-reflect ${kotlin-version} ``` Kotlin Gradle : kotlin dependencies { implementation(\"com.alibaba.fastjson2:fastjson2-kotlin:2.0.51\") } kotlin dependencies { implementation(\"org.jetbrains.kotlin:kotlin-stdlib:$kotlin_version\") implementation(\"org.jetbrains.kotlin:kotlin-reflect:$kotlin_version\") } Fastjson Extension 扩展模块 如果项目使用 SpringFramework 等框架，可以使用 fastjson-extension 模块，使用方式参考 SpringFramework Support 。 Maven : xml <dependency> <groupId>com.alibaba.fastjson2</groupId> <artifactId>fastjson2-extension-spring5</artifactId> <version>2.0.51</version> </dependency> xml <dependency> <groupId>com.alibaba.fastjson2</groupId> <artifactId>fastjson2-extension-spring6</artifactId> <version>2.0.51</version> </dependency> Gradle : groovy dependencies { implementation 'com.alibaba.fastjson2:fastjson2-extension-spring5:2.0.51' } groovy dependencies { implementation 'com.alibaba.fastjson2:fastjson2-extension-spring6:2.0.51' } 2. 简单使用 在 fastjson v2 中， package 和 1.x 不一样，是 com.alibaba.fastjson2 。如果你之前用的是 fastjson1 ，大多数情况直接更包名就即可。 2.1 将 JSON 解析为 JSONObject Java : ```java String text = \"...\"; JSONObject data = JSON.parseObject(text); byte[] bytes = ...; JSONObject data = JSON.parseObject(bytes); ``` Kotlin : ```kotlin import com.alibaba.fastjson2.* val text = ... // String val data = text.parseObject() val bytes = ... // ByteArray val data = bytes.parseObject() // JSONObject ``` 2.2 将 JSON 解析为 JSONArray Java : java String text = \"...\"; JSONArray data = JSON.parseArray(text); Kotlin : ```kotlin import com.alibaba.fastjson2.* val text = ... // String val data = text.parseArray() // JSONArray ``` 2.3 将 JSON 解析为 Java 对象 Java : java String text = \"...\"; User data = JSON.parseObject(text, User.class); Kotlin : ```kotlin import com.alibaba.fastjson2.* val text = ... // String val data = text.to () // User val data = text.parseObject () // User ``` 2.4 将 Java 对象序列化为 JSON Java : java Object data = \"...\"; String text = JSON.toJSONString(data); byte[] text = JSON.toJSONBytes(data); Kotlin : ```kotlin import com.alibaba.fastjson2.* val data = ... // Any val text = text.toJSONString() // String val bytes = text.toJSONByteArray() // ByteArray ``` 2.5 使用 JSONObject 、 JSONArray 2.5.1 获取简单属性 ```java String text = \"{\\\"id\\\": 2,\\\"name\\\": \\\"fastjson2\\\"}\"; JSONObject obj = JSON.parseObject(text); int id = obj.getIntValue(\"id\"); String name = obj.getString(\"name\"); ``` ```java String text = \"[2, \\\"fastjson2\\\"]\"; JSONArray array = JSON.parseArray(text); int id = array.getIntValue(0); String name = array.getString(1); ``` 2.5.2 读取 JavaBean Java : ```java JSONArray array = ... JSONObject obj = ... User user = array.getObject(0, User.class); User user = obj.getObject(\"key\", User.class); ``` Kotlin : ```kotlin val array = ... // JSONArray val obj = ... // JSONObject val user = array.to (0) val user = obj.to (\"key\") ``` 2.5.3 转为 JavaBean Java : ```java JSONArray array = ... JSONObject obj = ... User user = obj.toJavaObject(User.class); List users = array.toJavaList(User.class); ``` Kotlin : ```kotlin val array = ... // JSONArray val obj = ... // JSONObject val user = obj.to () // User val users = array.toList () // List ``` 2.6 将 JavaBean 对象序列化为 JSON Java : ```java class User { public int id; public String name; } User user = new User(); user.id = 2; user.name = \"FastJson2\"; String text = JSON.toJSONString(user); byte[] bytes = JSON.toJSONBytes(user); ``` Kotlin : ```kotlin class User( var id: Int, var name: String ) val user = User() user.id = 2 user.name = \"FastJson2\" val text = user.toJSONString() // String val bytes = user.toJSONByteArray() // ByteArray ``` 序列化结果: json { \"id\" : 2, \"name\" : \"FastJson2\" } 3. 进阶使用 3.1 使用 JSONB 3.1.1 将 JavaBean 对象序列化 JSONB java User user = ...; byte[] bytes = JSONB.toBytes(user); byte[] bytes = JSONB.toBytes(user, JSONWriter.Feature.BeanToArray); 3.1.2 将 JSONB 数据解析为 JavaBean java byte[] bytes = ... User user = JSONB.parseObject(bytes, User.class); User user = JSONB.parseObject(bytes, User.class, JSONReader.Feature.SupportBeanArrayMapping); 3.2 使用 JSONPath 3.2.1 使用 JSONPath 读取部分数据 ```java String text = ...; JSONPath path = JSONPath.of(\"$.id\"); // 缓存起来重复使用能提升性能 JSONReader parser = JSONReader.of(text); Object result = path.extract(parser); ``` 3.2.2 使用 JSONPath 读取部分 byte[] 的数据 ```java byte[] bytes = ...; JSONPath path = JSONPath.of(\"$.id\"); // 缓存起来重复使用能提升性能 JSONReader parser = JSONReader.of(bytes); Object result = path.extract(parser); ``` 3.2.3 使用 JSONPath 读取部分 byte[] 的数据 ```java byte[] bytes = ...; JSONPath path = JSONPath.of(\"$.id\"); // 缓存起来重复使用能提升性能 JSONReader parser = JSONReader.ofJSONB(bytes); // 注意这里使用ofJSONB方法 Object result = path.extract(parser); ``` Star History;🚄 FASTJSON2 is a Java JSON library with excellent performance.;json,fastjson,json-parser,jsonb,java-json,json-serialization,json-path,high-performance,fastjson2,android\n\nalibaba/fastjson2\n\nwarp-tech/warpgate;Warpgate is a smart SSH, HTTPS and MySQL bastion host for Linux that doesn't need special client apps. Set it up in your DMZ, add user accounts and easily assign them to specific hosts and URLs within the network. Warpgate will record every session for you to view (live) and replay later through a built-in admin web UI. Not a jump host - forwards your connections straight to the target instead. Native 2FA and SSO support (TOTP & OpenID Connect) Single binary with no dependencies. Written in 100% safe Rust. Getting started & downloads See the Getting started wiki page (or Getting started on Docker ). Release / beta binaries Nightly builds Project Status The project is currently in alpha stage and is gathering community feedback. See the official roadmap for the upcoming features. In particular, we're working on: Requesting admin approvals for sessions Support for tunneling PostgreSQL connections, and much more. How it works Warpgate is a service that you deploy on the bastion/DMZ host, which will accept SSH, HTTPS and MySQL connections and provide an (optional) web admin UI. Run warpgate setup to interactively generate a config file, including port bindings. See Getting started for details. It receives connections with specifically formatted credentials, authenticates the user locally, connects to the target itself, and then connects both parties together while (optionally) recording the session. When connecting through HTTPS, Warpgate presents a selection of available targets, and will then proxy all traffic in a session to the selected target. You can switch between targets at any time. You manage the target and user lists and assign them to each other through the admin UI, and the session history is stored in an SQLite database (default: in /var/lib/warpgate ). You can also use the admin web interface to view the live session list, review session recordings, logs and more. Contributing / building from source You'll need Rust, NodeJS and Yarn Clone the repo Just is used to run tasks - install it: cargo install just Install the admin UI deps: just yarn Build the frontend: just yarn build Build Warpgate: cargo build (optionally --release ) The binary is in target/{debug|release} . Tech stack Rust 🦀 HTTP: poem-web Database: SQLite via sea-orm + sqlx SSH: russh Typescript Svelte Bootstrap Backend API Warpgate admin and user facing APIs use autogenerated OpenAPI schemas and SDKs. To update the SDKs after changing the query/response structures, run just openapi-all . Contributors ✨ Thanks goes to these wonderful people ( emoji key ): Eugeny 💻 Spencer Heywood 💻 Andreas Piening 💻 Niklas 💻 Nooblord 💻 Shea Smith 💻 This project follows the all-contributors specification. Contributions of any kind welcome!;Smart SSH, HTTPS and MySQL bastion that requires no additional client-side software;bastion,bastion-host,infrastructure,ssh,ssh-server,proxy,rust,https,https-proxy,mysql\n\nwarp-tech/warpgate\n\nydb-platform/ydb;YDB Website | Documentation | Official Repository | Blog | YouTube | Discord | Telegram | LinkedIn | X YDB is an open source Distributed SQL Database that combines high availability and scalability with strict consistency and ACID transactions. Main YDB Advantages YDB was designed from scratch to respond to the growing demand for scalable interactive web services. Scalability, strict consistency, and effective cross-row transactions were a must for such an OLTP-like workload. YDB was built by people with strong backgrounds in databases and distributed systems who have experience developing a NoSQL database and the MapReduce system for one of the largest search engines in the world. Basic YDB features: Both row-oriented and column-oriented tables for transactional and analytical workloads. Also, persistent queues (topics) for moving data around. Fault-tolerant configuration that survives disk, node, rack, or even datacenter outages. Automatic disaster recovery with minimum latency disruptions for applications. Independent horizontal scalability of storage and compute layers. ACID transactions across multiple nodes and tables with strict consistency. Rich SQL dialect (YQL) for data manipulation and schema definition. PostgreSQL-compatible mode for table operations and Kafka-compatible mode for topics. YDB clusters can be deployed with Ansible , Kubernetes , or manually . Fault-tolerant Configurations YDB can be deployed in three availability zones (datacenters). A cluster remains available for both reads and writes during a complete outage of a single zone. Availability zones and regions are covered in more detail in documentation . Horizontal Scalability Unlike traditional relational databases, YDB scales out , providing developers with the capability to simply extend clusters with computation or storage resources to handle increasing load. YDB has disaggregated storage and compute layers, which allow you to scale storage and compute resources independently. Current production installations have over 10000 nodes, store petabytes of data, and handle millions of distributed transactions per second. Automatic Disaster Recovery YDB's built-in automatic recovery support allows it to seamlessly survive hardware failures. After unpredictable disk, node, rack, or even datacenter failure, YDB remains fully available for reads and writes and automatically restores required data redundancy. Multitenant and Serverless Database YDB supports multitenant and serverless setups. A user can run a YDB cluster and create several databases that share one pool of storage and have different compute nodes. Alternatively, a user can run several serverless databases that share one pool of compute resources to utilize them effectively. Supported Platforms Minimal system requirements YDB runs on x86 64-bit platforms with at least 8 GB of RAM. Operating Systems In most production environments, YDB runs on 64-bit x86 machines working under Ubuntu Linux. For development purposes, it is regularly tested that YDB can be compiled and run under the latest versions of MacOS and Microsoft Windows. Getting Started If you want to experiment with YDB, start with the Quick Start guide . It will yield a single-node cluster suitable for functional testing, app development, and similar tasks. Suppose you want to jump into more serious scenarios like testing YDB fault tolerance, running performance benchmarks, or even running production or preproduction workloads. In that case, you'll need a full-fledged multi-node YDB cluster that can be deployed with either Ansible for bare metal or virtual machines or Kubernetes for containers. How to Build from Source Code Instructions on how to build YDB server (ydbd) and client (ydb) binaries are provided in BUILD.md . Also, see documentation on Ya Make build system . How to Contribute We are glad to welcome new contributors! The contributor's guide provides more details on how to get started as a contributor. There's also a separate section of YDB documentation for contributors , mostly with more technical content. Success Stories Visit YDB website for the latest success stories and user scenarios.;YDB is an open source Distributed SQL Database that combines high availability and scalability with strong consistency and ACID transactions;database,distributed,sql,dbms,cloud-native,cpp,distributed-database,distributed-sql,distributed-sql-database\n\nydb-platform/ydb\n\nhemansnation/God-Level-AI;god level AI A collection of scientific methods, processes, algorithms, and systems to build stories & models. An in-depth learning resource for humans. Build Your Strong Machine Learning Gen AI MLOps Portfolio/Personal Brand🚀 The‌ ‌Roadmap‌ Duration:‌ ‌(11 ‌Months)‌ ‌and many more hours for practice and project building. Phase 1 Python‌ ‌Programming‌ ‌and‌ ‌Logic‌ ‌Building‌ Data‌ ‌Structure‌ ‌&‌ ‌Algorithms‌ Git & GitHub Phase 2 It contains 7 Modules Mathematics of Machine Learning‌ Machine‌ ‌Learning‌ Concepts Data Processing X Machine Learning Models Natural‌ ‌Language‌ ‌Processing‌ Computer‌ ‌Vision‌‌ GenerativeAI ML Operations ML System Design ML Interview and Projects Phase 3 Data‌ ‌Visualization‌ ‌with‌ ‌Tableau‌ Structure‌d ‌Query‌ ‌Language‌ ‌(SQL)‌ Data Engineering Data System Design Five‌ ‌Major‌ Capstone ‌Projects‌ Interview Preparations Personal Branding and portfolio Resources Dataset Collection Technology‌ ‌Stack‌ Python‌ Data‌ ‌Structures‌ NumPy‌ Pandas‌ Matplotlib‌ Seaborn‌ Scikit-Learn‌ Statsmodels‌ Natural‌ ‌Language‌ ‌Toolkit‌ ‌(‌ ‌NLTK‌ ‌)‌ PyTorch‌ OpenCV‌ Tableau‌ Structure‌ ‌Query‌ ‌Language‌ ‌(‌ ‌SQL‌ ‌)‌ PySpark‌ Azure‌ ‌Fundamentals‌ Azure‌ ‌Data‌ ‌Factory‌ Databricks‌ 5‌ ‌Major‌ ‌Projects‌ Git‌ ‌and‌ ‌GitHub‌ ‌ 1 | Python Programming and Logic Building I will prefer Python Programming Language. Python is the best for starting your programming journey. Here is the roadmap of python for logic building. Python basics, Variables, Operators, Conditional Statements List and Strings While Loop, Nested Loops, Loop Else For Loop, Break, and Continue statements Functions, Return Statement, Recursion Dictionary, Tuple, Set File Handling, Exception Handling Object-Oriented Programming Modules and Packages In-Depth Roadmap of Python 2 | Data Structure & Algorithms Data Structures Stack Queue Linked List Tree Graph Algorithms List Searching Swapping and Sorting Recursion Hashing Strings Dynamic Programming Fundamentals 3 | Git and GitHub Part 1 - YouTube Tutorial Part 1 Understanding Git Commands and How to commit your first code? How to use GitHub? How to work with a team? How to make your first open-source contribution? Part 2 - YouTube Tutorial Part 2 How to create your stunning GitHub profile? How to build your own viral repository? Building a personal landing page for your Portfolio for FREE How to grow followers on GitHub? How to work with a team? - issues, milestones, and projects Git Notes and Resources on Notion Python supports n-dimensional arrays with Numpy. For data in 2-dimensions, Pandas is the best library for analysis. You can use other tools but tools have drag-and-drop features and have limitations. Pandas can be customized as per the need as we can code depending upon the real-life problem. Numpy Vectors, Matrix Operations on Matrix Mean, Variance, and Standard Deviation Reshaping Arrays Transpose and Determinant of Matrix Diagonal Operations, Trace Add, Subtract, Multiply, Dot, and Cross Product. Pandas Series and DataFrames Slicing, Rows, and Columns Operations on DataFrame Different ways to create DataFrame Read, Write Operations with CSV files Handling Missing values, replace values, and Regular Expression GroupBy and Concatenation Matplotlib Graph Basics Format Strings in Plots Label Parameters, Legend Bar Chart, Pie Chart, Histogram, Scatter Plot 4 | Statistics Descriptive Statistics Measure of Frequency and Central Tendency Measure of Dispersion Probability Distribution Gaussian Normal Distribution Skewness and Kurtosis Regression Analysis Continuous and Discrete Functions Goodness of Fit Normality Test ANOVA Homoscedasticity Linear and Non-Linear Relationship with Regression Inferential Statistics t-Test z-Test Hypothesis Testing Type I and Type II errors t-Test and its types One way ANOVA Two way ANOVA Chi-Square Test Implementation of continuous and categorical data 5 | Machine Learning The best way to master machine learning algorithms is to work with the Scikit-Learn framework. Scikit-Learn contains predefined algorithms and you can work with them just by generating the object of the class. These are the algorithm you must know including the types of Supervised and Unsupervised Machine Learning: Linear Regression Logistic Regression Decision Tree Gradient Descent Random Forest Ridge and Lasso Regression Naive Bayes Support Vector Machine KMeans Clustering Other Concepts and Topics for ML Measuring Accuracy Bias-Variance Trade-off Applying Regularization Elastic Net Regression Predictive Analytics Exploratory Data Analysis 6 | MLOps You can master any one of the cloud services provider from AWS, GCP and Azure. You can switch easily once you understand one of them. We will focus on AWS - Amazon Web Services first Deploy ML models using Flask Amazon Lex - Natural Language Understanding AWS Polly - Voice Analysis Amazon Transcribe - Speech to Text Amazon Textract - Extract Text Amazon Rekognition - Image Applications Amazon SageMaker - Building and deploying models Working with Deep Learning on AWS 7 | Natural Language Processing If you are interested in working with Text, you should do some of the work an NLP Engineer do and understand the working of Language models. Sentiment analysis POS Tagging, Parsing, Text preprocessing Stemming and Lemmatization Sentiment classification using Naive Bayes TF-IDF, N-gram, Machine Translation, BLEU Score Text Generation, Summarization, ROUGE Score Language Modeling, Perplexity Building a text classifier Identifying the gender 8 | Computer Vision To work on image and video analytics we can master computer vision. To work on computer vision we have to understand images. PyTorch Tensors Understanding Pretrained models like AlexNet, ImageNet, ResNet. Neural Networks Building a perceptron Building a single layer neural network Building a deep neural network Recurrent neural network for sequential data analysis Convolutional Neural Networks Understanding the ConvNet topology Convolution layers Pooling layers Image Content Analysis Operating on images using OpenCV-Python Detecting edges Histogram equalization Detecting corners Detecting SIFT feature points 9 | Data Visualization with Tableau How to use it Visual Perception What is it, How it works, Why Tableau Connecting to Data Building charts Calculations Dashboards Sharing our work Advanced Charts, Calculated Fields, Calculated Aggregations Conditional Calculation, Parameterized Calculation 10 | Structured Query Language (SQL) Fundamental to SQL syntax and Installation Creating Tables, Modifiers Inserting and Retrieving Data, SELECT INSERT UPDATE DELETE Aggregating Data using Functions, Filtering and RegEX Subqueries, retrieve data based on conditions, grouping of Data. Practice Questions JOINs Advanced SQL concepts such as transactions, views, stored procedures, and functions. Database Design principles, normalization, and ER diagrams. Practice, Practice, Practice: Practice writing SQL queries on real-world datasets, and work on projects to apply your knowledge. 11 | Data Engineering BigData What is BigData? How is BigData applied within Business? PySpark Resilient Distributed Datasets Schema Lambda Expressions Transformations Actions Data Modeling Duplicate Data Descriptive Analysis on Data Visualizations ML lib ML Packages Pipelines Streaming Packaging Spark Applications 12 | Data System Design What is system design? IP and OSI Model Domain Name System (DNS) Load Balancing Clustering Caching Availability, Scalability, Storage Databases and DBMS SQL databases NoSQL databases SQL vs NoSQL databases Database Replication Indexes Normalization and Denormalization CAP theorem System Design Interview URL Shortener Whatsapp, Twitter, Netflix, Uber 13 | Five Major Projects and Git We follow project-based learning and we will work on all the projects in parallel. 14 | Interview Preperation 16 | Personal Profile & Portfolio Resources Datasets 1️⃣ Awesome Public Datasets This list of a topic-centric public data sources in high quality. 2️⃣ NLP Datasets Alphabetical list of free/public domain datasets with text data for use in NLP. 3️⃣ Awesome Dataset Tools A curated list of awesome dataset tools. 4️⃣ Awesome time series database A curated list of time series databases. 5️⃣ Awesome-Cybersecurity-Datasets A curated list of amazingly awesome Cybersecurity datasets. 6️⃣ Awesome Robotics Datasets Robotics Dataset Collections. Research Starting Point Machine Learning Introduction to Statistical Learning Deep Learning Reinforcement Learning Projects Here is the list of project ideas Data Science ML Full Stack -> Notion Template Join the WhatsApp Community Group https://chat.whatsapp.com/BSUPbYhzzM1BcJplcTTIxb Socials Join Telegram for Data Science ML AI Resources: https://t.me/+sREuRiFssMo4YWJl Connect with me on these platforms: LinkedIn: https://www.linkedin.com/in/hemansnation/ YouTube: https://www.youtube.com/@Himanshu-Ramchandani Twitter: https://twitter.com/hemansnation GitHub: https://github.com/hemansnation Instagram: https://www.instagram.com/masterdexter.ai/ AI Jobs LinkedIn Group: https://www.linkedin.com/groups/12540639/ Medium Blog: https://medium.com/@hemansnation Notes on Data, Product, and AI - Newsletter: https://www.linkedin.com/build-relation/newsletter-follow?entityUrn=7014799989251956736 Any Query? Email Me Here: connect@himanshuramchandani.co;A collection of scientific methods, processes, algorithms, and systems to build stories & models.;python,datastructures,numpy,pandas,matplotlib,scikit-learn,machine-learning,deep-learning,pytorch,data-science\n\nhemansnation/God-Level-AI\n\nBewlyBewly/BewlyBewly;BewlyBewly English | 官话 - 简体中文 | 官話 - 正體中文 | 廣東話 BewlyBewly Just make a few small changes to your Bilibili homepage. 👋 Introduction BewlyBewly is a browser extension for BiliBili that aims to enhance the user experience by redesigning the BiliBili UI. The design is inspired by YouTube, Vision OS, and iOS, resulting in a more visually appealing and user-friendly interface. This project uses the vitesse-webext template for development. Without this template, it may not be possible to develop this project. 🔨 Build (Firefox) Please make sure you have Node.js and pnpm installed locally, and it is recommended to use Visual Studio Code for development. To build the extension, run ```bash Install dependencies pnpm install pnpm build-firefox ``` Load the generated extension-firefox/ folder in the browser, The extension will then take effect on www.bilibili.com . Chrome & Edge ⬇️ Installation Online Installation [!Caution] Even in the Edge browser, we strongly recommend you install it in the Chrome web store. In terms of review speed, the Chrome web store is faster than Edge Add-ons. Additionally, the Chrome Web Store version of BewlyBewly will address and fix critical bugs more quickly. Chrome: https://chromewebstore.google.com/detail/bewlybewly/bbbiejemhfihiooipfcjmjmbfdmobobp Edge: https://chromewebstore.google.com/detail/bewlybewly/bbbiejemhfihiooipfcjmjmbfdmobobp Firefox: https://addons.mozilla.org/en-US/firefox/addon/bewlybewly/ To Firefox users [!WARNING] When using the Firefox browser, remember to enable all permissions shown in the picture below for normal use of BewlyBewly Local Installation CI : Automatically build with the latest code Releases : Stable version Edge & Chrome (RECOMMENDED) Ensure you installed extension.zip . Opening the edge://extensions page in the Edge or chrome://extensions page in Chrome, simply drag and drop the downloaded extension.zip file into the browser to complete the installation. Another installation method for Edge & Chrome #### Edge > Ensure you installed [extension.zip](https://github.com/hakadao/BewlyBewly/releases) and decompress this file. 1. Type in `edge://extensions/` in the address bar and press Enter 2. Turn on `Developer mode` then press `Load Unpacked` 3. Load the decompressed extension folder in your browser #### Chrome > > Ensure you installed [extension.zip](https://github.com/hakadao/BewlyBewly/releases) and decompress this file. 1. Type in `chrome://extensions/` in the address bar and press Enter 2. Turn on `Developer mode` then press `Load Unpacked` 3. Load the decompressed extension folder in your browser 🤝 Contribution See CONTRIBUTION.md Contributors ❤️ Credits vitesse-webext - The template used for this project UserScripts/bilibiliHome , bilibili-app-recommend - Reference source for obtaining the access key Bilibili-Evolved - Partial implementation of functionalities bilibili-API-collect;Improve your Bilibili homepage by redesigning it, adding more features, and personalizing it to match your preferences. (English | 简体中文 | 正體中文 | 廣東話);bilibili,chrome-extension,browser-extension,dark-mode,dark-theme\n\nBewlyBewly/BewlyBewly\n\nkeploy/keploy;⚡️ API tests faster than unit tests, from user traffic ⚡️ 🌟 The must-have tool for developers in the AI-Gen era 🌟 [![Slack](https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&logo=slack&logoColor=white)](https://join.slack.com/t/keploy/shared_invite/zt-2dno1yetd-Ec3el~tTwHYIHgGI0jPe7A) [![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/company/keploy/) [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg) [![Twitter](https://img.shields.io/badge/Twitter-%231DA1F2.svg?style=for-the-badge&logo=Twitter&logoColor=white)](https://twitter.com/Keployio) Keploy is developer-centric API testing tool that creates tests along with built-in-mocks , faster than unit tests. Keploy not only records API calls, but also records database calls and replays them during testing, making it easy to use, powerful, and extensible . 🐰 Fun fact: Keploy uses itself for testing! Check out our swanky coverage badge: 🚨 Here for Unit Test Generator (ut-gen)? Keploy's new launched world's first unit test generator(ut-gen) implementation of Meta LLM research paper , it understands code semantics and generates meaningful unit tests, aiming to: Automate unit test generation (UTG) : Quickly generate comprehensive unit tests and reduce the redundant manual effort. Improve edge cases : Extend and improve the scope of tests to cover more complex scenarios that are often missed manually. Boost test coverage : As codebase grows, ensuring exhaustive coverage should become feasible. 📜 Follow Unit Test Generator README ! ✅ 📘 Documentation! Become a Keploy pro with Keploy Documentation . 🚀 Quick Installation (API test generator) Integrate Keploy by installing the agent locally. No code-changes required. shell curl --silent -O -L https://keploy.io/install.sh && source install.sh 🎬 Recording Testcases Start your app wit Keploy to convert API calls as Tests and Mocks/Stubs. zsh keploy record -c \"CMD_TO_RUN_APP\" For example, if you're using a simple Python app the CMD_TO_RUN_APP would resemble to python main.py , for Golang go run main.go , for java java -jar xyz.jar , for node npm start .. zsh keploy record -c \"python main.py\" 🧪 Running Tests Shut down the databases, redis, kafka or any other services your application uses. Keploy doesn't need those during test. zsh keploy test -c \"CMD_TO_RUN_APP\" --delay 10 ✅ Test Coverage Integration To integrate with your unit-testing library and see combine test coverage, follow this test-coverage guide . If You Had Fun: Please leave a 🌟 star on this repo! It's free, and you'll bring a smile. 😄 👏 🤔 Questions? Reach out to us. We're here to help! 🌐 Language Support From Go's gopher 🐹 to Python's snake 🐍, we support: 🫰 Keploy Adopters 🧡 So you and your organisation are using Keploy? That’s great. Please add yourselves to this list, and we'll send you goodies! 💖 We are happy and proud to have you all as part of our community! 💖 🎩 How's the Magic Happen? Keploy proxy captures and replays ALL (CRUD operations, including non-idempotent APIs) of your app's network interactions. Take a journey to How Keploy Works? to discover the tricks behind the curtain! Here are Keploy's core features: 🛠 ♻️ Combined Test Coverage: Merge your Keploy Tests with your fave testing libraries(JUnit, go-test, py-test, jest) to see a combined test coverage. 🤖 EBPF Instrumentation: Keploy uses EBPF like a secret sauce to make integration code-less, language-agnostic, and oh-so-lightweight. 🌐 CI/CD Integration: Run tests with mocks anywhere you like—locally on the CLI, in your CI pipeline (Jenkins, Github Actions..) , or even across a Kubernetes cluster. 📽️ Record-Replay Complex Flows: Keploy can record and replay complex, distributed API flows as mocks and stubs. It's like having a time machine for your tests—saving you tons of time! 🎭 Multi-Purpose Mocks: You can also use keploy Mocks, as server Tests! 👨🏻‍💻 Let's Build Together! 👩🏻‍💻 Whether you're a newbie coder or a wizard 🧙‍♀️, your perspective is golden. Take a peek at our: 📜 Contribution Guidelines ❤️ Code of Conduct 🐲 Current Limitations! Unit Testing: While Keploy is designed to run alongside unit testing frameworks (Go test, JUnit..) and can add to the overall code coverage, it still generates integration tests. Production Lands : Keploy is currently focused on generating tests for developers. These tests can be captured from any environment, but we have not tested it on high volume production environments. This would need robust deduplication to avoid too many redundant tests being captured. We do have ideas on building a robust deduplication system #27 ✨ Resources! 🤔 FAQs 🕵️‍️ Why Keploy ⚙️ Installation Guide 📖 Contribution Guide;Test generation for Developers. Generate tests and stubs for your application that actually work!;testing,test-automation,golang,productivity,api,api-testing,unit-testing,unit-testing-framework,go,testing-tools\n\nkeploy/keploy\n\nNVIDIA/warp;NVIDIA Warp Warp is a Python framework for writing high-performance simulation and graphics code. Warp takes regular Python functions and JIT compiles them to efficient kernel code that can run on the CPU or GPU. Warp is designed for spatial computing and comes with a rich set of primitives that make it easy to write programs for physics simulation, perception, robotics, and geometry processing. In addition, Warp kernels are differentiable and can be used as part of machine-learning pipelines with frameworks such as PyTorch and JAX. Please refer to the project Documentation for API and language reference and CHANGELOG.md for release history. A selection of physical simulations computed with Warp Installing Python version 3.9 or newer is recommended. Warp can run on x86-64 and ARMv8 CPUs on Windows, Linux, and macOS. GPU support requires a CUDA-capable NVIDIA GPU and driver (minimum GeForce GTX 9xx). The easiest way to install Warp is from PyPI : pip install warp-lang You can also use pip install warp-lang[extras] to install additional dependencies for running examples and USD-related features. The binaries hosted on PyPI are currently built with the CUDA 11.8 runtime. We provide binaries built with the CUDA 12.5 runtime on the GitHub Releases page. Copy the URL of the appropriate wheel file ( warp-lang-{ver}+cu12-py3-none-{platform}.whl ) and pass it to the pip install command, e.g. pip install https://github.com/NVIDIA/warp/releases/download/v1.2.0/warp_lang-1.2.0+cu12-py3-none-manylinux2014_x86_64.whl The --force-reinstall option may need to be used to overwrite a previous installation. Getting Started An example first program that computes the lengths of random 3D vectors is given below: ```python import warp as wp import numpy as np num_points = 1024 @wp.kernel def length(points: wp.array(dtype=wp.vec3), lengths: wp.array(dtype=float)): # thread index tid = wp.tid() # compute distance of each point from origin lengths[tid] = wp.length(points[tid]) allocate an array of 3d points points = wp.array(np.random.rand(num_points, 3), dtype=wp.vec3) lengths = wp.zeros(num_points, dtype=float) launch kernel wp.launch(kernel=length, dim=len(points), inputs=[points, lengths]) print(lengths) ``` Running Examples The warp/examples directory contains a number of scripts categorized under different subdirectories that show how to implement different simulation methods using the Warp API. Most examples will generate USD files containing time-sampled animations (stored in the current working directory). Before running examples, users should ensure that the usd-core , matplotlib , and pyglet packages are installed using: pip install usd-core matplotlib pyglet Examples can be run from the command-line as follows: python -m warp.examples.<example_subdir>.<example> To browse the example source code, you can open the directory where the files are located like this: python -m warp.examples.browse Most examples can be run on either the CPU or a CUDA-capable device, but a handful require a CUDA-capable device. These are marked at the top of the example script. USD files can be viewed or rendered inside NVIDIA Omniverse , Pixar's UsdView, and Blender. Note that Preview in macOS is not recommended as it has limited support for time-sampled animations. Built-in unit tests can be run from the command-line as follows: python -m warp.tests examples/core dem fluid graph capture marching cubes mesh nvdb raycast raymarch sph torch wave examples/fem apic fluid convection diffusion diffusion 3d diffusion mixed elasticity navier stokes stokes transfer stokes examples/optim bounce cloth throw diffray drone inverse kinematics spring cage trajectory walker examples/sim cartpole cloth granular granular collision sdf jacobian ik quadruped rigid chain rigid contact rigid force rigid gyroscopic rigid soft contact soft body Building For developers who want to build the library themselves, the following tools are required: Microsoft Visual Studio 2019 upwards (Windows) GCC 9.4 upwards (Linux) CUDA Toolkit 11.5 or higher Git LFS installed After cloning the repository, users should run: python build_lib.py This will generate the warp.dll / warp.so core library respectively. It will search for the CUDA Toolkit in the default install directory. This path can be overridden by setting the CUDA_PATH environment variable. Alternatively, the path to the CUDA Toolkit can be passed to the build command as --cuda_path=\"...\" . After building, the Warp package should be installed using: pip install -e . This ensures that subsequent modifications to the library will be reflected in the Python package. Learn More Please see the following resources for additional background on Warp: Product Page GTC 2022 Presentation GTC 2021 Presentation SIGGRAPH Asia 2021 Differentiable Simulation Course GTC 2024 Presentation The underlying technology in Warp has been used in a number of research projects at NVIDIA including the following publications: Accelerated Policy Learning with Parallel Differentiable Simulation - Xu, J., Makoviychuk, V., Narang, Y., Ramos, F., Matusik, W., Garg, A., & Macklin, M. (2022) DiSECt: Differentiable Simulator for Robotic Cutting - Heiden, E., Macklin, M., Narang, Y., Fox, D., Garg, A., & Ramos, F (2021) gradSim: Differentiable Simulation for System Identification and Visuomotor Control - Murthy, J. Krishna, Miles Macklin, Florian Golemo, Vikram Voleti, Linda Petrini, Martin Weiss, Breandan Considine et al. (2021) Frequently Asked Questions See the FAQ in the Warp documentation. Support Problems, questions, and feature requests can be opened on GitHub Issues . The Warp team also monitors the #warp channel on the public Omniverse Discord server, come chat to us! Versioning Versions take the format X.Y.Z, similar to Python itself : Increments in X are reserved for major reworks of the project causing disruptive incompatibility (or reaching the 1.0 milestone). Increments in Y are for regular releases with a new set of features. Increments in Z are for bug fixes. In principle there are no new features. Can be omitted if 0 or not relevant. This is similar to Semantic Versioning but less strict around backward compatibility. Like with Python, some breaking changes can be present between minor versions if well documented and gradually introduced. Note that prior to 0.11.0 this schema was not strictly adhered to. License Warp is provided under the NVIDIA Software License, please see LICENSE.md for full license text. Contributing Contributions and pull requests from the community are welcome and are taken under the terms described in the 9. Feedback section of the license . CONTRIBUTING.md provides additional information on how to open a pull request for Warp. Citing If you use Warp in your research please use the following citation: bibtex @misc{warp2022, title= {Warp: A High-performance Python Framework for GPU Simulation and Graphics}, author = {Miles Macklin}, month = {March}, year = {2022}, note= {NVIDIA GPU Technology Conference (GTC)}, howpublished = {\\url{https://github.com/nvidia/warp}} };A Python framework for high performance GPU simulation and graphics;[]\n\nNVIDIA/warp\n\nlwthiker/curl-impersonate;curl-impersonate A special build of curl that can impersonate the four major browsers: Chrome, Edge, Safari & Firefox. curl-impersonate is able to perform TLS and HTTP handshakes that are identical to that of a real browser. curl-impersonate can be used either as a command line tool, similar to the regular curl, or as a library that can be integrated instead of the regular libcurl. See Usage below. Why? When you use an HTTP client with a TLS website, it first performs a TLS handshake. The first message of that handshake is called Client Hello. The Client Hello message that most HTTP clients and libraries produce differs drastically from that of a real browser. If the server uses HTTP/2, then in addition to the TLS handshake there is also an HTTP/2 handshake where various settings are exchanged. The settings that most HTTP clients and libraries use differ as well from those of any real browsers. For these reasons, some web services use the TLS and HTTP handshakes to fingerprint which client is accessing them, and then present different content for different clients. These methods are known as TLS fingerprinting and HTTP/2 fingerprinting respectively. Their widespread use has led to the web becoming less open, less private and much more restrictive towards specific web clients With the modified curl in this repository, the TLS and HTTP handshakes look exactly like those of a real browser. How? To make this work, curl was patched significantly to resemble a browser. Specifically, The modifications that were needed to make this work: * Compiling curl with nss, the TLS library that Firefox uses, instead of OpenSSL. For the Chrome version, compiling with BoringSSL, Google's TLS library. * Modifying the way curl configures various TLS extensions and SSL options. * Adding support for new TLS extensions. * Changing the settings that curl uses for its HTTP/2 connections. * Running curl with some non-default flags, for example --ciphers , --curves and some -H headers. The resulting curl looks, from a network perspective, identical to a real browser. Read the full technical description in the blog posts: part a , part b . Supported browsers The following browsers can be impersonated. | Browser | Version | Build | OS | Target name | Wrapper script | | --- | --- | --- | --- | --- | --- | | | 99 | 99.0.4844.51 | Windows 10 | chrome99 | curl_chrome99 | | | 100 | 100.0.4896.75 | Windows 10 | chrome100 | curl_chrome100 | | | 101 | 101.0.4951.67 | Windows 10 | chrome101 | curl_chrome101 | | | 104 | 104.0.5112.81 | Windows 10 | chrome104 | curl_chrome104 | | | 107 | 107.0.5304.107 | Windows 10 | chrome107 | curl_chrome107 | | | 110 | 110.0.5481.177 | Windows 10 | chrome110 | curl_chrome110 | | | 116 | 116.0.5845.180 | Windows 10 | chrome116 | curl_chrome116 | | | 99 | 99.0.4844.73 | Android 12 | chrome99_android | curl_chrome99_android | | | 99 | 99.0.1150.30 | Windows 10 | edge99 | curl_edge99 | | | 101 | 101.0.1210.47 | Windows 10 | edge101 | curl_edge101 | | | 91 ESR | 91.6.0esr | Windows 10 | ff91esr | curl_ff91esr | | | 95 | 95.0.2 | Windows 10 | ff95 | curl_ff95 | | | 98 | 98.0 | Windows 10 | ff98 | curl_ff98 | | | 100 | 100.0 | Windows 10 | ff100 | curl_ff100 | | | 102 | 102.0 | Windows 10 | ff102 | curl_ff102 | | | 109 | 109.0 | Windows 10 | ff109 | curl_ff109 | | | 117 | 117.0.1 | Windows 10 | ff117 | curl_ff117 | | | 15.3 | 16612.4.9.1.8 | MacOS Big Sur | safari15_3 | curl_safari15_3 | | | 15.5 | 17613.2.7.1.8 | MacOS Monterey | safari15_5 | curl_safari15_5 | This list is also available in the browsers.json file. Basic usage For each supported browser there is a wrapper script that launches curl-impersonate with all the needed headers and flags. For example: curl_chrome116 https://www.wikipedia.org You can add command line flags and they will be passed on to curl. However, some flags change curl's TLS signature which may cause it to be detected. Please note that the wrapper scripts use a default set of HTTP headers. If you want to change these headers, you may want to modify the wrapper scripts to fit your own purpose. See Advanced usage for more options, including using libcurl-impersonate as a library. Documentation More documentation is available in the docs/ directory. Installation There are two versions of curl-impersonate for technical reasons. The chrome version is used to impersonate Chrome, Edge and Safari. The firefox version is used to impersonate Firefox. Pre-compiled binaries Pre-compiled binaries for Linux and macOS (Intel) are available at the GitHub releases page. Before you use them you need to install nss (Firefox's TLS library) and CA certificates: * Ubuntu - sudo apt install libnss3 nss-plugin-pem ca-certificates * Red Hat/Fedora/CentOS - yum install nss nss-pem ca-certificates * Archlinux - pacman -S nss ca-certificates * macOS - brew install nss ca-certificates Also ensure you have zlib installed on your system. zlib is almost always present, but on some minimal systems it might be missing. The pre-compiled binaries contain libcurl-impersonate and a statically compiled curl-impersonate for ease of use. The pre-compiled Linux binaries are built for Ubuntu systems. On other distributions if you have errors with certificate verification you may have to tell curl where to find the CA certificates. For example: curl_chrome116 https://www.wikipedia.org --cacert /etc/ssl/certs/ca-bundle.crt Also make sure to read Notes on Dependencies . Building from source See INSTALL.md . Docker images Docker images based on Alpine Linux and Debian with curl-impersonate compiled and ready to use are available on Docker Hub . The images contain the binary and all the wrapper scripts. Use like the following: ```bash Firefox version, Alpine Linux docker pull lwthiker/curl-impersonate:0.6-ff docker run --rm lwthiker/curl-impersonate:0.6-ff curl_ff109 https://www.wikipedia.org Chrome version, Alpine Linux docker pull lwthiker/curl-impersonate:0.6-chrome docker run --rm lwthiker/curl-impersonate:0.6-chrome curl_chrome110 https://www.wikipedia.org ``` Distro packages AUR packages are available to Archlinux users: * Pre-compiled package: curl-impersonate-bin , libcurl-impersonate-bin . * Build from source code: curl-impersonate-chrome , curl-impersonate-firefox . Unofficial Homebrew receipts for Mac (Chrome only) are available here : brew tap shakacode/brew brew install curl-impersonate Advanced usage libcurl-impersonate libcurl-impersonate.so is libcurl compiled with the same changes as the command line curl-impersonate . It has an additional API function: c CURLcode curl_easy_impersonate(struct Curl_easy *data, const char *target, int default_headers); You can call it with the target names, e.g. chrome116 , and it will internally set all the options and headers that are otherwise set by the wrapper scripts. If default_headers is set to 0, the built-in list of HTTP headers will not be set, and the user is expected to provide them instead using the regular CURLOPT_HTTPHEADER libcurl option. Calling the above function sets the following libcurl options: * CURLOPT_HTTP_VERSION * CURLOPT_SSLVERSION , CURLOPT_SSL_CIPHER_LIST , CURLOPT_SSL_EC_CURVES , CURLOPT_SSL_ENABLE_NPN , CURLOPT_SSL_ENABLE_ALPN * CURLOPT_HTTPBASEHEADER , if default_headers is non-zero (this is a non-standard HTTP option created for this project). * CURLOPT_HTTP2_PSEUDO_HEADERS_ORDER , CURLOPT_HTTP2_NO_SERVER_PUSH (non-standard HTTP/2 options created for this project). * CURLOPT_SSL_ENABLE_ALPS , CURLOPT_SSL_SIG_HASH_ALGS , CURLOPT_SSL_CERT_COMPRESSION , CURLOPT_SSL_ENABLE_TICKET (non-standard TLS options created for this project). * CURLOPT_SSL_PERMUTE_EXTENSIONS (non-standard TLS options created for this project). Note that if you call curl_easy_setopt() later with one of the above it will override the options set by curl_easy_impersonate() . Using CURL_IMPERSONATE env var If your application uses libcurl already, you can replace the existing library at runtime with LD_PRELOAD (Linux only). You can then set the CURL_IMPERSONATE env var. For example: bash LD_PRELOAD=/path/to/libcurl-impersonate.so CURL_IMPERSONATE=chrome116 my_app The CURL_IMPERSONATE env var has two effects: * curl_easy_impersonate() is called automatically for any new curl handle created by curl_easy_init() . * curl_easy_impersonate() is called automatically after any curl_easy_reset() call. This means that all the options needed for impersonation will be automatically set for any curl handle. If you need precise control over the HTTP headers, set CURL_IMPERSONATE_HEADERS=no to disable the built-in list of HTTP headers, then set them yourself with curl_easy_setopt() . For example: bash LD_PRELOAD=/path/to/libcurl-impersonate.so CURL_IMPERSONATE=chrome116 CURL_IMPERSONATE_HEADERS=no my_app Note that the LD_PRELOAD method will NOT WORK for curl itself because the curl tool overrides the TLS settings. Use the wrapper scripts instead. Notes on dependencies If you intend to copy the self-compiled artifacts to another system, or use the Pre-compiled binaries provided by the project, make sure that all the additional dependencies are met on the target system as well. In particular, see the note about the Firefox version . Contents This repository contains two main folders: * chrome - Scripts and patches for building the Chrome version of curl-impersonate . * firefox - Scripts and patches for building the Firefox version of curl-impersonate . The layout is similar for both. For example, the Firefox directory contains: * Dockerfile - Used to build curl-impersonate with all dependencies. * curl_ff91esr , curl_ff95 , curl_ff98 - Wrapper scripts that launch curl-impersonate with the correct flags. * curl-impersonate.patch - The main patch that makes curl use the same TLS extensions as Firefox. Also makes curl compile statically with libnghttp2 and libnss. Other files of interest: * tests/signatures - YAML database of known browser signatures that can be impersonated. Contributing If you'd like to help, please check out the open issues . You can open a pull request with your changes. This repository contains the build process for curl-impersonate . The actual patches to curl are maintained in a separate repository forked from the upstream curl. The changes are maintained in the impersonate-firefox and impersonate-chrome branches. Sponsors Sponsors help keep this project open and maintained. If you wish to become a sponsor, please contact me directly at: lwt at lwthiker dot com.;curl-impersonate: A special build of curl that can impersonate Chrome & Firefox;https,curl,ssl,tls,security\n\nlwthiker/curl-impersonate\n\nThreekiii/Awesome-Redteam;Awesome-Redteam 【免责声明】本项目所涉及的技术、思路和工具仅供学习，任何人不得将其用于非法用途和盈利，不得将其用于非授权渗透测试，否则后果自行承担，与本项目无关。使用本项目前请先阅读 法律法规 。 Roadmap 目录 Contents 目录 Contents 项目导航 Project Navigation 速查文档 CheatSheets 一些代码 Scripts 攻防知识 Tips 开源导航 Open-Source Navigation 编解码/加解密 Cryptography 威胁情报 Threat Intelligence 网络空间测绘 Cyberspace Search Engine 开源情报 Open-Source Intelligence 攻防相关 Offensive Security 漏洞相关 Vulnerabilities 社区/知识库 Open-Source Resources 工具集 Open-Source Toolkit 信息收集 Reconnaissance 综合工具 Nice Tools IP/域名/子域名 IP/Domain/Subdomain 指纹识别 Fingerprint 扫描/爆破 Brute Force 扫描/爆破工具 Brute Force Tools 扫描/爆破字典 Brute Force Dictionaries 字典生成 Generate a Custom Dictionary 默认口令查询 Default Credentials 社会工程学 Social Engineering 凭据泄露 Leaked Credentials 邮箱 Email 短信 SMS 钓鱼 Phishing 移动端 Mobile 漏洞研究 Vulnerability Research 漏洞复现 Reproduce PoC Proof of Concept 漏洞利用 Exploits 综合工具 Nice Tools 反序列化 Deserialization 代码审计 Code Audit 数据库 Database 信息泄露 Information Disclosure CMS/OA 中间件/应用层 Middleware/Application 渗透测试 Penertation Testing 综合工具 Nice Tools Web DNSLog Payload and Bypass 内网渗透 Red Teaming 凭证获取 Credential Access 后渗透 Post Exploitation 权限提升 Privilege Escalation 权限维持 Persistence 免杀项目 Defense Evasion 内网穿透 Proxy 辅助工具 Auxiliary Tools 域渗透 Active Directory / Kerberos 开源资源 Resources 域内信息收集 Collection and Discovery 域内已知漏洞 Known Vulnerabilities 域内渗透方式 Methodology ADCS Active Directory Certificate Services 安全防护 Defensive Security 内存马查杀 Memshell Dectect Webshell查杀 Webshell Dectect 攻击研判 Blue Teaming 基线加固 Enforcement 勒索病毒 Ransomware 开源蜜罐 Open-Source Honeypot 云安全 Cloud Security 开源资源 Resources 云安全矩阵 Cloud Matrices AK/SK Docker Kubernetes 移动端安全 Mobile Security 小程序 Mini Program APK SessionKey 逆向工程 Reverse engineering 提高生产力的辅助工具 Shell Chrome Extensions Infrastructure 提高生产力的使用姿势 如何通过.bat使用alias 如何通过.bat激活conda并运行py 如何配合tabby实现高效操作 如何解决cmd中文乱码 项目导航 Project Navigation 速查文档 CheatSheets 戳这里 Click Here DefaultCreds-Cheat-Sheet.csv Huawei-iBMC-DefaultCreds.csv Huawei-Product-Cheat-Sheet.csv WeakPassword-Cheat-Sheet.csv 安全厂商及官网链接速查.txt 一些代码 Scripts 戳这里 Click Here ShellcodeWrapper: Shellcode加密 AntivirusScanner: 杀软进程检测脚本 runtime-exec-payloads.html: java.lang.Runtime.exec() Payloads生成 Ascii2Char: ASCII码和字符互相转换脚本 修改webshell文件名密码 Weakpass_Generator: 在线弱密码生成工具 汉化版 Godzilla_Decryptor: 哥斯拉流量解密 Behinder4_Key_Bruteforce: 冰蝎4密钥爆破 Flask_Session_Decryptor: Flask session注入解密 攻防知识 Tips 戳这里 Click Here 信息收集-敏感信息收集 内网渗透-免杀 内网渗透-隐藏 内网渗透-Pentesting AD Mindmap 安全架构-网络攻击与防御图谱 平台搭建-DNS Log 流量分析-CobaltStrike 流量分析-Webshell 社会工程学-钓鱼邮件主题汇总 逆向分析-微信小程序反编译 开源导航 Open-Source Navigation 编解码/加解密 Cryptography Online: http://www.ip33.com/ https://evilcos.me/lab/xssee/ http://www.metools.info/ https://www.107000.com/ https://github.com/wangyiwy/oktools http://www.hiencode.com/ http://www.atoolbox.net/ https://www.sojson.com/ https://the-x.cn/ Offline: https://github.com/Ciphey/Ciphey https://github.com/gchq/CyberChef http://1o1o.xyz/bo_ctfcode.html https://github.com/guyoung/CaptfEncoder MD5: https://www.cmd5.org/ https://www.somd5.com/ https://www.onlinehashcrack.com/ https://crackstation.net/ https://crack.sh/ https://passwordrecovery.io/ https://md5decrypt.net/en/Sha256/ https://hashes.com/en/decrypt/hash RSA: https://www.ssleye.com/ssltool/ https://www.lddgo.net/en/encrypt/rsa work with .pem Encode/Decode: GB2312: http://code.mcdvisa.com/ Unicode: https://www.compart.com/en/unicode/ UUencode: http://web.chacuo.net/charsetuuencode Escape/Unescape: https://tool.chinaz.com/tools/escape.aspx HTML 实体编码: https://zh.rakko.tools/tools/21/ Regular Expressions: https://regex101.com/ https://github.com/VincentSit/ChinaMobilePhoneNumberRegex https://github.com/any86/any-rule 威胁情报 Threat Intelligence Virustotal: https://www.virustotal.com/ 腾讯哈勃分析系统: https://habo.qq.com/tool/index 微步在线威胁情报: https://x.threatbook.com/ 奇安信威胁情报: https://ti.qianxin.com/ 360 威胁情报: https://ti.360.net/ 网络安全威胁信息共享平台: https://share.anva.org.cn/web/publicity/listPhishing 安恒威胁情报: https://ti.dbappsecurity.com.cn/ 火线安全平台: https://www.huoxian.cn 知道创宇黑客新闻流: https://hackernews.cc/ Hacking8 安全信息流: https://i.hacking8.com/ SecWiki 安全信息流: https://www.sec-wiki.com/ 网络空间测绘 Cyberspace Search Engine Fofa: https://fofa.info/ Shodan: https://www.shodan.io/ ZoomEye: https://www.zoomeye.org/ 鹰图: https://hunter.qianxin.com/ 谛听: https://www.ditecting.com/ Quake: https://quake.360.cn/quake/ Censys: https://search.censys.io/ Netlas: https://app.netlas.io/domains/ Wayback Machine: 网页历史缓存 https://web.archive.org/ VisualPing: 网页变动监测 https://visualping.io/ Dark Web Exposure: https://www.immuniweb.com/darkweb/ SG TCP/IP 端口数据库: https://www.speedguide.net/ports.php Google Hacking Database: https://www.exploit-db.com/google-hacking-database https://github.com/cipher387/Dorks-collections-list https://cxsecurity.com/dorks/ Google Hacking Online: https://dorks.faisalahmed.me/ https://pentest-tools.com/information-gathering/google-hacking http://advangle.com/ https://0iq.me/gip/ Google Hacking Cli: https://github.com/obheda12/GitDorker https://github.com/six2dez/dorks_hunter Github Dork: https://github.com/search/advanced https://github.com/obheda12/GitDorker https://github.com/damit5/gitdorks_go 开源情报 Open-Source Intelligence OSINT Resource List: https://start.me/p/rx6Qj8/nixintel-s-osint-resource-list OSINT Framework: https://osintframework.com/ OSINT Handbook: https://i-intelligence.eu/uploads/public-documents/OSINT_Handbook_2020.pdf Public APIs: https://www.postman.com/explore/ https://rapidapi.com/ Discover secret API keys: https://serene-agnesi-57a014.netlify.app/ Source code Search Engine: https://publicwww.com/ https://searchcode.com/ 攻防相关 Offensive Security Red Teaming and Offensive Security: https://www.ired.team/ https://www.thehacker.recipes/ https://ppn.snovvcrash.rocks/ https://book.hacktricks.xyz/ https://blog.harmj0y.net/ https://hausec.com/domain-penetration-testing/ https://dirkjanm.io/ https://casvancooten.com/ https://evasions.checkpoint.com/ https://redteam.guide/docs/definitions https://github.com/HadessCS/Red-team-Interview-Questions Blue Teaming and Defensive Security: https://github.com/Purp1eW0lf/Blue-Team-Notes OPSEC: https://github.com/WesleyWong420/OPSEC-Tradecraft 漏洞相关 Vulnerabilities 国内信息披露平台: 国家信息安全漏洞库: https://www.cnnvd.org.cn/ 国家互联网应急中心: https://www.cert.org.cn/ 360 网络安全响应中心: https://cert.360.cn/ 知道创宇漏洞库: https://www.seebug.org/ 长亭漏洞库: https://stack.chaitin.com/vuldb/ 阿里云漏洞库: https://avd.aliyun.com/high-risk/list PeiQi 漏洞库: https://peiqi.wgpsec.org/ 国外信息披露平台: https://www.hackerone.com/ https://cve.mitre.org/ https://nvd.nist.gov/ https://www.rapid7.com/db/ https://packetstormsecurity.com/files/tags/exploit https://github.com/trickest/cve Exploits 搜索引擎: https://sploitus.com/ https://www.exploit-db.com/ kali 中可以配合命令 searchsploit <keywords> 使用 社区/知识库 Open-Source Resources 先知社区: https://xz.aliyun.com/ Infocon: https://infocon.org/ ffffffff0x 团队安全知识框架: https://github.com/ffffffff0x/1earn 狼组公开知识库: https://wiki.wgpsec.org/ Mitre ATT&CK: matrices: https://attack.mitre.org/matrices/enterprise techniques: http://attack.mitre.org/techniques/enterprise/ Hacking articles: https://www.hackingarticles.in/ PostSwigger blog: https://portswigger.net/blog InGuardians Labs blog: https://www.inguardians.com/ Pentest Workflow: https://pentest.mxhx.org/ Pentest cheatsheet: https://pentestbook.six2dez.com/ Programming/Toolkit/Command/OS/Shortcuts Cheatsheets: https://cheatsheets.zip/ https://learnxinyminutes.com/ 工具集 Open-Source Toolkit Nice Tools: https://forum.ywhack.com/bountytips.php?tools https://github.com/knownsec/404StarLink https://pentest-tools.com/ Beautifier： http://web.chacuo.net/formatsh https://beautifier.io/ http://jsnice.org/ Reverse Shell Generator: https://www.revshells.com/ https://forum.ywhack.com/reverse-shell/ https://tex2e.github.io/reverse-shell-generator/index.html https://github.com/0dayCTF/reverse-shell-generator File Download Generator: https://github.com/r0eXpeR/File-Download-Generator Shorten URLs: https://a.f8x.io/ 信息收集 Reconnaissance 综合工具 Nice Tools AlliN: https://github.com/P1-Team/AlliN fscan: https://github.com/shadow1ng/fscan TscanPlus: https://github.com/TideSec/TscanPlus kscan: https://github.com/lcvvvv/kscan Kunyu: https://github.com/knownsec/Kunyu OneForAll: https://github.com/shmilylty/OneForAll ShuiZe: https://github.com/0x727/ShuiZe_0x727 FofaX: https://github.com/xiecat/fofax Fofa Viewer: https://github.com/wgpsec/fofa_viewer ENScan_GO: https://github.com/wgpsec/ENScan_GO Amass: https://github.com/owasp-amass/amass IP/域名/子域名 IP/Domain/Subdomain IP 信息收集: https://www.ipuu.net/ https://site.ip138.com/ https://myip.ms/ https://ipwhois.cnnic.net.cn 多个地点 Ping 服务器: https://ping.chinaz.com/ https://www.host-tracker.com/ https://www.webpagetest.org/ https://dnscheck.pingdom.com/ IP 反查域名: https://site.ip138.com/ https://x.threatbook.cn/ https://www.virustotal.com/ Whois 信息收集: https://whois.chinaz.com/ https://whois.aliyun.com/ https://who.is/ https://www.whoxy.com/ DNS 信息收集: https://hackertarget.com/find-dns-host-records https://dnsdumpster.com https://dnsdb.io/zh-cn https://centralops.net/co/ https://viewdns.info/ https://dnsdumpster.com/ https://rapiddns.io/ ASN 信息收集: https://wq.apnic",
      "# [Make Your Day](https://www.tiktok.com/discover/bank-confirmation-letter-from-absa-bank)\n",
      "# [canvas Alternatives and Reviews](https://www.libhunt.com/r/obsidian-node-canvas)\nthanks for sharing\n\nI personally feel most graph patterns are just easier implemented using functions unless the graph has some other purpose like observability or even just visualization also those can always be added ;)\n\nI prototyped a similar system at a hackerthon last year: https://github.com/Davidiusdadi/obsidian-node-canvas\n\nYour docs would be more readable if you made the code blocks just wide enough so that the lines don't wrap.\n\nhttps://pocketflow.ai/ whitepaper link is 404ing btw.|",
      "# [Junzhou Huang](https://ranger.uta.edu/~huang/Publication.htm)\nPublication\n\n2025\n\n2020\n\n2018"
    ],
    "# Comprehensive Report on Pocketflow\n\n## Company Overview\n**Pocketflow** is a technology company focused on developing innovative frameworks and tools for artificial intelligence and machine learning applications. The company aims to simplify complex AI processes, making them more accessible to developers and researchers. Pocketflow is particularly known for its lightweight and user-friendly frameworks that facilitate the creation of AI agents with memory capabilities.\n\n## Product Overview\n**Pocketflow** is a framework designed to help developers build AI agents that can remember and recall information effectively. It is particularly useful for creating chatbots and other conversational agents that require memory functionality. The framework is lightweight, consisting of only about 100 lines of code, which makes it easy to understand and implement. \n\n### Key Features of Pocketflow:\n- **Simplicity**: Pocketflow is designed to be straightforward, allowing users to grasp the core concepts of AI memory without getting bogged down by complex code.\n- **Modular Design**: The framework is modular, enabling developers to expand its capabilities at their own pace. Users can start with basic functionalities and gradually incorporate more advanced features.\n- **Memory Management**: Pocketflow provides a structured approach to managing both short-term and long-term memory, allowing AI agents to recall past interactions and maintain context over time.\n\n## Recent Developments\n### Tutorial and Community Engagement\nA recent tutorial titled \"Build AI Agent Memory From Scratch — Tutorial For Dummies\" was published on March 24, 2025, which explains how to use Pocketflow to create AI agents with memory capabilities. The tutorial emphasizes the ease of use and the practical applications of the framework in building conversational agents [(Huang, Dev.to, 2025)](https://dev.to/zachary62/build-ai-agent-memory-from-scratch-tutorial-for-dummies-47ma).\n\n### Comparison with Competitors\nIn a recent article discussing the decline of LangChain, developers have started to favor alternatives like Pocketflow due to its reliability and user-friendliness. The article highlights that many developers find Pocketflow to be more modular and flexible compared to other frameworks, making it a preferred choice for building AI applications [(Singh, TechGig, 2025)](https://content.techgig.com/technology/why-developers-are-not-using-langchain/articleshow/118705898.cms).\n\n## Company Scale and Community Feedback\nWhile specific metrics regarding Pocketflow's employee count and revenue are not publicly available, the growing interest in the framework, as evidenced by community discussions and tutorials, suggests a positive reception among developers. The framework's simplicity and effectiveness have led to a burgeoning community of users who appreciate its straightforward approach to AI memory management.\n\n## Executive Insights\nThe leadership behind Pocketflow has a strong background in AI and software development, which informs the design and functionality of the framework. Their commitment to making AI technology accessible is reflected in the framework's design philosophy, which prioritizes ease of use and modularity.\n\n## Conclusion\nPocketflow is positioned as a valuable tool for developers looking to create AI agents with memory capabilities. Its lightweight design, ease of use, and positive community feedback make it a compelling choice in the landscape of AI frameworks. As the demand for intelligent conversational agents continues to grow, Pocketflow's innovative approach may well establish it as a leader in this niche market.\n\n### References\n- [(Huang, Dev.to, 2025)](https://dev.to/zachary62/build-ai-agent-memory-from-scratch-tutorial-for-dummies-47ma)\n- [(Singh, TechGig, 2025)](https://content.techgig.com/technology/why-developers-are-not-using-langchain/articleshow/118705898.cms)"
  ],
  "lineage": {
    "run_at": "2025-03-28T22:47:00.483009",
    "git_sha": "9e00c41"
  }
}