{
  "summary_markdown": "# About Inngest\n\nInngest is a technology company founded on January 1, 2021, that specializes in providing a serverless workflow engine designed to simplify the development of event-driven applications [(Crunchbase, 2025)](https://www.crunchbase.com/organization/inngest). The company focuses on enhancing the developer experience by allowing developers to concentrate on writing code rather than managing infrastructure, aligning with the trend towards serverless architectures and event-driven programming.\n\nInngest offers a platform that combines event streaming, queues, and durable execution into a single reliability layer for applications. This architecture aims to reduce the complexity and time required to build and maintain distributed systems and serverless applications. The company's products include:\n\n- **Inngest Platform**: A unified solution for managing application reliability, featuring flow control, durable execution, and event handling.\n- **AgentKit**: A framework for building AI agents, supporting various AI models and providing tools for orchestration.\n\nInngest operates on a B2B model, serving software teams and developers who are building complex workflows and AI applications. The company has received positive feedback from customers such as Resend, SoundCloud, Aomni, and Otto, who have highlighted the platform's impact on development efficiency and ease of use [(Inngest Company Overview, 2023)](https://www.inngest.com/).\n\nThe company has experienced significant growth, reportedly tripling its team size over the past year [(Product & Engineering blog, 2023)](https://www.inngest.com/blog). Inngest has raised a total of $10 million in funding, with notable rounds including $6 million on January 30, 2024, and $3 million on July 12, 2023 [(Crunchbase, 2025)](https://www.crunchbase.com/organization/inngest).\n\nInngest's products are distributed through a tiered pricing model, offering plans ranging from a free tier to an enterprise plan with custom pricing for critical products requiring additional scale and support [(Inngest Company Overview, 2023)](https://www.inngest.com/).\n\n# Key Personnel\n\nTony Holdstock-Brown is the co-founder and CEO of Inngest. He has emphasized the importance of simplifying the developer experience in building AI applications, highlighting the company's commitment to bridging the gap between complex AI workflows and user-friendly development tools [(Building Production Workflows for AI Applications, 2024)](https://a16z.com/podcast/building-production-workflows-for-ai-applications/).\n\n# News\n\n## Funding and Growth\n\nInngest has successfully raised $6.1 million as part of its expansion efforts for its workflow engine. This funding round was reported by multiple sources, including TechCrunch, on January 30, 2024 [(TechCrunch, 2024-01-30)](https://techcrunch.com/2024/01/30/inngest-raises-6-1m-as-it-expands-its-workflow-engine/). The company has also reportedly tripled its team size over the past year, indicating significant growth and investment in its capabilities [(Product & Engineering blog, 2023)](https://www.inngest.com/blog).\n\n## Partnerships and Product Developments\n\nInngest has formed partnerships with various companies, including Render, to enhance its service offerings and improve integration capabilities for developers [(Customer Story - Fey, 2024)](https://render.com/customers/fey). The company has also introduced technical innovations such as a sharded infrastructure to enhance performance and reliability, allowing for high-throughput operations without downtime [(Product & Engineering blog, 2024)](https://www.inngest.com/blog).\n\n## Customer Success Stories\n\nInngest has been utilized by several companies to improve their operational efficiency and reduce costs. For example, the personal finance app Fey migrated from Google Cloud Composer to Inngest, resulting in a 50x increase in data processing speed and a significant reduction in operational costs [(Customer Story - Fey, 2024)](https://render.com/customers/fey). Another customer, Otto, has successfully implemented Inngest to build and scale AI agents, demonstrating the platform's versatility in handling complex workflows and integrations [(Product & Engineering blog, 2023)](https://www.inngest.com/blog).\n\nIn conclusion, Inngest is positioned as a key player in the serverless and event-driven application landscape, with a strong focus on enhancing developer productivity through innovative workflow management solutions. The company's recent growth, successful funding rounds, and positive customer outcomes underscore its potential for continued success in the rapidly evolving tech ecosystem.",
  "target": [
    "Inngest",
    "Inngest",
    "inngest.com",
    null,
    false,
    false,
    null,
    [
      false,
      false
    ]
  ],
  "webpage_result": {
    "summary_markdown": "# Inngest Company Overview\n\n## Company History\nInngest is a modern software platform designed to streamline queuing and orchestration for software teams. It focuses on enhancing developer experience (DX) by simplifying the management of background jobs and workflows.\n\n## Services\nInngest provides a comprehensive platform that combines event streaming, queues, and durable execution into a single reliability layer for applications. This architecture is aimed at reducing the complexity and time required to build and maintain distributed systems and serverless applications.\n\n## Products\n- **Inngest Platform**: A unified solution for managing application reliability, including features like flow control, durable execution, and event handling.\n- **AgentKit**: A framework for building AI agents, allowing developers to create, test, and deploy reliable AI applications at scale. It supports various AI models and provides tools for orchestration.\n  \n## Customer Success Stories\nInngest has received positive feedback from various customers, highlighting its impact on development efficiency and ease of use:\n- **Bu Kinoshita**, Co-founder of Resend, praised the visibility and speed of development with Inngest.\n- **Matthew Drooker**, CTO of SoundCloud, emphasized the importance of focusing on code rather than infrastructure management.\n- **David Zhang**, Founder of Aomni, recommended Inngest for building multi-step AI agents due to its traceability and built-in features.\n- **Sully Omar**, Co-founder of Otto, noted the transformation in AI orchestration and scaling capabilities provided by Inngest.\n\n## Leadership Team\nWhile specific details about the leadership team were not provided, the company is led by individuals with experience in software development and AI technologies.\n\n## Culture\nInngest promotes a developer-centric culture, focusing on enhancing the developer experience through intuitive tools and streamlined processes. The company values feedback from its users, as evidenced by the testimonials from developers who appreciate the platform's capabilities.\n\n## Pricing\nInngest offers a tiered pricing model:\n- **Free Plan**: 50K runs/month, 5 concurrent steps, and basic support.\n- **Basic Plan**: Starting at $50/month for 100K runs/month and 25 concurrent steps.\n- **Pro Plan**: Starting at $350/month for 5M runs/month and 200 concurrent steps, with additional features for scaling companies.\n- **Enterprise Plan**: Custom pricing for critical products requiring additional scale and support.\n\n## Conclusion\nInngest is positioned as a valuable tool for modern software teams, particularly those working with AI and complex workflows. Its focus on developer experience, combined with robust features and positive customer feedback, makes it a compelling choice for organizations looking to enhance their application reliability and orchestration capabilities.\n\nFor more information, visit [Inngest](https://www.inngest.com/).",
    "page_markdowns": [
      "# [Queuing and orchestration for modern software teams](https://www.inngest.com/)\nDeveloper love\n\nWhat devs are saying about Inngest\n\nDon't just take our word for it, this is what developers think about Inngest.\n\nErik Munson@ erikmunson\n\nI've worked on workflow systems before and am consistently amazed with the @inngest team's ability to do them better than anyone else. it takes me a few lines of app code to do things that would've been huge projects for an entire team in past jobs, largely due to work like this\n\nTaj English@ KINGiTAJ\n\nToday @listedBApp says goodbye to Kafka and I couldn't be more excited to be replacing it with @inngest. Not every day do you get to replace a major infra component that improves DX, saves money and enables faster innovation :rocket:\n\nDavid@ dzhng\n\nFor anyone who is building multi-step AI agents (e.g AutoGPT type systems), I highly recommend building it on top of a job queue orchestration framework like @inngest, the traceability these things provide out of the box is super useful, plus you get timeouts & retries for free.\n\nJesse Thomson@ jessethomson11\n\nI think the game has changed with @inngest.\n\nTo me, it is the missing piece for making a JS/TS a serious backend contender.\n\nIt has queuing, rate limits, backoff, & everything else you named, without needing to muck around with SQS. 10/10 recommend\n\nPatrick Göler von Ravensburg@ patrick_gvr\n\nHeadache prevented by @inngest and their concurrency feature 🤯\n\nThis function potentially runs for a long time and this allows us to not run this function again when the previous function hasn't finished based on the combination specified in 'key'.\n\nJames Q Quick@ jamesqquick\n\nTried @inngest for the first time today and …WOW! I'm really excited to fit this into some of my app ideas!\n\nRay Amjad@ theramjad\n\nI love this product so much! I spent 2 days setting up some background workers on Render.com and it was a total pain in the ass. I gave up and I got my background jobs set up in under 10 minutes with Inngest.\n\nMichael Roberts@ codewithbhargav\n\nYeh so @inngest is perhaps one of the best SaaS platforms I have EVER used, incredible stability and crystal clear APIs. Love it already!\n\nBhargav@ codewithbhargav\n\n@inngest feels like a cheat code. Beautifully done!\n\nJB@ julianbenegas8\n\nok, @inngest is incredible... really clear messaging, great docs, fast and well designed dashboard, great DX, etc... highly recommend.",
      "# [Inngest](https://www.inngest.com/ai)\nLearn how Aomni built and scaled their AI research analyst to deliver deal-critical insights, analysis and automations to strategic sellers.\n\nAomni leverages Inngest's platform for orchestration of chained LLM calls, including tree of thought, chain of thought, and retrieval augmented generation (RAG).",
      "# [Customer success stories](https://www.inngest.com/customers)\n“The DX and visibility with Inngest is really incredible. We able to develop functions locally easier and faster that with our previous queue. Also, Inngest's tools give us the visibility to debug issues much quicker than before.”\n\nBu Kinoshita\n\nCo-founder - Resend\n\n“I wanted to find a solution that would let us just write the code, not manage the infrastructure around queues, concurrency, retries, error handling, prioritization... I don't think that developers should be even configuring and managing queues themselves in 2024.”\n\nMatthew Drooker\n\nCTO - SoundCloud\n\n“For anyone who is building multi-step AI agents (such as AutoGPT type systems), I highly recommend building it on top of Inngest's job queue orchestration framework, the traceability it provides out of the box is super useful, plus you get timeouts & retries for free.”\n\nDavid Zhang\n\nFounder - Aomni\n\n“Inngest completely transformed how we handle AI orchestration at Otto. Its intuitive developer experience, built-in multi-tenant concurrency, and flow control allowed us to scale without the complexity of other tools or the need to build custom solutions. What would have taken us a month.”\n\nSully Omar\n\nCo-founder - Otto",
      "# [Platform overview](https://www.inngest.com/platform)\nPlatform\n\nYour application reliability layer\n\nInngest's architecture combines an event stream, queues, and durable execution into a single reliability layer for your application. From distributed systems to serverless, Inngest is designed to help you build the complex with less headaches and in far less time.\n\nEvents\n\nFlow control\n\nDurable execution\n\nThe platform you need, built for you\n\nThe Inngest platform combines multiple components that software teams typically would have to create, combine, and maintain into a single architecture. We've combined everything that you need into a single, cohesive platform solution.\n\nEverything that Inngest replaces\n\nInngest can be run in local development or CI as a single binary. This means simpler, faster feedback loops during dev and integration testing.\n\nView the open source repo\n\nor run it now\n\n$ npx inngest-cli@latest dev",
      "# [Inngest roadmap](https://roadmap.inngest.com/roadmap)\nNew Events Stream\n\nNew events pages in Cloud and Dev Server, with better event search and filter\n\nLong-lived connections - `connect()`\n\nProvide an outbound connection from the SDK to the Dev Server and Cloud. Allowing long lived connections to handle long running jobs which can exceed HTTP request timeouts. This also allows users to run the SDK within their network without opening ports.\n\nEdge Event API\n\nDeploy the Event API to multiple regional locations to reduce latency for all events sent to Inngest\n\nSelf hosting\n\nExperimental support out now: https://www.inngest.com/docs/self-hosting. Run the open source Inngest on your own infrastructure with minimal dependencies. Postgres support coming soon.\n\nPer-step options\n\nSteps should be able to override retry policies and set their own concurrency keys\n\nMulti-region data support\n\nAllow passing in regions, eg: eu, within HTTP headers when sending events, ensuring that all data is parsed, stored, and executed within the specified region.\n\nTS SDK Data Transformers\n\nTools like superjson are common in the JS ecosystem, allowing users to maintain objects such as dates across network boundaries. The SDK can support these patterns by allowing a \"transformer\" to serialize/deserialize data passing to/from Inngest.\n\nWebhooks: requests sent\n\nAbility to see webhook requests sent to Inngest. It will help users create and test transform functions and debug webhook issues, such as mismatch of event format.\n\nLookback - Retroactive waitForEvent\n\nAdd the ability to set a timestamp in the past for waitForEvent to retroactively look backwards for an event. This is useful for race conditions and waitForEvent.\n\nWebhooks: Debugging transforms\n\nImproving the DX os webhooks to make it easier to write, test, and debug issues with webhook transforms.\n\nStep timeouts\n\nAllow configuration of step timeouts on a per-step basis, cancelling work if the timeout is reached before steps finish.\n\nPHP SDK\n\nWrite Inngest functions in PHP and serve them using your favorite frameworks like Laravel.\n\nProgrammatic triggers\n\nDefine triggers (events or crons) via an API rather than in a function definition\n\nError searching, categorization, and resolution\n\nStore function failures and allow full text search (eg. for filtering, which lets us replay specific errors). Categorize errors, eg. for function timeouts, and show smart tips to resolve.\n\nSDK: Function invocation + awaits from anywhere\n\nInvoke an Inngest function outside of the scope of a function handler and await it's result.\n\nFunction priorities\n\nExpose low, normal, and high priorities for functions. Potentially allow replays to have their own priorities (note that if a function has high priority and a replay has high priority, this will be a noop).\n\nDisable crons in Branch Environments\n\nWhen deploying crons, having them run in each branch environment can make testing more difficult and increase function calls unnecessarily. Users can still manually invoke crons in Branch Envs.\n\nDev Server webhook event forwarding\n\nEnable users to select webhooks within their Inngest Cloud account that they want to temporarily forward to a running Dev Server. Useful for testing webhook functions during local dev.\n\nFlink-style stream reducing: `step.subscribe`\n\nAdd a tool which allows for continual linear subscriptions to an event stream, eg: step.subscribe(\"event/name\", { if: \"xyz == 123\", timeout: \"10m\" }, (acc, async, ctx) => {}). This lets us listen for all events of a type within a function.\n\nRerun from failed step\n\nWhen rerunning a function, start the new run from the failed step\n\nAbility to \"continue\" sleeping functions in Dev Server UI\n\nA user testing function that use \"sleep\" or \"sleepUntil\" should be able to click a ▶️ or similar button that forces the function to continue and complete the sleep faster. This is key to testing long sleeps.\n\nLog \"skipped\" runs due to flow control\n\nLog skipped runs along side events that did not trigger function runs due to flow control configuration like rate limit, debounce, idempotentcy.\n\nFunction Singletons\n\nA flow control option to ensure that if another run will not be triggered if there is a run that is actively running with the same key.\n\nFunction run & event tags\n\nUse an SDK to add key-value tags to a given function run enabling future search and filtering.\n\nGithub Action to initialize sync in continuous deployment\n\nA pre-build Github action that will trigger an App sync via Inngest REST API. This should provide a more seamless syncing experience similar to the Vercel integration for all users.\n\nDisplay function config in dev sever\n\nClicking a function in the dev server function list should show the configuration options to the user in order to verify their config is correct (e.g. concurrency)",
      "# [Pricing](https://www.inngest.com/pricing)\nSimple pricing that scales with you\n\nFrom early-stage startups to scaling enterprises, Inngest has you covered. Get started for free today.\n\nFree\n\nGet started with modern durable execution for free, with the future to grow\n\n$0/mo\n\n50K runs/mo free\n\n5 concurrent steps\n\nFree plan includes:\n\nUnlimited branch and staging envs\n\nLogs, traces, and observability\n\nBasic alerting\n\nCommunity support\n\nFree plan includes:\n\nBasic\n\nBuild and deploy small scale reliable systems effortlessly\n\nStarting at\n\n$50/mo\n\nStarts at 100K runs/mo\n\nStarts at 25 concurrent steps\n\nEverything in Free plus:\n\n7 day trace and history retention\n\nUnlimited functions and apps\n\nNo event rate limit\n\nBasic email and ticketing support\n\nEverything in Free plus:\n\nRecommended\n\nPro\n\nProduction-ready systems with extended features for scaling companies\n\nStarting at\n\n$350/mo\n\nStarts at 5M runs/mo\n\nStarts at 200 concurrent steps\n\nIncludes everything in Basic plus:\n\n14 day trace retention\n\nGranular metrics\n\nIncreased scale and throughput\n\nHigher usage limits\n\nSOC2\n\nHIPAA as a paid addon\n\nIncludes everything in Basic plus:\n\nEnterprise\n\nFor critical products with additional scale, security, observability, latency, and support\n\nContact us\n\nFrom 0-100B runs/mo\n\nFrom 200-100K concurrent steps\n\nIncludes everything in pro plus:\n\nSAML, RBAC, and audit trails\n\nExportable observability\n\nDedicated infrastructure\n\n90 day trace retention\n\n99.99% uptime SLAs\n\nSupport SLAs\n\nDedicated slack channel\n\nIncludes everything in pro plus:\n\nPricing calculator\n\nFunction runs\n\nIncluded steps (runs x 5)\n\n750,000CALCULATED\n\nAverage steps per function\n\nEstimated step usage\n\n750,000CALCULATED\n\nMaximum concurrent steps\n\nRecommended plan: Basic\n\nEstimated cost: $55/mo.\n\nBase\n\n$ 50\n\nAdditional Runs\n\n$ 5\n\nTotal\n\n$ 55\n\nTrusted and used in production by companies across the world\n\nDeployed within 1 week\n\nRead the customer story\n\n50x faster after processing\n\nRead the customer story\n\nSolved bi-directional synchronization\n\nRead the customer story\n\nNeed help deciding which plan to choose?\n\nLet's talk",
      "# [AgentKit by Inngest](https://agentkit.inngest.com/overview)\nAgentKit is a framework to build AI Agents, from single model inference calls to multi-agent systems that use tools. Designed with orchestration at its core, AgentKit enables developers to build, test, and deploy reliable AI applications at scale.\n\nWith AgentKit, you get:\n\n✨ Simple and composable primitives to build from simple Support Agents to semi-autonomous Coding Agents.\n\n🧠 Support for OpenAI, Anthropic, Gemini and all OpenAI API compatible models.\n\n🛠️ Powerful tools building API with support for Claude’s Model Context Protocol as tools.\n\n🔌 Integrates with your favorite AI libraries and products (ex: E2B, Browserbase, Smithery).\n\n📊 Local Live traces and input/output logs when combined with the Inngest Dev Server.\n\nNew to AI Agents? Follow our Guided Tour to learn how to build your first AgentKit application.\n\nAll the above sounds familiar? Check our Getting started section or the “How AgentKit works” section to learn more about AgentKit’s architecture.\n\nGetting started\n\nHow AgentKit works\n\nThe entire system is orchestration-aware and allows for customization at runtime for dynamic, powerful AI workflows and agentic systems. Here is what a simple Network looks like in code:\n\nllms.txt\n\nYou can access the entire AgentKit docs in markdown format at agentkit.inngest.com/llms-full.txt. This is useful for passing the entire docs to an LLM, AI-enabled IDE, or similar tool to answer questions about AgentKit.",
      "# [Stoplight](https://api-docs.inngest.com/)\n",
      "# [AgentKit by Inngest](https://agentkit.inngest.com/concepts/networks)\nNetworks are Systems of Agents. Use Networks to create powerful AI workflows by combining multiple Agents.\n\nA network contains three components:\n\nThe Agents that the network can use to achieve a goal\n\nA State including past messages and a key value store, shared between Agents and the Router\n\nA Router, which chooses whether to stop or select the next agent to run in the loop\n\nHere’s a simple example:\n\nBy calling run(), the network runs a core loop to call one or more agents to find a suitable answer.\n\nHow Networks work\n\nNetworks can be thought of as while loops with memory (State) that call Agents and Tools until the Router determines that there is no more work to be done.\n\nModel configuration\n\nA Network must provide a default model which is used for routing between Agents and for Agents that don’t have one:\n\nCombination of multiple models\n\nEach Agent can specify it’s own model to use so a Network may end up using multiple models. Here is an example of a Network that defaults to use an OpenAI model, but the summaryAgent is configured to use an Anthropic model:\n\nRouting & maximum iterations\n\nRouting\n\nA Network can specify an optional defaultRouter function that will be used to determine the next Agent to run.\n\nRefer to the Router documentation for more information about how to create a custom Router.\n\nMaximum iterations\n\nA Network can specify an optional maxIter setting to limit the number of iterations.\n\nCombining maxIter and defaultRouter\n\nYou can combine maxIter and defaultRouter to create a Network that will stop after a certain number of iterations or when a condition is met.\n\nHowever, please note that the maxIter option can prevent the defaultRouter from being called (For example, if maxIter is set to 1, the defaultRouter will only be called once).\n\nProviding a default State\n\nA Network can specify an optional defaultState setting to provide a default State.",
      "# [AgentKit by Inngest](https://agentkit.inngest.com/concepts/state)\nState is shared memory, or context, that is be passed between different Agents in a Networks. State is used to store message history and build up structured data from tools.\n\nState enables agent workflows to execute in a loop and contextually make decisions. Agents continuously build upon and leverage this context to complete complex tasks.\n\nAgentKit’s State stores data in two ways:\n\nHistory of messages - A list of prompts, responses, and tool calls.\n\nFully typed state data - Typed state that allows you to build up structured data from agent calls, then implement deterministic state-based routing to easily model complex agent workflows.\n\nBoth history and state data are used automatically by the Network to store and provide context to the next Agent.\n\nHistory\n\nThe history system maintains a chronological record of all Agent interactions in your Network.\n\nEach interaction is stored as an InferenceResult. Refer to the InferenceResult reference for more information.\n\nTyped state\n\nState contains typed data that can be used to store information between Agent calls, update agent prompts, and manage routing. Networks, agents, and tools use this type in order to set data:\n\nCommon uses for data include:\n\nStoring intermediate results that other Agents might need within lifecycles\n\nStoring user preferences or context\n\nPassing data between Tools and Agents\n\nState based routing\n\nState, which is required by Networks, has many uses across various AgentKit components.\n\nRefer to the State reference for more information.",
      "# [AgentKit by Inngest](https://agentkit.inngest.com/concepts/agents)\nAgents are the core of AgentKit. Agents are stateless entities with a defined goal and an optional set of Tools that can be used to accomplish a goal.\n\nAgents can be called individually or, more powerfully, composed into a Network with multiple agents that can work together with persisted State.\n\nAt the most basic level, an Agent is a wrapper around a specific provider’s model, OpenAI gpt-4 for example, and a set of of tools.\n\nCreating an Agent\n\nTo create a simple Agent, all that you need is a name, system prompt and a model. All configuration options are detailed in the createAgent reference.\n\nHere is a simple agent created using the createAgent function:\n\nAny Agent can be called using run() with a user prompt. This performs an inference call to the model with the system prompt as the first message and the input as the user message.\n\nTools are functions that extend the capabilities of an Agent. Along with the prompt (see run()), Tools are included in calls to the language model through features like OpenAI’s “function calling” or Claude’s “tool use.”\n\nTools are defined using the createTool function and are passed to agents via the tools parameter:\n\nWhen run() is called, any step that the model decides to call is immediately executed before returning the output. Read the “How agents work” section for additional information.\n\nLearn more about Tools in this guide.\n\nHow Agents work\n\nAgents themselves are relatively simple. When you call run(), there are several steps that happen:\n\nLifecycle hooks\n\nAgent lifecycle hooks can be used to intercept and modify how an Agent works enabling dynamic control over the system:\n\nAs mentioned in the “How Agents work” section, there are a few lifecycle hooks that can be defined on the Agent’s lifecycle options object.\n\nDynamically alter prompts using Network State or the Network’s history.\n\nParse output of model after an inference call.\n\nLearn more about lifecycle hooks and how to define them in this reference.\n\nSystem prompts\n\nAn Agent’s system prompt can be defined as a string or an async callback. When Agents are part of a Network, the Network State is passed as an argument to create dynamic prompts, or instructions, based on history or the outputs of other Agents.\n\nDynamic system prompts\n\nDynamic system prompts are very useful in agentic workflows, when multiple models are called in a loop, prompts can be adjusted based on network state from other call outputs.\n\nStatic system prompts\n\nAgents may also just have static system prompts which are more useful for simpler use cases.\n\nUsing Agents in Networks\n\nAgents are the most powerful when combined into Networks. Networks include state and routers to create stateful workflows that can enable Agents to work together to accomplish larger goals.\n\nAgent descriptions"
    ],
    "search_results": [
      {
        "title": "Queuing and orchestration for modern software teams",
        "link": "https://www.inngest.com/",
        "snippet": "AI and backend workflows, orchestrated at any scale. Inngest's durable functions replace queues, state management, and scheduling to enable developers to build ...",
        "formattedUrl": "https://www.inngest.com/"
      },
      {
        "title": "AI - Inngest",
        "link": "https://www.inngest.com/ai",
        "snippet": "Inngest simplifies the orchestration of AI agents, ensuring your applications run reliably and efficiently in production. From complex agentic workflows to long ...",
        "formattedUrl": "https://www.inngest.com/ai"
      },
      {
        "title": "Customer success stories - Inngest",
        "link": "https://www.inngest.com/customers",
        "snippet": "Our customers deliver reliable products for their customers. From startups to public companies, our customers chose Inngest to power their products.",
        "formattedUrl": "https://www.inngest.com/customers"
      },
      {
        "title": "Platform overview - Inngest",
        "link": "https://www.inngest.com/platform",
        "snippet": "Your application reliability layer. Inngest's architecture combines an event stream, queues, and durable execution into a single reliability layer for your ...",
        "formattedUrl": "https://www.inngest.com/platform"
      },
      {
        "title": "Inngest roadmap",
        "link": "https://roadmap.inngest.com/roadmap",
        "snippet": "Ability to see webhook requests sent to Inngest. It will help users create and test transform functions and debug webhook issues, such as mismatch of event ...",
        "formattedUrl": "https://roadmap.inngest.com/roadmap"
      },
      {
        "title": "Pricing - Inngest",
        "link": "https://www.inngest.com/pricing",
        "snippet": "Simple pricing that scales with you. From early-stage startups to scaling enterprises, Inngest has you covered. Get started for free today.",
        "formattedUrl": "https://www.inngest.com/pricing"
      },
      {
        "title": "Patterns: Async + Event-Driven - Inngest",
        "link": "https://www.inngest.com/patterns",
        "snippet": "The common patterns listed here are flexible and powerful enough to solve problems across all types of projects and codebases.",
        "formattedUrl": "https://www.inngest.com/patterns"
      },
      {
        "title": "About Inngest - Inngest",
        "link": "https://www.inngest.com/about",
        "snippet": "Inngest is the developer platform for easily building reliable workflows with zero infrastructure. Shipping reliable background jobs and workflows are a time ...",
        "formattedUrl": "https://www.inngest.com/about"
      },
      {
        "title": "Product & Engineering blog - Inngest",
        "link": "https://www.inngest.com/blog",
        "snippet": "Introducing Inngest: an event workflow platform ... We're launching Inngest, a platform designed to make building event-driven systems fast and easy. Ready to ...",
        "formattedUrl": "https://www.inngest.com/blog"
      },
      {
        "title": "Schedule a demo - Inngest",
        "link": "https://www.inngest.com/contact",
        "snippet": "Chat with sales engineering. Explore and evaluate Inngest and learn about custom Enterprise plans and pricing.",
        "formattedUrl": "https://www.inngest.com/contact"
      },
      {
        "title": "AgentKit - AgentKit by Inngest",
        "link": "https://agentkit.inngest.com/overview",
        "snippet": "AgentKit. A TypeScript library to create and orchestrate AI Agents. AgentKit is a framework to build AI Agents, from single model inference calls to multi-agent ...",
        "formattedUrl": "https://agentkit.inngest.com/overview"
      },
      {
        "title": "Newsletter signup - Inngest",
        "link": "https://www.inngest.com/newsletter",
        "snippet": "Stay in the loop. Be the first to hear about new features, beta releases, and other important updates. Get Notified. Submit. All systems operational ...",
        "formattedUrl": "https://www.inngest.com/newsletter"
      },
      {
        "title": "Inngest Status",
        "link": "https://status.inngest.com/",
        "snippet": "Inngest ... We're not aware of any issues affecting our systems. System status. Dec 2024-Mar 2025. Event API. 99.96 % uptime. Event API. Function execution. 99.37 ...",
        "formattedUrl": "https://status.inngest.com/"
      },
      {
        "title": "Inngest | Stoplight",
        "link": "https://api-docs.inngest.com/",
        "snippet": "The API Design Management Platform powering the world's leading API first companies. Powered by Stoplight.",
        "formattedUrl": "https://api-docs.inngest.com/"
      },
      {
        "title": "Sending events - Inngest Documentation",
        "link": "https://www.inngest.com/docs/events",
        "snippet": "Now with this client, you can send events from anywhere in your app. You can send a single event, or multiple events at once.",
        "formattedUrl": "https://www.inngest.com/docs/events"
      },
      {
        "title": "Launch Week II - September 23-27, 2024 - Inngest",
        "link": "https://www.inngest.com/launch-week",
        "snippet": "Sep 27, 2024 ... Announcing self-hosting. With our 1.0 open-source self-hosting release, Inngest offers greater flexibility for developers.",
        "formattedUrl": "https://www.inngest.com/launch-week"
      },
      {
        "title": "Customer story - GitBook",
        "link": "https://www.inngest.com/customers/gitbook",
        "snippet": "GitBook's switch to Inngest significantly improved how they handle background tasks and solved their bi-directional sync challenges.",
        "formattedUrl": "https://www.inngest.com/customers/gitbook"
      },
      {
        "title": "TypeScript - Inngest Documentation",
        "link": "https://www.inngest.com/docs/typescript",
        "snippet": "The Inngest SDK leverages the full power of TypeScript, providing you with some awesome benefits when handling events.",
        "formattedUrl": "https://www.inngest.com/docs/typescript"
      },
      {
        "title": "Customer story - Fey",
        "link": "https://www.inngest.com/customers/fey",
        "snippet": "Fey is a personal finance app that that's making financial research more accessible and effortless for anyone. Built by a small team, the app uses Next.js, ...",
        "formattedUrl": "https://www.inngest.com/customers/fey"
      },
      {
        "title": "Networks - AgentKit by Inngest",
        "link": "https://agentkit.inngest.com/concepts/networks",
        "snippet": "​. How Networks work. Networks can be thought of as while loops with memory (State) that call Agents and Tools until the Router determines that there is no more ...",
        "formattedUrl": "https://agentkit.inngest.com/concepts/networks"
      },
      {
        "title": "State - AgentKit by Inngest",
        "link": "https://agentkit.inngest.com/concepts/state",
        "snippet": "State enables agent workflows to execute in a loop and contextually make decisions. Agents continuously build upon and leverage this context to complete complex ...",
        "formattedUrl": "https://agentkit.inngest.com/concepts/state"
      },
      {
        "title": "Agents - AgentKit by Inngest",
        "link": "https://agentkit.inngest.com/concepts/agents",
        "snippet": "​. How Agents work ... The initial messages are created using the system prompt, the run() user prompt, and Network State, if the agent is part of a Network. For ...",
        "formattedUrl": "https://agentkit.inngest.com/concepts/agents"
      },
      {
        "title": "Customer story - Resend",
        "link": "https://www.inngest.com/customers/resend",
        "snippet": "Resend (YC W23) is modern email sending platform that's raising the bar for developer experience. The team's early success building the popular React Email ...",
        "formattedUrl": "https://www.inngest.com/customers/resend"
      },
      {
        "title": "Introducing Branch Environments: Full-Stack Testing for Every ...",
        "link": "https://www.inngest.com/blog/branch-environments",
        "snippet": "May 17, 2023 ... Inngest will now create an environment for every branch that you deploy, allowing you to test your entire application in a fully isolated sandbox.",
        "formattedUrl": "https://www.inngest.com/blog/branch-environments"
      },
      {
        "title": "Introducing Inngest: an event workflow platform - Inngest Blog",
        "link": "https://www.inngest.com/blog/introducing-inngest",
        "snippet": "Oct 5, 2021 ... Inngest is a serverless event platform. It aggregates events from your internal and external systems, then allows you automatically run serverless code.",
        "formattedUrl": "https://www.inngest.com/blog/introducing-inngest"
      },
      {
        "title": "Throttling - Inngest Documentation",
        "link": "https://www.inngest.com/docs/guides/throttling",
        "snippet": "Throttling allows you to specify how many function runs can start within a time period. When the limit is reached, new function runs over the throttling limit ...",
        "formattedUrl": "https://www.inngest.com/docs/guides/throttling"
      },
      {
        "title": "Self-hosting - Inngest Documentation",
        "link": "https://www.inngest.com/docs/self-hosting",
        "snippet": "How to self-host Inngest. To begin self-hosting Inngest, you only need to install the Inngest CLI. The Inngest CLI is a single binary which includes all Inngest ...",
        "formattedUrl": "https://www.inngest.com/docs/self-hosting"
      },
      {
        "title": "Upgrading from Inngest SDK v2 to v3 - Inngest Documentation",
        "link": "https://www.inngest.com/docs/sdk/migration",
        "snippet": "This guide walks through migrating your code from v2 to v3 of the Inngest TS SDK. Upgrading from an earlier version? See further down the page.",
        "formattedUrl": "https://www.inngest.com/docs/sdk/migration"
      },
      {
        "title": "Durable Workflows - Inngest",
        "link": "https://www.inngest.com/uses/durable-workflows",
        "snippet": "Write complex workflows as code and let Inngest handle the rest. Inngest manages state, retries, logging and observability for you.",
        "formattedUrl": "https://www.inngest.com/uses/durable-workflows"
      },
      {
        "title": "Vercel + Inngest: The fastest way to ship background functions ...",
        "link": "https://www.inngest.com/blog/vercel-integration",
        "snippet": "Oct 24, 2022 ... Announcing our new Vercel integration.",
        "formattedUrl": "https://www.inngest.com/blog/vercel-integration"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Dan Farrelly | Inngest.com (@djfarrelly) / X](https://x.com/djfarrelly)\n\n# Job boards\n- [Go/Golang job: Infrastructure Engineer at Inngest (work from ...](https://www.golangprojects.com/golang-go-job-grx-Remote-Infrastructure-Engineer-Inngest-remotework.html)\n\n# App stores\n- No relevant app store links found.\n\n# Product reviews\n- No detailed product reviews found.\n\n# News articles (most recent first, grouped by event)\n### Funding and Company Growth\n- [Inngest helps developers build their back-end workflows, raises $3M ...](https://techcrunch.com/2023/07/12/inngest-helps-developers-build-their-backend-workflows-raises-3m/) - Jul 12, 2023\n\n### AI and Workflow Automation\n- [Building Production Workflows for AI Applications | Andreessen ...](https://a16z.com/podcast/building-production-workflows-for-ai-applications/) - Jun 14, 2024\n- [The Rise of AI Agent Infrastructure](https://www.madrona.com/the-rise-of-ai-agent-infrastructure/) - Jun 5, 2024\n\n### Product Updates and Features\n- [Show HN: Inngest 1.0 – Open-source durable workflows on every ...](https://news.ycombinator.com/item?id=41604042) - Sep 20, 2024\n- [Launch Week II - September 23-27, 2024 - Inngest](https://www.inngest.com/launch-week) - Sep 27, 2024\n\n# Key employees (grouped by employee)\n### Dan Farrelly\n- [Dan Farrelly - Inngest | LinkedIn](https://www.linkedin.com/in/djfarrelly)\n- [Dan Farrelly | Inngest.com (@djfarrelly) / X](https://x.com/djfarrelly)\n\n### Sanjana Laddha\n- [Sanjana Laddha – Product Designer – Inngest | LinkedIn](https://de.linkedin.com/in/sanjana-laddha)\n\n### Charly Poly\n- [Charly Poly - Inngest | LinkedIn](https://fr.linkedin.com/in/charly-poly)\n\n### Jack Williams\n- [Jack Williams - Inngest | LinkedIn](https://uk.linkedin.com/in/jackpwilliams)\n\n# Other pages on the company website\n- [About Inngest - Inngest](https://www.inngest.com/about)\n- [Product & Engineering blog - Inngest](https://www.inngest.com/blog)\n- [Customer success stories - Inngest](https://www.inngest.com/customers)\n- [Inngest Documentation](https://www.inngest.com/docs)\n\n# Other\n### Customer Stories\n- [Customer story - Fey](https://www.inngest.com/customers/fey) - Apr 4, 2024\n- [Customer story - GitBook](https://www.inngest.com/customers/gitbook)\n- [Customer story - Resend](https://www.inngest.com/customers/resend)\n\n### Technical Documentation\n- [Durable Workflows - Inngest](https://www.inngest.com/uses/durable-workflows)\n- [Next.js Quick Start - Inngest Documentation](https://www.inngest.com/docs/getting-started/nextjs-quick-start)",
  "crunchbase_markdown": "# Inngest, founded 2021-01-01 [(Crunchbase, 2025)](https://www.crunchbase.com/organization/inngest)\nInngest is the developer platform for easily building reliable workflows with zero infrastructure.\n\n- [Website](https://www.inngest.com)\n- [LinkedIn](https://www.linkedin.com/company/inngest-inc)\n- [Twitter](https://twitter.com/inngest)\n\n## Funding (10M USD total)\n\n- 6M USD on 2024-01-30\n- 3M USD on 2023-07-12\n- 1M USD on 2021-05-07\n\n## News\n\n- Building Production Workflows for AI Applications ([Andreessen Horowitz, 2024-07-01](https://a16z.com/podcast/building-production-workflows-for-ai-applications/))\n- Building Production Workflows for AI Applications - Building Production Workflows for AI Applications Building ... ([Andreessen Horowitz, 2024-06-15](https://a16z.com/podcast/building-production-workflows-for-ai-applications/))\n- Inngest raises $6.1M as it expands its workflow engine ([TechCrunch, 2024-01-30](https://techcrunch.com/2024/01/30/inngest-raises-6-1m-as-it-expands-its-workflow-engine/))\n- Inngest raises $6.1M as it expands its workflow engine ([TechCrunch, 2024-01-30](https://techcrunch.com/2024/01/30/inngest-raises-6-1m-as-it-expands-its-workflow-engine/))\n- Inngest raises $6.1M as it expands its workflow engine ([TechCrunch, 2024-01-30](https://techcrunch.com/2024/01/30/inngest-raises-6-1m-as-it-expands-its-workflow-engine/))\n- Inngest raises $6.1M as it expands its workflow engine ([Frederic Lardinois, 2024-01-30](https://techcrunch.com/2024/01/30/inngest-raises-6-1m-as-it-expands-its-workflow-engine/))\n- Inngest raises $6.1M as it expands its workflow engine ([TechCrunch, 2024-01-29](https://techcrunch.com/2024/01/30/inngest-raises-6-1m-as-it-expands-its-workflow-engine/))\n- Inngest raises $6.1M as it expands its workflow engine ([TechCrunch, 2024-01-29](https://techcrunch.com/2024/01/30/inngest-raises-6-1m-as-it-expands-its-workflow-engine/))\n\n",
  "customer_experience_result": {
    "output_text": "# Positive Sentiment\n\n## General Impressions\n- \"I’m using it right now and i gotta say inngest is great\" [(sidsidroc, Reddit, 2023-02-17)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8vl1ig/)\n- \"Inngest easy peasy\" [(IM_AXIS, Reddit, 2025-01-26)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m98dga2/)\n- \"Looks pretty nice. It has delayed jobs which is something I want. Will give it a look.\" [(functions-and-glory, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8sbxnl/)\n\n## Functionality and Features\n- \"With Inngest you can do Python and TypeScript: - and there’s support for calling functions across languages and codebases\" [(self-taught16, Reddit, 2025-01-27)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m9itwa5/)\n- \"I must say it's an exceptional tool. Creating extensive, persistent user journeys – waiting for certain events, performing actions, and enduring over the course of a month – would demand a significant amount of development time.\" [(yaronlevi, Reddit, 2023-11-07)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/)\n- \"In one day I was able to re-implement a workflow that had previously taken a week to implement and I was able to re-use all the types and composables and utilities I was using in the Nuxt server routes.\" [(safetywerd, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/)\n- \"The workflows were so much simpler to build - and I mean I think I ended up with 4 distinct files versus the 12 or so in Laravel for the same flow.\" [(safetywerd, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/)\n- \"Inngest truly is a unique enabler.\" [(k81afq9, Reddit, 2023-11-06)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k81afq9/)\n- \"I feel like I've gained a new superpower in your toolbox.\" [(yaronlevi, Reddit, 2023-11-06)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k81afq9/)\n- \"Inngest is amazing, each job runs up to the maximum duration limit of the Vercel plan you're on.\" [(Tall-Title4169, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka6ugk8/)\n\n# Negative Sentiment\n\n## Pricing Concerns\n- \"The pricing model that depends on usage is the most annoying ones. They only give you limited amount of usage credit per plan.\" [(pencilcheck, Reddit, 2024-07-06)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lbu5npe/)\n- \"Inngest ended up being cost prohibitive.\" [(safetywerd, Reddit, 2024-02-03)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/kopb660/)\n- \"The current pricing, which is based on the number of steps, may deter adoption of Inngest for certain use cases.\" [(yaronlevi, Reddit, 2023-11-07)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/)\n- \"I wish they used some other metric.\" [(k8egyjp, Reddit, 2023-11-08)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k8egyjp/)\n\n# Comparisons and Alternatives\n\n## Service Comparisons\n- \"Inngest or its OS alternatives.\" [(lenfakii, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka6gwpm/)\n- \"I use Inngest but it is a service and not quite open source.\" [(vivekkhera, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5f5dy/)\n- \"Use a third party service like Inngest or Upstash.\" [(None, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1m51zy/)\n- \"Inngest, trigger.dev, pipedream, the list goes on.\" [(eedren2000, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1mmve8/)\n- \"I could be wrong, but since you are running on digital ocean, you should be able to use agendajs for handle your crons as well.\" [(Intelligent-Clock987, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1n8vn1/)\n\n# Company Insights\n\n## Development Motivation\n- \"one of the reasons why we built Inngest\" [(self-taught16, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8rurou/)",
    "intermediate_steps": [
      "- \"I’m using it right now and i gotta say inngest is great\" [(sidsidroc, Reddit, 2023-02-17)](cache://reddit/38)\n- \"Inngest easy peasy\" [(IM_AXIS, Reddit, 2025-01-26)](cache://reddit/26)\n- \"With Inngest you can do Python and TypeScript: - and there’s support for calling functions across languages and codebases\" [(self-taught16, Reddit, 2025-01-27)](cache://reddit/27)\n- \"Looks pretty nice. It has delayed jobs which is something I want. Will give it a look.\" [(functions-and-glory, Reddit, 2023-02-16)](cache://reddit/37)\n- \"one of the reasons why we built Inngest\" [(self-taught16, Reddit, 2023-02-16)](cache://reddit/35)",
      "- \"I must say it's an exceptional tool. Creating extensive, persistent user journeys – waiting for certain events, performing actions, and enduring over the course of a month – would demand a significant amount of development time.\" [(yaronlevi, Reddit, 2023-11-07)](cache://reddit/74)\n- \"In one day I was able to re-implement a workflow that had previously taken a week to implement and I was able to re-use all the types and composables and utilities I was using in the Nuxt server routes.\" [(safetywerd, Reddit, 2023-10-28)](cache://reddit/101)\n- \"The workflows were so much simpler to build - and I mean I think I ended up with 4 distinct files versus the 12 or so in Laravel for the same flow.\" [(safetywerd, Reddit, 2023-10-28)](cache://reddit/101)\n- \"Inngest truly is a unique enabler.\" [(k81afq9, Reddit, 2023-11-06)](cache://reddit/123)\n- \"I feel like I've gained a new superpower in your toolbox.\" [(yaronlevi, Reddit, 2023-11-06)](cache://reddit/123)\n- \"The pricing model that depends on usage is the most annoying ones. They only give you limited amount of usage credit per plan.\" [(pencilcheck, Reddit, 2024-07-06)](cache://reddit/87)\n- \"Inngest ended up being cost prohibitive.\" [(safetywerd, Reddit, 2024-02-03)](cache://reddit/111)\n- \"The current pricing, which is based on the number of steps, may deter adoption of Inngest for certain use cases.\" [(yaronlevi, Reddit, 2023-11-07)](cache://reddit/74)\n- \"I wish they used some other metric.\" [(k8egyjp, Reddit, 2023-11-08)](cache://reddit/126)",
      "- \"Inngest is amazing, each job runs up to the maximum duration limit of the Vercel plan you're on.\" [(Tall-Title4169, Reddit, 2023-11-21)](cache://reddit/161)\n- \"Inngest or its OS alternatives.\" [(lenfakii, Reddit, 2023-11-21)](cache://reddit/160)\n- \"I use Inngest but it is a service and not quite open source.\" [(vivekkhera, Reddit, 2023-11-21)](cache://reddit/154)\n- \"Use a third party service like Inngest or Upstash.\" [(None, Reddit, 2024-04-28)](cache://reddit/202)\n- \"Inngest, trigger.dev, pipedream, the list goes on.\" [(eedren2000, Reddit, 2024-04-28)](cache://reddit/203)\n- \"I could be wrong, but since you are running on digital ocean, you should be able to use agendajs for handle your crons as well.\" [(Intelligent-Clock987, Reddit, 2024-04-28)](cache://reddit/208)"
    ],
    "url_to_review": {},
    "review_markdowns": [
      "# Post ID 17psu33: Inngest pricing model (and others like trigger.dev and more) with +36 score by [(yaronlevi, Reddit, 2023-11-07)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/)\nWe've recently begun using Inngest for a specific use case, and I must say it's an exceptional tool.\n\nCreating extensive, persistent user journeys – waiting for certain events, performing actions, and enduring over the course of a month – would demand a significant amount of development time.\n\nI also want to mention that IMHO, Inngest stands out from the multitude of services that have emerged in this space, such as Trigger.dev ([https://trigger.dev](https://trigger.dev)), Defer ([https://www.defer.run](https://www.defer.run)), Mergent ([https://mergent.co](https://mergent.co)), Zeplo ([https://zeplo.io](https://zeplo.io)), and Restate ([https://restate.dev](https://restate.dev)). The ability to wait for events is a game changer, and the DX is amazing, including local development.\n\nHowever, I'd like to bring up some considerations regarding the pricing structure. The current pricing, which is based on the number of steps, may deter adoption of Inngest for certain use cases. For instance, as mentioned earlier, in the context of B2C customer journeys. Even for a small user base, let's say 100,000 users, the costs can escalate quickly, potentially reaching tens of dollars for a single journey. And it's common to have multiple recurring journeys, each renewing every month.\n\nOn a related note, we recently selected an orchestrator for our technology stack and narrowed it down to a choice between Prefect and Dagster. We ruled out Dagster due to its pricing structure, which is based on steps. When you're building pipelines in Dagster, you aim for reliability and robustness, and you shouldn't have to think twice about adding new steps to your pipeline. However, their pricing model encourages the opposite, with costs increasing as you use more steps.In contrast, Prefect's pricing model is based on seats and environments. You pay a fixed amount per seat and per environment. For example, it might cost $39 per user and $300 per environment (with one environment included for free). This pricing model allows you to build robust pipelines without constraints and use as many @Flow and @Task annotations as needed.\n\nComparing Prefect and Inngest, it's apparent that they operate in a similar manner, with orchestration and state management in the cloud, and the orchestrator invoking your backend when required.\n\nWhen discussing the price per seat instead of the price per 'event,' there's another excellent example in Castled ([https://www.castled.io](https://www.castled.io/)), a CDP that operates on Snowflake. With Castled, you can define user journeys without being constrained by steps or actions. While it employs a completely different execution model compared to Inngest, the end result, a B2C customer journey, could be quite similar.\n\nI may be mistaken here, as Inngest's 'backend economics' may differ significantly from Prefect's. Nevertheless, I believe it's worth discussing this topic.\n\nAnother potential scenario could be that, as we continue using Inngest for an increasing number of use cases, the pricing becomes prohibitive. In that case, we might consider switching to a self-hosted version. This would be suboptimal for both parties: Inngest loses a customer, and we have to allocate resources to infrastructure, which isn't our core business.\n\nI sense that there might be a missed opportunity here – a fantastic service hindered by a pricing model that limits its adoption.\n\nWould love to hear your thoughts on this.\n\n## Comment ID k8l8rnc with +3 score by [(Meander333, Reddit, 2023-11-10)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/k8l8rnc/) (in reply to ID 17psu33):\nI've created a workflow system for myself using inngest and xstate.  Due to the pricing structure i've actually only use steps when i need idempotency or other features.  Otherwise the state is persisted in a cache after every state transition and then continues executing in the same function call.  \n\n\nif the function called again for the same runId, due to the restoration of the persisted state it continues where it left off.  \n\n\ni had to use the gymnastics due to the pricing model\n\n### Comment ID k8xqvgg with +1 score by [(yaronlevi, Reddit, 2023-11-12)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/k8xqvgg/) (in reply to ID k8l8rnc):\nInteresting. Xstate is in-memory javascript framework, so you had to persist the data in a DB?\n\n#### Comment ID k90yoan with +2 score by [(Meander333, Reddit, 2023-11-13)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/k90yoan/) (in reply to ID k8xqvgg):\nYeah i use cf kv or D1 for persistance\n\n### Comment ID lni8q57 with +1 score by [(kemon9, Reddit, 2024-09-17)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lni8q57/) (in reply to ID k8l8rnc):\nCurious why the need for X-state as well? Performance?\n\n## Comment ID kcx7r1v with +3 score by [(praveendath92, Reddit, 2023-12-11)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/kcx7r1v/) (in reply to ID 17psu33):\nTrigger doesn't charge per step but rather per job invocation - this doesn't force you to make suboptimal code design\n\n### Comment ID lbu5npe with +2 score by [(pencilcheck, Reddit, 2024-07-06)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lbu5npe/) (in reply to ID kcx7r1v):\nthis kinda pricing model that depends on usage is the most annoying ones. they only give you limited amount of usage credit per plan.\n\n### Comment ID lr2hvv5 with +1 score by [(Slight_Air_8635, Reddit, 2024-10-09)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lr2hvv5/) (in reply to ID kcx7r1v):\n[Trigger.dev](http://Trigger.dev) doesn't have steps\n\n#### Comment ID lr2i3lq with +1 score by [(Slight_Air_8635, Reddit, 2024-10-09)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lr2i3lq/) (in reply to ID lr2hvv5):\nsorry, it seems they have retry on throw. It is similar to inngest steps. [https://trigger.dev/docs/errors-retrying#retry-onthrow](https://trigger.dev/docs/errors-retrying#retry-onthrow)\n\n## Comment ID ke9zdfe with +2 score by [(rubenfiszel, Reddit, 2023-12-21)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/ke9zdfe/) (in reply to ID 17psu33):\nYou should give https://windmill.dev a try and get everything for free by self-hosting it\n\n### Comment ID kxvof3n with +1 score by [(None, Reddit, 2024-04-03)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/kxvof3n/) (in reply to ID ke9zdfe):\nThx! I didn't know this project it's really interesting.\n\n#### Comment ID lbu58z2 with +1 score by [(pencilcheck, Reddit, 2024-07-06)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lbu58z2/) (in reply to ID kxvof3n):\nWhat do you think? Windmill or Inngest?\n\n## Comment ID lmifa0j with +1 score by [(enesakar, Reddit, 2024-09-10)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lmifa0j/) (in reply to ID 17psu33):\nyou can try upstash workflow. it is $1 100k invocation. event support is coming soon.  \n[https://upstash.com/docs/qstash/workflow/getstarted](https://upstash.com/docs/qstash/workflow/getstarted)\n\n### Comment ID m3uqwc4 with +1 score by [(tonyabracadabra, Reddit, 2024-12-26)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/m3uqwc4/) (in reply to ID lmifa0j):\nIs it supported now?\n\n## Comment ID lr31krc with +1 score by [(self-taught16, Reddit, 2024-10-09)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lr31krc/) (in reply to ID 17psu33):\nInngest recently updated their pricing to charge by function run (job) instead of step: https://www.inngest.com/pricing\n\n### Comment ID lu934x4 with +1 score by [(marbemac, Reddit, 2024-10-28)](https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/lu934x4/) (in reply to ID lr31krc):\nSeems they still charge by step.. just now scaling on both jobs AND steps (scroll down to the plan feature matrix to see what I mean).",
      "# Post ID 17i8f6y: I wish I had known about Inngest earlier with +42 score by [(safetywerd, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/)\n*I want to be clear I don't work for inngest, I'm just a new and very enthusiastic customer.*\n\nI've been working on a large Nuxt app for the last 7 months (about 250 server routes, 400 components).  The one missing piece that prevented us from using Nuxt 100% for the entire app was the lack of a job queue/workflow system.  We decided to use Laravel for that because Laravel's job queues are really good and really flexible.  We knew about [https://temporal.io](https://temporal.io) but we found the DX to be no where near as good as Laravel for what we needed.\n\nThe problem with using Laravel though is that for every feature we build in Nuxt, we end up replicating some of it in Laravel.  The context switching wasn't bad at first but has grown very tiresome the longer we've gone into the project.  One example is that we have a pretty complicated redis based caching layer for Nuxt.  The caching layer allows you to define a cache for a specific class of data and then any other caching dependencies that might trigger an invalidation.  For example, when a user posts a new post we need to invalidate their cached profile because of updated statistics, invalidate the cache of their existing posts, invalidate any searches that could possibly contain their posts in the results, etc.  So any bugs we fix in the nuxt version we have to verify and fix in the Laravel version.\n\nWe looked at other node based job queues like bullmq and the like, but they don't do half of what Laravel does and the \"pro\" versions cost money. Which would be fine if they did everything Laravel does.\n\nSo we started working on our last major feature before we launch and I'm dreading having to implement the Laravel side of things.  Basically the feature allows other users to collaborate with other users to create custom content.  They send a request, the other users decides how much its going to cost, the requesting user makes a deposit or pays the full amount into escrow and then the creative process kicks off with some back and forth collaboration.  When the piece is finally done, it's delivered, the escrow gets transferred, everyone is happy.  It's a pretty complicated feature with a lot of moving parts and a lot of possible states and a lot of possible outcomes.  Did I mention I'm really dreading implementing that workflow in Laravel?\n\nAnd then I ran across [https://inngest.com](https://inngest.com) and at first thought this was going to be another Temporal clone.  But as I was reading the docs it quickly became apparent that it wasn't.  So I took a day and decided to re-implement that Laravel job queue workflow using Inngest to see how it went.  And holy shit ...\n\nI've been building websites for 25 years now and this is the first time in quite awhile were I can say I was literally **delighted**.  Like it felt like I was watching a magic trick that's so good you believe magic is real.  In one day I was able to re-implement a workflow that had previously taken a week to implement and I was able to re-use all the types and composables and utilities I was using in the Nuxt server routes.  The workflows were *so much* simpler to build - and I mean I think I ended up with 4 distinct files versus the 12 or so in Laravel for the same flow.\n\nNow granted I had implemented it all once already in Laravel so I saved some time there.  But writing future features that use this will allow me to re-use quite a bit from before and the workflows are still considerably less code than Laravel.  And once you grok how inngest works, it's such a natural way to reason about workflows.\n\nSome of you might be wondering wtf I'm talking about, so here's an example of how awesome this is.  Let's say you have this workflow when a new user signs up:\n\n* User signs up\n   * Send a validation email\n      * Wait for a day for them to validate their account.\n* User validates their account\n   * Send welcome mail\n   * Wait 1 week and send a tips and tricks email\n   * Wait 1 month and send a link to a survey\n\nIn Laravel, I'd have to do the following:\n\n* When the user signs up, have Nuxt ping the Laravel API\n* Laravel sends the validation email\n* Write a command line command that gets called every day to pull any new user accounts that haven't validated and send them a reminder email.  Create a table in the database to track if a user has been sent a specific email.\n* When the user validates, have Nuxt ping the Laravel API\n* Laravel sends the reminder email\n* Write a command line command that runs daily to send welcome emails to newly validated users.\n* Write a command line command that runs daily to send a survey to validated user accounts that have been validated for over a month.\n\nNow with inngest,  I have to write two functions that handle the two events 'user signs up' and 'user validates account'.  They look exactly like this:\n\n    import { inngest } from \"~/server/inngest/client\";\n    \n    export default inngest.createFunction(\n      { id: \"user-sign-up\", name: \"User Signed Up\" },\n      { event: \"users/account.created\" },\n      async ({ event, step, runId, logger }) => {\n        await step.run('send-validation-email', async () => {\n          sendValidationEmail();\n        });\n        \n        const validated = await step.waitForEvent('wait-for-validation', {\n           event: 'users/account.validated',\n           timeout: '1d',\n           match: 'data.userId'\n        });\n    \n        if (!validated) {\n          await step.run('send-reminder-email', async () => {\n            sendReminderEmail();\n          });\n        }\n      }\n    );\n\nand:\n\n    import { inngest } from \"~/server/inngest/client\";\n    \n    export default inngest.createFunction(\n      { id: \"user-validated\", name: \"User Signed Up\" },\n      { event: \"users/account.validated\" },\n      async ({ event, step, runId, logger }) => {\n        await step.run('send-welcome-email', async () => {\n          sendWelcomeEmail();\n        });\n    \n        await step.sleep(\"wait-a-days\", \"1d\");\n        await step.run('send-tips-trick-email', async () => {\n          sendTipsAndTricks();\n        });\n        \n        await step.sleep(\"wait-a-month\", \"1m\");\n        await step.run('send-survey', async () => {\n          sendSurvey();\n        });\n      }\n    );\n\nThat's it, that's all there is.  These functions deploy with your Nuxt app, no extra steps needed.  You trigger them by:\n\n    import { inngest } from \"~/server/inngest/client\";\n    \n    await inngest.send({ name: 'user/account.validated', data: {}});\n\nI really feel like inngest is the missing piece for Nuxt if you are doing front to back apps with it.\n\nAnyways, I hope this helps someone.  I wish I had known about it 7 months ago :)\n\n[https://inngest.com/](https://inngest.com/)\n\n## Comment ID k6sndfy with +7 score by [(cderm, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k6sndfy/) (in reply to ID 17i8f6y):\nThanks for sharing, this might help me with some user flows I’m trying to build too for my app. Don’t you just love when you start using something and have that “holy shit this is amazing” moment 😂\n\n## Comment ID k6sxro2 with +3 score by [(SpaceManaRitual, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k6sxro2/) (in reply to ID 17i8f6y):\nWish there was a self hosted version …\n\n### Comment ID k6symjj with +5 score by [(safetywerd, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k6symjj/) (in reply to ID k6sxro2):\nthey are working on it apparently\n\n#### Comment ID lelwdyk with +1 score by [(Prudent_Ad1036, Reddit, 2024-07-23)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/lelwdyk/) (in reply to ID k6symjj):\nTo date not self-hostable yet :(\n\n## Comment ID k7wd14a with +2 score by [(mjJRnFnRYYiu, Reddit, 2023-11-05)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k7wd14a/) (in reply to ID 17i8f6y):\nThanks for sharing! Very helpful\n\n## Comment ID kopauy1 with +2 score by [(brucew11, Reddit, 2024-02-03)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/kopauy1/) (in reply to ID 17i8f6y):\nYes, Inngest is so incredible. I've worked at places where we had multiple teams owning queuing workflow infrastructure for our company that wasn't half as good as Inngest. It opens up so many use cases for small teams where the complexity was previously cost prohibitive.\n\n### Comment ID kopb660 with +1 score by [(safetywerd, Reddit, 2024-02-03)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/kopb660/) (in reply to ID kopauy1):\nWe actually ended up replacing Inngest with [https://slayq-docs.vercel.app](https://slayq-docs.vercel.app)\n\nMostly inngest compatible jobs (multiple steps, sleep, invoke, etc).\n\nInngest ended up being cost prohibitive.\n\n#### Comment ID kx6a885 with +1 score by [(satoshiMotoMoto, Reddit, 2024-03-29)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/kx6a885/) (in reply to ID kopb660):\nare you still using SlayQ? The website is up but I can't find the repo or user on github. Online searches give me nothing 😭  \n\n\nEdit:   \nTLDR: the new location is https://github.com/jawngee/slay-q/\n\nThis lead me down a rabbit hole. \n\nThe only reference to SlayQ other than this reddit comment was this [hackernews post](https://news.ycombinator.com/item?id=39315833). I tracked down the user jawngee to his github profile, where he had a public fork of the now-public /slay-utils folder.\n\nFrom what I can tell, his name is Jon Gilkison, a seasoned engineer. It's unclear whether he's still working on [Slay Pics](https://slay.pics) (NSFW), which seems to be an onlyfans competitor. Unsure whether the company decided to shut down, or he quit.\n\nSo glad that I could find the code.\n\n#### Comment ID kopdmhy with +1 score by [(brucew11, Reddit, 2024-02-03)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/kopdmhy/) (in reply to ID kopb660):\nIt's interesting to me how it's super cost prohibitive for some people, but not a problem for others. I'm curious what scale you are operating at?\n\n## Comment ID lelxa0n with +1 score by [(Prudent_Ad1036, Reddit, 2024-07-23)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/lelxa0n/) (in reply to ID 17i8f6y):\nI'm looking at temporal now. What didn't you like about the DX?\n\n## Comment ID lq3xgzz with +1 score by [(Slight_Air_8635, Reddit, 2024-10-03)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/lq3xgzz/) (in reply to ID 17i8f6y):\nThis is exactly what i needed. I really liked temporal io suspend feature, I didn't know inngest has the same featurs. I really low the dx of inngest.\n\n## Comment ID k6v5o7s with +1 score by [(Lumethys, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k6v5o7s/) (in reply to ID 17i8f6y):\nWhile my favorite backend framework is Laravel, I wouldn't use it only as a queue when i *already* had a backend built on a different framework, let alone language.\n\n### Comment ID k6v8vh3 with +2 score by [(safetywerd, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k6v8vh3/) (in reply to ID k6v5o7s):\nNonsense.\n\nQueue isn't a backend, it's a service.  The laravel queue only did queue things.  I would never use Laravel for anything else.  I don't view it any differently than the other stuff we use like Amazon Batch and our custom Go media processing pipeline.\n\nThere is almost zero choice for a durable, configurable queue that scales horizontally like Laravel for NodeJS let alone Nuxt.  All of the big ones, bullMQ and friends, were missing some of the options that Laravel provides for things like job batching. BullMQ pro edition is $139 a month to get close to feature parity with Laravel. \n\nOr you use something like Temporal where the DX is not great.\n\nAnd like the title of the post says, if I had known about inngest 7 months ago I would have never fucked with Laravel for this piece of the pie to begin with.  But Laravel still remains the second best option.\n\n#### Comment ID k6vf8r4 with +1 score by [(Lumethys, Reddit, 2023-10-28)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k6vf8r4/) (in reply to ID k6v8vh3):\n>Queue isnt a backend, it is a service\n\nThen why are you re-implement your *business logic* at Laravel side? What kind of external service would require to re-implement business logic?\n\nQueue *can be* used solely as an external service, but *your particular use* doesnt, does it?\n\n&#x200B;\n\nBut anyway, if you have to re-implement business logic in a different language (note it is different than a microservice architecture where each \"node\" of the system is completely isolated), then it is by no means a good solution.\n\nMy 2 cents is that whole re-implementing-business-logic-in-another-language-and-manually-syncing-them is not worth it compared to some missing features (that may or may not be used)  or worse DX\n\n## Comment ID k81afq9 with +1 score by [(yaronlevi, Reddit, 2023-11-06)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k81afq9/) (in reply to ID 17i8f6y):\nu/safetywerd Today I experienced exactly what you've mentioned. The Inngest event model and the overall DX are really something special. I completely agree that after playing with it for a couple of hours, you feel like you've gained a new superpower in your toolbox.\n\nHowever, I think we are stuck on pricing. Let me explain:\n\nWe have a fairly simple use case for a feature called \"sleep reminder\" in our mobile app. When activated, the user receives two push notifications, one in the morning (9 am) and one in the evening (8 pm). Both notifications are sent at the user's specific timezone.\n\nCurrently, this is implemented using a CRON job that wakes up every hour (using Prefect) to query all the users who have enabled the feature and for whom the current time is either 9 am or 8 pm in their timezone.\n\nI've implemented this in Inngest. It was quite small, just a couple of lines of JavaScript. It's a very clean and contained solution that I can understand from a single function. Instead of waking up every hour unnecessarily, each user has their own \"thread\" and calls step.waitFor() with their exact relevant timestamp in their timezone.\n\nThis process continues until the user turns off the feature. In terms of pricing, we're talking about 2 steps per day (morning and evening) \\* 30 days, which equals 60 steps per user per month. We have approximately 100,000 users who have turned on the feature, so we're looking at 6,000,000 steps per month for this feature.\n\nWe have many other features similar to the \"sleep reminder,\" and some are even more complex with more steps.\n\nLooking at Inngest's \"Startup\" plan, I'll set aside the included 5 million steps, as that will be quickly depleted. So we're left with $5 for an additional 200,000 steps. With these numbers, the \"sleep reminder\" would cost $150 each month.\n\nThis is a significant monthly expense for such a small feature. I say it's small because it's not a \"core\" feature. By that, I mean it's not something like an \"Uber-like\" app where the main \"hail a cab\" flow is critical to the business and generates the primary revenue. Nevertheless, the \"sleep reminder\" feature and other \"small,\" time-sensitive workflows are used by many of our users and create substantial value for us.\n\nNow that it's so easy to describe and execute these flows with Inngest, the product team will have an eye-opening 'aha' moment and will provide these for the development team to implement. We can really get creative with the complexity and variety, which is amazing. Inngest truly is a unique enabler.\n\nBut at a price of $150 just for the simplest \"2-step per day\" feature, it makes it hard for us to adopt.\n\nAm I missing something here? I'd love to be corrected on this.\n\n### Comment ID k81mwfc with +1 score by [(safetywerd, Reddit, 2023-11-06)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k81mwfc/) (in reply to ID k81afq9):\nThe pricing is a bit much, I agree.  In your case, in particular, that's tough.  They are setting up to release the self-hostable version though.  \n\nFor us, it's replacing 4 servers (5 including the QA one) that we use to run jobs.  Plus we no longer need to spend hours maintaining those servers so it kind of evens out for us.\n\n#### Comment ID k81siad with +1 score by [(yaronlevi, Reddit, 2023-11-06)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k81siad/) (in reply to ID k81mwfc):\nAnd using something Prefect (the cloud version) wouldn't work for your CRON use case?\n\n### Comment ID k8egyjp with +1 score by [(Meander333, Reddit, 2023-11-08)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k8egyjp/) (in reply to ID k81afq9):\nThe pricing metic of steps isn't a good one. I wish they used some other metric.\n\n#### Comment ID k8h6mol with +1 score by [(yaronlevi, Reddit, 2023-11-09)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/k8h6mol/) (in reply to ID k8egyjp):\nYou can take a look at this post. I've talked exactly about this:\n\nhttps://www.reddit.com/r/node/comments/17psu33/inngest\\_pricing\\_model\\_and\\_others\\_like\\_triggerdev/\n\n### Comment ID kso9vy6 with +1 score by [(Adventurous-Action66, Reddit, 2024-02-29)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/kso9vy6/) (in reply to ID k81afq9):\nI would use:\n\n1) scheduled local notification on-device for this (free)\n\n  \nor\n\n  \n2) selecting 100,000 records with \"enabled=true AND timezone=$1' is such a cheap query on any modern database, that I would rather just run it once an hour and send notification to selected users.\n\n#### Comment ID kv2t5f7 with +1 score by [(FormerKarmaKing, Reddit, 2024-03-16)](https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/kv2t5f7/) (in reply to ID kso9vy6):\nAgreed. On top of a workflow engine being overkill for an alarm, as a user I don't see why I would want to rely on a network connection for an alarm.",
      "# Post ID 1hl6wao: How Do You Handle Real-Time Client Updates with Inngest? with +2 score by [(Top_Main_6200, Reddit, 2024-12-24)](https://www.reddit.com/r/nextjs/comments/1hl6wao/how_do_you_handle_realtime_client_updates_with/)\nHi everyone! 👋\n\nI'm exploring **Inngest** for managing workflows in my app, and I have a question about handling real-time client updates. Specifically, when a task or workflow step is completed, how do you notify all connected clients (frontend) in real time?\n\nThanks\n\n## Comment ID m3k62j1 with +2 score by [(Null_Execption, Reddit, 2024-12-24)](https://www.reddit.com/r/nextjs/comments/1hl6wao/how_do_you_handle_realtime_client_updates_with/m3k62j1/) (in reply to ID 1hl6wao):\n[trigger.dev](http://trigger.dev) has that feature\n\n## Comment ID m3k0owi with +1 score by [(eggucated, Reddit, 2024-12-24)](https://www.reddit.com/r/nextjs/comments/1hl6wao/how_do_you_handle_realtime_client_updates_with/m3k0owi/) (in reply to ID 1hl6wao):\nInterested in others experiences with inngest as well\n\n## Comment ID m3kxj9v with +1 score by [(___Nazgul, Reddit, 2024-12-24)](https://www.reddit.com/r/nextjs/comments/1hl6wao/how_do_you_handle_realtime_client_updates_with/m3kxj9v/) (in reply to ID 1hl6wao):\nI believe with inngest gotta do your own backend for this\n\n## Comment ID m50brvv with +1 score by [(Rough_Grapefruit1900, Reddit, 2025-01-02)](https://www.reddit.com/r/nextjs/comments/1hl6wao/how_do_you_handle_realtime_client_updates_with/m50brvv/) (in reply to ID 1hl6wao):\nalso interested",
      "# Post ID 1134125: What is NextJS missing from being a truly full stack framework? with +32 score by [(skibideeboo, Reddit, 2023-02-15)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/)\nI’ve used Ruby on Rails in the past and loved the power of it but have since grown to prefer Next.JS. \n\nI was wondering if paired with Next Auth what is a full stack framework able to do that next can’t ? I know we’re now soon to get CRON jobs as well so that’s great. \n\nAlso would a good side project stack be to use a Node.JS server for anything that can’t be done?\n\n## Comment ID j8nxjoj with +55 score by [(functions-and-glory, Reddit, 2023-02-15)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8nxjoj/) (in reply to ID 1134125):\nSome sort queue system and some sort of websocket/realtime system.\n\n### Comment ID j8rurou with +1 score by [(self-taught16, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8rurou/) (in reply to ID j8nxjoj):\nAgreed - one of the reasons why we built Inngest: https://www.inngest.com/ - Next and similar frameworks are focused on the front end and synchronous API endpoints, there needs to be something in the JAM stack space that takes care of background jobs and durable functions\n\n#### Comment ID j8sbxnl with +3 score by [(functions-and-glory, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8sbxnl/) (in reply to ID j8rurou):\nLooks pretty nice. It has delayed jobs which is something I want. Will give it a look.\n\n#### Comment ID j8vl1ig with +2 score by [(sidsidroc, Reddit, 2023-02-17)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8vl1ig/) (in reply to ID j8rurou):\nI’m using it right now and i gotta say inngest is great\n\n## Comment ID j8pxmd5 with +12 score by [(JoyousTourist, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8pxmd5/) (in reply to ID 1134125):\nA lot.\n\n* Background jobs\n* CLI or some admin interface\n* Middleware system that actually allows req modification and doesn’t involve wrapping each route by hand \n* An ORM\n* Caching layer\n* web socket / sse support\n\nAll of these except the middleware issue are solvable with other services, just feels like rebuilding the wheel.\n\n### Comment ID j8pybdg with +8 score by [(_hypnoCode, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8pybdg/) (in reply to ID j8pxmd5):\n>* Middleware system that actually allows req modification and doesn’t involve wrapping each route by hand \n\n\nThis is not true at all. It supports slugs and regex. If you want to wrap everything then use a `/(.*)` regex.\n\nhttps://nextjs.org/docs/advanced-features/middleware#matcher\n\n>* Caching layer\n\nBuilt in since the first day I started using it.\n\n#### Comment ID j8qtguh with +2 score by [(ZeRo2160, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8qtguh/) (in reply to ID j8pybdg):\nYou are right. But you can't modify the req object like you do with express for example. Changes to it don't reflect to your api route. Except there is already something new i don't know. If yes i am happy to hear from you. I am searching for this. :)\n\n#### Comment ID j979ahb with +1 score by [(JoyousTourist, Reddit, 2023-02-19)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j979ahb/) (in reply to ID j8pybdg):\nYes, I said _req_ modification just like any other middleware system out there - like Express, Koa, etc.\n\nNext.js's official middleware doesn't support modifying the _req_, only the _res_.\n\nSo while there's a nice manifest for defining middleware application against groups of routes (nice), however it misses the point of being able to modify the _req_ so you can inject databases, the currently authenticated user, etc.\n\nSo close, but not what I'm talking about.\n\n## Comment ID j8pswag with +7 score by [(MisterJimson, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8pswag/) (in reply to ID 1134125):\nCron is a Vercel feature coming, not NextJS. \n\nMatters if you host elsewhere.\n\n## Comment ID j8ofthh with +12 score by [(src_main_java_wtf, Reddit, 2023-02-15)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8ofthh/) (in reply to ID 1134125):\nThere was a pretty good HN comment about the shortcomings that nextjs:\n\n[https://news.ycombinator.com/item?id=27186870](https://news.ycombinator.com/item?id=27186870)\n\n>We rewrote the thing in 1/4 the time with Rails + sorcery + Tailwind + delayed\\_job + a few other smaller gems. Just a bunch of models and some \"services\" (plain ruby objects), hotwire for the \"spa feel\" and stimulus for things such as date pickers, modals, etc.\n\nThat being said, nextjs allows you to not have to worry about SSL certs, deployment related tasks, etc especially if you use vercel.\n\nSo when it comes to launching a UI or some static marketing pages, the combo of nextjs / vercel is pretty much unbeatable in terms of productivity (defined as spending time on business problems vs tech boilerplate problems).\n\nBut when comes to creating apps (re-creating airbnb, for example), other full stack frameworks (RoR, Django, etc) offer more solutions that are better integrated to solving app problems.\n\nOf course it goes without saying, neither approach is right or wrong, but there are tradeoffs.\n\n&#x200B;\n\n>Also would a good side project stack be to use a Node.JS server for anything that can’t be done?\n\nBuild a kanban style board with 3 columns (todo, in progress, done) where you can add tasks (form), movie them from column to column, and delete. Basically, anything that makes you render and act on user behavior.\n\n### Comment ID j8p6u8p with +4 score by [(_hypnoCode, Reddit, 2023-02-15)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8p6u8p/) (in reply to ID j8ofthh):\nfwiw, the first point in that comment is the biggest one and there is middleware now. \n\nhttps://nextjs.org/docs/advanced-features/middleware\n\nPoint 3 about i18n doesn't sound like an issue with NextJS. Not a lot of frameworks come with this baked in. \n\nAnd point 4 sounds like bad architecture decisions.\n\n#### Comment ID j8tb2uc with +2 score by [(novagenesis, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8tb2uc/) (in reply to ID j8p6u8p):\nI would take a step further and say *all* their issues were architecture decisions.  Their problem commonly seemed to be that the libraries they were using gave them too many options and they didn't know how to pick the appropriate one.  They either didn't have the expertise to know to pick one and run with it OR they couldn't come to a consensus and wrote bad code because of that.\n\n### Comment ID j8tb0o4 with +1 score by [(novagenesis, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8tb0o4/) (in reply to ID j8ofthh):\nThat was pretty all-over-the-place for me (the linked story), but last time I wrote or worked on a scratch-made-SPA I wanted to jump off the nearest bridge.  I think it shows either a lack of expertise or a lack of agreed standards in their app.  With Next, you really should be going mainly-SSR or mainly-hydrated-AJAX for data grabbing, and should definitely have all your biz logic in APIs that handle the authorization.  Next-auth is great at making sure both front-end and back-end can authorize the same way.  \n\n> \"had to check for authentication in three places\" (the article)\n\nThis is code-smell, and not next.js's fault IMO.  \n\n...I tried to take it seriously after that, I really did.  But the validation complaints were equally problematic to me. The logic process seems identical in Next.js as it would in Rails.  There's a few right ways to do it, and they're all pretty easy.\n\nAnd then i18n.  Let me be clear.  Internationalization is annoying in the best of libraries.  But \"another axis of complexity because translations need to be available both at SSR time plus at the client side\"?  I mean, not really.  The library gives you options because they're supposed to give you options, but in a well designed app you only need `useTranslation` everywhere.  One mechanism.\n\n*Everything* they said about CLI.... Yeah not really.  If your business logic isn't in files you can `import` into a `.js` or `.ts` file, that's not next.js's fault.\n\nReact is cumbersome on DX until it's established in a project, that's not a lie.  That's why things like svelte are trying so hard to take over the market.  But that was the only thing they didn't complain about.  I get the feeling they were trying to join the node.js hype train with zero SPA experience and very little next.js experience.  It's always better to use what you know.\n\n## Comment ID j8p7qjw with +2 score by [(_hypnoCode, Reddit, 2023-02-15)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8p7qjw/) (in reply to ID 1134125):\nI think it depends on what you think should be in a framework. I personally think it already is a full stack framework, but it doesn't do quite as much as Rails does. But I don't want something to do everything that Rails does because going outside the box hurts. It's mainly that reason why even after 17yrs, nothing similar has really taken off to be nearly as widespread as Rails despite there being a version of Rails created in almost every language out there. Django might be the only other major one I can think of. \n\nThe biggest thing that NextJS is missing is some way to natively handle DB connection pooling without using something like Prisma, Hasura, Supabase, or creating your own based on shared pooling like PHP does.\n\n## Comment ID j8r340p with +2 score by [(thanghil, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8r340p/) (in reply to ID 1134125):\nReact and State-management opinions. \n“Next works best if you write react like this”\n”Next will help you with hydration, persistence, infrastructure architecture if you use state-management-tools in this way”\n\nNot that I can’t figure it out my self, but rather that a big framework could benefit from clear best practices enforced within the tool.\n\n### Comment ID j8tc1am with +2 score by [(novagenesis, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8tc1am/) (in reply to ID j8r340p):\nYeah, they give a lot of options and I think that overwhelms some developers.\n\nYou can write everything like it's react and use a tool that handles the first render automatically.\n\nor you can put everything possible in SSR, leaving client-side code for changes and just calling `router.replace(router.asPath)` whenever you need to invalidate Server-Side Props\n\nOr you can do any combination of that or any crazy convoluted middleware you see fit.\n\n## Comment ID ld4oc87 with +1 score by [(GenazaNL, Reddit, 2024-07-14)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/ld4oc87/) (in reply to ID 1134125):\nModuled federation. I did hear it was internally achieved by the Vercel team, but would love to use this\n\n\n\n\n\n## Comment ID j8rmkma with +1 score by [(rmkblnd, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8rmkma/) (in reply to ID 1134125):\nI would like if Next became more opinionated about how you write your front-end. And stopped using magic variables to configure pages behavior 💀, just add an strong-typed object, please\n\n## Comment ID j8sdyyz with +1 score by [(RedLibra, Reddit, 2023-02-16)](https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/j8sdyyz/) (in reply to ID 1134125):\nWell next is a react framework so a lot of missing things are BE related stuffs...",
      "# Post ID 1csbrqt: Running serverless functions as background jobs instead of using Inngest or AWS sqs.  with +6 score by [(ApprehensiveCut799, Reddit, 2024-05-15)](https://www.reddit.com/r/nextjs/comments/1csbrqt/running_serverless_functions_as_background_jobs/)\nI'm developing a Next.js application deployed on Vercel, and I'm facing a design decision regarding handling multiple API calls concurrently. In my application, a user action triggers a batch of x number of API calls to OpenAI, each initiated through a separate API route in Next.js. These routes invoke functions that execute the API calls asynchronously, without awaiting their completion before responding to the initial HTTP request. Once the api call is completed the result is updated on Supabase. Since Vercel supports up to 30,000 concurrent functions for the pro version,  I'm considering running all API calls simultaneously for each user action. Before I was using Inngest or thinking about using AWS SQS for handling the background jobs but I'm just wondering would it be cheaper and more simple to just run them on Vercel's function and update the result on Supabase? \n\n## Comment ID l43zbr9 with +2 score by [(bipolarNarwhale, Reddit, 2024-05-15)](https://www.reddit.com/r/nextjs/comments/1csbrqt/running_serverless_functions_as_background_jobs/l43zbr9/) (in reply to ID 1csbrqt):\n100% will not be cheaper on Vercel. AWS also gives you a crapload of free monthly invokes on Lambda. Whenever this question comes up just remember that Vercel is reselling AWS services essentially, so you’re going to pay a premium to have that pleasure.\n\n## Comment ID l44099q with +1 score by [(femio, Reddit, 2024-05-15)](https://www.reddit.com/r/nextjs/comments/1csbrqt/running_serverless_functions_as_background_jobs/l44099q/) (in reply to ID 1csbrqt):\nAre all of your requests hitting OpenAI at the same time?\n\nIn general though if you don't need the data immediately I would certainly reach for AWS and just invoke some lambdas.\n\n### Comment ID l44dr6b with +1 score by [(ApprehensiveCut799, Reddit, 2024-05-15)](https://www.reddit.com/r/nextjs/comments/1csbrqt/running_serverless_functions_as_background_jobs/l44dr6b/) (in reply to ID l44099q):\nYes. This was actually a fun little side project I had while I was in university. I'm now getting back into it and thinking of using it as an MVP and test it out with real users. Which is why I haven't thought of  dealing with rate limits and other stuff. When I start to scale this app would it be better practice to implement a queue for this? I was using Inngest previously for background tasks but I'm thinking of trying it on AWS SQS.\n\n#### Comment ID lb7twwi with +1 score by [(AnimalPowers, Reddit, 2024-07-02)](https://www.reddit.com/r/nextjs/comments/1csbrqt/running_serverless_functions_as_background_jobs/lb7twwi/) (in reply to ID l44dr6b):\nWhat did you end up going with?  \nWhat made you want to move away from inngest?  \n\nI had my own task management system that was using vercel natively and I was in the middle of upgrading it for timeouts and retries I searched for an existing library and found inngest - which is how i found this post, so as I'm thinking about moving into it, you're thinking about moving out of it - I'd like to know why.\n\n## Comment ID l441ybw with +1 score by [(Schmibbbster, Reddit, 2024-05-15)](https://www.reddit.com/r/nextjs/comments/1csbrqt/running_serverless_functions_as_background_jobs/l441ybw/) (in reply to ID 1csbrqt):\nI am using quirrel.dev for stuff like that\n\n## Comment ID m5h7yh2 with +1 score by [(SerialEntrepreneur6, Reddit, 2025-01-05)](https://www.reddit.com/r/nextjs/comments/1csbrqt/running_serverless_functions_as_background_jobs/m5h7yh2/) (in reply to ID 1csbrqt):\nWhen handling tasks like these, running them in the background is usually the way to go, especially if users don’t expect instant results. It keeps the experience smoother and more predictable. On Vercel/Next.js, while you can technically trigger serverless functions directly, handling retries, failures, and other edge cases can become a headache without additional setup (e.g., AWS Lambda or similar).\n\nAfter running into these challenges multiple times myself, I eventually built a background job queue tailored for serverless apps. It uses simple HTTP requests to dispatch jobs and sends a webhook back when the job is ready to be processed. If you're exploring solutions for this, feel free to try it out (there’s a free tier to experiment with): [https://dispatched.dev](https://dispatched.dev)",
      "# Post ID 1i971yq: Is there an npm library or AWS service alternative to Temporal, Inngest, Trigger.dev in Next.js? with +3 score by [(backtrack432, Reddit, 2025-01-24)](https://www.reddit.com/r/nextjs/comments/1i971yq/is_there_an_npm_library_or_aws_service/)\nI can’t use third party vendor due to strict third party vendor policy. I’d rather not self host after seeing some horrendous patterns in the past. I’m fine with an additional database (Redis, Cassandra) or solutions inside AWS though.\n\n## Comment ID m901c0l with +3 score by [(pverdeb, Reddit, 2025-01-24)](https://www.reddit.com/r/nextjs/comments/1i971yq/is_there_an_npm_library_or_aws_service/m901c0l/) (in reply to ID 1i971yq):\nAWS just provides the primitives, there’s not a service that does exactly the same thing. Even if it was, Amazon is a third party, so what’s the difference? You’ll be operating a new service here one way or another.\n\nThe AWS resources to look at are SQS, which is a queue for background jobs, and Step Functions, which are very similar to the interruptible pipelines you can build in Inngest. You will almost certainly need to get familiar with Cloudwatch if you’re not already.\n\nAlternatively you could do this all with a couple Redis/Elasticache instances, or even Dynamo. The difference is just that you’ll be responsible for a lot more of the business logic.\n\nWhat features are you looking for specifically? There are tons of good resources for this stuff, happy to try and share something more directly applicable if I can.\n\n## Comment ID m901rcv with +2 score by [(Beginning-Sweet88, Reddit, 2025-01-24)](https://www.reddit.com/r/nextjs/comments/1i971yq/is_there_an_npm_library_or_aws_service/m901rcv/) (in reply to ID 1i971yq):\nAws step functions https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html\n\n## Comment ID m93mq30 with +1 score by [(Fit_Acanthisitta765, Reddit, 2025-01-25)](https://www.reddit.com/r/nextjs/comments/1i971yq/is_there_an_npm_library_or_aws_service/m93mq30/) (in reply to ID 1i971yq):\nuse aws step functions with sam framework, it's a breeze after a little studying.  check out the official aws [serverlessland.com](http://serverlessland.com) website for examples",
      "# Post ID 1hmvddf: [HELP] Verifying Supabase Sessions with Inngest in Python FastAPI App with +2 score by [(Cool-Deal8288, Reddit, 2024-12-26)](https://www.reddit.com/r/Supabase/comments/1hmvddf/help_verifying_supabase_sessions_with_inngest_in/)\nHey folks! I've been working on implementing background job processing with Inngest in my FastAPI/Supabase app, but I'm running into some questions about session verification. Here's what I have so far:\n\n# Current Setup\n\nI'm using Inngest for background job processing with FastAPI. Here's my basic setup:\n\n    pythonCopyinngest_client = inngest.Inngest(\n        app_id=\"\",\n        logger=logging.getLogger(\"uvicorn\"),\n        signing_key=os.getenv(\"INNGEST_SIGNING_KEY\"),\n        is_production=os.getenv(\"INNGEST_DEV\")\n    )\n    \n    u/inngest_client.create_function(\n        fn_id=\"create_chapters_function\",\n        trigger=inngest.TriggerEvent(event=\"novel/generate_chapter\"),\n    )\n    def create_chapters_function(ctx: inngest.Context, step: inngest.Step) -> str:\n        \n    # Function implementation here\n        pass\n    \n    inngest.fast_api.serve(app, inngest_client, [create_chapters_function], serve_path=\"/api/py/inngest\")\n\n# What I'm Trying to Achieve\n\n1. I want to ensure that only authenticated Supabase users can trigger the Inngest background jobs\n2. Need to verify the Supabase session before processing the job\n3. Want to maintain security while keeping the code clean and maintainable\n\n# Questions\n\n1. What's the best way to pass the Supabase session token to Inngest functions?\n2. Should I verify the session in a middleware or within each Inngest function?\n3. Has anyone implemented something similar and can share their approach?\n\n## Comment ID m4m5vqq with +1 score by [(metalzzzx, Reddit, 2024-12-31)](https://www.reddit.com/r/Supabase/comments/1hmvddf/help_verifying_supabase_sessions_with_inngest_in/m4m5vqq/) (in reply to ID 1hmvddf):\nI'm not sure what is the best approach.\n\nWhat I would do is to share the same JWT\\_SECRET\\_KEY between Supabase and your Python app. Probably initialize the key on your Python app as an Env variable, just like Supabase does.\n\nThen use standard OAuth/JWT routines. You can decode the token in your FastAPI endpoints and go from there.\n\n```\nimport jwt\n\nSECRET_KEY = \"your supabase jwt key\"\nALGORITHM = \"HS256\"\npayload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\n```\n\nLet me know if you have a better approach. I haven't gotten so far yet on my app.\n\nI'm having trouble with Supabase Auth. User sign-up and email confirmation are not working for me. Are those working for you? I'm self-hosting on Docker, btw.\n\n### Comment ID m4mkv7f with +1 score by [(Cool-Deal8288, Reddit, 2024-12-31)](https://www.reddit.com/r/Supabase/comments/1hmvddf/help_verifying_supabase_sessions_with_inngest_in/m4mkv7f/) (in reply to ID m4m5vqq):\nRight now, I have a middleware.ts that seems to be providing me protection. I'm just not sure if that is the best way to go.\n\nI'm using Supabase cloud for mine so not sure I'll be of much help with your issue. Their docs helped me get through the auth piece: [https://supabase.com/docs/guides/auth/server-side/nextjs](https://supabase.com/docs/guides/auth/server-side/nextjs)\n\n#### Comment ID m4n5zfb with +1 score by [(metalzzzx, Reddit, 2024-12-31)](https://www.reddit.com/r/Supabase/comments/1hmvddf/help_verifying_supabase_sessions_with_inngest_in/m4n5zfb/) (in reply to ID m4mkv7f):\nSo you're using FastAPI and NextJS on your backend? What are each of them doing?\n\nHow's your experience with cloud Supabase going so far?",
      "# Post ID 180fmch: Any good open source library for managing Background jobs? with +15 score by [(pushkarsingh32, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/)\nSo on bulk execution where time needed is big. it doesnt make sense to make user wait. \nCould you suggest any good lib for this? \n\nPS: Not talking about crons. \n\nThanks\n\n## Comment ID ka64sle with +9 score by [(halcyonPi, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka64sle/) (in reply to ID 180fmch):\nWe use [Bull](https://github.com/OptimalBits/bull) since it is part of NestJS ecosystem.\n\nOnly thing is we can’t edit job’s payload on the fly (would be interesting for failed jobs).\n\nOther than that, so far so good.\n\n### Comment ID ka6d9yr with +1 score by [(Initial_Specialist69, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka6d9yr/) (in reply to ID ka64sle):\nI put the failed Job data into a Redis database and try it again After a specific amount of time.\n\n### Comment ID ka6v9w9 with +1 score by [(rover_G, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka6v9w9/) (in reply to ID ka64sle):\nWhen the task involves processing multiple records, I’ve recorded job partial success in the primary database and rerun the job filtering out records that were already processed.\n\n## Comment ID ka5lfbb with +6 score by [(None, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5lfbb/) (in reply to ID 180fmch):\n[deleted]\n\n### Comment ID ka8dr1z with +6 score by [(propjames, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka8dr1z/) (in reply to ID ka5lfbb):\nHi! James from Mergent here. Thanks for the shout out.\n\nYou're right. There's so much we can do to make things easier, and we're working on that & other QOL improvements now. To date, most of our work has been focused on scaling, reliability & speed (see: [https://twitter.com/jamescmartinez/status/1721927564522840225](https://twitter.com/jamescmartinez/status/1721927564522840225))\n\nIf you're open to it, I'd love to chat with you about your experience so we can make things better. I'll message you.\n\n### Comment ID ka5npph with +2 score by [(pushkarsingh32, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5npph/) (in reply to ID ka5lfbb):\nThanks\n\n### Comment ID ka7u40k with +1 score by [(_MadLex, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka7u40k/) (in reply to ID ka5lfbb):\nJust curious. What problems did you have? I am using trigger.dev and everything is fine\n\n## Comment ID ka7sx18 with +5 score by [(danjamesmedia, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka7sx18/) (in reply to ID 180fmch):\nUpstash qStash is a good use for this\n\n### Comment ID ka7tszz with +1 score by [(pushkarsingh32, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka7tszz/) (in reply to ID ka7sx18):\nThis seems cost effective too\n\n## Comment ID ka6ba33 with +4 score by [(GpsGalBds, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka6ba33/) (in reply to ID 180fmch):\nInngest\n\n## Comment ID ka5nzql with +4 score by [(TheUserIsDrunk, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5nzql/) (in reply to ID 180fmch):\nThe folks at [trigger.dev](https://trigger.dev) are doing a fine job. Self-hosted or cloud.\n\nhttps://www.reddit.com/r/webdev/comments/10zq2dp/y\\_combinator\\_invested\\_500k\\_into\\_my\\_developerfirst\n\n### Comment ID ka6h0jn with +2 score by [(lenfakii, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka6h0jn/) (in reply to ID ka5nzql):\nTrigger.dev and inngest are such huge qol upgrades. +1 no more queues for me\n\n#### Comment ID lfxylya with +1 score by [(bravelogitex, Reddit, 2024-08-01)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/lfxylya/) (in reply to ID ka6h0jn):\nwhat do you use queues for? and what did you use to impleent queues before?\n\n### Comment ID ka5o4cy with +1 score by [(pushkarsingh32, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5o4cy/) (in reply to ID ka5nzql):\nYes heard many recommendations for them. Did you try self hosting?\n\n#### Comment ID ka5p56j with +1 score by [(TheUserIsDrunk, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5p56j/) (in reply to ID ka5o4cy):\nMainly toy projects but they're one of the most helpful folks out there. Their guide is straightforward: https://trigger.dev/docs/documentation/guides/self-hosting\n\n[https://twitter.com/maverickdotdev](https://twitter.com/maverickdotdev) (Eric) and /u/matt-aitken (Matt)\n\n## Comment ID ka5tznm with +2 score by [(bdz, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5tznm/) (in reply to ID 180fmch):\nCould you give an example of a background job that a cron couldn't help with? Mergent was suggested but its serverless crons\n\nNot challenging at all, just curious and would like to know.\n\nEdit: Nvm, I'm guessing its the scheduling aspect\n\n### Comment ID ka8g8s8 with +2 score by [(propjames, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka8g8s8/) (in reply to ID ka5tznm):\nIt comes down to whether or not you want your job to run once, possibly after a delay (background job), or multiple times (cron) on a regular schedule.\n\nbackground jobs (think **when** something happens):\n\n* **when** user signs up, send welcome email\n* **when** user uploads image, process the image into many sizes and upload to S3\n\ncrons (think **every** N minutes):\n\n* **every** 24 hours, get the most recent data from Stripe and report it in Slack\n* **every** 5 minutes, count customer's usage and send that number to Stripe for billing\n\nMergent offers both. In fact, our crons are powered by our background jobs.\n\n## Comment ID ka5f5dy with +1 score by [(vivekkhera, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5f5dy/) (in reply to ID 180fmch):\nI use Inngest but it is a service and not quite open source. Some people like trigger.dev but running it yourself is a lot of work.\n\n### Comment ID ka5nr3e with +1 score by [(pushkarsingh32, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5nr3e/) (in reply to ID ka5f5dy):\nI see thanks\n\n## Comment ID ka808ek with +1 score by [(Diogovski555, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka808ek/) (in reply to ID 180fmch):\n[https://www.inngest.com/](https://www.inngest.com/) ( generous free tier )\n\n## Comment ID ka5wcxl with +1 score by [(keonik-1, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5wcxl/) (in reply to ID 180fmch):\nI haven’t used it yet but I think you could push it off to a worker like partytown that won’t block the users from interacting while the request takes a bit.\n\n## Comment ID ka5zb8t with +1 score by [(XxDonaldxX, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka5zb8t/) (in reply to ID 180fmch):\nSlurm?\n\n## Comment ID ka61tr7 with +1 score by [(Crisu83, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka61tr7/) (in reply to ID 180fmch):\nYou could use scheduled Azure functions. That’s what I’ve done in the past.\n\n## Comment ID ka6gwpm with +1 score by [(lenfakii, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka6gwpm/) (in reply to ID 180fmch):\nInngest or its OS alternatives.\n\n## Comment ID ka6ugk8 with +1 score by [(Tall-Title4169, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka6ugk8/) (in reply to ID 180fmch):\nInngest is amazing, each job runs up to the [maximum duration limit](https://vercel.com/docs/functions/serverless-functions/runtimes#size-limits) of the Vercel plan you're on.  \n\n\nYou can chain events to extend this and run each item/function in a loop so each is its own execution.  \n\n\nIf you need one process to run for a very long time then you're better off deploying to a Node server like on Railway.\n\n## Comment ID ka71f95 with +1 score by [(SteveTabernacle2, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka71f95/) (in reply to ID 180fmch):\nhttps://github.com/graphile/worker\n\nVery simple setup if you’re already using postgres\n\n### Comment ID ka7wxpq with +1 score by [(pushkarsingh32, Reddit, 2023-11-21)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka7wxpq/) (in reply to ID ka71f95):\nI am using Supabase. Any guide?\n\n#### Comment ID ka8hj45 with +1 score by [(SteveTabernacle2, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka8hj45/) (in reply to ID ka7wxpq):\nI’d just try using the connection string\n\n## Comment ID ka8q16r with +1 score by [(do4mother, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka8q16r/) (in reply to ID 180fmch):\nRun processing in synchronous. Then add in the DB status \"processing\". After that client side do some long polling until status is ready.\n\n## Comment ID ka8qltm with +1 score by [(Liltripple_reid, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka8qltm/) (in reply to ID 180fmch):\nNot open source but a really good alternative is https://defer.run\n\n## Comment ID ka8r0o5 with +1 score by [(taranify, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka8r0o5/) (in reply to ID 180fmch):\nI’m using trigger.dev and defer run\n\n## Comment ID ka9muf3 with +1 score by [(HelpfulCommand, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka9muf3/) (in reply to ID 180fmch):\nBull or BullMQ, works great in production and you get a dashboard to view background jobs.\n\nBull - [https://github.com/OptimalBits/bull](https://github.com/OptimalBits/bull)  \nBullMQ is the newer version - https://bullmq.io/\n\n## Comment ID ka9oiup with +1 score by [(levelingupeveryday, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka9oiup/) (in reply to ID 180fmch):\ncheckout [Trigger.dev](https://Trigger.dev)\n\n## Comment ID ka9xeha with +1 score by [(tarektweeti, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/ka9xeha/) (in reply to ID 180fmch):\nYou may take a look at https://docs.defer.run/get-started/concepts\n\nEasy way to create/deploy/manage background jobs\n\n## Comment ID kaa9zvf with +1 score by [(peekkk, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/kaa9zvf/) (in reply to ID 180fmch):\nRegardless of which tool you decide to use, split your big job into many smaller dependent jobs. This will make it much easier to use something like BullMQ or [Trigger.dev](https://Trigger.dev). \n\nAlso make jobs idempotent and consider something like Cloud Tasks or Cloud Run Jobs if they are the exact same job. It is usually much easier to manage those than self-hosting something like Bull, etc which often needs a Redis or Memorystore to actually hold the jobs. \n\nI found some success with Google Cloud Pub/Sub + Cloud Tasks, but again, depends on your use case and tooling. Best of luck!\n\n## Comment ID kac69lj with +1 score by [(elk-x, Reddit, 2023-11-22)](https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/kac69lj/) (in reply to ID 180fmch):\nGoogle Cloud Tasks",
      "# Post ID 1cf0q8c: Background Processing with +29 score by [(wolfGang91, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/)\nWhats the recommended way of handing background jobs in nextjs, I have a small app deployed on digital ocean. I need to send some emails and some api calls in background, and may be a cron job that exports data on hourly bases. I am using server actions to save data in mongodb. I don't want to have a separate server for background processing since its a small app.\n\n## Comment ID l1me4kc with +11 score by [(clearlight, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1me4kc/) (in reply to ID 1cf0q8c):\nA cron job to call your API route handlers?\n\n### Comment ID l1nh1g1 with +2 score by [(Relevant_Worry8647, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1nh1g1/) (in reply to ID l1me4kc):\nThis 🔝\n\n#### Comment ID l1osu4x with +1 score by [(None, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1osu4x/) (in reply to ID l1nh1g1):\nThis\n\n### Comment ID l1t9558 with +1 score by [(wolfGang91, Reddit, 2024-04-29)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1t9558/) (in reply to ID l1me4kc):\nnot necessarily, cron can execute some service from the next code.\n\n## Comment ID l1n4war with +8 score by [(Tall-Title4169, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1n4war/) (in reply to ID 1cf0q8c):\nInngest, Trigger if you are hosting on Vercel or another serverless platform. Otherwise it will work the same as a Node.js server on any other traditional host. \n\nhttps://www.inngest.com/\n\nhttps://trigger.dev/\n\n### Comment ID l1qfgn8 with +3 score by [(Potential_Soup, Reddit, 2024-04-29)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1qfgn8/) (in reply to ID l1n4war):\nThis is the way to go. Inngest is great\n\n## Comment ID l1mj00o with +6 score by [(Longjumping-Till-520, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1mj00o/) (in reply to ID 1cf0q8c):\nI own my VPS\n\n* Periodic: Linux crontab\n* Message Queue: pg-boss (easiest if you use postgres), bull (needs some config), AWS SQS\n\nI use serverless\n\n* Periodic: vercel cron  jobs, trigger dev, AWS, etc.\n* Message Queue: probably AWS SQS\n\n## Comment ID l1ma42k with +25 score by [(revattojs, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1ma42k/) (in reply to ID 1cf0q8c):\nThat's when a real backend comes into play.\n\nNext won't replace a real backend.\n\nBefore jumping into a technology think about scalability and if you'll ever need a particular feature later on, then decide if Next or a backend framework would do the work.\n\n### Comment ID l1nl2hu with +11 score by [(geodebug, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1nl2hu/) (in reply to ID l1ma42k):\nLol, wouldn’t be a programming sub without the top comment being condescending and unhelpful. \n\nThere are options beyond setting up a so-called “real backend”\n\nCould use a cloud service to do the cron and ping a Nextjs api endpoint or page.   OP says they use Mongo so could look into Mongo’s scheduled triggers.  Could look into installing a small cron app side by side on his production server (I assume it is Node). \n\nSome hosts like Vercel have cron jobs available that will do the ping.\n\n### Comment ID l1ngv0s with +3 score by [(sickcodebruh420, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1ngv0s/) (in reply to ID l1ma42k):\nPlenty of “real backends” offload async tasks to something Redis-backed. Your typical Express, Rails, or Django web servers will still use libraries and workers because the web server is unsuitable for it.\n\n#### Comment ID l1nvjsk with +2 score by [(revattojs, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1nvjsk/) (in reply to ID l1ngv0s):\nMy point is that you can't do everything with nextjs unless you build your backend with a technology meant for that especially if it's something that would scale.\n\n### Comment ID l1o0bug with +1 score by [(ZeRo2160, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1o0bug/) (in reply to ID l1ma42k):\nBackground Jobs, cronjobs and so on are all possible with nextjs. And easyly achievable too. The nextjs backend part can do anything an express backend could do too. If your first though is, but its not possible with serverless functions, you are right. But thats an architectual problem. Not an framework Problem. You dont have to use serverless functions with nextjs.\n\n### Comment ID mcv1w83 with +1 score by [(Ukpersfidev, Reddit, 2025-02-15)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/mcv1w83/) (in reply to ID l1ma42k):\nYou can absolutely process jobs in a next js handler.\n\n### Comment ID l1monta with +1 score by [(procrastinator1012, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1monta/) (in reply to ID l1ma42k):\nYeah. Next is more like a frontend and a backend for frontend combined.\n\n## Comment ID l1mdmmi with +6 score by [(Kyan1te, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1mdmmi/) (in reply to ID 1cf0q8c):\nNext's hosting model is different to that of a traditional Node server.  \nYour best bet is to expose a protected endpoint from your Next.js application & have *something else* that hits the endpoint whenever the CRON job (or similar) needs to run.\n\nIf you don't want to host a separate server, then you can use a scheduler as a service type service such as Vercel CRON Jobs (https://vercel.com/docs/cron-jobs) or something like Mergent (https://docs.mergent.co/quickstart/nextjs).\n\n### Comment ID l1oc09e with +3 score by [(cas8180, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1oc09e/) (in reply to ID l1mdmmi):\nDon’t forget trigger.dev\n\nIf you’re tech savvy you can self host trigger.dev on your own Vps the using it’s api to schedule and invoke jobs\n\n## Comment ID l1mm7l7 with +2 score by [(SkipBopBadoodle, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1mm7l7/) (in reply to ID 1cf0q8c):\nEasy and free way without too much extra overhead while keeping full control that I've been using is to use Google VM free tier to set up pm2 that runs a cron schedule script which calls my Next app's protected endpoints.\n\nI like doing it this way because I can type any TS code I want and have them as separate modules that I import into the schedule script, so if I have to hit my endpoints with different queries, I can easily automate it and keep it in the same format and language as my main codebase.\n\n## Comment ID l1mr64q with +2 score by [(nautybags, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1mr64q/) (in reply to ID 1cf0q8c):\nI use bullmq\n\n## Comment ID l1n1cym with +2 score by [(KM_Koushik, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1n1cym/) (in reply to ID 1cf0q8c):\nSince you’re using a DO it’s not hard to run background jobs. 3 ways I would recommend \n\n1. Run a promise without await. I usually use this for non important quick tasks. Note: can’t use this in Vercel or any serverless environment\n\n2. This is my favourite one. Pgboss, it uses postgres run store jobs. Very handy if you already use postgres. So might not be the best choice for you \n\n3. Good ol Redis queue with library like bullmq\n\n## Comment ID l1m51zy with +3 score by [(None, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1m51zy/) (in reply to ID 1cf0q8c):\nUse a third party service like Inngest or Upstash\n\n## Comment ID l1mmve8 with +3 score by [(eedren2000, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1mmve8/) (in reply to ID 1cf0q8c):\nInngest, trigger.dev, pipedream, the list goes on\n\n## Comment ID l1m9a83 with +1 score by [(fredsq, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1m9a83/) (in reply to ID 1cf0q8c):\nnextjs doesn’t expose its usage of Node so you could write CRON jobs… another server it is\n\n## Comment ID l1mirwq with +1 score by [(indicava, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1mirwq/) (in reply to ID 1cf0q8c):\nI host my nextjs site on Google Cloud Run (with a docker image) and supplement functionality like you described using other GCP services like Scheduled Functions, Cloud Tasks, etc. it works really great and the performance is stellar. \n\n(Also, some GCP services like Cloud Run have a more than decent free tier so that’s an added bonus)\n\n## Comment ID l1mq2a6 with +1 score by [(TotomInc, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1mq2a6/) (in reply to ID 1cf0q8c):\nTrigger.dev is exactly built for this, for next.js users. The DX is awesome\n\n## Comment ID l1msn3l with +1 score by [(cat-duck-love, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1msn3l/) (in reply to ID 1cf0q8c):\nExtract the business logic into a runnable node script. If you are in a monorepo, then it’s easier to do this. Then since you are already on DO, just add a cron job that triggers this script.\n\nThe idea is also the same even if you are in a serverless environment. Extract the business logic, and deploy them individually as lambdas. You just need to test your handlers in isolation and let your runtime/infra handle the scheduling. That’s why if I’m doing fullstack in next/node, I really like to use a monorepo approach since doing these will be trivial.\n\n## Comment ID l1n8vn1 with +1 score by [(Intelligent-Clock987, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1n8vn1/) (in reply to ID 1cf0q8c):\nYou can either run another app on the same server to run the samething or use services like Inngest  to get your background jobs sorted. \n\nI could be wrong, but since you are running on digital ocean, you dont have the limitation of Vercel, you should be able to use agendajs for handle your crons as well.\n\n## Comment ID l1njs56 with +1 score by [(previouslyanywhere, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1njs56/) (in reply to ID 1cf0q8c):\nprobably an overkill but did you try [trigger.dev](http://trigger.dev) ?\n\n## Comment ID l1nq63y with +1 score by [(parsasabet, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1nq63y/) (in reply to ID 1cf0q8c):\nNext is not built for such thing, generally cron jobs. I’d recommend you pick another server for that, but still do check Vercel out: https://vercel.com/guides/how-to-setup-cron-jobs-on-vercel\n\n## Comment ID l1odazb with +1 score by [(ericc59, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1odazb/) (in reply to ID 1cf0q8c):\nOption 1: third-party service like inngest or trigger.dev\nOption 2: use SST to easily set up a queue and lambda consumer on AWS\nOption 3: run a small redis server (or upstash) and worker on digital ocean\n\n## Comment ID l1oh5oz with +1 score by [(Commercial_Ear_6989, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1oh5oz/) (in reply to ID 1cf0q8c):\nGraphile Worker\n\n## Comment ID l1orr3y with +1 score by [(jamesbrooks94, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1orr3y/) (in reply to ID 1cf0q8c):\nSeparate service running and a messaging service to offload the processing. \n\nI’d recommend looking at AWS Lambda for processing, using SES for sending the emails, and SQS as the queueing mechanism. \n\nShould be pretty damn cheap.\n\n## Comment ID l1qalce with +1 score by [(thambroni, Reddit, 2024-04-29)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1qalce/) (in reply to ID 1cf0q8c):\nJust use GitHub actions. Nice n easy\n\n## Comment ID l22uzzk with +1 score by [(NotElonMuzk, Reddit, 2024-05-01)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l22uzzk/) (in reply to ID 1cf0q8c):\nI use Laravel\n\n## Comment ID l27hxzw with +1 score by [(samiy8030, Reddit, 2024-05-02)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l27hxzw/) (in reply to ID 1cf0q8c):\nThis question gets asked on here like once per month and every time, there are different answers\n\n## Comment ID lvjbs5e with +1 score by [(pencilcheck, Reddit, 2024-11-05)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/lvjbs5e/) (in reply to ID 1cf0q8c):\ni'm self hosting now on hostlinger, so I have a lot of self hosting options instead of using cloud options.\n\n## Comment ID l1me6yg with +1 score by [(Mysterious-Yam-4772, Reddit, 2024-04-28)](https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/l1me6yg/) (in reply to ID 1cf0q8c):\nTrigger.dev might help you",
      "# Post ID 1i8zxr3: Is there a Python equivalent to Trigger.dev for simple background job scheduling? with +15 score by [(Volunder_22, Reddit, 2025-01-24)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/)\nI'm using \\[Trigger.dev\\](http://Trigger.dev) for background jobs in TypeScript and appreciate how straightforward it is to set up and run background tasks. Looking for something with similar ease of use but for Python projects. Ideally want something that's beginner-friendly and doesn't require complex infrastructure setup.\n\n## Comment ID m8y3h5y with +9 score by [(jay_and_simba, Reddit, 2025-01-24)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m8y3h5y/) (in reply to ID 1i8zxr3):\nI use APScheduler to run task as if it's a cronjob\n\n### Comment ID m9434yd with +2 score by [(tarsild, Reddit, 2025-01-25)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m9434yd/) (in reply to ID m8y3h5y):\nLove it. There I also https://asyncz.dymmond.com that is basically a revamped written in pydantic version of APScheduler with some extras.\n\n## Comment ID m8yrlxs with +8 score by [(WJMazepas, Reddit, 2025-01-24)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m8yrlxs/) (in reply to ID 1i8zxr3):\nFastapi has a native Background task feature\n\n## Comment ID m8xuml8 with +7 score by [(fueled_by_caffeine, Reddit, 2025-01-24)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m8xuml8/) (in reply to ID 1i8zxr3):\nCelery or dramatiq\n\n## Comment ID m8y184u with +2 score by [(knksmith57, Reddit, 2025-01-24)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m8y184u/) (in reply to ID 1i8zxr3):\nProcrastinate, Hatchet\n\n### Comment ID m8yn22b with +1 score by [(sexualrhinoceros, Reddit, 2025-01-24)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m8yn22b/) (in reply to ID m8y184u):\nI worked with Hatchet for a while, very solid product\n\n## Comment ID m8z09ct with +2 score by [(hornetmadness79, Reddit, 2025-01-24)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m8z09ct/) (in reply to ID 1i8zxr3):\nPrefect it pretty awesome.\nOpenfaas\n\n## Comment ID m905j0o with +1 score by [(trojans10, Reddit, 2025-01-24)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m905j0o/) (in reply to ID 1i8zxr3):\nDBOS looks really cool\n\n## Comment ID m90gmyt with +1 score by [(Schmibbbster, Reddit, 2025-01-25)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m90gmyt/) (in reply to ID 1i8zxr3):\nSimple async queue is my go-to\n\n## Comment ID m927dcy with +1 score by [(ironman_gujju, Reddit, 2025-01-25)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m927dcy/) (in reply to ID 1i8zxr3):\nHatchet, I dumped celery & taskiq for this\n\n## Comment ID m92e1z2 with +1 score by [(LeonTur, Reddit, 2025-01-25)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m92e1z2/) (in reply to ID 1i8zxr3):\nAsync queu + custom Task service\n\n## Comment ID m92opic with +1 score by [(scmkr, Reddit, 2025-01-25)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m92opic/) (in reply to ID 1i8zxr3):\nI used rq in the past, and I was reasonably happy with it. Less complicated than celery\n\n## Comment ID m952wm6 with +1 score by [(Frohus, Reddit, 2025-01-25)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m952wm6/) (in reply to ID 1i8zxr3):\ncelery with beat\n\n## Comment ID m959c33 with +1 score by [(Volunder_22, Reddit, 2025-01-25)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m959c33/) (in reply to ID 1i8zxr3):\nthanks everyone 👍\n\n## Comment ID m98dga2 with +1 score by [(IM_AXIS, Reddit, 2025-01-26)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m98dga2/) (in reply to ID 1i8zxr3):\nInngest easy peasy\n\n### Comment ID m9itwa5 with +1 score by [(self-taught16, Reddit, 2025-01-27)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m9itwa5/) (in reply to ID m98dga2):\nWith Inngest you can do Python and TypeScript: https://www.inngest.com/docs - and there’s support for calling functions across languages and codebases: https://www.inngest.com/docs\n\n#### Comment ID m9vnpmn with +1 score by [(inngest-mktg, Reddit, 2025-01-29)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/m9vnpmn/) (in reply to ID m9itwa5):\nThanks for the shoutout u/IM_AXIS and u/self-taught16 ...for those interested our founder Tony's always up for giving a demo: [https://savvycal.com/inngest/demo?utm\\_medium=reddit&utm\\_source=thread](https://savvycal.com/inngest/demo?utm_medium=reddit&utm_source=thread)\n\n## Comment ID mas088z with +1 score by [(ZuploAdrian, Reddit, 2025-02-03)](https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/mas088z/) (in reply to ID 1i8zxr3):\nIs Inngest a food solution?"
    ],
    "sources": {
      "steam_url": null,
      "steam_reviews": null,
      "google_play_url": null,
      "google_play_reviews": null,
      "apple_store_url": null,
      "apple_reviews": null,
      "reddit_urls": [
        "https://www.reddit.com/r/node/comments/17psu33/inngest_pricing_model_and_others_like_triggerdev/",
        "https://www.reddit.com/r/Nuxt/comments/17i8f6y/i_wish_i_had_known_about_inngest_earlier/",
        "https://www.reddit.com/r/nextjs/comments/1hl6wao/how_do_you_handle_realtime_client_updates_with/",
        "https://www.reddit.com/r/nextjs/comments/1134125/what_is_nextjs_missing_from_being_a_truly_full/",
        "https://www.reddit.com/r/nextjs/comments/1csbrqt/running_serverless_functions_as_background_jobs/",
        "https://www.reddit.com/r/nextjs/comments/1i971yq/is_there_an_npm_library_or_aws_service/",
        "https://www.reddit.com/r/Supabase/comments/1hmvddf/help_verifying_supabase_sessions_with_inngest_in/",
        "https://www.reddit.com/r/nextjs/comments/180fmch/any_good_open_source_library_for_managing/",
        "https://www.reddit.com/r/nextjs/comments/1cf0q8c/background_processing/",
        "https://www.reddit.com/r/FastAPI/comments/1i8zxr3/is_there_a_python_equivalent_to_triggerdev_for/"
      ],
      "reddit_search_url": "https://www.google.com/search?q=site%3Areddit.com+%22Inngest%22+related%3Ainngest.com+"
    }
  },
  "glassdoor_result": null,
  "news_result": [
    [
      "Inngest",
      "Inngest",
      "inngest.com",
      null,
      false,
      false,
      null,
      [
        false,
        false
      ]
    ],
    [
      {
        "title": "Product & Engineering blog - Inngest",
        "link": "https://www.inngest.com/blog",
        "snippet": "Feb 26, 2025 ... Updates from the Inngest team about our product, engineering, and community. Categories:Product updatesCompany newsEngineeringChangelog ... Tutorial: Custom ...",
        "formattedUrl": "https://www.inngest.com/blog"
      },
      {
        "title": "Show HN: Inngest 1.0 – Open-source durable workflows on every ...",
        "link": "https://news.ycombinator.com/item?id=41604042",
        "snippet": "Sep 20, 2024 ... Inngest is an open-source durable workflow platform that works on any cloud. Durable workflows are stateful, long running step functions written in code, which ...",
        "formattedUrl": "https://news.ycombinator.com/item?id=41604042"
      },
      {
        "title": "Customer story - Fey",
        "link": "https://www.inngest.com/customers/fey",
        "snippet": "Apr 4, 2024 ... How Fey leverages Inngest in data-intensive processes. “As soon as companies release their data, we want to have it in Fey. With our old tool it would take up ...",
        "formattedUrl": "https://www.inngest.com/customers/fey"
      },
      {
        "title": "Inngest - Crunchbase Company Profile & Funding",
        "link": "https://www.crunchbase.com/organization/inngest",
        "snippet": "May 29, 2024 ... Inngest is the developer platform for easily building reliable workflows with zero infrastructure ... Recent News & Activity. News• Jul 1, 2024. Andreessen ...",
        "formattedUrl": "https://www.crunchbase.com/organization/inngest"
      },
      {
        "title": "Product & Engineering Blog - Engineering - Inngest",
        "link": "https://www.inngest.com/blog/category/engineering",
        "snippet": "May 15, 2024 ... Read about how we rolled our new sharded infrastructure out to production without a millisecond of downtime and how it improved Inngest's overall performance.",
        "formattedUrl": "https://www.inngest.com/blog/category/engineering"
      },
      {
        "title": "Custom Hacker News summaries in your inbox—build an AI Agent ...",
        "link": "https://render.com/blog/hacker-news-ai-agent-inngest-render",
        "snippet": "Jan 16, 2025 ... js app, and a cron job, which are all hosted on Render. They communicate with each other securely over a private network. AI workflow orchestrated by Inngest: ...",
        "formattedUrl": "https://render.com/blog/hacker-news-ai-agent-inngest-render"
      },
      {
        "title": "Elixir SDK Support In The Roadmap? - Community Support - Temporal",
        "link": "https://community.temporal.io/t/elixir-sdk-support-in-the-roadmap/12513",
        "snippet": "Jun 16, 2024 ... Additionally, I'm seeing other similar projects like inngest where they are taking a crack at elixir support. ... Great news, thanks for taking up the challenge.",
        "formattedUrl": "https://community.temporal.io/t/elixir-sdk-support-in-the.../12513"
      },
      {
        "title": "Building Production Workflows for AI Applications | Andreessen ...",
        "link": "https://a16z.com/podcast/building-production-workflows-for-ai-applications/",
        "snippet": "Jun 14, 2024 ... In this AI + a16z episode, Inngest CEO Tony Holdstock-Brown discusses the reality of running AI agents and multistep AI workflows in production.",
        "formattedUrl": "https://a16z.com/podcast/building-production-workflows-for-ai-applications/"
      },
      {
        "title": "Customer Story - Fey | Render",
        "link": "https://render.com/customers/fey",
        "snippet": "Apr 15, 2024 ... From Cloud Composer (Google Cloud's managed Airflow product) to Inngest; From a human-powered data vendor to OpenAI. We sat down with Dennis Brotzky, CTO/co- ...",
        "formattedUrl": "https://render.com/customers/fey"
      },
      {
        "title": "AWS Step Functions · Issue #4660 · sst/sst · GitHub",
        "link": "https://github.com/sst/ion/issues/376",
        "snippet": "May 5, 2024 ... inngest.com also has a similar syntax for defining state machines. All ... erolabzait commented on Nov 27, 2024. Any news on this? Still using the ...",
        "formattedUrl": "https://github.com/sst/ion/issues/376"
      },
      {
        "title": "Running Durable Workflows in Postgres using DBOS",
        "link": "https://supabase.com/blog/durable-workflows-in-postgres-dbos",
        "snippet": "Dec 10, 2024 ... dev, Inngest, Windmill, Temporal, and AWS Step Functions. DBOS offers a relatively unique approach to Workflows, storing the state in your own Postgres ...",
        "formattedUrl": "https://supabase.com/blog/durable-workflows-in-postgres-dbos"
      },
      {
        "title": "interviewed 100 DevTools founders and this is what I learned",
        "link": "https://scalingdevtools.com/blog/i-interviewed-100-devtools-founders/",
        "snippet": "Oct 7, 2024 ... But growth is harder. This is what I heard emphatically from two of my favorite fellow-Brit DevTools founders, David from ArcJet and Tony from Inngest. It's ...",
        "formattedUrl": "https://scalingdevtools.com/blog/i-interviewed-100-devtools-founders/"
      },
      {
        "title": "Framework Wars are Dead! Get them All at this event (Free!) - Vue.js ...",
        "link": "https://vuejsdevelopers.com/2024/05/08/fen-announement-article/",
        "snippet": "May 7, 2024 ... React: Kent C. Dodds (React superstar), Tejas Kumar (Fluent React author), Sylwia Vargas (DevRel Lead at Inngest); Angular: Minko Gechev (Angular Product ...",
        "formattedUrl": "https://vuejsdevelopers.com/2024/05/08/fen-announement-article/"
      },
      {
        "title": "The Rise of AI Agent Infrastructure",
        "link": "https://www.madrona.com/the-rise-of-ai-agent-infrastructure/",
        "snippet": "Jun 5, 2024 ... dev, Ollama, Langserve), persistence (Inngest, Hatchet.run, Trigger.dev ... Related Insights. October 20, 2023. by Palak Goel and Karan Mehandru. Moving ...",
        "formattedUrl": "https://www.madrona.com/the-rise-of-ai-agent-infrastructure/"
      },
      {
        "title": "Clerk Update — July 2024 - DEV Community",
        "link": "https://dev.to/clerk/clerk-update-july-2024-3mba",
        "snippet": "Jul 12, 2024 ... Here's a rundown of the highlights:. Tagged with showdev, clerk, news ... We've partnered with Xata, Prisma, and Inngest to bring you a two-week summer hackathon ...",
        "formattedUrl": "https://dev.to/clerk/clerk-update-july-2024-3mba"
      },
      {
        "title": "Solving the Multiple-Frontend Problem in Modern Applications",
        "link": "https://directus.io/blog/solving-the-multiple-frontend-problem-in-modern-applications",
        "snippet": "Feb 18, 2025 ... Join us and Inngest on March 20 to learn how to build advanced content workflows ... Get insights, releases, and exciting news delivered directly to your inbox ...",
        "formattedUrl": "https://directus.io/.../solving-the-multiple-frontend-problem-in-modern-app..."
      },
      {
        "title": "Building Effective AI Agents: Insights from Anthropic and Hacker ...",
        "link": "https://medium.com/@lordmoma/building-effective-ai-agents-insights-from-anthropic-and-hacker-news-discussions-881cee2ab6d6",
        "snippet": "Dec 21, 2024 ... ... News. But as I dived into the discussions, it became ... I came across several tools in the discussion — Temporal, Hatchet, Inngest, and Windmill — all designed ...",
        "formattedUrl": "https://medium.com/.../building-effective-ai-agents-insights-from-anthropic..."
      },
      {
        "title": "Introducing Project Configuration for Directus Cloud Projects",
        "link": "https://directus.io/blog/cloud-project-configuration",
        "snippet": "Dec 4, 2024 ... Join us and Inngest on March 20 to learn how to build advanced content workflows ... Get insights, releases, and exciting news delivered directly to your inbox ...",
        "formattedUrl": "https://directus.io/blog/cloud-project-configuration"
      },
      {
        "title": "Next.js + Inngest: Unlocking Long-Running AI Workflow Automation ...",
        "link": "https://www.youtube.com/watch?v=9F7RLFwg9H8",
        "snippet": "Sep 16, 2024 ... Build durable AI workflows in JavaScript or TypeScript to work with your NextJS or React applications quickly and easily using Inngest.",
        "formattedUrl": "https://www.youtube.com/watch?v=9F7RLFwg9H8"
      },
      {
        "title": "@andyrmitchell/pg-queue - npm",
        "link": "https://www.npmjs.com/package/@andyrmitchell/pg-queue",
        "snippet": "Jun 4, 2024 ... This is related to Zod, and probably MultiStepPgQueue's inference of type ... Temporal.io, Inngest, etc. are enticing, but there is lock in to their ...",
        "formattedUrl": "https://www.npmjs.com/package/@andyrmitchell/pg-queue"
      }
    ],
    [
      "# [Product & Engineering blog](https://www.inngest.com/blog)\nCustomer story: Otto\n\n2/7/2025\n\nLearn how Otto uses Inngest to build and scale AI Agents that are as easy as a spreadsheet.\n\nThe Principles of Durable Execution Explained\n\n12/10/2024\n\nLearn what Durable Execution is, how it works, and why it's beneficial to your system.\n\nstep.ai: the quickest way to build reliable AI applications on Serverless while saving on compute\n\n12/10/2024\n\nCombining step.run() and step.ai.infer() is the best toolset to build reliable AI applications on Serverless while saving on compute.\n\n4 solutions to Vercel function timeouts\n\n10/30/2024\n\nSolving Vercel timeout issues isn't only about increasing the timeout but also using the right tools for the job.\n\nMEGA SEO: Building the next generation of blogging with AI workflows\n\n10/4/2024\n\nJoe Adams from MEGA SEO shares how Inngest enabled them to build AI workflows that would have been difficult or impossible to achieve with SQS.\n\nNext.js Serverless Functions vs Durable Functions\n\n8/13/2024\n\nLearn how Durable Functions remove the need of a separate server to handle long-running workflows or to power queues.\n\nInngest's new design: Our process in rethinking our information architecture\n\n8/8/2024\n\nThe Inngest Cloud and Dev Server got a brand new design. This post digs into the process behind this new Information Architecture.\n\nSharding high-throughput Redis without downtime\n\n7/23/2024\n\nRead about how we rolled our new sharded infrastructure out to production without a millisecond of downtime and how it improved Inngest's overall performance.\n\nWhat is waitUntil (Vercel, Cloudflare) and when should I use it?\n\n5/16/2024\n\nWhat is it, when to use it, and when not to use it\n\nAI in production: Managing capacity with flow control\n\n4/18/2024\n\nWhat do you need to take your LLM based product from demo to production?\n\nLaunch Week Recap\n\n1/26/2024\n\nA look at all the releases of the past week: from Replay and per-step error handling to new SKDs and integrations.\n\nMigrating long running workflows across clouds with zero downtime\n\n1/23/2024\n\nHow the Inngest system is designed to help you migrate across clouds with minimal effort.\n\nAdding workflows to an Astro app with Inngest\n\n1/12/2024\n\nLearn how to extend the range of your Astro app with long-running processes, and when to do so.\n\n2023 Wrapped\n\n12/22/2023\n\nOver the past twelve months, we've shipped a lot and improved the DX across the board, our team has grown three-fold, and we were able to raise a seed round.\n\nUser-Defined Workflows in Next.js with Sanity and Inngest\n\n10/6/2023\n\nGet your workflows up and running quickly with Sanity and Inngest in Next.js\n\nIntroducing Inngest TypeScript SDK v3.0\n\n10/5/2023\n\nLearn about the exciting new features in v3.0 and how to upgrade.\n\nSending customer lifecycle emails with Resend and Inngest\n\n8/21/2023\n\nHow to Send Effective and Reliable Emails in your Next.js Applications with Resend & Inngest\n\nIntroducing Inngest TypeScript SDK v2.0\n\n6/9/2023\n\nLearn about the exciting new features in v2.0 and how to upgrade.\n\n5 Lessons Learned From Taking Next.js App Router to Production\n\n5/5/2023\n\nWhat did we learn from building and shipping our new app with the Next.js 13 App Router?\n\nCustomer story: Ocoya\n\n4/7/2023\n\nLearn how Ocoya uses Inngest to develop and deliver their world class product in record time, with end-to-end local testing.\n\nAI Personalization and the Future of Developer Docs\n\n2/9/2023\n\nProviding developer-specific examples to help developers learn how to use the Inngest SDK. The beginning of AI-personalized learning flows for users.\n\nCompleting the Jamstack: What's needed in 2022?\n\n11/2/2022\n\nWhere the Jamstack is today and what is left to complete the vision.\n\nRun Next.js functions in the background with events and schedules on Vercel and Netlify\n\n10/4/2022\n\nLearn how to use Next.js api functions and run them as you would a message queue or a cron job.\n\nLoad testing an event-driven message queue\n\n8/1/2022\n\nHow to quickly run load tests on event-driven queues via K6\n\nBuilding Webhooks That Scale\n\n7/27/2022\n\nLessons learned scaling webhooks to millions of requests a day\n\nInngest: OS v0.5 released\n\n7/26/2022 Release Notes\n\nThis release contains exciting new functionality, including replay and our self-hosting services\n\nMessage queue vs message bus: the practical differences\n\n6/29/2022\n\nWe explore the difference between queueing systems and message busses\n\nBuilding an event-driven queue based on common standards\n\n6/14/2022\n\nThe design decisions and architecture for a next-gen queuing platform\n\nIntroducing Inngest DevServer\n\n6/9/2022\n\nThe first tool purposely designed for event-driven asynchronous system local development\n\nRapidly building interactive CLIs in Go with Bubbletea\n\n4/15/2022\n\nOur product is just different enough to make our CLI require really good interactivity. We bundle an interactive event browser in our CLI. Here's how it's built.\n\nBuilding a real-time websocket app using SvelteKit\n\n2/22/2022\n\nOur experience building https://typedwebhook.tools in 2 days using SvelteKit.\n\nProduct updates: Feb 8, 2022\n\n2/8/2022\n\nWhat's fresh out of the oven recently, and what's cooking? Here's our bi-weekly product deep dive.\n\nProduct updates: Jan 18, 2022\n\n1/19/2022\n\nWhat's fresh out of the oven recently, and what's cooking? Here's our bi-weekly product deep dive.\n\nProgrammable event platforms\n\n1/10/2022\n\nProgrammable event platforms allow you to build serverless event-driven systems in minutes. Here's an introduction to them.",
      "# [Show HN: Inngest 1.0 – Open-source durable workflows on every platform](https://news.ycombinator.com/item?id=41604042)\nThere might be a bit of misunderstanding on what's in that git repo here. It actually contains the executor, state store, queue, and our production UI, plus the syncing, registration, and logic for functions.\n\nEarlier this year we didn't want folks to roll their own production cloud due to queueing migrations. It would make your life hard. We're entirely responsible for that right now, as we discouraged self hosting.\n\nThat's actually coming to a close, and we'll make it easy to spin up prod clusters using this code and eg. MemoryDB, Dragonfly, or what have you.\n\nWell, my experience has been closer to the \"more eyes make for shallow bugs\" school of thought, so opening the source to contributions would actually help that process, not hinder it\n\nI've written quite a lot of CI for projects because it's something I believe in and am willing to roll up my sleeves to get done (as a concrete example). I believe strongly that being able to reference the canonical CI build helps contributors since they can see how it's built for different systems and also ensure they don't submit \"works on my machine\" patches\n\nUsed this for a short while and the dev experience was great (the console in particular which allowed for copying events to reproduce them locally). The typescript integration was good.\n\nMy only issue was that the execution of an inngest function wasn't completely intuitive, at least in TS, and you have to think in terms of inngest or, more precisely, the abstraction it is providing. Is it an actor, a step function, an event consumer, a saga? or a combination of some?\n\nWhen you get used to it it's nice, less overhead than building your own actor model or your own event sources, and really good visibility into what is happening.\n\n> My only issue was that the execution of an inngest function wasn't completely intuitive, at least in TS, and you have to think in terms of inngest or, more precisely, the abstraction it is providing. Is it an actor, a step function, an event consumer, a saga? or a combination of some?\n\nI'm personally curious about this. I'm not saying you don't, but why would you need to understand what kind of abstraction it is beyond it just being Inngest\"? I like to think I've been able to use it effectively without this having ever crossed my mind. But I also just might be dumb. Hence the curiosity!\n\nBecause code doesn't execute as you might think it does, which is why Inngest has docs describing best practices.\n\nYou have to be careful about how you structure effectful code and how you might share data between steps, and you have to understand when that code might be executed, so the more you know about that, the better. Inngest itself, at least with Vercel, doesn't do its own compute.\n\nInngest, as far as I know, does not do its own compute, it piggybacks on your own, so if you're not careful you can go hard with inngest but you'll see the impact on your hosting bill; especially with Vercel.\n\nInngest is a breath of fresh air but, you know, you have to audit your dependencies whether they're SaaS or not. Know how they work, know how to debug them, know how much they'll cost you.\n\nThanks! There are a few things at play. High level, it's important to note we provide infra for you — so our multi-tenancy supports many tenants for every user.\n\nIn general, fairness means distributing work evenly amongst all accounts. This largely means partitioned queues. Firstly, every functions have their own queues. We have queues of queues: queues of functions available. And then we have queues of accounts. And so on. It's like nesting dolls all the way down.\n\nThere are lots of really fine details to get right: continuations, step parallelism, `connect()` with long running workers all mess with fairness, as do batching, debounce, throttling.\n\nWe wrote about it in some detail here: https://www.inngest.com/blog/building-the-inngest-queue-pt-i.... We'll probably do some deeper dives on this next year, too!\n\nThere are similarities with \"durable workflows\" but, honestly, a completely different approach. Lots of respect for them.\n\nA few critical things:\n\n* Inngest is primarily event driven. You send an event, we run one or more functions.\n\n* Events give you lots of benefits: batching, rate limiting, replay, archiving, fan-out, etc.\n\n* You also get a powerful event-based API in functions: `step.waitForEvent`. This lets you do a lot of things: human in the loop flows, coordination — and you don't have to learn complex APIs, worry about state, can handle timeouts easily.\n\n* And events also let you connect things like webhooks, CDC, external systems to functions with basically zero overhead.\n\n* Because of this, you can pause individual functions, then redrive events through specific functions - as events are stored for you in an OLAP event store for your workspace.\n\nFundamentally, in terms of DX:\n\n* You don't have to register individual activities and workflows. Steps are lambdas. It's easy to work with\n\n* Every step (activity) has an ID, which means versioning, replay, determinism is easier to reason about and see in our model.\n\n* We also run on servers as well as serverless. It's actually quite nice bringing state and retries to serverless functions - they're good for (some) bursty workloads\n\n* We also embed a bunch of flow control into the system for you.\n\nOverall, both replace queueing systems. I think that's a good thing: you shouldn't really have to think about the specifics of your underlying infra when you're writing application code.\n\nAnswered this in depth here: https://news.ycombinator.com/item?id=41605220\n\nThe TL;DR is both us and Temporal help with durable execution. We layer on events and a differing DX to make things easier, faster, and to also work on serverless if people need.\n\nI can't speak to Trigger, as they've changed a lot since I last looked. It doesn't look like they do durable execution, workflows, steps, or events — it looks like they're an alternative to Lambda + SQS for TS only, so very different — more for your simple \"run one thing in the background\", from what I can gather. Take this with a grain of salt, though!\n\nit depends on your load really. there are background job frameworks in other languages like Oban in Elixir that utilizes postgres.\n\nif scale is low, it's not an issue. but once you have high usage, what typically people do is they move it to a separate database, otherwise you're saturating the resources and it starts impacting the application itself.\n\nat that point, that's not much different from external state stored else where.\n\nalso another thing about databases is their ACID transactions can only handle up to certain amount of load. again, if you don't hit that limit, it's totally fine. once you do, which usually means outages, severe delays, etc, and it'll be a shit show.\n\ndisclaimer: I do work at Inngest, but also this is speaking from experience. :)",
      "# [Customer story](https://www.inngest.com/customers/fey)\nFey is a personal finance app that that's making financial research more accessible and effortless for anyone. Built by a small team, the app uses Next.js, Inngest, and Render, leveraging serverless functions wherever appropriate.\n\nThe Challenge: Quickly process massive datasets\n\nFey relies on different financial data providers for data like price history, earnings, analyst estimates, financials, statistics, among many others. At the core of this data-intensive application are data pipelines which fetch, parse, clean, sort, and store the data. Also, different pieces of data come from different providers which adds additional complexity. Most of these complicated pipelines are run on schedules and may contain many discrete steps.\n\nFey needed a tool that can quickly orchestrate tasks and reliably trigger scheduled jobs and which would allow them to easily execute these background processes from the client through an API.\n\nInngest: An SDK that reduces code complexity\n\nInitially, the team used Google Cloud Composer — a platform that, designed for data pipelines, required everything to be written as DAGs in Python and considerable additional customization.\n\nThe technology we were using before was a lot harder and wasn't as efficient. It was difficult to work with events, it required Python (when Fey's tech stack is JavaScript), and deploying was more annoying since it didn't integrate to Vercel. Inngest made it much easier and as a result, we now get much faster data updates in our application.\n\nThe team discovered Inngest by coincidence and quickly saw the potential benefits. Using the Inngest SDK could simplify the hard parts of their problems: it was easier to define pipeline stages as steps and re-usable functions then combine via function invocation.\n\nAs a result, their codebase also significantly simplified and because all of the jobs now lived in a single TypeScript codebase, sharing code, packages, or database helper methods prevented repeated work. Additionally, Inngest's Vercel integration enabled a fully-automated and stress free deployment process.\n\nSimpler code and developer workflow weren't the only improvements. The new data pipelines completed in a fraction of the time of their previous system: on average, data was now processed 50x faster.\n\nFinally, they saw a major reduction in unit costs - workloads that previously cost them $2,800 monthly to run could now be completed for less than $100 due to significant efficiencies. This improved margins and gives them much more room to scale.\n\nAs soon as companies release their data, we want to have it in Fey. With our old tool it would take up to a day for them to show up, which was a result of mostly complicated configuration. And with Inngest now it's like almost instant, maximum 30 minutes.\n\nCombining ingestion with OpenAI\n\nOne of the competitive advantages of Fey is how they use generative AI to enhance stock research reporting.\n\nThere are two features where Fey employs OpenAI. First is summarizing news articles to provide a “human-friendly” rundown of different types financial data.\n\nThe second feature are SEC filings, both 10-Ks and 10-Qs. Fey generates a summary of the highlights, risks, and strengths. In this way, users don't have to deal with the cognitive load of financial jargon.\n\nBoth features are orchestrated using Inngest's step.invoke(), which allows you to asynchronously call another function and handle the result, making it perfect for composing complex workflows with re-usable components.\n\nInngest Benefits\n\nThe adoption of Inngest resulted in several positive outcomes for Fey:\n\nConcise codebase: Inngest's SDK is designed with developers in mind, which results in elegant and self-evident code. Moreover, given that all code lives in a single codebase now, there's no need for duplicated logic in different language codebases.\n\nDecreased context-switching: Connected to the previous point, it is easier to introduce new features because all code lives in the same place. Working across frontend and backend is not necessary anymore.\n\n50x faster execution: When companies release earnings, Fey needs to process this data and serve it to the users, which with the previous provider could take up to a day. With Inngest, the data is available within 30 minutes or most often, instantly.\n\n50x lower bills: Previous provider billed Fey team $2,800 a month. Having switched to Inngest, the bills went down to less than $100 due to significant efficiencies.\n\nConclusion\n\nInngest became Fey's single solution for scheduled jobs, data ingestion, and AI orchestration. The integration of Inngest into Fey's data-intensive processes has increased the efficiency and performance of the application. By simplifying codebase management and reducing redundancy, Inngest contributed to a more cohesive development experience, allowing the team to focus on product innovation. This aligns with Inngest's mission of helping developers focus on just code.\n\nBy integrating Inngest, Fey saw a 50x increase in speed in data processing, while the monthly expenses plummeting from $2,800 to less than $100. This is a testament to how cost-effective Inngest is for companies of all sizes.",
      "# [](https://www.inngest.com/blog/category/engineering)\nThe Principles of Durable Execution Explained\n\n12/10/2024\n\nLearn what Durable Execution is, how it works, and why it's beneficial to your system.\n\nstep.ai: the quickest way to build reliable AI applications on Serverless while saving on compute\n\n12/10/2024\n\nCombining step.run() and step.ai.infer() is the best toolset to build reliable AI applications on Serverless while saving on compute.\n\nIncident report for August 16, 2024 - Function execution outage\n\n8/16/2024\n\nA full report on the incident that caused function execution to fail on August 16, 2024 UTC.\n\nSharding high-throughput Redis without downtime\n\n7/23/2024\n\nRead about how we rolled our new sharded infrastructure out to production without a millisecond of downtime and how it improved Inngest's overall performance.",
      "# [Custom Hacker News summaries in your inbox—build an AI Agent with Inngest and Render](https://render.com/blog/hacker-news-ai-agent-inngest-render)\nFor busy developers, staying on top of AI news today can be overwhelming. If you’re like us, you’ve bookmarked far more tutorials than you’ve read or implemented. And now—here’s another one. So we’re going to make this tutorial hopefully more useful than average. You’ll:\n\nLearn the fundamental pieces of architecture you need to build AI agents and workflows\n\nDeploy a working end-to-end app that features two AI agents within a workflow, and\n\nBe able to use the app you deployed to help you stay on top of AI news (or any other topic)\n\nThe app you’ll build is an AI agent that periodically searches Hacker News for custom questions you’re interested in and then sends you an email summary. For example, you can ask, “What are the most popular new demos that involve AI agents?” or “What are new libraries in the Next.js ecosystem?” The architecture of this bot includes:\n\nInfra hosted on Render: Components include a PostgreSQL database with the pgvector extension, a full-stack Next.js app, and a cron job, which are all hosted on Render. They communicate with each other securely over a private network.\n\nAI workflow orchestrated by Inngest: Inngest provides a framework called AgentKit that lets you easily define and orchestrate AI agents and offers a platform to run them reliably.\n\nSee this GitHub repo for the code and detailed deployment instructions. Let’s dive in!\n\nDemo\n\nFirst, let’s take a look at the app in action: As a quick summary, here’s how you use the app:\n\nEnter your email address: You can provide more than one email address—i.e. this bot can update several people.\n\nEnter topics and questions: For each email recipient, you can specify one or more custom topics and questions for the bot to track and how frequently you want to get updates.\n\nReceive an email, or “Preview” results: At the specified frequency, the bot will scan the latest stories from Hacker News, identify stories that match your questions, and send you an email summary. You can also hit “Preview” in the app to see an immediate result.\n\nArchitecture overview\n\nImage too small? View the full image here. This app consists of three main components:\n\nDatabase: Stores the Hacker News stories (both the original text and vectorized embedding), your email addresses, and topics/questions you’ve specified.\n\nIndexer cron job: Periodically fetches new Hacker News stories based on topics you’re interested in, generates embeddings of the content, and stores the data in the database.\n\nFull-stack Next.js app: Provides the UI that lets you configure email addresses & topics/questions. Also hosts the backend logic of the AI workflow: searching the database for relevant stories, summarizing them, and sending emails.\n\nThese components are all deployed on Render, and can communicate securely with each other on a private network. Let’s take a closer look at each one.\n\nDatabase\n\nThis app stores data in a PostgreSQL database with the pgvector extension. pgvector is an open-source extension that lets you efficiently store and query vector embeddings in PostgreSQL. Your PostgreSQL database can then function as both a relational database and vector database. It’s easy to use pgvector with a managed Render PostgreSQL database. Just run the following command in psql: CREATE EXTENSION IF NOT EXISTS vector;. Our database has three tables, which are defined in the schema.sql file:\n\ninterests: Topics you want to track. For example, “AI agents” or “Next.js”.\n\nquestions: Questions you have about specific interests, and how often you want updates about them.\n\nstories: Stories from Hacker News, including the title, content, and comments. We also store the embedding of the title and content combined.\n\nNote that the schema of the stories table is made possible by pgvector:\n\nCREATE TABLE IF NOT EXISTS stories ( id SERIAL PRIMARY KEY, title TEXT, content TEXT, date DATE, comments TEXT, interest_id INTEGER REFERENCES interests(id), embedding vector(1536) ); -- Create an index on the embedding column for faster similarity searches CREATE INDEX IF NOT EXISTS stories_embedding_idx ON stories USING hnsw (embedding vector_cosine_ops);\n\nIn particular:\n\nThe pgvector extension provides the vector data type that’s used for the embedding column.\n\nWe generate an index on the embedding column using the hnsw (Hierarchical Navigable Small Worlds) function, which is also provided by pgvector. This index makes it faster to identify stories that are similar to the questions we’re interested in.\n\nIndexer cron job\n\nThe second component of our app is the Indexer, which is a cron job that periodically searches Hacker News for each topic you’re interested in. It indexes the top results into the stories database table. In this app, we use Playwright to automate the search for Hacker News stories. Via Playwright, the Indexer visits Algolia’s Hacker News Search, queries for each topic you’re interested in, and extracts stories from the results. You can see the full Playwright logic in searchHackerNews.ts. After the Indexer extracts the stories from Hacker News, it generates an embedding of each story and stores it in the database:\n\nasync function generateEmbedding(text: string): Promise<number[]> { const response = await openai.embeddings.create({ model: \"text-embedding-ada-002\", input: text, }); return response.data[0].embedding; } export async function storeStory(story: Story): Promise<void> { // [...] // Generate embedding from title and content const embedding = await generateEmbedding(`${story.title} ${story.content}`); // Insert new story into `stories` db table await client.query( \"INSERT INTO stories (title, content, date, comments, embedding, interest_id) VALUES ($1, $2, $3::date, $4, $5::vector, $6)\", [ story.title, story.content, story.date, story.comments, `[${embedding.join(\",\")}]`, story.interest_id, ] ); }\n\nFull-stack Next.js app\n\nThe third main component of our app is the full-stack Next.js web app. This app hosts the UI and backend logic that lets you configure your email address as well as the topics and questions you want to be notified about. It stores these settings in the database. On the backend, this app also contains the logic of the AI workflow, which reads your settings and also the stored Hacker News stories from the database. Let’s take a look at how this workflow is built.\n\nHow the AI workflow is implemented\n\nThe AI workflow is orchestrated using Inngest. Inngest is a workflow engine that lets you create backend workflows in TypeScript, Go, and Python. You define steps in your workflow, which can contain any code you write, and optionally conditions that trigger each step. Inngest executes your workflow and handles retries and recovery on failures—even when they happen in the middle of a workflow run. Note that the steps in the workflow are deployed as part of the backend of the Next.js app, and thus all of the logic executes on Render. Inngest’s job is to trigger each step of the workflow at the right time, and it does this by calling an endpoint on the Next.js app. Our AI Workflow starts with a step that fetches the question and interest for the current workflow run from the PostgreSQL database. No AI is needed here, so far:\n\nimport { inngest } from \"./client\"; export const hackerNewsAgent = inngest.createFunction( { id: \"hacker-news-agent\", }, { event: \"hacker-news-agent/run\" }, async ({ event, db, step }) => { const { interest_id, question_id } = event.data; // By wrapping code in step.run(), // the code will be retried if it throws an error. // If successful, its result is saved to prevent unnecessary re-execution. const { interest, question } = await step.run( \"fetch-interest-and-question\", async () => { const interest = await db.query( \"SELECT * FROM interests WHERE id = $1 LIMIT 1\", [interest_id] ); const question = await db.query( \"SELECT * FROM questions WHERE id = $1 LIMIT 1\", [question_id] ); return { interest: interest.rows[0], question: question.rows[0] }; } ); if (!interest || !question) { console.warn( \"[HackerNewsAgent] Interest or question not found, aborting\" ); return; } } );\n\nThen, we use Inngest’s AgentKit TypeScript library to power the AI agent part of our AI workflow. This library makes it easier to create agents, which require more flexibility than statically written workflows. Notably, the library lets you dynamically execute code based on the LLM’s reasoning. Our app defines two AI agents: a Search Agent and a Summarizer Agent.\n\nThe Summarizer Agent: an agent that uses state\n\nLet’s take a look at the Summarizer Agent first. The Summarizer Agent actually runs after the Search Agent in our workflow, but it’s simpler and easier to understand. The AgentKit library lets you define agents that each accomplishes specific subtasks (e.g. “search Next.js posts”, “summarize these 4 posts”) of your overall goal (e.g. answer “What are the latest Next.js tools?”). To create our Summarizer Agent, we specify a name, description, and then a system function:\n\nimport { createAgent } from \"@inngest/agent-kit\"; const summarizerAgent = createAgent({ name: \"Summarizer Agent\", description: \"Summarize the results of the search agent\", system: ({ network }) => { const searchResults = network?.state.kv.get(\"search-result\"); const trendsResults = network?.state.kv.get(\"trends-result\"); const prompt = ` Prepare the answers to the questions based on the results of the search agent. If the user is interested in trends, use the trends-result to answer the questions and provide a summary of the trends. If the user is not interested in trends, use the search-result to answer the questions. The user is interested in ${ interest.name }. They asked the following questions: <questions> ${question.question} </questions> The search agent found the following results online: <search-results> ${(searchResults || []).join(`\\n`)} </search-results> The trends agent found the following trends: <trends-results> ${(trendsResults || []).join(`\\n`)} </trends-results> Provide you answer wrapped in <answer> tags. `; return prompt; }, / ... });\n\nThe meat of this agent is in the system function. Note that this function receives all state that’s saved from earlier steps in the AgentKit network. The Summarizer Agent reads two pieces of state, searchResults and trendsResults, and summarizes them. As we’ll see, these two pieces of state are generated by the Search Agent. In AgentKit, you can specify tools that each agent can use. The agent can dynamically call these tools to achieve its goal. Our Search Agent comes with two valuable tools: search and identify-trends:\n\nimport { createAgent, createTool, } from \"@inngest/agent-kit\"; const searchAgent = createAgent({ name: \"Search Agent\", description: \"Search Hacker News for a given set of interests\", system: `You are a search agent that searches Hacker News for posts that are relevant to a given set of interests. Today is ${ new Date().toISOString().split(\"T\")[0] }. Search for posts from the last ${frequencyToRelativeHuman( question.frequency )} period.`, tools: [ createTool({ name: \"search\", description: \"Search Hacker News for a given set of interests\", parameters: z.object({ query: z.string(), startDate: z.string(), endDate: z.string(), }), handler: async (input, { network }) => { // ... }, }), createTool({ name: \"identify-trends\", description: \"Identify trends on Hacker News for a given set of interests\", parameters: z.object({ query: z.string(), startDate: z.string(), endDate: z.string(), }), handler: async (input, { network }) => { // ... }, }), ], });\n\nLet’s take a closer look at the identify-trends tool. This tool helps the Search Agent answer questions involving trends, such as “What are the most popular devtools?”\n\nimport { createAgent, createTool, } from \"@inngest/agent-kit\"; const searchAgent = createAgent({ name: \"Search Agent\", // ... tools: [ // ... createTool({ name: \"identify-trends\", description: \"Identify trends on Hacker News for a given set of interests\", parameters: z.object({ query: z.string(), startDate: z.string(), endDate: z.string(), }), handler: async (input, { network }) => { console.info(\"[HackerNewsAgent] Identifying trends\", input); // Generate embedding for the query const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY, }); const embedding = await openai.embeddings.create({ model: \"text-embedding-ada-002\", input: input.query, }); // Find similar stories using vector similarity const similarStories = await db.query( `WITH similar_stories AS ( SELECT title, content, date::timestamp as date, comments, (embedding <=> $1::vector) as distance FROM stories WHERE (embedding <=> $1::vector) < 0.3 AND interest_id = $2 AND date >= $3::date AND date <= $4::date ORDER BY date DESC ) SELECT date_trunc('day', date) as story_date, COUNT(*) as story_count, STRING_AGG(title, ' | ' ORDER BY date DESC) as titles FROM similar_stories GROUP BY date_trunc('day', date) ORDER BY story_date DESC LIMIT 10`, [ `[${embedding.data[0].embedding.join(\",\")}]`, interest.id, input.startDate, input.endDate, ] ); // Format results to show trends const result = similarStories.rows.map((row) => { const date = new Date(row.story_date).toLocaleDateString(); return `Date: ${date}\\nNumber of Related Stories: ${row.story_count}\\nTitles: ${row.titles}\\n\\n`; }); console.info( \"[HackerNewsAgent] Trends results:\", input.query, result.length ); network?.state.kv.set(\"trends-result\", result); return result; }, }), ], });\n\nNote that tools can receive input parameters. Here, the identify-trends tool takes in a query, startDate, and endDate. Here’s how the identify-trends tool works:\n\nFirst, it creates an embedding from the input query. Notably, we must use the same model (OpenAI’s \"text-embedding-ada-002\") that the indexer cron job uses to create the embeddings of each Hacker News story.\n\nNext, it queries the PostgreSQL database to retrieve stories similar to the input query. Specifically, it looks for similar_stories, which consists of stories that the indexer cron job found for our given “interest” that have a similarity distance that’s < 0.3 (indicating strong similarity). Then, it aggregates the stories by day, returning a total count of stories for each day and a concatenated list of all of the titles of stories from that day.\n\nThe Network: combining and routing our agents\n\nOnce we’ve defined our agents and their tools with AgentKit, we combine them into a network. As we mentioned earlier, the network gives agents the ability to write to and read from shared state. In a network, you can also write custom routing logic that determines when each agent should be used. For example, in our app, we specify that we should only call the Summarizer Agent if there are search results or trend results in our shared state. (Otherwise, there would be nothing to summarize!)\n\nimport { openai } from \"inngest\"; import { createNetwork, getDefaultRoutingAgent, } from \"@inngest/agent-kit\"; const model = openai({ model: \"gpt-4\" }); const network = createNetwork({ agents: [searchAgent.withModel(model), summarizerAgent.withModel(model)], defaultModel: model, maxIter: 4, defaultRouter: ({ network }) => { if (network?.state.kv.has(\"answers\")) { return; } else if ( network?.state.kv.has(\"search-result\") || network?.state.kv.has(\"trends-result\") ) { return summarizerAgent; } return getDefaultRoutingAgent(); }, }); const result = await network.run( `I am passionate about ${interest.name}. Answer the following questions: ${question.question}` );\n\nAfter we create the network, we can run it by calling network.run with a prompt. See the AgentKit docs to learn more about the three types of network routing.\n\nSending email: the final step\n\nThe final step of our workflow is sending the summary email. This step also does not require any AI, so we implement it as a regular Inngest workflow step:\n\nif (result.state.kv.has(\"answers\") && !event.data.preview) { await step.run(\"send-email\", async () => { console.info(\"[HackerNewsAgent] Preparing to send email\"); const answers = result.state.kv.get(\"answers\"); if (!event.data.preview) { const { data, error } = await resend.emails.send({ from: \"Hacker News Agent <onboarding@resend.dev>\", to: interest.email, subject: `Your Hacker News Agent Update on ${interest.name}`, text: `Here are the answers to \"${question.question}\":\\n\\n${answers}`, }); // …\n\nThat wraps up our AI workflow. You can find the full workflow defined in this code file. To summarize, Inngest orchestrates the steps in our Hacker News AI Agent, which we define as part of the backend of our Next.js app using Inngest’s AgentKit framework. The main pieces of this workflow (Search -> Summarize -> Send email) always run in the same order, but the Search Agent is able to dynamically leverage its tools (search and identify-trends) to extract the most relevant information from our vector database.\n\nTry it out\n\nNow that you know how the app works, you can try to deploy it!\n\nGet the code. Visit this GitHub repo to get the code.\n\nFollow the README. The README contains detailed instructions to help you deploy each component of this app on Render: the database, indexer cron job, and Next.js web service.\n\nAdd your own features. We invite you to extend the app. Here are two ideas that could make this app even more useful:\n\nIn the emails, add links to the original Hacker News articles.\n\nEnable yourself to ask follow-up questions by replying to an email.\n\nTo go deeper on the tech stack, you can:\n\nLearn more about Render: See the different services types you can deploy on Render, and understand how to combine multiple services into a single app.\n\nLearn more about Inngest: Explore Inngest’s TypeScript SDK and AgentKit documentation.\n\nRead about a production use case: Read how Fey uses both Render and Inngest to build their AI-powered personal finance app.\n\nRender takes your infrastructure problems away and gives you a battle-tested, powerful, and cost-effective cloud with an outstanding developer experience.\n\nFocus on building your apps, shipping fast, and delighting your customers, and leave your cloud infrastructure to us.",
      "# [Elixir SDK Support In The Roadmap? by andrzej-mag on 2024-06-16](https://community.temporal.io/t/elixir-sdk-support-in-the-roadmap/12513)\nHey All,\n\nJust wondering if anyone knows of plans for an ELixir SDK? I see this: How much work is it to write an SDK? that hasn’t had any movement for some time.\n\nSeems like the only language missing in this ectosystem, and I think it would be great to see elixir supoprted here. Additionally, I’m seeing other similar projects like inngest where they are taking a crack at elixir support.\n\nI think the warning that this is likely a 6 month plus task maybe put a lot of people off just beginning this, is there any docs anywhere that might help with building out a bare bones api for this?\n\nAlso, there is already a protobuff generated elixir project here temporalio | Hex which looks like a good start.\n\nChris\n\nHey @andrzej-mag did you make any progress in this endeavor?\n\nIf so, do you have a public GitHub repo to see the state of play?\n\nOne thought, while it’s amazing to have a fully fledged feature complete version, I think there’s a lot of value in just a partial solution.\n\nFor example just bring able to bundle up Erlang/elixir activities, with limited functionality, and have workflows defined in other languages may still be valuable.\n\nChris\n\nHi Chris,\n\nProject is advancing steadily however it is not ready for publishing yet. Tentative project schedule was provided in my previous answer.\n\nAs you mentioned Temporal activities, quick preview of current WIP Erlang SDK activities API implementation:\n\n-module(temporal_sdk_activity). -export([ await/0, await/1, cancel/1, complete/1, fail/3, heartbeat/0, is_cancel_requested/0, elapsed_time/0, remaining_time/0, get_data/0, get_failure_info/0, get_last_heartbeat/0, set_data/1, set_failure_info/1 ]). -include(\"temporal_sdk_proto.hrl\"). -type task() :: ?TEMPORAL_SPEC:'temporal.api.workflowservice.v1.PollActivityTaskQueueResponse'(). -export_type([task/0]). -type data() :: term(). -export_type([data/0]). -type last_heartbeat() :: term(). -export_type([last_heartbeat/0]). -type context() :: #{ cluster := temporal_sdk_cluster:cluster_name(), executor_pid := pid(), otel_ctx := otel_ctx:t(), worker_opts := temporal_sdk_worker:opts(), task := task(), started_at := SystemTime :: integer(), is_cancel_requested := boolean(), task_timeout := erlang:timeout(), data := data(), last_heartbeat := last_heartbeat() }. -export_type([context/0]). -type fail_reason() :: {Message :: term(), Source :: term(), Stacktrace :: term()}. -export_type([fail_reason/0]). -type handle_event_result() :: term(). -export_type([handle_event_result/0]). %% ------------------------------------------------------------------------------------------------- %% behaviour -type cancel_action() :: {cancel, CanceledDetails :: temporal_sdk:term_to_payloads()}. -type complete_action() :: {complete, Result :: temporal_sdk:term_to_payloads()}. -type fail_action() :: {fail, Reason :: fail_reason()} | {fail, Reason :: fail_reason(), FailureInfo :: temporal_sdk_worker:failure_info()}. -type terminate_action() :: cancel_action() | complete_action() | fail_action(). -type heartbeat_action() :: heartbeat | {heartbeat, Heartbeat :: temporal_sdk:term_to_payloads()}. -callback execute(Context :: context(), Args :: temporal_sdk:term_from_payloads()) -> Result :: temporal_sdk:term_to_payloads(). -callback handle_heartbeat(Context :: context()) -> terminate_action() | heartbeat_action(). -callback handle_cancel(Context :: context()) -> terminate_action() | ignore. -callback handle_call(Context :: context(), From :: gen_statem:from(), Request :: term()) -> handle_event_result() | ignore. -callback handle_cast(Context :: context(), Request :: term()) -> handle_event_result() | ignore. -callback handle_info(Context :: context(), Info :: term()) -> handle_event_result() | ignore. -optional_callbacks([ handle_heartbeat/1, handle_cancel/1, handle_call/3, handle_cast/2, handle_info/2 ]). %% ------------------------------------------------------------------------------------------------- %% public -spec await() -> handle_event_result() | no_return(). await() -> await(infinity). -spec await(Timeout :: erlang:timeout()) -> handle_event_result() | no_return() | timeout. await(Timeout) -> % implementation follows...\n\nProject is moving forward, (full) SDK implementation is almost complete. Few minor items like Nexus or documentation are still missing - I need some more time.\n\nActivities API mentioned above is now cleaner and simpler:\n\n-module(temporal_sdk_activity). -export([ await_data/1, await_data/2, complete/1, cancel/1, fail/3, heartbeat/0, heartbeat/1, is_cancel_requested/0, is_activity_paused/0, elapsed_time/0, elapsed_time/1, remaining_time/0, remaining_time/1, get_data/0, get_failure_info/0, get_last_heartbeat/0, set_data/1, set_failure_info/1 ]). -type context() :: #{ cluster := temporal_sdk_cluster:cluster_name(), executor_pid := pid(), otel_ctx := otel_ctx:t(), task := temporal_sdk_api_activity_task:task(), worker_opts := temporal_sdk_worker:opts(), started_at := SystemTime :: integer(), task_timeout := erlang:timeout() }. -export_type([context/0]). -type handler_context() :: #{ data := data(), is_cancel_requested := boolean(), is_activity_paused := boolean(), last_heartbeat := heartbeat(), elapsed_time := non_neg_integer(), remaining_time := erlang:timeout() }. -export_type([handler_context/0]). -type data() :: term(). -export_type([data/0]). -type heartbeat() :: temporal_sdk:term_to_payloads(). -export_type([heartbeat/0]). %% ------------------------------------------------------------------------------------------------- %% behaviour -type complete_action() :: {complete, Result :: temporal_sdk:term_to_payloads()}. -type cancel_action() :: {cancel, CanceledDetails :: temporal_sdk:term_to_payloads()}. -type fail_action() :: {fail, { Source :: temporal_sdk:serializable(), Message :: temporal_sdk:serializable(), Stacktrace :: temporal_sdk:serializable() }}. -type terminate_action() :: cancel_action() | complete_action() | fail_action(). -type heartbeat_action() :: heartbeat | {heartbeat, Heartbeat :: heartbeat()}. -type data_action() :: {data, NewData :: data()}. -callback execute(Context :: context(), Args :: temporal_sdk:term_from_payloads()) -> Result :: temporal_sdk:term_to_payloads(). -callback handle_heartbeat(HandlerContext :: handler_context()) -> terminate_action() | heartbeat_action(). -callback handle_cancel(HandlerContext :: handler_context()) -> terminate_action() | ignore. -callback handle_message(HandlerContext :: handler_context(), Message :: term()) -> terminate_action() | data_action() | ignore. -optional_callbacks([ handle_heartbeat/1, handle_cancel/1, handle_message/2 ]).\n\nHi,\n\nMy current best estimate is 2-3 months to RC1 release.\n\nI have considered releasing a partial implementation many times. Erlang SDK introduces a number of unique, interrelated core features and concepts that were improved and have matured in recent months. Such new additions need to be supported with solid documentation and examples which are not ready yet. As I mentioned before some other smaller pieces like Nexus are still work in progress. In my opinion publishing incomplete and undocumented complex software with frequently changing APIs would cause a lot of confusion, and this is the main reason for not releasing this yet.\n\nGood work @andrzej-mag, being a long time since I thought of this and ended up using various other flavors of the sdk, but an Erlang and elixir flavor would be more then welcome.\n\nHonestly, I think you should just make what you have public …at this stage nobody is expecting anything other than constant breaking changes and a half dine solution… and you can always disable any GitHub issues etc.\n\nBut not too push, I’m glad you taken up they mantel in this either way. Keep up they good work.",
      "# [Building Production Workflows for AI Applications by Tony Holdstock-Brown, Yoko Li, Derrick Harris, Zeno Rocha, Matt Biilmann, Martin Casado, Guido Appenzeller, Marco Mascorro, Brian Long, Dylan Ayrey on 2024-06-14](https://a16z.com/podcast/building-production-workflows-for-ai-applications/)\nIn this episode of the AI + a16z podcast, Inngest cofounder and CEO Tony Holdstock-Brown joins a16z partner Yoko Li to discuss the reality and complexity of running AI agents and other multistep AI workflows in production. Tony also shares why developer tools for generative AI — and their founders — might look very similar to previous generations of these products, and where there are opportunities for optimization.\n\nHere’s a sample of the discussion, where Tony shares some advice for engineers looking to build in AI:\n\n“We almost have two parallel tracks right now as, as engineers. We’ve got the CPU track in which we’re all like, ‘Oh yeah, CPU-bound, big O notation. What are we doing on the application-level side?’ And then we’ve got the GPU side, in which people are doing like crazy things in order to make numbers faster, in order to make differentiation better and smoother, in order to do gradient descent in a nicer and more powerful way. The two disciplines right now are working together, but are also very, very, very different from an engineering point of view.\n\n“This is one interesting part to think about for new engineers, people that are just thinking about what to do if they want to go into the engineering field overall. Do you want to be on the side using AI, in which you take all of these models, do all of this stuff, build the application-level stuff, and chain things together to build products? Or do you want to be on the math side of things, in which you do really low-level things in order to make compilers work better, so that your AI things can run faster and more efficiently? Both are engineering, just completely different applications of it.”",
      "# [Customer Story - Fey](https://render.com/customers/fey)\nFey is an easy-to-use research tool that helps savvy individuals make better financial choices. Back in February, their team made some savvy financial choices of their own by simplifying their infrastructure.\n\nBy making three changes, the Fey team saved over $72,000 a year. They migrated:\n\nFrom an overprovisioned Google Kubernetes Engine (GKE) cluster to Render\n\nFrom Cloud Composer (Google Cloud’s managed Airflow product) to Inngest\n\nFrom a human-powered data vendor to OpenAI\n\nWe sat down with Dennis Brotzky, CTO/co-founder at Fey, to understand how and why they migrated, and to learn more about how Fey uses generative AI to enhance stock research. (Spoiler: It’s not with a chatbot.)\n\nDennis, who graduated from college with degrees in psychology and music, took a nontraditional path into tech startups. He shares his serendipitous journey into software, and lessons for aspiring startup founders in the early stages.\n\nFey is financial research, made sleek\n\nRender: Tell us a bit about Fey. What does it do, and how are you different?\n\nDennis: Fey helps you quickly and easily research stocks, so you can make informed financial decisions. Think of Fey as a sleek, beautiful version of Bloomberg Terminal built for individuals.\n\nFey makes research simple:\n\nJust one app: Fey lets you look up any information about a stock in a single app. Fey pulls together a stock’s historical financials, current news, insider trades, SEC filings, and more. Usually, you have to check many sites to get this information.\n\nSimple UI: Fey is easy to use. Our stock overviews show summaries of the most important stats, and let you drill into just the details you want to see. Our stock screener lets you begin a stock search with one attribute, whereas other apps expose hundreds of attributes by default.\n\nSmart summarization: Fey helps you quickly digest news and reports, by using generative AI to create short summaries of these types of financial data.\n\nHow Fey uses GPT-4 to accelerate research\n\nRender: Can you say more about Fey’s generative AI features? How did you build them?\n\nDennis: Two places we use genAI are in news stories and SEC filings. Fey shows you recent news headlines for each stock, and you can click on any headline to get a two-sentence summary of the article. You can also read a summary of any SEC filing, both 10-Ks and 10-Qs. Fey generates a summary of the highlights, risks, and strengths.\n\nThese features are now implemented with OpenAI’s GPT-4 model via their Assistants API. Our architecture has evolved over time: before our big tech stack migration in February, we pulled the news summaries from a human-powered news aggregator. At one point, we explored storing vectors of the parsed SEC reports into Pinecone, but found we didn’t need to store these vectors for our use case.\n\nWe did spend a lot of time and effort on prompt engineering, and we sought guidance from the OpenAI team. For the SEC filings, we got the best results from splitting each filing into several pieces and running different prompts on each piece. We also found all sorts of optimizations. For example, in the version of GPT-4 we’re using, we ask for results in Markdown instead of JSON, because we found that gives us more consistent results. These optimizations are specific to each version of GPT, and we expect them to change as OpenAI releases new models.\n\nMigrating from GCP to Render and Inngest—saving headaches and costs\n\nRender: Let’s talk about your big tech stack migration. Why did you migrate, and where did the savings come from?\n\nDennis: In January, I knew we needed a change. Our Google Cloud Platform (GCP) bill was excessive, and our setup on GKE and Cloud Composer was hard to understand and interfered with building our product. It took us a lot of time to configure simple things like environment variables. Our team is extremely product-focused, and managing infra doesn’t give us joy. Google Cloud’s pricing was also complex, which made it hard to understand our growing bill.\n\nSo in February, we buckled down to find and migrate to new providers that were easier for us to use.\n\nIn the end, two changes we made accounted for about $60k—over 80%—of our annual cost savings:\n\nRight-sizing our compute: We migrated from our overprovisioned infra on GKE to right-sized compute on Render. This migration took the least time: only 1-2 hours.\n\nScheduling our data jobs more efficiently: We migrated off Cloud Composer to Inngest, which offers serverless background jobs with a simple step-based pricing scheme. We then updated our data-fetching jobs to run only when new data was available, rather than on a fixed schedule.\n\nThe other 20% in savings came from migrating away from the human-powered news aggregator to OpenAI’s GPT-4.\n\nWhy Render?\n\nRender: We’re glad to hear Render was easy to migrate to. Why did you pick Render?\n\nDennis: I was looking for a platform where the following things would be easy to use:\n\nPricing: Easy-to-understand monthly billing.\n\nEnvironments: An easy way to set up production and staging environments. Render projects check this box.\n\nRedis: We had a specific need to support Redis, so it was convenient that Render offers managed Redis.\n\nService setup and configuration: An easy way to spin up additional services, and to set up environment variables. Render’s environment groups are great.\n\nDocumentation and examples: Render’s documentation was clear and covered what I needed.\n\nThe biggest factor was that Render just worked. I tried to deploy our main backend, a pricing service, on Render, and it worked right away. This surprised me; I was used to battling Google Cloud over all kinds of things: to get yarn working, to configure permissions to deploy certain things, to configure internal IPs and set up a custom domain, and so on. On Render, I saw one build error, caused by extra files I’d pushed to GitHub. I fixed that, and then I got a working URL. It took me 1-2 hours total to migrate our entire backend.\n\nI also evaluated alternatives. In comparison, I found the information on Render—from marketing site to docs—to be easier to navigate and use. Render gave the impression of a platform that was more mature, which is what I’m looking for in an infrastructure provider.\n\nPush to deploy, a favorite Render feature\n\nRender: What’s something you’ve found delightful or surprising on Render?\n\nDennis: This is a simple thing, but I like that Render autodeploys services on each git commit. I’d previously encountered autodeploys for frontend apps using Netlify and Vercel, but this was my first time seeing it on a full-stack hosting platform like Render.\n\nA nontraditional journey to tech startup CTO\n\nRender: We found your original portfolio from ten years ago. It’s beautiful and tells an unusual story. Can you tell us about your journey to co-founding a tech startup?\n\nDennis: I discovered tech by accident. During my undergrad at McGill, I majored in psychology and minored in music. I’ve always been interested in the brain and why people do the things they do. I also used to DJ underground techno and house music. By underground, I mean: if it already had a thousand views on YouTube, it wasn't for me.\n\nI knew my job prospects with just a bachelors in psychology wouldn’t be great. So in my second to last semester, on a whim, I took a class called Music and the Internet. It was an eight-person class, very small and niche for my minor. The professor was really cool. In the class, he taught us about JavaScript and showed us a for loop. He taught us a bit about HTML and CSS. I didn’t really get it at first. I was like, “What do you mean, it just prints ‘Hello’ ten times?”\n\nNear the end of the semester, on a Monday, he challenged us to build a website for our favorite artist. The class would vote on the best website that Friday, and the winner would get a 1% bonus on their total grade. I started building the site, and got really into it. For every hour of that week, I was building this site and looking up how to do everything: line breaks, onClick handlers, different CSS attributes. That Friday, people were blown away by what I built, and I won the bonus percentage. I found coding to be really fun.\n\nSo the next semester, I took the equivalent of CS 101, a basic Java programming class. To my surprise, I did poorly. It was disheartening. I was a fourth year student in a class with mostly first year students who were doing a lot better than me. Meanwhile, I was having trouble grasping nested for loops.\n\nI could have given up then. After I graduated, I got a part-time job making 10 dollars an hour cataloging classical music CDs to sell on Amazon. I worked in Excel all day in a dingy one room warehouse, and I hated it. But that pain was good motivation. I studied all the JavaScript and web development books I could get my hands on in my spare time.\n\nFinally, I applied to and got my first frontend development job at Lightspeed, which is one of Canada’s best-known tech companies alongside Shopify. This changed everything for me. At Lightspeed, I met Thiago, who’s now one of my co-founders at Fey.\n\n“Harder than it looks”—but easier with Render\n\nRender: What would you share with someone looking to build a tech startup?\n\nDennis: I’d say first, everything is a lot harder than it looks. It took me a week to build my first website, months of studying to get a job, and years of work to feel confident in my craft. Building a company has been like that too.\n\nWhen you build a company, you’re forced into so many difficult, uncomfortable situations. It’s been brutal at times. I think that’s why founders have such respect for each other: we know the pain and sacrifice we’ve been through.\n\nBut it’s worth it, and I’d do it again. You grow. You learn you can push through the hardship.\n\nIf I could start again, though, I’d start with Render instead of GCP.\n\nRender: Thanks so much Dennis! Where can folks find you if they want to get in touch or learn more about Fey?",
      "# [AWS Step Functions · Issue #4660 · sst/sst](https://github.com/sst/ion/issues/376)\nAny chance the way step functions are built with CDK could be copied for Ion? The default pulumi def is a pain to use.\n\nCDK: https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_stepfunctions-readme.html",
      "# [Running Durable Workflows in Postgres using DBOS by github.com on 2024-12-10](https://supabase.com/blog/durable-workflows-in-postgres-dbos)\nMichael Stonebraker is the inventor of Postgres and a Turing Award winner. His latest venture is DBOS, a three-year joint research project between Stanford and MIT. The DBOS team have built a Durable Workflow engine using Postgres. It's one of the more elegant designs I've seen, leveraging the features of Postgres to keep it lightweight and fast.\n\nThe DBOS team have released a Supabase integration, so you can use your Postgres database as a durable workflow engine.\n\nContinue reading or just get started?\n\nI really love the design of DBOS, so I'm going to write more below. Their design is aligned with our philosophy at Supabase: “just use Postgres”. I'll take you through the lower-level details in the rest of this post. If you just want to get started using DBOS with Supabase, get started using their tutorial:\n\nUse DBOS With Supabase →\n\nWhat's a Durable Workflow engine?#\n\nLet's start with a common situation where a workflow is useful: you're running an e-commerce platform where an order goes through multiple “steps”:\n\nThe process is simple, but writing a robust program for this is surprisingly difficult. Some potential problems:\n\nYou get to step 2, “Check Inventory”, and you're out of stock. You need to wait 24 hours for the new inventory before you can ship it. You need that “step” to sleep for a day.\n\nYour program crashes during step 3, “Ship Order”, and it doesn't record that you've shipped the inventory. You end up sending the same order twice.\n\nA Durable Workflow Engine helps with these problems (and more). There are a few on the market that provide different architectures like Oban, Trigger.dev, Inngest, Windmill, Temporal, and AWS Step Functions.\n\nDBOS offers a relatively unique approach to Workflows, storing the state in your own Postgres database. Let's explore how DBOS does it.\n\nWhat is DBOS?#\n\nDBOS is a platform where you can write your programming logic in serverless functions (similar to Supabase Edge Functions). Functions can be written in either Python or TypeScript.\n\nCreating workflows with decorators#\n\nOne thing that's different to Supabase Edge Functions is the ability to add decorators to your Functions with DBOS.step() and DBOS.workflow():\n\nWhen you do this, DBOS stores the “state” of every step in Postgres:\n\nThis is the part I find the most interesting! If you're a gamer, it's a bit like having a “save point” in your programs. If a Function fails at any point, a new Function can start, picking up at the last checkpoint.\n\nStoring function state in Postgres#\n\nWhen you create an application with DBOS, they create a new database inside your Postgres cluster for storing this state.\n\nUsing their “Widget Store” example, you can see two new databases -\n\nwidget_store: for storing the application data\n\nwidget_store_dbos_sys: for storing the workflow state.\n\nThe widget_store_dbos_sys database holds the workflow state:\n\nWorkflow logic#\n\nThe DBOS team were kind enough to share some of the logic with me about how their workflow engine works:\n\nWhen a workflow starts, it generates a unique ID and stores it in a Postgres workflow_status table with a PENDING status. It also stores its inputs in Postgres.\n\nEach time a step completes, it stores its output in a Postgres operation_outputs table.\n\nWhen a workflow completes, it updates its status in the Postgres workflow_status table to SUCCESS (or to ERROR, if it threw an uncaught exception).\n\nError logic#\n\nIf a program is interrupted, on restart the DBOS library launches a background thread that resumes all incomplete workflows from the last completed step.\n\nIt queries Postgres to find all PENDING workflows, then starts each one. Because workflows are just Python functions, it can restart a workflow by simply calling the workflow function with its original inputs, retrieved from Postgres.\n\nAs a workflow re-executes, before trying each step, it first checks Postgres to see if that step was previously executed. If it finds the step in Postgres, it doesn't re-execute the step, instead re-using its original output.\n\nEventually, the workflow reaches the first step whose output isn't stored in Postgres and resumes execution from there - “resuming from the last completed step.”\n\nAll this works because workflows are deterministic, so they can re-execute them using stored step outputs to recover their pre-interruption state.\n\nThe benefits of using Postgres#\n\nDBOS isn't the first to create a workflow engine. Others in the market include Temporal and AWS Step Functions. DBOS provides a number of benefits over workflow engines that use external orchestrators like AWS Step Functions:\n\nPerformance#\n\nBecause a step transition is just a Postgres write (~1ms) versus an async dispatch from an external orchestrator (~100ms), it means DBOS is 25x faster than AWS Step Functions:\n\nExactly-once execution#\n\nDBOS has a special @DBOS.Transaction decorator. This runs the entire step inside a Postgres transaction. This guarantees exactly-once execution for databases transactional steps.\n\nIdempotency#\n\nYou can set an idempotency key for a workflow to guarantee it executes only once, even if called multiple times with that key. Under the hood, this works by setting the workflow's unique ID to your idempotency key.\n\nOther Postgres features#\n\nSince it's all in Postgres, you get all the tooling you're familiar with. Backups, GUIs, CLI tools - you name it. It all “just works”.\n\nGet started#\n\nTo get started with DBOS and Supabase, check out their official integration docs:",
      "# [Scaling DevTools](https://scalingdevtools.com/blog/i-interviewed-100-devtools-founders/)\n",
      "# [Framework Wars are Dead! Get them All at this event (Free!) by Anthony Gore on 2024-05-08](https://vuejsdevelopers.com/2024/05/08/fen-announement-article/)\nCalling all framework fans, code enthusiasts, and anyone who loves building awesome things with code! Vue School has announced an exciting new conference coming our way. Introducing: Frontend Nation, the LARGEST FREE ONLINE FRONTEND EVENT. EVER.\n\nMark your calendars! From June 4th to 7th, 2024, Frontend Nation will be bringing together the brightest minds in frontend development for three incredible days of learning, sharing, and collaboration and one day of live coding with the experts!\n\nWhy Frontend Nation?\n\nForget framework wars! The creators of Frontend Nation believe that a shared passion for building a better web transcends the tools we use. Frontend Nation is your chance to connect with fellow developers, regardless of your preferred framework.\n\nWhat do they have lined up?\n\nGet ready for a 4-day extravaganza featuring talks from 40**+** industry superstars across frameworks and technologies. Here's a taste:\n\nVue.js: Evan You (Vue and Vite creator), Alex Kyriakidis (Vue School founder), Anthony Fu (Vitest creator), Jessica Sachs (Ionic Framework engineer)\n\nReact: Kent C. Dodds (React superstar), Tejas Kumar (Fluent React author), Sylwia Vargas (DevRel Lead at Inngest)\n\nAngular: Minko Gechev (Angular Product Lead at Google), Mike Hartington (Ionic Framework DevRel Director), Alain Chautard (Angular GDE & Google Maps expert)\n\nNuxt: Sébastien Chopin (Nuxt creator), Daniel Roe (Nuxt Head of Framework), Pooya Parsa (Nitro & UnJS creator)\n\nBeyond the Big Three: Frontend Nation isn't just about the usual suspects. There will also be talks and workshops covering hot technologies like Astro, Vite, Tailwind, Inertia, and more.\n\nAfter 3 days of awesome talks, there will be a dedicated day with live coding workshops. Dive into Vue.js, Angular, or React with industry experts guiding you step-by-step. Choose your track and get ready to build something awesome alongside the best.\n\nTopics you want to hear\n\nBeyond the amazing speakers and workshops, Frontend Nation offers a wide variety of talks on hot topics relevant to all frontend developers:\n\nAccessibility for all: Get practical guidance on implementing web accessibility best practices.\n\nOpen source mastery: Gain insights and strategies for contributing to and maintaining open-source projects.\n\nDeceptive design traps: Learn how to identify and avoid user experience pitfalls in your apps.\n\nThe joy of creative coding: Unleash your creativity with a playful exploration of browser-based engineering.\n\nCutting-edge concepts: Unpack the mysteries of building for the edge, especially with Nuxt.js.\n\nDocs that empower: Discover how to write documentation that truly helps users, not just fills space.\n\nWant to contribute to the success of Frontend Nation? Here’s what you can do next.\n\nSign up for FREE to claim your spot and get updates.\n\nMark your calendars! Frontend Nation takes place June 4th-7th, 2024. ️\n\nSpread the Frontend Love! Follow Frontend Nation on social media and share the excitement with fellow frontend devs. The more the merrier! (Twitter, Slack, Discord – you name it!)\n\nInterested in becoming an event sponsor? Check out the various sponsor packages they have available and get your brand seen.\n\nWant to have your community featured in Frontend Nation? ****Complete a short form to gain access to exclusive marketing materials, win prizes for your members, and get featured at the event.\n\nSee you there!",
      "# [The Rise of AI Agent Infrastructure by Coral Garnick on 2024-06-05](https://www.madrona.com/the-rise-of-ai-agent-infrastructure/)\n(For a more recent AI Infrastructure market map, see Jon Turow’s story from March 2025.)\n\nAn explosion of GenAI apps is plain to see, with applications for productivity, development, cloud infrastructure management, media consumption, and even healthcare revenue cycle management. That explosion is made possible by rapidly improving models and the underlying platform infrastructure our industry has built over the past 24 months, which simplified hosting, fine-tuning, data loading, and memory — and made it easier to build apps.\n\nAs a result, the eyes of many founders and investors have turned north to the top of the stack, where we can finally start to put our most advanced technologies to work for end-users. But the blistering pace of GenAI development means few assumptions hold true for long. Apps are now being built in a new way that will impose new requirements on the underlying infrastructure. Those developers are speeding across a half-finished bridge. Their apps won’t achieve their full potential if our industry fails to support them lower in the stack with a new set of AI agent Infrastructure components.\n\nThe Rise of Agents\n\nOne key change is the rise of AI agents: autonomous actors that can plan and execute multi-step tasks. Today, AI agents — not direct prompts to the underlying model — are becoming a common interface that end-users encounter and even becoming a core abstraction that developers build upon. This is further accelerating how fast new apps can be built and is creating a new set of opportunities at the platform layer.\n\nStarting with projects like MRKL in 2022 and ReAct, BabyAGI, and AutoGPT in 2023, developers started to find that chains of prompt and response could decompose large tasks into smaller ones (planning) and execute them autonomously. Frameworks like LangChain, LlamaIndex, Semantic Kernel, Griptape, and more showed that the agents could interact with APIs via code, and research papers like Toolformer and Gorilla showed that the underlying models could learn to use APIs effectively. Research from Microsoft, Stanford, and Tencent has shown that AI agents work even better together than they do by themselves.\n\nToday, the word agent means different things to different people. If you speak to enough practitioners, a spectrum emerges with multiple concepts that could all be called agents. BabyAGI creator Yohei Nakajima has one great way to look at this:\n\nHand-Crafted Agents: Chains of prompts and API calls that are autonomous but operate within narrow constraints.\n\nSpecialized Agents: Dynamically decide what to do within a subset of task types and tools. Constrained, but less so than hand-crafted agents are.\n\nGeneral Agents: The AGI of Agents – still at the horizon versus practical reality today.\n\nReasoning limitations of our most advanced frontier models (GPT-4o, Gemini 1.5 Pro, Claude 3 Opus, etc.) are the key constraint that holds back our ability to build, deploy, and rely upon more advanced agents (specialized and general). Agents use frontier models to plan, prioritize, and self-validate – that is, to decompose large tasks into smaller ones and ensure the output is correct. So modest levels of reasoning mean the agents are constrained as well. Over time, new frontier models with more advanced reasoning capabilities (GPT-5, Gemini 2, etc.) will make for more advanced agents.\n\nApplying Agents\n\nToday, developers say that the best-performing agents are all extremely hand-crafted. Developers are being scrappy about how to apply these technologies in their current state by figuring out which use cases work today under the right constraints. Agents are proliferating despite their limitations. End-users are sometimes aware of them, as with a coding agent that responds on Slack. Increasingly, agents also get buried under other UX abstractions such as a search box, spreadsheet, or canvas.\n\nConsider Matrices, a spreadsheet application company formed in 2024. Matrices builds spreadsheets that complete themselves on users’ behalf, for example, by inferring what information a user wants in (say) cells A1:J100 based on the row and column titles, then searching the web and parsing web pages to find each piece of data. Matrices’ core spreadsheet UX is not so different from Excel (launched 1985) or even Visicalc (launched 1979). But the developers of Matrices can use 1,000+ agents for independent multi-step reasoning about each row, column, or even every cell.\n\nOr consider Gradial, a marketing automation company formed in 2023. Gradial lets digital marketing teams automate their content supply chain by helping create asset variants, execute on content updates, and create/migrate pages across channels. Gradial offers a chat interface, but can also meet marketers in their existing workflows by responding to tickets in tracking systems like JIRA or Workfront. The marketer does not need to break down high-level tasks into individual actions. Instead, the Gradial agent accomplishes that and finishes the task(s) behind the scenes on the marketers’ behalf.\n\nTo be sure, agents today have lots of limitations. They are often wrong. They need to be managed. Running too many of them has implications for bandwidth, cost, latency, and user experience. And developers are still learning how to use them effectively. But readers would be right to notice that those limitations echo complaints about foundation models themselves. Techniques like validation, voting, and model ensembles reinforce for AI agents what recent history has shown for GenAI overall: developers are counting on rapid science and engineering improvements and building with a future state in mind. They are speeding across the half-finished bridge I mentioned above, under the assumption it will be finished rapidly.\n\nSupporting Agents with Infrastructure\n\nAll of this means that our industry has work to do to build infrastructure that supports AI agents and the applications that rely upon them.\n\nToday, many agents are almost entirely vertically integrated, without much managed infrastructure. That means: self-managed cloud hosts for the agents, databases for memory and state, connectors to ingest context from external sources, and something called Function Calling, Tool Use, or Tool Calling to use external APIs. Some developers stitch things together with software frameworks like LangChain (especially its evaluation product Langsmith). This stack works best today because developers are iterating quickly and feel they need to control their products end-to-end.\n\nBut the picture will change in the coming months as use cases solidify and design patterns improve. We are still solidly in the era of hand-crafted and specialized agents. So, the most useful infrastructure primitives in the near term are going to be the ones that meet developers where they are and let them build hand-crafted agent networks they control. That infrastructure can also be forward-looking. Over time, reasoning will gradually improve, frontier models will come to steer more of the workflows, and developers will want to focus on product and data — the things that differentiate them. They want the underlying platform to “just work” with scale, performance, and reliability.\n\nSure enough, when you look at it this way, you can see that a rich ecosystem has already started to form that provides AI agent infrastructure. Here are some of the key themes:\n\nAgent-specific developer tools\n\nTools like Flowplay, Wordware, and Rift natively support common design patterns (voting, ensembles, validation, “crews”), which will help more developers understand these patterns and put them to use to build agents. A useful and opinionated developer tool could be one of the most important pieces of infrastructure that unblocks the next wave of applications based on this powerful agent technology.\n\nAgents as a service\n\nHand-crafted agents for specific tasks are starting to act as infrastructure that developers can choose to buy versus build. Such agents offer opinionated functionality like UI automation (Tinyfish, Reworkd, Firecrawl, Superagent, Induced, and Browse.ai), tool selection (NPI, Imprompt), and prompt creation and engineering. Some end-customers may apply those agents directly, but developers will also access those agents via API and assemble them into broader applications.\n\nBrowser Infrastructure\n\nReading the web and acting upon it is a key priority. Developers make their agents richer by letting them interact with APIs, SaaS applications, and the web. API interfaces are straightforward enough, but websites and SaaS applications are complex to access, navigate, parse, and scrape. Doing so makes it possible to use any web page or web app as they would use an API to access its information and capabilities in structured form. That requires managing connections, proxies, and captchas. Browserbase, Browserless, Apify, Bright Data, Platform.sh, and Cloudflare Browser Rendering are all examples of companies that have products in this area.\n\nPersonalized Memory\n\nWhen agents distribute tasks across multiple models, it becomes important to provide shared memory and ensure each model has access to relevant historical data and context. Vector stores like Pinecone, Weaviate, and Chroma are useful for this. But a new class of companies with complementary, opinionated functionality exist, including WhyHow and Cognee, a feature of LangChain called LangMem, and a popular open-source project called MemGPT. These companies show how to personalize agent memory for an end-user and that user’s current context.\n\nAuth for Agents\n\nThese agents manage authentication and authorization on behalf of the agents as they interact with external systems on the end-user’s behalf. Today, developers are using OAuth tokens to let agents impersonate the end-users (delicate), and, in some cases, even asking users to provide API keys. But the UX and security implications are serious, and not all the web supports Oauth (this is why Plaid exists in Financial Services). Anon.com, Mindware, and Statics.ai are three examples of what developers are going to want at scale: managed authentication and authorization for the agents themselves.\n\n“Vercel for Agents”\n\nSeamlessly manage, orchestrate, and scale the hosting of agents with a distributed system. Today there is a disparate set of primitives for agent hosting (E2b.dev, Ollama, Langserve), persistence (Inngest, Hatchet.run, Trigger.dev, Temporal.io), and orchestration (DSPy, AutoGen, CrewAI, Sema4.ai, LangGraph). Some platforms (LangChain and Griptape) offer managed services for different combinations of these things. A consolidated service that offers scalable, managed hosting with persistence and orchestration on an app developer’s behalf will mean developer no longer have to think at multiple levels of abstraction (app and agent) and can instead focus on the problem they wish to solve.\n\nBuilding the Future of AI Agent Infrastructure\n\nIt is so early in the evolution of AI agent infrastructure that today, we see a mix of operational services and open-source tools that have yet to be commercialized or incorporated into broader services. And it’s far from clear who the winners will be — in this domain, the endgame winners may be young today or may not yet exist. So let’s get to work.",
      "# [Clerk Update — July 2024 by Nick Parsons on 2024-07-12](https://dev.to/clerk/clerk-update-july-2024-3mba)\nThe Clerk team has been hard at work shipping new features to help you build secure applications faster. Here’s a rundown of the highlights:\n\nClerk Elements (Beta)\n\nClerk Elements is currently in beta and introduces an entirely new set of unstyled UI primitives that make it easy to build completely custom authentication and user management UIs on top of Clerk's APIs and business logic.\n\nCustomize with CSS Frameworks: Because everything is unstyled by default, Clerk Elements gives you complete control over the markup rendered in your authentication flows. Rendered markup accepts a className prop for easy styling with CSS frameworks such as Tailwind.\n\nExtend with Component Libraries: Clerk Elements also support the asChild prop, popularized by component libraries like Radix. Bring your existing component library and it'll take care of the rest.\n\nTo learn more, visit the Clerk Changelog and Clerk Elements docs →\n\nGoogle One Tap\n\nGoogle One Tap support introduces seamless, one-click user sign-ins and sign-ups. This allows your users to effortlessly access your services without having to remember passwords or undergo lengthy registration processes.\n\nNew <GoogleOneTap /> Component: If you have already configured Google OAuth with custom credentials, adding support for Google One Tap is as easy as including the new <GoogleOneTap /> component.\n\nSupport for Custom Flows & Non-React Environments: For those building applications that require custom flows or do not use React, Google One Tap is supported via clerk-js.\n\nTo learn more, visit the Clerk Changelog and <GoogleOneTap /> component docs →\n\nOther Features, Fixes & Improvements\n\nImproved Clerk + Expo Docs: We have fully refactored our Expo docs with:\n\nNew quickstart guide and accompanying starter repo.\n\nUpdated examples for Impersonation, MFA, and OAuth.\n\nAdded section that addresses common Expo deployment questions.\n\nClerk + Next.js 15: Clerk is now fully compatible with Next.js 15, with support for the React 19 RC. To use Clerk with Next.js 15, upgrade @clerk/nextjs to v5.1.2 or later.\n\nNeon + Clerk Integration Guide: We've published a new integration guide demonstrating how to use Neon with Clerk in a Next.js application, utilizing drizzle-orm for database interactions.\n\nEvents & Community Updates\n\nClerk OSS Fellowship\n\nWe are thrilled to announce the launch of Clerk's Open Source Fellowship program, created to foster continued innovation in the open source software community. Our inaugural recipient is Colin McDonnell, the creator of Zod, who will receive funding while he works on bringing Zod to its next version.\n\nRead the announcement →\n\nClerk + Backdrop Build\n\nWe are excited to announce our partnership with Backdrop Build, a hackathon-centric accelerator that enables thousands of builders to take on the challenge of building and launching an idea in just 4 weeks.\n\nApply to Build →\n\nSummer Hackathon with Xata, Clerk, Inngest & Prisma\n\nWe've partnered with Xata, Prisma, and Inngest to bring you a two-week summer hackathon challenge. Winners will be announced on the Xata Community Discord via live stream on July 19, 2024, at 12:00 PM EST.\n\nRead the announcement →\n\nResources\n\nBuilding a Hybrid Sign-Up/Subscribe Form with Stripe Elements by @brianmmdev\n\nBuild a Modern Authenticated Chat Application with Next.js, Ably & Clerk by @bookercodes\n\nHow to use Clerk with PostHog Identify in Next.js by @brianmmdev\n\nWorking with Clerk and Per-User Databases by @notrab\n\nZoom-Clone using NextJS-14, Clerk, TailwindCSS & StreamSDK by @faarehahmed\n\nHow to Build Your Own ChatGPT Clone Using React & AWS Bedrock by @conermurphy\n\nHow to Secure API Gateway Using JWT & Lambda Authorizers with Clerk by @brianmmdev\n\nGetting Started with React, Vite & Clerk Auth on Netlify by @pauliescanlon\n\nUsing Clerk with Liveblocks by Karl Koch\n\nBuild a Finance SaaS Platform With Nextjs, React & Hono by Code with Antonio\n\nHow to Authenticate API Requests with Clerk & FastAPI by Redouane Achouri\n\nUnlocking the Power of Convex & Clerk by @syedahmedullah14\n\nBuild a team-based task manager with Next.js, Neon & Clerk by @brianmmdev\n\nIf you have feedback or suggestions, we want to hear them! Let us know at feedback.clerk.com. For the latest on our product releases, follow @ClerkDev on 𝕏 or join the Clerk Community on Discord.",
      "# [Solving the Multiple-Frontend Problem in Modern Applications by Matt Minor, Matt Minor Director, Demand Generation on 2025-02-18](https://directus.io/blog/solving-the-multiple-frontend-problem-in-modern-applications)\nMultiple frontend architecture is when your application needs to support different user interfaces across various platforms - web, mobile, IoT devices, internal tools - each potentially built with different frameworks and technologies.\n\nSuddenly, you find yourself maintaining React for your customer dashboard, Vue for your marketing site, and React Native for your mobile app. Each has their own technical stack, team preferences, and maintenance headaches.\n\nMaking all these pieces work together is the real challenge. Most architectural advice out there still assumes you're building a single, unified frontend. Or worse, suggests you rewrite everything in the latest trending framework.\n\nIn this article, we'll break down practical approaches to managing multiple frontends that won't require rewriting your entire codebase or making your teams learn yet another framework. We'll look at real patterns that work, common pitfalls to avoid, and how to build an architecture that can actually scale with your business needs. Let's hop in 🐇\n\nThe Reality of Modern Frontend Architecture\n\nYou may have heard of \"micro-frontends.\" micro-frontend architecture breaks down your web application into smaller, independent pieces that can be built and deployed separately.\n\nThink of your e-commerce site split into independent features - product catalog, shopping cart, checkout - each potentially built by different teams using different tech stacks.\n\nThe numbers tell an interesting story. In 2022, 75% of developers indicated that they had jumped on the micro-frontend bandwagon in 2022. That number dropped to 23% in 2024.\n\nIt's the classic tech hype cycle - rapid adoption followed by the realization that it's not a universal solution. The problem is that in the span of those two years, companies built complex systems that now require constant maintenance.\n\nTeams rushed to split up their monolithic frontends, created independent services, and now find themselves managing an ecosystem instead of an application. What started as a solution to complexity often ended up creating more of it.\n\nPiecing Together The Architecture Puzzle\n\nThe problem isn't that we need to choose between monoliths and micro-frontends. We need a practical approach that lets different frontends coexist without creating a maintenance nightmare.\n\nStart With Your Foundation: API-First\n\nYour API layer is your foundation. It needs to work consistently whether the request comes from your React dashboard, Vue marketing site, or mobile app. Here's what actually works:\n\nCreate a consistent API contract\n\nDefine clear data structures that work across platforms\n\nDocument everything\n\nKeep response formats consistent regardless of the frontend\n\nVersion from day one\n\nCreate clear upgrade paths for breaking changes\n\nAllow frontends to migrate at their own pace\n\nMaintain backwards compatibility until all frontends upgrade\n\nImplement an API gateway\n\nRoute traffic efficiently between services\n\nHandle authentication in one place\n\nMonitor and rate limit as needed\n\nThis approach lets each frontend team work independently while ensuring they all speak the same language at the data level.\n\nShare Code, Not Complexity: Module Federation\n\nWith 52% of developers already using Module Federation, it's becoming a key part of managing multiple frontends. But what exactly is it?\n\nModule Federation lets you share code between applications without rebuilding them each time something changes. Think of it as a way to load pieces of one application inside another - but each piece can be deployed independently.\n\nHere's why it matters:\n\nTeams can work independently but share common components\n\nEach frontend can deploy on its own schedule\n\nYou can update shared components without rebuilding every app\n\nApplications load only the code they need, when they need it\n\nThe catch? (There's always a catch 😔) You'll need to think carefully about which modules to share across applications, how to handle versioning of shared code, and where to draw the boundaries between apps.\n\nStill, for teams managing multiple frontends, Module Federation offers a practical way to share code without creating a maintenance nightmare.\n\nThe Reality of Implementation\n\nTheory sounds great until you actually try to make it work. Let's talk about what really happens when you implement multiple frontends in production.\n\nFinding Your Natural Boundaries\n\nMost teams try to split their frontends based on technical concerns - by framework or deployment method. That's backwards. Your boundaries should follow your business logic.\n\nLook at your user journeys. Where do people naturally switch between different parts of your application? That's usually where your frontend boundaries should be. A real example: an e-commerce platform might split between:\n\nThe marketing site (content-heavy, SEO-focused)\n\nThe shopping experience (dynamic, interactive)\n\nThe account dashboard (complex state management)\n\nEach of these has different technical needs. By splitting here, you're working with your business logic instead of against it.\n\nThe Performance Paradox\n\nHere's the thing about multiple frontends that no one talks about: they can make your application faster and slower at the same time. The trick is knowing which is which.\n\nLoading your entire application upfront? That's slow. Loading just the marketing site, then fetching the shopping cart experience only when needed? That's fast. We've seen teams improve initial load times by 80% by splitting frontends strategically.\n\nBut there's a catch. If you're not careful with shared dependencies, you'll end up downloading React three times for three different parts of your application. Your dependency strategy needs to be as thoughtful as your frontend split.\n\nReal numbers from production:\n\nShared dependencies can reduce bundle sizes by 60%\n\nSmart code splitting can cut initial load times in half\n\nBut poor implementation can triple your JavaScript payload\n\nSecurity: The Part Everyone Forgets\n\nMultiple frontends create multiple entry points - that's just math. But the real security challenges aren't where most teams look.\n\nIt's not about adding more authentication checks. It's about maintaining consistency across your entire system. Users shouldn't have to log in again just because they moved from your main app to your dashboard.\n\nYour API gateway becomes mission-critical here. It's not just about routing traffic - it's your first line of defense. Use it to:\n\nEnforce consistent authentication\n\nMonitor for unusual patterns\n\nRate limit at a system level\n\nTrack and audit cross-frontend communication\n\nThe Integration Challenge\n\nHere's where most implementations actually fail: integration points. Each frontend needs to know about the others, but too much coupling defeats the purpose of separation.\n\nThe solution? Build a contract between your frontends. Not just API endpoints, but actual interfaces that define how they interact. Document these contracts like you would document your APIs.\n\nFor example, your shopping cart frontend needs to know how to:\n\nHand off to the checkout process\n\nReturn to the product catalog\n\nAccess shared user data\n\nCommunicate with the notification system\n\nBut it shouldn't need to know how those other systems work internally.\n\nGetting Started\n\nYou don't have to rebuild everything from scratch. Start with your API layer - make it consistent and versioned. Then look for opportunities to share code between your frontends using Module Federation.\n\nFocus on the boundaries that already exist in your application. Don't force separation where it doesn't make sense. Let your team structure guide your technical boundaries - when the same team owns both sides of an interface, you'll have fewer integration headaches.\n\nRemember: the goal isn't to build the perfect architecture. It's to create something your team can understand, maintain, and scale. Something that lets you ship features instead of fighting framework wars.\n\nAnd if someone suggests rewriting everything in the latest trending framework? Show them your API documentation instead.",
      "# [Building Effective AI Agents: Insights from Anthropic and Hacker News Discussions by David Lee, medium.com on 2024-12-21](https://medium.com/@lordmoma/building-effective-ai-agents-insights-from-anthropic-and-hacker-news-discussions-881cee2ab6d6)\nWhen I first stumbled upon Anthropic’s article on building effective AI agents, I wasn’t expecting the lively debate it would ignite on Hacker News. But as I dived into the discussions, it became clear that the community is grappling with critical challenges and opportunities in AI agent development. Let me take you through what I discovered from the insights shared by Anthropic and the passionate developers on Hacker News.\n\nSimplicity: The Key to Success\n\nOne of the standout points from Anthropic’s article was its advocacy for simplicity. They recommend using straightforward patterns directly at the API level rather than overcomplicating things with frameworks like LangChain. For me, it brought back memories of the Gang of Four design patterns — keeping systems clean and manageable by following the “rule of least power.”\n\nThe Hacker News crowd seemed to echo this sentiment. I read several stories from developers who explained how frameworks, while promising abstraction and ease, often ended up complicating their workflows. It struck me that simplicity isn’t just elegant; it’s practical.\n\nWorkflows vs. Agents\n\nAnthropic’s distinction between workflows and agents was one of those “aha” moments for me. They define workflows as predictable, automated processes. In contrast, agents are fully autonomous systems that operate independently for extended periods, leveraging various tools to tackle complex tasks. This clear line between workflows and agents really resonated with me and helped clarify what we’re actually building when we say “agent.”\n\nAnatomy of an Autonomous AI Agent\n\nSo, what exactly makes up an autonomous AI agent? According to Anthropic, there are four key components:\n\nProfile: Defining the agent’s identity and capabilities.\n\nMemory: Retaining information across interactions.\n\nPlanning: Strategizing how to achieve objectives.\n\nAction: Executing tasks to accomplish goals.\n\nI found it fascinating that these components can be implemented using simple LLM calls…",
      "# [Introducing Project Configuration for Directus Cloud Projects by Christina Harker, Christina Harker Director, Product Marketing on 2024-12-04](https://directus.io/blog/cloud-project-configuration)\nOur latest addition to Directus Cloud brings a powerful yet safe way to customize your projects.\n\nDirectus Cloud now has a new Project Configuration panel, offering preset controls without the complexity of raw environment variables. This marks a shift from direct environment variable access to a curated set of configuration options, giving you the control you need while maintaining project stability.\n\nProject Configuration provides preset options for essential project settings. These settings can be adjusted through an intuitive interface in the Cloud dashboard, allowing for easy customization of your project's behavior:\n\nSimplified Controls: Configure your project through an intuitive interface with pre-validated options\n\nSafety First: Each setting comes with carefully selected presets that prevent accidental misconfiguration\n\nSmart Defaults: All options come with production-ready defaults that work for most use cases\n\nInstant Updates: Changes trigger automatic redeployment, ensuring your settings take effect immediately\n\nUsing Project Configuration\n\nLet's look at how Project Configuration works in practice. Imagine you're running a multi-region application that needs specific security and CORS settings for different environments.\n\nHere's how Project Configuration makes this simple:\n\nSet file upload limits that match your application's needs\n\nConfigure allowed URLs for user management\n\nSet up CORS settings for your different domains\n\nApply the changes and let automatic redeployment handle the rest\n\nAvailable Configuration Areas\n\nThe Project Configuration panel focuses on three key areas:\n\nFiles: Control maximum upload sizes\n\nSecurity: Manage URL allowlists for user management\n\nCORS: Configure cross-origin resource sharing settings\n\nEach area offers preset options that cover common use cases while preventing potential configuration errors. For a full list of our configuration options, check out our docs – https://docs.directus.io/self-hosted/config-options.html#cors\n\nGet Started with Project Configuration\n\nThe new Project Configuration panel is available now in your Directus Cloud dashboard. Visit your project settings to explore these new capabilities.",
      "# [Next.js + Inngest: Unlocking Long-Running AI Workflow Automation on 2024-09-16](https://www.youtube.com/watch?v=9F7RLFwg9H8)\n",
      "# [@andyrmitchell/pg-queue on 2024-06-04](https://www.npmjs.com/package/@andyrmitchell/pg-queue)\nThe 'No Maintenance' Postgres Queue\n\nBuilt for solo / small teams who already use Postgres.\n\nThis library is designed to eliminate all sources of dev ops or maintenance headaches, letting you focus on building features.\n\nPowered by Postgres:\n\nNo New Software Needed: Integrate seamlessly with your existing stack. The core queue operations (add job, pick job, release/retry job) are all handled by Postgres functions.\n\nStandard for Robustness: Postgres is renowned for its data integrity and reliability, ensuring your queue operations are rock-solid.\n\nLanguage Agnostic:\n\nUniversal Compatibility: Use it from any environment with a database connector. The native (plpgsql) Postgres functions enable you to add and manage jobs effortlessly. (It also includes a TypeScript client for added convenience.)\n\nInfinitely Scalable Worker Fleet:\n\nServerless Integration: Automatically dispatch jobs to serverless HTTP workers. Specify the serverless function for each queue and let the system handle the rest. (You can also use traditional long-running workers.)\n\nSimplified Complex Workflows:\n\nDeclarative Steps: Turn multi-step jobs into a simple, readable array of functions in TypeScript. Each step is retried until successful, ensuring robustness and clarity.\n\nLifetime Dependability:\n\nMIT Licensed: Depend on it indefinitely without fear of business changes or price hikes. And use your existing data location, for simple privacy law compliance (e.g. GDPR).\n\nThoughtful Details\n\nEffortless Migrations:\n\nSQL or TypeScript: Generate SQL migration files, or use the TypeScript client to install updates directly into Postgres. It's incremental and idempotent, so you can rerun it as often as you like.\n\nRobust Testing:\n\nPgTap and TypeScript Tests: Integrate seamlessly with your existing testing suite or CI/CD pipeline, ensuring confidence in every deployment.\n\nQueue Essentials with Postgres Advantages:\n\nTransactional Safety: Queuing jobs can be made conditional on a larger transaction succeeding, ensuring consistency and reliability.\n\nFast and Reliable: Utilizes SKIP LOCKED for efficient job handling.\n\nAutomatic Retries and Concurrency Control: Manage spikes without overwhelming your workers.\n\nWhy make a new queue in 2024?\n\nThere are many existing appealing options:\n\nDurable Execution paradigms\n\nTemporal.io\n\nInngest.com\n\nHatchet.run\n\nOpen source queues\n\nriverqueue.com\n\nrabbitmq.com\n\nPostgres native, open source queues\n\nPg-Boss\n\nBut with the exception of Pg-Boss, all of these require either a cloud package or a dedicated server deployment in a specific language.\n\nI.e. there's either cost in maintenance (self hosting an esoteric system) or cloud (subscriptions, and data location concerns for privacy laws).\n\nPg-Boss solved those issues, but still lacks:\n\nPure serverless workers (e.g. Supabase). Instead, you must set up a fleet of long-running workers.\n\nSimple multi-step workflows (replacing spaghetti-ish job spawning with a single array of functions).\n\nLanguage independence. Instead of being primarily in Postgres, it's written in Node.\n\nA TypeScript client that can autocomplete / validate each queue's payload.\n\nSet up\n\nInstalling / Updating\n\nThe installation process is incremental and idempotent, so you can run it multiple times in the same schema, and you'll safely get the latest version.\n\nInstalling using the CLI to generate .sql migration files\n\nIn Terminal, navigate to the root of your code (if you have an existing package.json, or existing sql migration files, the root should include both of these).\n\nnpm i @andyrmitchell/pg-queue@latest\n\nnpx pg-queue-install-node\n\nIt will ask if you want to use a custom schema in Postgres (otherwise it'll add to the schema in the exported const DEFAULT_SCHEMA)\n\nIt will ask you which folders you want to add .sql files to\n\nInstalling via a live Postgres connection from a TypeScript environment\n\nnpm i @andyrmitchell/pg-queue@latest\n\ninstall(reader:IFileIo, db:Queryable, config: {schema_name?:string})\n\nIFileIo and Queryable are abstractions for the file system and Postgres respectively\n\nIt comes with a IFileIo for Node: pgcFileReaderNode. Otherwise you'll need to implement the interface IFileIo.\n\nIt comes with a Queryable for TypeScript/postgres that uses 'postgres' (from npm): PostgresDb\n\nIf you don't provide a schema_name, it'll use the exported const DEFAULT_SCHEMA\n\nAs every Postgres installation is unique, you should run the queue test scripts on your production server.\n\nGenerating PgTap tests for your existing SQL deployment test\n\nThe Install CLI steps above will also let you specify a sql tests directory, and install the the PgTap .sql files into it.\n\nYou can just drop the schema: DROP SCHEMA $1 CASCADE\n\nWhere $1 is the custom schema name you used, otherwise it's the exported const DEFAULT_SCHEMA.\n\nHow it works\n\nAdding a job to a queue\n\nconst db = new PostgresDb({/*TODO psql terms*/}); const queue = new PgQueue<{payload_data_can_be_anything:boolean}>( db, 'test_queue_1', 'optional_custom_schema_1' ); queue.addJob({payload_data_can_be_anything: true})\n\nWhen this is later picked by a worker, it'll receive the payload data.\n\nSetting max concurrency on a queue\n\nconst db = new PostgresDb({/*TODO psql terms*/}); const queueConfig = new PgQueueConfig( db, 'test_queue_1', 'optional_custom_schema_1' ); await queueConfig.set({ max_concurrency: 25 });\n\nDeclaring a multi-step workflow, and starting a job on it\n\nMulti Step Workflows use the standard PgQueue underneath, but automatically handle setting up the next job for the next step.\n\nconst db = new PostgresDb({/*TODO psql terms*/}); const msq = new MultiStepPgQueue( db, 'test_multistep_queue_1', 'workflow_1', [ { id: 'no1', handler: async (payload, jobID) => { // Do something, e.g. read a value from the payload, process it, and write it to the database if( payload.name==='Bob' ) { } } }, { id: 'no2', handler: async (payload, jobID) => { // Do something, e.g. read a value from the database, process it, and write it to the database } } ], z.object({name: z.string()}), // Payload format in Zod, given to the step handler 'optional_custom_schema_1' ) await msq.addJob({ name: 'Bob' });\n\nThe createMultiStepPgQueueAsRecord helper increases robustness\n\nIf you have multiple workflows, you can rely on TypeScript to access them with the correct ID.\n\nUse the createMultiStepPgQueueAsRecord helper, which wraps the MultiStepPgQueue instantiation.\n\nExample:\n\nconst workflows = { ...createMultiStepPgQueueAsRecord( db, 'queue_v1', 'v1', [ { id: 'step1', handler: async (payload) => { workflows.v2.addJob(...) } }, ], z.object({name: z.string()}) ), ...createMultiStepPgQueueAsRecord( db, 'queue_v1', 'v2', [ { id: 'step1', handler: async (payload) => {} }, ], z.object({name: z.string()}) ) } // TypeScript now knows the ID of each workflow, so you can do this (and will be warned if the ID is wrong) workflows.v1.addJob(...)\n\nServerless Function Workers\n\nYou'll need to set up two things:\n\nA Dispatcher, which continually picks available jobs off the queue, and sends them to...\n\nA http endpoint that is a Job Handler for the queue\n\n1. Setting up a Job Dispatcher\n\nServerless Function Dispatcher\n\nSee\n\nLong-running Dispatcher\n\nSee\n\nPostgres Native Dispatcher\n\nThis removes the need for a separate Dispatcher, by letting Postgres run it internally (using pg_net and pg_cron).\n\nTo finish implementing (See Roadmap)\n\n2. Setting up a Job Handler\n\nFor a queue\n\nSee\n\nFor a multi-step workflow\n\nSee\n\n3. Informing the queue where the Job Handler is located\n\n// Load the config editor for the queue const queueConfig = new PgQueueConfig( db, 'test_queue_1', 'optional_custom_schema_1' ); // Update the config to know where the end point is located await queueConfig.setEndpoint(true, { endpoint_method: 'POST', endpoint_url: `${Deno.env.get('SUPABASE_URL')}/functions/v1/job_handler_for_test_queue_1`, endpoint_bearer_token_location: 'inline', // can also be 'supabase_vault' endpoint_timeout_milliseconds: 60000, endpoint_manual_release: true // Indicate that the endpoint script will mark this job complete or failed (instead of the Dispatcher waiting) }); // Tell the Dispatcher how to authorise the call to the endpoint. The value will be passed as a Bearer token in the Authorization header. // The token storage location depends on 'endpoint_bearer_token_location' above (inline = in the Postgres database, supabase_vault = still in Postgres, but more secure) await queueConfig.setQueueEndPointApiKey(Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? '');\n\nThis will then be used by the Dispatcher to pass the payload to the Job Handler (at that endpoint).\n\nA long-running worker\n\nYou'll need to set up one thing:\n\nA long-running script, that continually loops, trying to pick a job off the queue and completing it.\n\nYou can add as many concurrent long-running workers as you wish.\n\nFor a queue\n\nSee\n\nFor a multi-step workflow\n\nSee\n\nSlow TypeScript in IDE or \"Type instantiation is excessively deep and possibly infinite.\" error\n\nThis is related to Zod, and probably MultiStepPgQueue's inference of type from a passed in schema.\n\nPossible Causes:\n\nYou use a different version of Zod to create the schema, than this package uses to infer a type from the schema\n\nTo help you test it, this package exports the Zod it uses. Try using that version to generate you schema, and see if it fixes it.\n\nIn Deno, even if your Zod uses the same version as this package, you must also import from the same registry (i.e. not deno.land)\n\nUse import z from \"npm:zod\" when creating schemas\n\nZod inference requires TypeScript in strict mode\n\nThis package is fully in strict mode, and that should be sufficient. But just in case, your consumer code should also be strict (it's good practice anyway!).\n\nCode Tags\n\n#ZOD_SCHEMA_COMPATIBILITY\n\nWhy Postgres?\n\nhttps://news.ycombinator.com/item?id=37636841\n\nhttps://adriano.fyi/posts/2023-09-24-choose-postgres-queue-technology/\n\nReduce worker costs / bottlenecks (at the expense of more dev ops): replace serverless\n\nCombining queues with serverless functions eliminates the need to think about managing a worker fleet.\n\nBut serverless has two drawbacks:\n\nOnce your queue is fast moving, being charged per invocation might become expensive.\n\nThis is a champagne problem: your service is probably popular enough to afford dev ops!\n\nServerless providers typically cap CPU run time, so it might not be able to finish an intensive job - which is the point of background workers - leading to endless retries.\n\nYou can replace it with either:\n\nYour own http API end point, that's uncapped\n\nA traditional worker that picks jobs from the queue, and processes them\n\nThere's a lot of great platforms out there for hosting long running workers:\n\nRender.com\n\nDigital Ocean\n\nPorter.run\n\nFly.io\n\nWhen it's time to move beyond a simple queue\n\nTemporal.io (as well as inngest.com, and perhaps hatchet.run) introduce new coding primitives that abstract away all the complexity of logic for retrying failed asyncs (e.g. failed network requests, runtime time outs, such as waiting on a backend to process something).\n\nFor traditional queues, riverqueue.com looks really nice.\n\nWhat maintenance hassles remain?\n\nIn pursuit of transparency, some of the issues you might face:\n\nIf your worker code fails, you'll need to fix it like any other software; and optionally restart affected jobs.\n\nAt a certain scale, Postgres will start to creak. But that's probably much further away than you think: https://news.ycombinator.com/item?id=37636841\n\nI'm also certain that the tables/functions can be further optimised. See the Roadmap.\n\nYou still need to think in terms of queues: e.g. starting a job, executing code for each job. (I mention this only because some solutions, such as Temporal.io and Inngest, aim to abstract even that away, by just letting you write \"const x = await backgroundJobX(); await backgroundJobY(x)\" with the queue advantages of complete fault tolerance and spike-smoothing background processes).\n\nFinish the Postgres-native dispatcher (using pg_net)\n\nI paused development because at the time, pg_net wasn't mature enough to use with local testing development. It has since been updated.\n\nLittle Bits\n\nAdd tests that verify all operations run inside a transaction\n\nA queue can only use supabase-vault if supabase installed\n\nSwitch pgmock for pglite in tests, when pglite fixes the throw_ok error (see TODO in migration.test.ts)\n\nPostgres tests can just be flattened, using testhelpers_ by default, but can be converted to PgTap if needed in CLI.\n\nMultiStep passes in old function handler arrays, to continue to support them for jobs that started on that function set.\n\nReview the latest ideas\n\nPostgres queues\n\nhttps://news.ycombinator.com/item?id=40077233\n\nhttps://news.ycombinator.com/item?id=37636841\n\nhttps://news.ycombinator.com/item?id=39643136\n\nhttps://news.ycombinator.com/item?id=39315833\n\nhttps://news.ycombinator.com/item?id=39092849\n\nBack pressure in systems\n\nhttps://news.ycombinator.com/item?id=39041477\n\nhttps://news.ycombinator.com/item?id=39813660\n\nhttps://news.ycombinator.com/item?id=29220338\n\nGain visibility into execution\n\nThe main pain points:\n\nAre jobs routinely failing, especially if it's a (broken) step in a workflow (alarm, restart)\n\nWhy is a job routinely failing? What is its history of attempts? What happened to the worker?\n\nAre jobs very slow to start (alarm)\n\nIs back pressure threatening to collapse the system (alarm / 429 the incoming requests)\n\nAlso, make restarting a failed job trivial.\n\nSupport 3rd party observability\n\nPlug in logging systems. Most likely they'll want to subscribe/listen to all activity on the queue, but it could be done imperatively by the TypeScript classes too.\n\nFairness: don't let one customer dominate your background workers\n\nExtend the concurrency logic to not just limit concurrency on a queue, but also on a group within that queue. Each job will be allotted to a group (most likely a customer ID).\n\nElegant queue invocation and outcome usage\n\nExample 1: Client creates a new thing\n\nClient sends a write to a Collection {collection: 'bundles', type: 'create', data: {bundle_name: 'Customer X'}}\n\nIn Postgres, adding an item to the Collection triggers it to be added as a job to a queue workflow (perhaps this rule is defined in a DDL for the Collection)\n\nThe workflow runs in the background\n\nWhen it's complete, the worker updates Postgres with the result and releases the job in a single transaction (for robustness)\n\nBack in the client the Collection data live updates with the change, which is reflected in the UI\n\nNotably in that example:\n\nThe developer hasn't needed to explicitly think about invoking a job, or handling the result\n\nThere's just a one time job to set up the trigger rule, and the multi-step workflow\n\nThere would be alarms/reporting for any disruption to the queue - otherwise it's hands off\n\nExample 2: respond to a new Gmail message (e.g. for AI processing)\n\nWatch Gmail history for new messages (this could be a Collection itself, that uses a Postgres store to persist the latest history ID per mailbox, and has a DDL to trigger invoking a job on the queue)\n\nWorker code that uses Durable Execution but without lock in\n\nTemporal.io, Inngest, etc. are enticing, but there is lock in to their platform (or complexity self-hosting their systems).\n\nSome ideas:\n\nExpand multi-step workflow to be good enough, without fully embracing the new code model. E.g. let one step have multiple children, pass data objects between steps, etc.\n\nEject button: switch away to any other queue tool\n\nThis is achieved when the above Roadmap items are complete\n\nJob invocation from client apps that use a totally agnostic interface\n\nHot-switchable worker workflows\n\nOptimise Postgres\n\nThe current system of moving jobs between tables, logging, etc. is too heavy.\n\nOther ideas\n\nMake archiving the working table a batch process\n\nOnly log (don't have a complete/fail table)? Or keep current tables but make logging optional?\n\nJest pains\n\nIn theory it should be simple to get ESM working with Jest (all the code is written for ESM); but I've found switching the whole npm package to ESM to be full of sharks. So it's commonjs for now, with caveats for certain ESM modules / techniques (below).\n\nLonger term the package should move to ESM, but for now...\n\nImporting 3rd party ESM modules\n\nJest will complain about \"import\" statements. So tell Jest to not try to transform those packages, just use them.\n\nIn jest.config.ts:\n\ntransformIgnorePatterns: [ // Don't transform node_modules for any other ES modules you use '/node_modules/(?!lodash-es|dot-prop|\\@electric\\-sql\\/pglite|pkg-dir|find-up-simple|inquirer|chalk|ansi-styles|filenamify|filename-reserved-regex)' ],\n\nGetting import.meta.url working with Jest\n\nFollow this: https://stackoverflow.com/questions/64961387/how-to-use-import-meta-when-testing-with-jest to use the babel plugin: https://github.com/javiertury/babel-plugin-transform-import-meta\n\nIn jest.config.ts, I had to make the file explicit to use Babel instead of ts-jest:\n\ntransform: { // Use babel-jest to transform JS files '^.+\\\\.(js|jsx)$': 'babel-jest', '^.+getInvokedScriptDirectory\\\\.ts$': 'babel-jest', // Use ts-jest for ts/tsx files '^.+\\\\.(ts|tsx)$': 'ts-jest', },\n\nAn alternative solution would have been to create a mocks folder, with getInvokedScriptDirectory.ts, and then update jest.config.js with:\n\nmoduleNameMapper: { '^./getInvokedScriptDirectory$': '<rootDir>/path/to/__mocks__/getInvokedScriptDirectory.ts', },"
    ],
    "# Inngest Company and Product Report\n\n## Company Overview\n\nInngest is a technology company focused on providing a serverless workflow engine that simplifies the development of event-driven applications. The company has gained traction in the developer community for its ability to streamline complex workflows and enhance the efficiency of application development. Inngest's mission is to help developers focus on writing code rather than managing infrastructure, which aligns with the growing trend towards serverless architectures and event-driven programming.\n\n### Recent Developments\n\n- **Team Growth**: Inngest has reportedly tripled its team size over the past year, indicating significant growth and investment in its capabilities [(Product & Engineering blog, 2023)](https://www.inngest.com/blog).\n  \n- **Funding**: The company successfully raised a seed round, although specific financial details were not disclosed. This funding is expected to support further development and expansion of its product offerings [(Product & Engineering blog, 2023)](https://www.inngest.com/blog).\n\n- **Partnerships**: Inngest has formed partnerships with various companies, including Render, to enhance its service offerings and improve integration capabilities for developers [(Customer Story - Fey, 2024)](https://render.com/customers/fey).\n\n## Product Overview: Inngest\n\nInngest is a serverless workflow engine designed to facilitate the creation and management of event-driven applications. It allows developers to define workflows using a simple, intuitive interface, enabling them to orchestrate complex tasks without the overhead of traditional server management.\n\n### Key Features\n\n- **Durable Execution**: Inngest supports durable execution, which allows workflows to maintain state across multiple steps, making it easier to manage long-running processes [(The Principles of Durable Execution Explained, 2024)](https://www.inngest.com/blog/category/engineering).\n\n- **Integration with AI**: The platform has been utilized to build AI workflows, enabling developers to integrate generative AI capabilities into their applications seamlessly. For instance, Inngest has been used by the personal finance app Fey to enhance its data processing and AI summarization features [(Customer Story - Fey, 2024)](https://render.com/customers/fey).\n\n- **TypeScript SDK**: Inngest offers a TypeScript SDK that simplifies the development process, allowing developers to create workflows with minimal code complexity. The latest version, v3.0, includes new features aimed at improving developer experience [(Product & Engineering blog, 2023)](https://www.inngest.com/blog).\n\n### Customer Success Stories\n\n1. **Fey**: A personal finance app that migrated from Google Cloud Composer to Inngest, resulting in a 50x increase in data processing speed and a reduction in operational costs from $2,800 to less than $100 per month. Fey leverages Inngest for scheduled jobs and AI orchestration, significantly improving its operational efficiency [(Customer Story - Fey, 2024)](https://render.com/customers/fey).\n\n2. **Otto**: Another customer that has successfully implemented Inngest to build and scale AI agents, demonstrating the platform's versatility in handling complex workflows and integrations [(Product & Engineering blog, 2023)](https://www.inngest.com/blog).\n\n### Technical Innovations\n\n- **Sharded Infrastructure**: Inngest has implemented a new sharded infrastructure that enhances performance and reliability, allowing for high-throughput operations without downtime [(Product & Engineering blog, 2024)](https://www.inngest.com/blog).\n\n- **AI Workflows**: The introduction of features like `step.invoke()` allows for asynchronous function calls, making it easier to compose complex workflows with reusable components. This is particularly beneficial for applications that require real-time data processing and AI integration [(Customer Story - Fey, 2024)](https://render.com/customers/fey).\n\n## Executive Insights\n\nTony Holdstock-Brown, co-founder and CEO of Inngest, has emphasized the importance of simplifying the developer experience in building AI applications. He noted, \"We almost have two parallel tracks right now as engineers... The two disciplines are working together, but are also very, very, very different from an engineering point of view\" [(Building Production Workflows for AI Applications, 2024)](https://a16z.com/podcast/building-production-workflows-for-ai-applications/). This perspective highlights Inngest's commitment to bridging the gap between complex AI workflows and user-friendly development tools.\n\n## Conclusion\n\nInngest is positioned as a key player in the serverless and event-driven application landscape, with a strong focus on enhancing developer productivity through innovative workflow management solutions. The company's recent growth, successful funding rounds, and positive customer outcomes underscore its potential for continued success in the rapidly evolving tech ecosystem. Prospective candidates and investors should consider Inngest's strategic direction and its commitment to simplifying complex workflows as compelling reasons to engage with the company."
  ],
  "lineage": {
    "run_at": "2025-03-28T21:54:15.923584",
    "git_sha": "9e00c41"
  }
}