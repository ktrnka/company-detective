{
  "summary_markdown": "# About Yurts.ai\n\nYurts.ai, founded in August 2022, is a company specializing in secure and private Generative AI (GenAI) integration platforms. The company was established by Ben Van Roo, Jason Schnitzer, and Guruprasad Raghavan, emerging from a strategic partnership with the Department of Defense (DoD). Yurts focuses on enhancing mission-critical workflows, particularly within the defense and government sectors, by transforming knowledge management and operational efficiency through its adaptable GenAI platform [(Yurts AI, PR Newswire, 2024-10-23)](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html).\n\nYurts employs approximately 50 people, with about 25% holding active security clearances, indicating a strong focus on high-security environments [(Yurts AI, Washington Headquarters Services, 2024-12-04)](https://www.cbinsights.com/company/washington-headquarters-services). The company has secured a total of $58 million in funding, including a recent $40 million Series B round led by XYZ Venture Capital [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html).\n\nYurts primarily serves Fortune companies and government agencies, including the Department of Defense. The platform is designed to meet the stringent security standards required for classified use cases, making it suitable for mission-critical applications. The company's products are distributed through strategic partnerships and collaborations, such as those with Oracle and Redhorse Corporation, to deliver secure GenAI solutions to defense and intelligence sectors [(Yurts AI, PR Newswire, 2024-10-23)](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html).\n\n# Key Personnel\n\n- **Ben Van Roo**: CEO & Co-Founder, with a background in national security and data science. He emphasizes the company's commitment to delivering tangible results in AI integration [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html).\n\n- **Jason Schnitzer**: CTO & Co-Founder, experienced in production engineering and platform development.\n\n- **Guruprasad Raghavan**: Lead Research Scientist & Co-Founder, specializing in computational neuroscience and algorithm development.\n\n# News\n\n## Recent Developments\n\n### Partnerships and Collaborations\n\n1. **Oracle Collaboration**: In October 2024, Yurts announced a partnership with Oracle to deliver secure GenAI solutions to the defense and intelligence sectors. This collaboration leverages Oracle Cloud Infrastructure to enhance operational efficiency and decision-making capabilities for defense agencies [(Yurts AI, PR Newswire, 2024-10-23)](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html).\n\n2. **Redhorse Partnership**: In February 2024, Yurts formed a strategic partnership with Redhorse Corporation to deploy secure GenAI solutions for federal agencies. This partnership aims to modernize knowledge-driven enterprise workflows while ensuring operational efficiency and privacy [(Redhorse Corporation, 2024-02-21)](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/).\n\n### Funding Events\n\nYurts.ai successfully raised $40 million in a Series B funding round in December 2024, which will be used to accelerate growth and enhance its capabilities in integrating GenAI into mission-critical systems [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html). This funding round was led by XYZ Venture Capital, with participation from several other investors, bringing the total investment to $58 million [(Yurts AI, Washington Headquarters Services, 2024-12-04)](https://www.cbinsights.com/company/washington-headquarters-services).\n\n## Market Position and Scale\n\nYurts.ai is positioned as a leader in the secure AI integration space, particularly within the defense sector. The company has secured contracts with various branches of the U.S. military, including the Army, Air Force, and Special Operations Command, indicating a strong foothold in the government market [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html). The company's focus on high-security environments and compliance with DoD standards further enhances its market credibility.\n\n# Conclusion\n\nYurts.ai is rapidly establishing itself as a key player in the secure AI integration market, particularly for defense and government applications. With significant funding, strategic partnerships, and a robust product offering, the company is well-positioned to capitalize on the growing demand for secure and efficient AI solutions in mission-critical environments. Prospective candidates and investors should consider Yurts.ai's innovative approach and strong leadership as indicators of its potential for growth and impact in the industry.",
  "target": [
    "Yurts.ai",
    "Yurts.ai",
    "yurts.ai",
    null
  ],
  "webpage_result": {
    "summary_markdown": "# Yurts Company Overview\n\n## Company History\nYurts was founded in 2022 by Ben Van Roo, Jason Schnitzer, and Guruprasad Raghavan. The company emerged from a strategic partnership with the Department of Defense, focusing on creating a secure and private platform tailored for mission-critical environments. Yurts has quickly established itself as a leader in the generative AI space, particularly for enterprise and government applications.\n\n## Services and Products\nYurts offers a comprehensive generative AI platform designed to enhance knowledge management and streamline workflows across various industries. Key features include:\n\n- **Context-rich AI Assistants**: Seamlessly integrate AI assistants within applications for a consistent user experience.\n  \n- **Enterprise Search**: Query multiple applications simultaneously to break down data silos and harness knowledge.\n  \n- **Natural Language Processing**: Refine queries and generate context-rich reports using proprietary data.\n  \n- **Embedded Assistant**: Deploy AI assistants in favorite enterprise applications for a unified experience.\n  \n- **Security and Privacy**: Robust security measures, including stringent access controls and compliance with government standards.\n\n## Target Customers\nYurts primarily serves Fortune companies and government agencies, including the Department of Defense. The platform is designed to meet the stringent security standards required for classified use cases, making it suitable for mission-critical applications.\n\n## Leadership Team\n- **Ben Van Roo**: CEO & Co-Founder, with a background in national security and data science.\n  \n- **Jason Schnitzer**: CTO & Co-Founder, experienced in production engineering and platform development.\n  \n- **Guruprasad Raghavan**: Lead Research Scientist & Co-Founder, specializing in computational neuroscience and algorithm development.\n\n## Company Culture\nYurts promotes a vibrant and collaborative work environment, emphasizing continuous learning and employee well-being. The culture is characterized by:\n\n- **Autonomy**: Employees are empowered to take ownership of their work and tackle challenging problems.\n  \n- **Collaboration**: A friendly atmosphere where colleagues support each other and share knowledge.\n  \n- **Innovation**: A focus on integrating AI into everyday tools to simplify work processes and enhance productivity.\n\n## Recent Developments\nYurts recently secured $40 million in Series B funding to accelerate growth and expand its impact in the defense, government, and enterprise sectors. The company is also collaborating with Oracle to enhance its AI solutions for the defense and intelligence sectors.\n\n## Conclusion\nYurts is redefining how enterprises harness the power of AI, focusing on secure, scalable solutions that transform mission-critical systems and workflows. With a strong leadership team and a commitment to innovation, Yurts is well-positioned to lead in the generative AI space for both government and enterprise applications.\n\nFor more information, visit [Yurts](https://www.yurts.ai/).",
    "page_markdowns": [
      "# [AI That Knows Your Enterprise](https://www.yurts.ai/)\nAI Assistant\n\nContext-rich AI assistants in the apps you use everyday\n\nSeamlessly integrate AI assistants with your trusted data sources and embed within your applications for a consistent, intuitive experience across teams and customer experiences.\n\nYurts Platform\n\nBuilt for Success, Customized For You\n\nFeatures like secure deployment, real-time monitoring, context-aware search, integrations with legacy applications, and stringent access controls make up a platform designed to be efficient, trustworthy, and secure for enterprise and government use.\n\nSecurity and Privacy\n\nYour Data Deserves Mission Critical Security\n\nWith credentials from the departments of defense and energy, Yurts takes security seriously. Enhanced privacy features put you in charge of who sees what, when, where, and how.",
      "# [Generative AI for Government](https://www.yurts.ai/government)\nRELIABLE AND SECURE\n\nYurts is proud to deploy its transformative GenAI platform across the DoD, with production-ready deployments on Game Warden's ATO. Yurts recently received \"Awardable\" status in the Tradewinds Solutions Marketplace, ensuring fast and seamless integrations for government agencies.\n\n“Yurts’ expertise in deploying solutions for classified use cases accelerates adoption of this transformative technology across our customers while adhering to their stringent security standards.”\n\nMatt Teschke\n\nCTO of RedHorse",
      "# [Yurts Enterprise AI](https://www.yurts.ai/about)\nbridging ai and fortune companies\n\nYurts serves as a bridge for Fortune companies aiming to integrate AI, enhancing their security and privacy measures. Its unique value is in addressing AI challenges, such as secure connections across systems, that have hindered its adoption in the global workforce.\n\nConnecting any system enhancing adoption\n\nYurts fosters broad adoption by connecting with any system, transforming knowledge bases into searchable repositories, and upholding high security standards. Its evolving models allow customization to optimize cost, privacy, and performance.\n\nFounded in 2022, Yurts is an enterprise-ready GenAI platform on a mission to deliver secure and scalable GenAI solutions that transform mission-critical systems. Co-founded by Ben Van Roo, Jason Schnitzer, and Guruprasad Raghavan, the company emerged from a strategic partnership with the Department of Defense to create a secure and private platform tailored for mission-critical environments.\n\nBy transforming knowledge management and enterprise workflows at scale, Yurts empowers organizations to achieve unmatched efficiency through integration across diverse applications and data stores. Yurts is redefining the way enterprises harness the power of AI to maximize productivity and performance.\n\nYurts raises $40M in Series B! On a mission for secure, scalable GenAI to transform mission-critical systems. Read more about the announcement here.\n\nBen Van Roo\n\nCEO & Founder\n\nBen is the CEO/Co-Founder of Yurts. Ben served as the EVP of National Security at Primer AI, VP of Data Science at Chegg, and was a Researcher at RAND working with the DOD. Ben has spent his career building technology companies serving the Public and the Private sector.\n\nJason Schnitzer\n\nCTO & Founder\n\nAs CTO at Yurts, Jason supports the tech org. His journey includes roles in Production Engineering at Meta, VP on Infra at Looker, and CTO at Chegg. Throughout his career, Jason's passion has remained constant: building platforms, products, and teams.\n\nGuruprasad Raghavan\n\nLead Research Scientist & Founder\n\nGuru pursues a mix of pure & applied research to develop algorithms and strategies that power Yurts' platform. He derives most of his inspiration from the workings of the human brain and dreams to have Yurts's platform as adaptable, reliable and self-healing as the biological brain! He has his PhD from Caltech in Computational neuroscience.\n\nAre you ready to transform the way work gets done? Join a forward-thinking team where colleagues are friends, and our customers are our biggest advocates. Together, let's build the future by integrating AI into everyday tools, data, and workflows to simplify work processes.\n\nCheck it out",
      "# [Yurts Enterprise AI](https://www.yurts.ai/products)\nMission Critical GenAI At Scale\n\nTransform knowledge management and mission critical workflows at scale through a highly adaptable, secure, Gen AI platform.\n\nRequest Demo\n\nSearch\n\nQuery multiple applications at once\n\nBreak down data silos to harness the knowledge within your documents, apps, and daily operations.\n\nLearn More\n\nChat\n\nRefine queries with natural language\n\nDig deeper into data sources. Ask questions via Chat to refine searches.\n\nWrite\n\nGenerate reports using the best data available\n\nCreate personalized, context-rich reports and summaries using your own proprietary data.\n\nEMBEDDED ASSISTANT\n\nDeploy AI where you need it most\n\nEmbed your assistant into your favorite enterprise apps, giving you a consistent AI experience everywhere you go.\n\nLearn More\n\nENTERPRISE SEARCH\n\nMake decisions with confidence\n\nYurts leverages proprietary Retrieval Augmented Generation (RAG) models to ensure our platform serves your the most relevant and recent enterprise data.\n\nLearn More",
      "# [The Bridge to Enterprise AI](https://www.yurts.ai/blog)\nWhen you visit or interact with our sites, services or tools, we or our authorized service providers may use cookies for storing information to help provide you with a better, faster and safer experience and for marketing purposes.",
      "# [Current Job Openings](https://www.yurts.ai/careers)\nI've lost five pounds and gained the respect of my family since joining! Not a joke! Yurts has enabled me to take ownership of and work on engineering problems that are genuinely interesting to explain to others (who isn't fascinated by at least one modern AI app?) while allowing me the time and flexibility to take care of my family and myself. Not easy to find at a tech company, but much appreciated!\n\nWorking at Yurts means being surrounded by highly skilled and friendly people. The environment here is one of continuous learning and discovery, with excellent autonomy for those who seek challenges and growth. People here are fantastic, the space is full of technical challenges that are so rewarding to solve with this team, and lil yurty is the best company mascot!\n\nYurts is an exceptional company that blends a vibrant, creative, and busy environment with a commitment to autonomy and employee well-being. With outstanding leadership, Yurts fosters a culture of hard work and dedication, yet remains considerate and kind to its team members. It's a place where people are empowered to work independently while enjoying a fun, collaborative atmosphere.\n\nI love working at Yurts because it provides me the opportunity to see an organization's processes improve with our technology. There is nothing like helping someone realize that there is a solution to speed up their critical workflows, help them to be more accurate, and ultimately allow them to do less of what they hate and more of what they love about their job!",
      "# [Generative AI for Enterprise](https://www.yurts.ai/enterprise)\nSTREAMLINE ENTERPRISE OPERATIONS\n\nYurts delivers intelligent AI solutions that enable seamless efficiency and optimize customer experiences in large-scale enterprises. We empower any team across any industry with a unified, comprehensive AI platform for smarter, faster operations.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/pricing)\n“\n\nWorking with Yurts is a win-win knowing that they have a full stack platform that scales to 1000s of users and runs in the most secure environments.\n\nMatt Teschke, CTO Redhorse",
      "# [Yurts Enterprise AI](https://www.yurts.ai/platform)\n“Yurts’ expertise in deploying solutions for classified use cases accelerates adoption of this transformative technology across our customers while adhering to their stringent security standards.”\n\nMatt Teschke\n\nCEO of Redhorse\n\ninnovate and scale at the pace of ai\n\nEnsure your AI models remain up-to-date and cost-efficient, maintaining peak performance aligned with evolving business and tech changes. Flexibility and control so AI works for you.\n\nmonitor and adapt in real-time\n\nBalance costs, control usage. Gain insights into generative AI usage, capacity, and latency by tracking key metrics to optimize results.\n\n‍\n\nIdentify trends to enhance efficiency and adapt to technological changes.\n\nintegrations and embedded experiences\n\nSeamlessly integrate and leverage AI insights across various platforms and legacy applications—ensuring a cohesive and efficient workflow.\n\n‍\n\nEmbed wherever your people work and tailor the user experience.\n\nsecurity and access control\n\nSafeguard sensitive data through stringent and granular access controls, deploy in your datacenter, your VPC (Virtual Private Cloud), and across various public clouds.\n\nLearn More",
      "# [Explore product videos and demos](https://www.yurts.ai/video)\nWhen you visit or interact with our sites, services or tools, we or our authorized service providers may use cookies for storing information to help provide you with a better, faster and safer experience and for marketing purposes.",
      "# [Generative AI for Manufacturing](https://www.yurts.ai/manufacturing)\nGet Customers Answers Fast: Make every interaction with a customer first-class by giving your support team access to immediate answers.\n\nSupport R&D Efforts: Keep your research and development teams focused on innovation and let Yurts aggregate notes, write summaries, and distribute information for you.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/contact)\nGovernment-born and enterprise-ready. See how Yurts helps teams do their best work.\n\nSign up for a demo with our sales team to discover how Yurts can help you:",
      "# [Generative AI for Aerospace](https://www.yurts.ai/aerospace)\nImprove Efficiency with Automated Workflows:\n\n‍Spend more time on things that matter, and let repetitive tasks like weekly work reports get drafted for you.\n\nMake Decisions Faster: Instantly analyze and summarize documents, so you can make informed decisions without spending hours sifting through data.\n\nDrive Aerospace R&D:Allow your research and development teams to focus on innovation while Yurts aggregates notes, writes summaries, and distributes information for complex aerospace projects with in-text citations and direct quotes.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/ai-assistant)\nEmbedded Assistant\n\nYurts Assistants are everywhere you work\n\nEmbed your Assistant across your favorite enterprise apps, bringing you a consistent and intuitive experience no matter where your work takes you.",
      "# [Privacy Policy 2024](https://www.yurts.ai/privacy-policy)\n‍\n\nAbout\n\nThis Privacy Policy describes how Yurts Technologies, Inc. (\"Yurts\", “we\", “us” or \"our\") processes personal information that we collect through our digital properties that link to this Privacy Policy, including our website (collectively, the “Service”), as well as through social media, our marketing activities, and other activities described in this Privacy Policy. Yurts may provide additional or supplemental privacy policies to individuals depending upon the context at the time we collect personal information.\n\nYurts provides a comprehensive AI platform for its enterprise customers that modernizes enterprise knowledge and workflows. This Privacy Policy does not apply to personal information, if any, that we may process on behalf of our enterprise customers (such as businesses, government entities, and other organizations) while providing the platform and other services to them. Our use of information that we process on behalf of our enterprise customers may be governed by our agreements with such customers. If you have questions regarding your personal information that we process on behalf of an enterprise customer, please direct your question to that enterprise customer.\n\nWe designed our websites, AI platform and services for enterprise customers and their representatives. We do not offer products or services for use by individuals for their personal, familial or household purposes. Accordingly, we treat all personal information that we collect as described in this Privacy Policy as pertaining to individuals in their capacities as representatives of the relevant enterprise and not their individual capacities.\n\n‍\n\nPersonal information we collect\n\nInformation you provide to us or that we generate about you. Personal information you may provide to us through the Service or otherwise or that we generate about you may include:\n\nContact data, such as your first and last name, salutation, email address, mailing address, professional title and company name, and phone number.\n\nCommunications data based on our exchanges with you, including when you contact us through the Service, contact forms, social media, email or otherwise.\n\nMarketing data, such as your preferences for receiving our marketing communications and details about your engagement with them.\n\nOther data not specifically listed here such as that entered in freeform text, which we will use as described in this Privacy Policy or as otherwise disclosed at the time of collection. We ask that you not provide us with any confidential, sensitive or otherwise proprietary information through the Service.\n\nThird-party sources. We may combine personal information we receive from you with personal information we obtain from other sources, such as:\n\nPublic sources, such as government agencies, public records, social media platforms, and other publicly available sources.\n\nPrivate sources, such as data providers and social media platforms.\n\nMarketing partners, such as joint marketing partners and event co-sponsors.\n\nAutomatic data collection. We, our service providers, and our business partners may automatically log information about you, your computer or mobile device, and your interaction over time with the Service, our communications and other online services, such as:\n\nDevice data, such as your computer or mobile device’s operating system type and version, manufacturer and model, browser type, screen resolution, RAM and disk size, CPU usage, device type (e.g., phone, tablet), IP address, unique identifiers (including identifiers used for advertising purposes), language settings, mobile device carrier, radio/network information (e.g., Wi-Fi, LTE, 3G), and general location information such as city, state or general geographic area.\n\nOnline activity data, such as pages or screens you viewed, how long you spent on a page or screen, the website you visited before browsing to the Service, navigation paths between pages or screens, information about your activity on a page or screen, access times and duration of access, and whether you have opened our emails or clicked links within them.\n\nCommunication interaction data such as your interactions with our email or other communications (e.g., whether you open and/or forward emails) – we may do this through use of pixel tags (which are also known as clear GIFs), which may be embedded invisibly in our emails.\n\nCookies and similar technologies. Some of the automatic collection described above is facilitated by the following technologies:\n\nCookies, which are text files that websites store on a visitor‘s device to uniquely identify the visitor’s browser or to store information or settings in the browser for the purpose of helping you navigate between pages efficiently, remembering your preferences, enabling functionality, helping us understand user activity and patterns, and facilitating analytics and online advertising.\n\nLocal storage technologies, like HTML5, that provide cookie-equivalent functionality but can store larger amounts of data on your device outside of your browser in connection with specific applications.\n\nWeb beacons, also known as pixel tags or clear GIFs, which are used to demonstrate that a webpage or email was accessed or opened, or that certain content was viewed or clicked.\n\nChat technologies, such as those provided by us or another party that employ cookies and other software code to operate the chat features that you can use to communicate with us through the Service. To operate the chat features, we and the relevant other party may access and use information about webpages visited on our website, your IP address, your general geographic information (e.g., city, state), and other personal information you share through online chats for the purposes described in this Privacy Policy.\n\n‍\n\nData about others. We may offer features that help users invite their contacts to use the Service, and we may collect contact details about these invitees so we can deliver their invitations. Please do not refer someone to us or share their contact details with us unless you have their permission to do so.\n\n‍\n\nHow we use your personal information\n\nWe may use your personal information for the following purposes or as otherwise described at the time of collection:\n\nService delivery and operations. We may use your personal information to:\n\nprovide, operate and improve the Service and our business;\n\npersonalizing the Service, including remembering the devices from which you have previously logged in and remembering your selections and preferences as you navigate the Service;\n\nfacilitate Service features such as chat functionality;\n\ncommunicate with you about the Service, including by sending announcements, updates, security alerts, and support and administrative messages;\n\ncommunicate with you about events in which you participate;\n\nunderstand your needs and interests, and personalize your experience with the Service and our communications; and\n\nprovide support for the Service, and respond to your requests, questions and feedback.\n\nResearch and development. We may use your personal information for research and development purposes, including to analyze and improve the Service and our business. As part of these activities, we may create aggregated, de-identified and/or anonymized data from personal information we collect. We make personal information into de-identified or anonymized data by removing information that makes the data personally identifiable to you. We may use this de-identified or anonymous data and share it with third parties for our lawful business purposes, including to analyze and improve the Service and promote our business.\n\nMarketing. We may collect and use your personal information for marketing purposes:\n\nDirect marketing. We may send you Yurts-related or other direct marketing communications. You may opt-out of our marketing communications as described in the Opt-out of marketing section below.\n\nService improvement and analytics. We may use your personal information to analyze your usage of the Service, improve the Service, improve the rest of our business, help us understand user activity on the Service, including which pages are most and least visited and how visitors move around the Service, as well as user interactions with our emails, and to develop new products and services.\n\nCompliance and protection. We may use your personal information to:\n\ncomply with applicable laws, lawful requests, and legal process, such as to respond to subpoenas or requests from government authorities;\n\nprotect our, your or others’ rights, privacy, safety or property (including by making and defending legal claims);\n\naudit our internal processes for compliance with legal and contractual requirements or our internal policies;\n\nenforce the terms and conditions that govern the Service; and\n\nprevent, identify, investigate and deter fraudulent, harmful, unauthorized, unethical or illegal activity, including cyberattacks and identity theft.\n\nWith your consent. In some cases, we may specifically ask for your consent to collect, use or share your personal information, such as when required by law.\n\nCookies and similar technologies. In addition to the other uses included in this section, we may use the Cookies and similar technologies described above for the following purposes:\n\nTechnical operation. To allow the technical operation of the Service.\n\nFunctionality. To enhance the performance and functionality of our services.\n\nAnalytics. To help us understand user activity on the Service, including which pages are most and least visited and how visitors move around the Service, as well as user interactions with our emails.\n\nCookies may also be used by our online data partners or vendors to associate these activities with other personal information they or others have about you, including by association with your email or home address. We (or service providers on our behalf) may then send communications and marketing to these email or home addresses. You may opt out of receiving this advertising by visiting https://app.retention.com/optout\n\n‍\n\nHow we share your personal information\n\nWe may share your personal information with the following parties and as otherwise described in this Privacy Policy or at the time of collection.\n\nService providers. Third parties that provide services on our behalf or help us operate the Service or our business (such as hosting, information technology, customer support, chat providers, email delivery, consumer research, marketing, and website analytics).\n\nThird parties designated by you. We may share your personal data with third parties where you have instructed us or provided your consent to do so. We will share personal information that is needed for these other companies to provide the services that you have requested. We do not control how these third parties may use your personal information.\n\nProfessional advisors. Professional advisors, such as lawyers, auditors, bankers and insurers, where necessary in the course of the professional services that they render to us.\n\nAuthorities and others. Law enforcement, government authorities, and private parties, as we believe in good faith to be necessary or appropriate for the compliance and protection purposes described above.\n\nBusiness transferees. We may disclose personal information in the context of actual or prospective business transactions (e.g., investments in or financings of Yurts, or the sale, transfer or merger of all or part of our business, assets or shares), for example, we may need to share certain personal information with prospective counterparties and their advisers. We may also disclose your personal information to an acquirer, successor, or assignee of Yurts as part of any merger, acquisition, sale of assets, or similar transaction, and/or in the event of an insolvency, bankruptcy, or receivership in which personal information is transferred to one or more third parties as one of our business assets.\n\n‍\n\nYour choices\n\nYou may have the following choices with respect to your personal information.\n\nOpt-out of marketing communications. You may opt-out of marketing-related emails by following the opt-out or unsubscribe instructions at the bottom of the email, or by contacting us. Please note that if you choose to opt-out of marketing-related emails, you may continue to receive service-related and other non-marketing emails.\n\nCookies. Most browsers let you remove or reject cookies. To do this, follow the instructions in your browser settings. Many browsers accept cookies by default until you change your settings. Please note that if you set your browser to disable cookies, the Service may not work properly. For more information about cookies, including how to see what cookies have been set on your browser and how to manage and delete them, visit www.allaboutcookies.org. You can also configure your device to prevent images from loading to prevent web beacons from functioning.\n\nDo Not Track. Some Internet browsers may be configured to send “Do Not Track” signals to the online services that you visit. We currently do not respond to “Do Not Track” or similar signals. To find out more about “Do Not Track,” please visit http://www.allaboutdnt.com.\n\nDeclining to provide information. We need to collect personal information to provide certain services. If you do not provide the information we identify as required or mandatory, we may not be able to provide those services.\n\n‍\n\nOther sites and services\n\nThe Service may contain links to websites, mobile applications, and other online services operated by third parties. In addition, our content may be integrated into web pages or other online services that are not associated with us. These links and integrations are not an endorsement of, or representation that we are affiliated with, any third party. We do not control websites, mobile applications or online services operated by third parties, and we are not responsible for their actions. We encourage you to read the privacy policies of the other websites, mobile applications and online services you use.\n\n‍\n\nSecurity\n\nWe employ a number of technical, organizational and physical safeguards designed to protect the personal information we collect. However, security risk is inherent in all internet and information technologies, and we cannot guarantee the security of your personal information.\n\n‍\n\nInternational data transfer\n\nWe are headquartered in the United States and may use service providers that operate in other countries. Your personal information may be transferred to the United States or other locations where privacy laws may not be as protective as those in your state, province, or country.\n\n‍\n\nChildren\n\nThe Service is not intended for use by anyone under 18 years of age. If you are a parent or guardian of a child from whom you believe we have collected personal information in a manner prohibited by law, please contact us. If we learn that we have collected personal information through the Service from a child without the consent of the child’s parent or guardian as required by law, we will comply with applicable legal requirements to delete the information.\n\n‍\n\nChanges to this Privacy Policy\n\nWe reserve the right to modify this Privacy Policy at any time. If we make material changes to this Privacy Policy, we will notify you by updating the date of this Privacy Policy and posting it on the Service or other appropriate means. Any modifications to this Privacy Policy will be effective upon our posting the modified version (or as otherwise indicated at the time of posting). In all cases, your use of the Service after the effective date of any modified Privacy Policy indicates your acceptance of the modified Privacy Policy.\n\n‍\n\nHow to contact us",
      "# [Yurts Enterprise AI](https://www.yurts.ai/government-defense)\nGENAI SOLUTIONS FOR government defense\n\nYurts delivers a scalable GenAI platform for government defense enhancing mission-critical deployment, operational decision making, and intelligent military analytics.\n\nRobust Safeguards\n\n‍\n\nImplements stringent guardrails to prevent hallucinations and ensures the integrity of information, vital for analytics-driven responses and achieving mission-critical objectives.\n\nContinuous Verification\n\n‍\n\nIntroduces thorough review processes to evaluate the accuracy of intelligence, supporting informed strategic choices and maintaining operational success.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/press-release)\nYurts Secures $40M In Series B Funding To Accelerate Growth for Mission-Critical Defense, Government, and Enterprise Systems\n\nThe funding round, led by XYZ Venture Capital, expands Yurts' impact of empowering users by unlocking workflows with efficient, highly secure AI solutions.\n\nDecember 3, 2024\n\nOracle and Yurts Collaborate to Bring Secure Generative AI Solutions to Defense and Intelligence Sectors\n\nLeveraging Oracle Cloud Infrastructure (OCI) and Yurts' pioneering GenAI platform, the collaboration streamlines operations and enhances data management with the full benefits of Cloud and AI.\n\nOctober 23, 2024",
      "# [Government Civilian](https://www.yurts.ai/government-civilian)\nEnhancing Services for Civilians Agencies with Genai\n\nBy leveraging Yurts to identify and address challenges proactively, agencies can preempt service disruptions in their mission-critical tasks. This ensures continuous access to critical services for millions of constituents.\n\nRobust Safeguards\n\n‍\n\nImplements stringent guardrails to prevent hallucinations and ensures the integrity of information, vital for analytics-driven responses and achieving mission-critical objectives.\n\nContinuous Verification\n\n‍\n\nIntroduces thorough review processes to evaluate the accuracy of intelligence, supporting informed strategic choices and maintaining operational success.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/team/yurts)\nWhen you visit or interact with our sites, services or tools, we or our authorized service providers may use cookies for storing information to help provide you with a better, faster and safer experience and for marketing purposes.",
      "# [Generative AI for Supply Chain](https://www.yurts.ai/supply-chain-management)\nGenAI for Supply Chain Management\n\nYurts molds into every facet of your supply chain, ensuring you're equipped to handle the dynamics of today's demand and supply challenges. Get customized, AI-driven recommendations tailored to your supply chain needs.",
      "# [Security and Privacy](https://www.yurts.ai/security-and-privacy)\nMore on security\n\nIf you’ve found a security vulnerability or have Yurts AI security inquiries, please email us at security@yurts.ai. Contact our sales team for more details on Yurts Enterprise AI security and reliability.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/team/mark-allen)\nWhen you visit or interact with our sites, services or tools, we or our authorized service providers may use cookies for storing information to help provide you with a better, faster and safer experience and for marketing purposes.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/team/jessica-agarwal)\nMeet Yurts blog contributor\n\nJessica is fueled by curiosity and is passionate about building human-centric experiences. At Yurts she loves the challenge of helping our customers leverage the potential of Gen AI to transform the way humans work and interact.‍ Before Yurts, Jessica led Walmart’s marketing efforts in launching their people band to their 2.3 million associates globally, having joined them with acquisition of Jet.com, a company that redefined e-commerce and became a challenger to Amazon. Jessica previously held leadership roles in marketing at Chegg all the way from an early startup to IPO, and at Pricelock, a startup that was a disruptor in energy trading markets.‍",
      "# [Yurts Enterprise AI](https://www.yurts.ai/team/mike-tong)\nWhen you visit or interact with our sites, services or tools, we or our authorized service providers may use cookies for storing information to help provide you with a better, faster and safer experience and for marketing purposes.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/team/chris-jung)\nMeet Yurts blog contributor\n\nChris focuses on delivering value for Yurts customers and runs internal business operations at the company. Prior to Yurts, Chris was the Director of GTM Operations and Customer Success at Primer AI and was technology consultant at PwC.‍ The Yurts team voted Chris most likely to practice his golf swing during a meeting."
    ],
    "search_results": [
      {
        "title": "AI That Knows Your Enterprise | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/",
        "snippet": "Yurts Enterprise AI connects you to your data. Unlock efficiency and automation with secure, context-aware AI—embedded directly into your work environment.",
        "formattedUrl": "https://www.yurts.ai/"
      },
      {
        "title": "Generative AI for Government | Yurts enterprise AI",
        "link": "https://www.yurts.ai/government",
        "snippet": "Yurts amplifies your unit's productivity by automating repetitive documentation, enabling soldiers to be fully committed to mission success.",
        "formattedUrl": "https://www.yurts.ai/government"
      },
      {
        "title": "About | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/about",
        "snippet": "Yurts is on a mission, to connect people to their best work. An AI-powered platform where the everyday worker becomes the architect of their productivity.",
        "formattedUrl": "https://www.yurts.ai/about"
      },
      {
        "title": "Products | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/products",
        "snippet": "Discover Yurts Enterprise AI. Enhance efficiency and decision-making with secure AI platforms, assistants, search, chat, and analytics tools.",
        "formattedUrl": "https://www.yurts.ai/products"
      },
      {
        "title": "The Bridge to Enterprise AI | Blog | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/blog",
        "snippet": "Generative AI revolutionizes aerospace by streamlining workflows and improving decision-making. Yurts helps engineers, technicians, and supply managers manage ...",
        "formattedUrl": "https://www.yurts.ai/blog"
      },
      {
        "title": "Careers at Yurts | Current Job Openings",
        "link": "https://www.yurts.ai/careers",
        "snippet": "Join The Yurts Team. Be a part of the team that is bridging the gap between AI and real-world problems. We have a mission-focused culture, remote work, ...",
        "formattedUrl": "https://www.yurts.ai/careers"
      },
      {
        "title": "Generative AI for Enterprise | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/enterprise",
        "snippet": "Yurts delivers intelligent AI solutions that enable seamless efficiency and optimize customer experiences in large-scale enterprises. We empower any team across ...",
        "formattedUrl": "https://www.yurts.ai/enterprise"
      },
      {
        "title": "Pricing | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/pricing",
        "snippet": "Scalable costs combining a flat platform fee and per-user charges, with optimized resource usage and custom quotations.",
        "formattedUrl": "https://www.yurts.ai/pricing"
      },
      {
        "title": "Platform Overview | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/platform",
        "snippet": "Yurts' expertise in deploying solutions for classified use cases accelerates adoption of this transformative technology across our customers.",
        "formattedUrl": "https://www.yurts.ai/platform"
      },
      {
        "title": "Explore product videos and demos | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/video",
        "snippet": "Yurts, a powerful generative AI solution, securely connects across systems, fostering enterprise adoption. It integrates with company data, making knowledge ...",
        "formattedUrl": "https://www.yurts.ai/video"
      },
      {
        "title": "Generative AI for Manufacturing | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/manufacturing",
        "snippet": "Discover Yurts for manufacturing. Enhance automation, improve maintenance, streamline support, and boost R&D with secure, collaborative GenAI solutions.",
        "formattedUrl": "https://www.yurts.ai/manufacturing"
      },
      {
        "title": "Request a Demo | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/contact",
        "snippet": "Contact us for a demo to find out how Yurts AI automates Enterprise workflow.",
        "formattedUrl": "https://www.yurts.ai/contact"
      },
      {
        "title": "Generative AI for Aerospace | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/aerospace",
        "snippet": "Yurts delivers a scalable GenAI platform for Aerospace that transforms knowledge management and mission-critical workflows for operational teams.",
        "formattedUrl": "https://www.yurts.ai/aerospace"
      },
      {
        "title": "AI Assistant | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/ai-assistant",
        "snippet": "Yurts AI Assistant: Enhance productivity with seamless integration. Embed in apps for intuitive use. Optimize reporting and elevate customer interactions.",
        "formattedUrl": "https://www.yurts.ai/ai-assistant"
      },
      {
        "title": "Privacy Policy 2024 | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/privacy-policy",
        "snippet": "Sep 27, 2024 ... Read Yurts Privacy Policy to see how we collect, use, and protect personal information via our digital properties, social media, ...",
        "formattedUrl": "https://www.yurts.ai/privacy-policy"
      },
      {
        "title": "Government Defense | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/government-defense",
        "snippet": "Yurts offers a scalable GenAI platform for government defense, boosting mission-critical deployment, operational decision, & intelligent military analytics.",
        "formattedUrl": "https://www.yurts.ai/government-defense"
      },
      {
        "title": "Yurts Newsroom | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/press-release",
        "snippet": "Yurts Secures $40M In Series B Funding To Accelerate Growth for Mission-Critical Defense, Government, and Enterprise Systems. The funding round, led by XYZ ...",
        "formattedUrl": "https://www.yurts.ai/press-release"
      },
      {
        "title": "Government Civilian | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/government-civilian",
        "snippet": "By leveraging Yurts to identify and address challenges proactively, agencies can preempt service disruptions in their mission-critical tasks.",
        "formattedUrl": "https://www.yurts.ai/government-civilian"
      },
      {
        "title": "Yurts | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/yurts",
        "snippet": "Yurts is the go-to solution for Fortune companies to safely navigate and implement enterprise AI, streamline complex tasks, and boost business efficiency.",
        "formattedUrl": "https://www.yurts.ai/team/yurts"
      },
      {
        "title": "Generative AI for Supply Chain | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/supply-chain-management",
        "snippet": "Enhance supply chain efficiency with Yurts. Get custom recommendations, automated workflows, and improved support. Streamline your supply chain with GenAI.",
        "formattedUrl": "https://www.yurts.ai/supply-chain-management"
      },
      {
        "title": "Security and Privacy | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/security-and-privacy",
        "snippet": "Yurts: Secure AI Solutions - Prioritizing stringent security, trusted by Defense & Energy Departments. Discover our enterprise-level security commitments.",
        "formattedUrl": "https://www.yurts.ai/security-and-privacy"
      },
      {
        "title": "Mark Allen | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/mark-allen",
        "snippet": "Mark Allen, Head of Solutions and Analytics launches the Yurts product in the commercial space.",
        "formattedUrl": "https://www.yurts.ai/team/mark-allen"
      },
      {
        "title": "Jessica Agarwal | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/jessica-agarwal",
        "snippet": "Jessica Agarwal, VP of Marketing passionate about building human-centric experiences. .",
        "formattedUrl": "https://www.yurts.ai/team/jessica-agarwal"
      },
      {
        "title": "Mike Tong | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/mike-tong",
        "snippet": "Mike Tong, Sr. ML Engineer - Federal Mike Tong, Sr. Applied ML Engineer at Yurts. Innovator in AI and pet care. Dedicated to solving real-world problems ...",
        "formattedUrl": "https://www.yurts.ai/team/mike-tong"
      },
      {
        "title": "Chris Jung | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/chris-jung",
        "snippet": "Chris Jung, Chief of Staff runs internal business operations at Yurts..",
        "formattedUrl": "https://www.yurts.ai/team/chris-jung"
      },
      {
        "title": "Mike Mascari | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/mike-mascari",
        "snippet": "A former Intelligence, Surveillance, and Reconnaissance (ISR) aircraft operator working with USSOCOM, US Air Force, and US Army units.",
        "formattedUrl": "https://www.yurts.ai/team/mike-mascari"
      },
      {
        "title": "Maddie Wolf | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/maddie-wolf",
        "snippet": "Meet Yurts blog contributor Maddie leads operations at Yurts. She knows that “operations” can mean pretty much anything.",
        "formattedUrl": "https://www.yurts.ai/team/maddie-wolf"
      },
      {
        "title": "Alexandra Walker | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/alexandra-walker",
        "snippet": "Alexandra Walker, Executive Assistant, Operations Alexandra Walker, Executive Assistant & Ops at Yurts AI. Skilled in operations & team building.",
        "formattedUrl": "https://www.yurts.ai/team/alexandra-walker"
      },
      {
        "title": "Clara Kay | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/clara-kay",
        "snippet": "Clara Kay, Sr. Business Development Rep previously with Maergo & Netlify. An experience Account Exec leading foundational sales..",
        "formattedUrl": "https://www.yurts.ai/team/clara-kay"
      },
      {
        "title": "William Du | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/william-du",
        "snippet": "William Du, Staff Engineer, Applications & ML Lead passionate about ML/AI & its role in creating new productivity tools..",
        "formattedUrl": "https://www.yurts.ai/team/william-du"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Yurts AI on LinkedIn](https://www.linkedin.com/company/yurtsai)\n- [Yurts AI on X (formerly Twitter)](https://x.com/yurtsai?lang=en)\n- [Guruprasad Raghavan on X](https://twitter.com/guruprasad_r94?lang=en)\n\n# Job boards\n- [Careers at Yurts | Current Job Openings](https://www.yurts.ai/careers)\n\n# App stores\n- [AWS Marketplace: Yurts AI](https://aws.amazon.com/marketplace/seller-profile?id=seller-arsg6hmpabjvo)\n\n# Product reviews\n- No detailed product reviews found in the search results.\n\n# News articles (most recent first, grouped by event)\n### Funding and Partnerships\n- [Yurts Secures $40M In Series B Funding To Accelerate Growth for Mission-Critical Defense, Government, and Enterprise Systems](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html) - Dec 3, 2024\n- [Yurts Secures $16M Contract with SOCOM to Integrate Large Language Models](https://www.prnewswire.com/news-releases/yurts-secures-16m-contract-with-socom-to-integrate-large-language-models-in-defense-enterprises-302007065.html) - Dec 6, 2023\n- [Redhorse announces strategic partnership with Yurts AI to deploy secure Generative AI solutions](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/) - Feb 21, 2024\n- [Oracle and Yurts Collaborate to Bring Secure Generative AI to Enterprises](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html) - Oct 23, 2024\n\n### General News\n- [NVIDIA's Anthony Robbins Secures 7th Wash100 Award for Contributions Including Yurts AI](https://executivebiz.com/2024/02/nvidias-anthony-robbins-secures-7th-wash100-award-for-continuing-efforts-to-promote-ai-in-government/) - Feb 7, 2024\n- [We've come a long way from RPA: How AI agents are transforming customer support, featuring Yurts AI](https://venturebeat.com/ai/weve-come-a-long-way-from-rpa-how-ai-agents-are-revolutionizing-automation/) - 6 days ago\n- [Chegg Embraced AI. ChatGPT Ate Its Lunch Anyway | WIRED](https://www.wired.com/story/chegg-embraced-ai-chatgpt-ate-its-lunch-anyway/) - Jun 5, 2023\n\n# Key employees (grouped by employee)\n### Guruprasad Raghavan\n- [Exploring the Mind-Brain interface | Conscious Living](https://consciousliving.sites.stanford.edu/news/exploring-mind-brain-interface) - Apr 28, 2023\n- [Engineering artificial systems with natural intelligence](https://thesis.library.caltech.edu/15123/1/Guru_PhD_thesis_v2.pdf)\n\n### Other Key Employees\n- [Mark Hair on LinkedIn](https://rw.linkedin.com/posts/mhair_linkedin-activity-7029173585487261696-EmWd)\n- [Mike Tong, Sr. ML Engineer - Federal](https://www.yurts.ai/team/mike-tong)\n- [William Du, Staff Engineer, Applications & ML Lead](https://www.yurts.ai/team/william-du)\n\n# Other pages on the company website\n- [About | Yurts Enterprise AI](https://www.yurts.ai/about)\n- [Yurts Newsroom | Yurts Enterprise AI](https://www.yurts.ai/press-release)\n- [Generative AI for Enterprise | Yurts Enterprise AI](https://www.yurts.ai/enterprise)\n- [Generative AI for Government | Yurts enterprise AI](https://www.yurts.ai/government)\n\n# Other\n- [Yurts Company Overview, Contact Details & Competitors | LeadIQ](https://leadiq.com/c/yurts/63617f9bd4454f2aa396b5ff)\n- [Yurts Technologies - Crunchbase Company Profile & Funding](https://www.crunchbase.com/organization/yurts-technologies-inc)\n- [Yurts AI: Transforming Sales Performance](https://www.yurts.ai/blog/how-yurts-enterprise-ai-can-boost-your-sales-performance-4-key-ways) - Sep 4, 2024\n- [Yurts | Author | Yurts Enterprise AI](https://www.yurts.ai/team/yurts)",
  "crunchbase_markdown": null,
  "customer_experience_result": {
    "output_text": "# Positive Aspects of Yurts.ai\n\n- \"What’s attractive about this service is the access to tons of models, the pre canned prompts and plug ins, and easy data model management.\" [(leightjhou, Reddit, 2024-09-27)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/)\n- \"Yurts AI. IL-2 through IL-6, lots of users in the DOD. Can run on any cloud and bare metal, lots of different models, plug-ins, etc.\" [(Material_Reporter_27, Reddit, 2024-11-21)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/ly8p64m/)",
    "intermediate_steps": [
      "- \"What’s attractive about this service is the access to tons of models, the pre canned prompts and plug ins, and easy data model management.\" [(leightjhou, Reddit, 2024-09-27)](cache://reddit/1)\n- \"Yurts AI. IL-2 through IL-6, lots of users in the DOD. Can run on any cloud and bare metal, lots of different models, plug-ins, etc.\" [(Material_Reporter_27, Reddit, 2024-11-21)](cache://reddit/2)"
    ],
    "url_to_review": {},
    "review_markdowns": [
      "# Post ID 1fqyzfl: Ask Sage alternatives? with +1 score by [(leightjhou, Reddit, 2024-09-27)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/)\nI’m looking for any Ask Sage alternatives I should look at. What’s attractive about this service is the access to tons of models, the pre canned prompts and plug ins, and easy data model management. We don’t have a big dev team so something like this would get us off the ground faster. Any suggestions?\n\n\n## Comment ID ly8p64m with +2 score by [(Material_Reporter_27, Reddit, 2024-11-21)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/ly8p64m/) (in reply to ID 1fqyzfl):\nYurts AI.  IL-2 through IL-6, lots of users in the DOD. Can run on any cloud and bare metal, lots of different models, plug-ins, etc.\n\n## Comment ID lp93aqg with +1 score by [(None, Reddit, 2024-09-27)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/lp93aqg/) (in reply to ID 1fqyzfl):\n[deleted]\n\n### Comment ID lp93vwd with +1 score by [(leightjhou, Reddit, 2024-09-27)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/lp93vwd/) (in reply to ID lp93aqg):\nNothing specific yet. I’m just curious if there are alternatives to look at before I go down the rabbit hole with sage\n\n## Comment ID lq23bqa with +1 score by [(leightjhou, Reddit, 2024-10-02)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/lq23bqa/) (in reply to ID 1fqyzfl):\nBump",
      "# Post ID 1fs4ta3: Best LLM for quick on prem/hybrid RAG in regulated industry  with +7 score by [(None, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/)\n[deleted]\n\n## Comment ID lphqwhc with +2 score by [(e278e, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphqwhc/) (in reply to ID 1fs4ta3):\nWhat business uses/ solutions are you attempting to solve?  \n\n1. Chat with machinery manuals or medical records?  I need more information of the data please.\n2.  Can you give me a few examples of questions people may ask?\n\nData sources?\n\n### Comment ID lphtdt5 with +1 score by [(Informal-Fondant-855, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphtdt5/) (in reply to ID lphqwhc):\nYes. Chat with unstructured and structured docs, and find them based on keyword\n\n#### Comment ID lpjop6p with +2 score by [(Able-Tip240, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lpjop6p/) (in reply to ID lphtdt5):\nMistral and Llama3 I've had good luck with.\n\n#### Comment ID lpjuwd2 with +1 score by [(e278e, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lpjuwd2/) (in reply to ID lphtdt5):\nIf you want to just vectorize all the documents and pray for the best then that's simple, and you will rely on just similarity search.  Generally chunking is what causes the most information because it breaks the flow of everything. \n\nDepending on the source, I like to clean the data as much as possible. and extract the important stuff.  Or break it down by sections and topics, so those chunks are closer together.  I store the important topics and questions into json to create a library of information about everything.  Then if you want to go a step further and specialized knowledge is important.  then a graph representation usually helps (graph rag)\n\nAt the core, it is about language compression and ideas.  A one sentence with zero information does not help me if you are asking for guidance.\n\n## Comment ID lphv6mv with +1 score by [(passing_marks, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphv6mv/) (in reply to ID 1fs4ta3):\nFastest way might be to go ahead with Co-pilot studio or maybe setup Logic Apps, you have enough control and can make some iterations and improvements while still being a bit flexible.\nAlthough you might have something ready as a PoC, a week time is too little to have something that works well for structured and unstructured data.\n\n### Comment ID lphvzw2 with +1 score by [(Informal-Fondant-855, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphvzw2/) (in reply to ID lphv6mv):\nSo Co-Pilot studio looped in to azure/LogicApps? Interesting. What if I need to have permission controls on folder locks that are individualized for users?\n\n#### Comment ID lphwetb with +1 score by [(passing_marks, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphwetb/) (in reply to ID lphvzw2):\nSorry I meant either of them, not co-pilot studio in logic apps.\nThere are AI connectors and examples on LogicApps to do RAG by MS, you can check out them to see if it fits your short to medium term plans.\n\n## Comment ID lq4ulh5 with +1 score by [(Jdonavan, Reddit, 2024-10-03)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lq4ulh5/) (in reply to ID 1fs4ta3):\nUse GPT via Azure Open AI services and be done with it.  Easy Peasy.  \n\nFor a vector DB, Weaviate has on-prem installations and is quite good.\n\n### Comment ID lq57mgm with +1 score by [(Informal-Fondant-855, Reddit, 2024-10-03)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lq57mgm/) (in reply to ID lq4ulh5):\nNo file indexing? Seems costly if 500 users are searching across the sea of millions of docs?\n\n#### Comment ID lq5arfz with +1 score by [(Jdonavan, Reddit, 2024-10-03)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lq5arfz/) (in reply to ID lq57mgm):\n???  I’m not sure I follow.  Do you understand how RAG is implemented?"
    ],
    "sources": {
      "steam_url": null,
      "steam_reviews": null,
      "google_play_url": null,
      "google_play_reviews": null,
      "apple_store_url": null,
      "apple_reviews": null,
      "reddit_urls": [
        "https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/",
        "https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/"
      ],
      "reddit_search_url": "https://www.google.com/search?q=site%3Areddit.com+%22Yurts.ai%22+related%3Ayurts.ai+"
    }
  },
  "glassdoor_result": null,
  "news_result": [
    [
      "Yurts.ai",
      "Yurts.ai",
      "yurts.ai",
      null
    ],
    [
      {
        "title": "Terms of Use Policy | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/terms-of-use-policy",
        "snippet": "Jan 12, 2024 ... ... Yurts Technologies, Inc. (“Yurts,” “our” or “we”), including the website located at: https://www.yurts.ai/ (the “Website”). By clicking on the “i accept ...",
        "formattedUrl": "https://www.yurts.ai/terms-of-use-policy"
      },
      {
        "title": "Oracle and Yurts Collaborate to Bring Secure Generative AI ...",
        "link": "https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html",
        "snippet": "Oct 23, 2024 ... Yurts AI White Horizontal Version Logo (PRNewsfoto/Yurts AI) ... Yurts' advanced AI capabilities into their existing operations. ... News Releases in Similar Topics ...",
        "formattedUrl": "https://www.prnewswire.com/news.../oracle-and-yurts-collaborate-to-bring-..."
      },
      {
        "title": "Redhorse announces strategic partnership with Yurts AI to deploy ...",
        "link": "https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/",
        "snippet": "Feb 21, 2024 ... ... News. Redhorse announces strategic partnership with Yurts AI to deploy secure Generative AI solutions. Home / News / Redhorse announces strategic partnership ...",
        "formattedUrl": "https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yu..."
      },
      {
        "title": "Monitor performance and accuracy of enterprise RAG",
        "link": "https://www.yurts.ai/blog/chat-metrics-for-enterprise-scale-rag",
        "snippet": "Jul 30, 2024 ... Yurts Enterprise AI logo · Platform. Products. Search ... connected it all to a user interface. ... CompanyCareersBlogVideosIn the News. Contact. info@yurts.ai.",
        "formattedUrl": "https://www.yurts.ai/blog/chat-metrics-for-enterprise-scale-rag"
      },
      {
        "title": "Yurts Secures $40M In Series B Funding To Accelerate Growth for ...",
        "link": "https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html",
        "snippet": "Dec 3, 2024 ... Yurts AI White Horizontal Version Logo (PRNewsfoto/Yurts AI) ... similar challenges: integrating AI into legacy ... News Releases in Similar Topics ...",
        "formattedUrl": "https://www.prnewswire.com/news.../yurts-secures-40m-in-series-b-funding..."
      },
      {
        "title": "Unveiling the Future: AI Collaboration Takes Flight: Startup Connect ...",
        "link": "https://www.startupmontereybay.com/unveiling-the-future-ai-collaboration-takes-flight-startup-connect-meeting-recap/",
        "snippet": "Jun 19, 2024 ... The discussion went beyond AI and delved into the future. Craig Vachon, CEO at AI Redefined and Jason Schnitzer, CTO & Founder at Yurts AI explored how AI ...",
        "formattedUrl": "https://www.startupmontereybay.com/unveiling-the-future-ai-collaboration-..."
      },
      {
        "title": "Roadmap: Defense Tech - Bessemer Venture Partners",
        "link": "https://www.bvp.com/atlas/roadmap-defense-tech",
        "snippet": "Jan 28, 2024 ... ... Yurts.ai for enterprise AI across search and documentation. 2. The DOD is embracing the modern data and AI infrastructure stack alongside new network ...",
        "formattedUrl": "https://www.bvp.com/atlas/roadmap-defense-tech"
      },
      {
        "title": "Enterprise Solutions Showcase - Solution Providers at KMWorld 2024",
        "link": "https://www.kmworld.com/Conference/2024/Showcase.aspx",
        "snippet": "Mar 26, 2024 ... Yurts AI. Yurts delivers intelligent AI solutions ... news, trends analysis, case studies, and market ... We inform our more than 45,000 subscribers about the ...",
        "formattedUrl": "https://www.kmworld.com/Conference/2024/Showcase.aspx"
      },
      {
        "title": "(ART)ificial Intelligence from Madrona's IA Summit",
        "link": "https://www.nyse.com/insights/artificial-intelligence",
        "snippet": "Nov 15, 2024 ... Co-Founder & CEO, Yurts AI. posterUrl. Betsabeh Madani-Hermann. VP & Global Head of Research, Philips. posterUrl. Cody Coleman. CEO & Co-Founder, Coactive AI.",
        "formattedUrl": "https://www.nyse.com/insights/artificial-intelligence"
      },
      {
        "title": "Washington Headquarters Services - Products, Competitors ...",
        "link": "https://www.cbinsights.com/company/washington-headquarters-services",
        "snippet": "Dec 4, 2024 ... yasmeeta December 4, 2024 Yurts, an AI ... ai also vying for similar roles in military AI integration. ... ” Featured image courtesy of yurts.ai. Dec 4, 2024.",
        "formattedUrl": "https://www.cbinsights.com/company/washington-headquarters-services"
      },
      {
        "title": "KM & AI Summit Attendee Profile",
        "link": "https://www.kmworld.com/KMAISummit/2025/AttendeeProfile.aspx",
        "snippet": "Nov 19, 2024 ... Newport News Shipyard; NextEra Energy; NICE; Nice Systems Inc. Nike Inc ... Yurts AI; Zeta Alpha; Zimmerman Associates Inc. (ZAI). Brought to You By the ...",
        "formattedUrl": "https://www.kmworld.com/KMAISummit/2025/AttendeeProfile.aspx"
      },
      {
        "title": "We've come a long way from RPA: How AI agents are ...",
        "link": "https://venturebeat.com/ai/weve-come-a-long-way-from-rpa-how-ai-agents-are-revolutionizing-automation/",
        "snippet": "6 days ago ... For example, Sierra leverages AI to automate complex customer support scenarios, freeing up employees to focus on strategic initiatives. Startups like Yurts AI ...",
        "formattedUrl": "https://venturebeat.com/.../weve-come-a-long-way-from-rpa-how-ai-agents..."
      },
      {
        "title": "Engineering flexible machine learning systems by traversing ...",
        "link": "https://www.nature.com/articles/s42256-024-00902-x",
        "snippet": "Oct 3, 2024 ... Related work. The major contribution of our framework is that it provides ... Yurts AI, San Francisco, CA, USA. Guruprasad Raghavan. Alexandria University ...",
        "formattedUrl": "https://www.nature.com/articles/s42256-024-00902-x"
      },
      {
        "title": "Orbital Insight company information, funding & investors | Dealroom.co",
        "link": "https://app.dealroom.co/companies/orbital_insight",
        "snippet": "May 29, 2024 ... yurts ai. & 6 more. Related Content. Climate tech. Read more ... Recent News about Orbital Insight. Edit · Exclusive: Wozniak's space firm ...",
        "formattedUrl": "https://app.dealroom.co/companies/orbital_insight"
      },
      {
        "title": "Startup Monterey Bay",
        "link": "https://www.facebook.com/startupmontereybay/",
        "snippet": "Nov 6, 2024 ... Exciting News! ... We are thrilled to have Craig Vachon, CEO at AI Redefined (AIR) and Jason Schnitzer, CTO & Founder at Yurts AI leading the discussions on ...",
        "formattedUrl": "https://www.facebook.com/startupmontereybay/"
      },
      {
        "title": "The Science of Consciousness Conference",
        "link": "https://consciousness.arizona.edu/",
        "snippet": "Mar 17, 2024 ... Community News - SUMMER 2025 - Rome, Italy. Faith, Science, Mysticism - Rome ITALY ... (Yurts AI) (Catalina J). Dual Aspect Monism - Michael Silberstein ...",
        "formattedUrl": "https://consciousness.arizona.edu/"
      }
    ],
    [
      "# [Terms of Use Policy](https://www.yurts.ai/terms-of-use-policy)\nPlease read this Terms of Use Agreement (the “Terms of Use”) carefully. These Terms of Use govern your use of those websites (including web portals) owned or controlled by Yurts Technologies, Inc. (“Yurts,” “our” or “we”), including the website located at: https://www.yurts.ai/ (the “Website”).\n\nBy clicking on the “i accept” button, completing the registration process and/Or browsing the website, you represent that (1) You have read, understand, and agree to be bound by the terms of use, (2) You are of legal age to form a binding contract with yurts, and (3) You have the authority to enter into the terms of use personally or on behalf of yurts you have named as the user, and to bind that company to the terms of use. The term “you” refers to the individual or legal entity, as applicable, identified as the user when you registered on the website. If you do not agree to be bound by the terms of use, you may not access or use the website.\n\nPlease note that the terms of use are subject to change by yurts in its sole discretion at any time. When changes are made, yurts will make a new copy of the terms of use available at the website. We will also update the “last updated” date at the top of the terms of use. Yurts may require you to provide consent to the updated terms of use in a specified manner before further use of the website is permitted. If you do not agree to any change(s) After receiving a notice of such change(s), you shall stop using the website. Otherwise, your continued use of the website constitutes your acceptance of such change(s). Please regularly check the website to view the then-current terms of use.\n\n1. Use of the website\n\nThe Website and the content provided by Yurts via the Website (collectively, the “Yurts Properties”) are protected by copyright laws throughout the world. Unless otherwise specified by Yurts in a separate license, your right to use any Yurts Properties is subject to the Terms of Use.\n\n1.1 Updates\n\nYou understand that Yurts Properties are evolving. As a result, Yurts may require you to accept updates to Yurts Properties that you have installed on your computer or mobile device. You acknowledge and agree that Yurts may update Yurts Properties with or without notifying you.\n\n1.2 Certain Restrictions\n\nThe rights granted to you in the Terms of Use are subject to the following restrictions: (a) you shall not license, sell, rent, lease, transfer, assign, reproduce, distribute, host or otherwise commercially exploit Yurts Properties or any portion of Yurts Properties, (b) you shall not frame or utilize framing techniques to enclose any trademark, logo, or other Yurts Properties (including images, text, page layout or form) of Yurts; (c) you shall not use any metatags or other “hidden text” using Yurts’ name or trademarks; (d) you shall not modify, translate, adapt, merge, make derivative works of, disassemble, decompile, reverse compile or reverse engineer any part of Yurts Properties except to the extent the foregoing restrictions are expressly prohibited by applicable law; (e) access Yurts Properties in order to build a similar or competitive website, application or service; (f) except as expressly stated herein, no part of Yurts Properties may be copied, reproduced, distributed, republished, downloaded, displayed, posted or transmitted in any form or by any means; and (g) you shall not remove or destroy any copyright notices or other proprietary markings contained on or in Yurts Properties. Any future release, update or other addition to Yurts Properties shall be subject to the Terms of Use. Yurts, its suppliers and service providers reserve all rights not granted in the Terms of Use. Any unauthorized use of Yurts Properties terminates the licenses granted by Yurts pursuant to the Terms of Use.\n\n1.3 Unauthorized Use\n\nYou agree that you will not, under any circumstances: (a) interfere with or damage Yurts Properties, including, without limitation, through the use of viruses, cancel bots, Trojan horses, harmful code, flood pings, denial-of-service attacks, packet or IP spoofing, forged routing or electronic mail address information, or similar methods or technology; (b) modify or cause to be modified any files that are a part of Yurts Properties; (c) disrupt, overburden, or aid or assist in the disruption or overburdening of: (i) any computer or server used to offer or support Yurts Properties; or (ii) the enjoyment of Yurts Properties by any other person; (d) access, tamper with or use non-public areas of Yurts Properties, Yurts’ computer systems, or the technical delivery systems of Yurts’ providers; (e) attempt to probe, scan, or test the vulnerability of any Yurts system or network, or breach any security or authentication measures; (f) disrupt or interfere with the security of, or otherwise cause harm to, Yurts Properties, systems, resources, accounts, passwords, servers or networks connected to or accessible through Yurts Properties or any affiliated or linked sites; or (g) avoid, bypass, remove, deactivate, impair, descramble, or otherwise circumvent any technological measure implemented by Yurts or any of Yurts’ providers or any other third party to protect Yurts Properties.\n\n1.4 Third-Party Websites, Applications and Ads\n\nYurts Properties may contain links to third-party websites (“Third-Party Websites”) and applications (“Third-Party Applications”) and advertisements for third parties (“Third-Party Ads”). When you click on a link to a Third-Party Website, Third-Party Application or Third-Party Ad, we will not warn you that you have left Yurts Properties and are subject to the terms and conditions (including privacy policies) of another website or destination. Such Third-Party Websites, Third-Party Applications and Third-Party Ads are not under the control of Yurts. Yurts is not responsible for any Third-Party Websites, Third-Party Applications or Third-Party Ads. Yurts provides these Third-Party Websites, Third-Party Applications and Third Party Ads only as a convenience and does not review, approve, monitor, endorse, warrant, or make any representations with respect to Third-Party Websites, Third-Party Applications or Third-Party Ads, or any product or service provided in connection therewith. You use all links in Third-Party Websites, Third-Party Applications and Third-Party Ads at your own risk. When you leave our Website, the Agreement and policies no longer govern. You should review applicable terms and policies, including privacy and data gathering practices, of any Third-Party Websites or Third-Party Applications, and make whatever investigation you feel necessary or appropriate before proceeding with any transaction with any third party.\n\n2. Ownership\n\n2.1 Yurts Properties\n\nYou agree that Yurts and its suppliers own all rights, title and interest in Yurts Properties. You will not remove, alter or obscure any copyright, trademark, service mark or other proprietary rights notices incorporated in or accompanying Yurts Properties. Yurts’ stylized name and other related graphics, logos, service marks and trade names used on or in connection with Yurts Properties are the trademarks of Yurts and may not be used without permission in connection with any third-party products or services. Other trademarks, service marks and trade names that may appear on or in Yurts Properties are the property of their respective owners.\n\n2.2 Feedback\n\nYou agree that submission of any ideas, suggestions, documents, and/or proposals to Yurts through its suggestion, feedback, wiki, forum or similar pages (“Feedback”) is at your own risk and that Yurts has no obligations (including without limitation obligations of confidentiality) with respect to such Feedback. You represent and warrant that you have all rights necessary to submit the Feedback. You hereby grant to Yurts a fully paid, royalty-free, perpetual, irrevocable, worldwide, non-exclusive, and fully sublicensable right and license to use, reproduce, perform, display, distribute, adapt, modify, re-format, create derivative works of, and otherwise commercially or non-commercially exploit in any manner, any and all Feedback, and to sublicense the foregoing rights, in connection with the operation and maintenance of Yurts Properties.\n\n3. Indemnification\n\nYou agree to indemnify and hold Yurts, its parents, subsidiaries, affiliates, officers, employees, agents, partners and licensors (collectively, the “Yurts Parties”) harmless from any losses, costs, liabilities and expenses (including reasonable attorneys’ fees) relating to or arising out of: (a) your use of, or inability to use, Yurts Properties; (b) your violation of the Terms of Use; or (c) your violation of any applicable laws, rules or regulations. Yurts reserves the right, at its own cost, to assume the exclusive defense and control of any matter otherwise subject to indemnification by you, in which event you will fully cooperate with Yurts in asserting any available defenses. You agree that the provisions in this section will survive any termination of your Account, the Terms of Use or your access to Yurts Properties.\n\n4. Disclaimer of Warranties\n\nYou expressly understand and agree that to the extent permitted by applicable law, your use of yurts properties is at your sole risk, and yurts properties are provided on an “as is” and “as available” basis, with all faults. Yurts parties expressly disclaim all warranties, representations, and conditions of any kind, whether express or implied, including, but not limited to, the implied warranties or conditions of merchantability, fitness for a particular purpose and non-infringement. Yurts parties make no warranty, representation or condition that: (1) yurts properties will meet your requirements; (2) your use of yurts properties will be uninterrupted, timely, secure or error-free; (3) the results that may be obtained from use of yurts properties will be accurate or reliable; or (4) any errors in yurts properties will be corrected. The website may be subject to delays, cancellations and other disruptions. No advice or information, whether oral or written, obtained from yurts or through yurts properties will create any warranty not expressly made herein.\n\n5. Limitation of Liability\n\n5.1 Disclaimer of Certain Damages\n\nYou understand and agree that in no event shall yurts parties be liable for any loss of profits, revenue or data, indirect, incidental, special, exemplary, or consequential damages arising out of or in connection with yurts properties, or damages or costs due to loss of production or use, business interruption, procurement of substitute goods or services, or personal or property damage or emotional distress, whether or not yurts has been advised of the possibility of such damages, arising out of or in connection with the terms of use, or from any communications, interactions or meetings with other users of yurts properties, on any theory of liability, resulting from: (1) the use or inability to use yurts properties; (2) the cost of procurement of substitute goods or services resulting from any goods, data, information or services purchased or obtained or messages received for transactions entered into through yurts properties; (3) unauthorized access to or alteration of your transmissions or data; (4) statements or conduct of any third party on yurts properties; or (5) any other matter related to yurts properties, whether based on warranty, copyright, contract, tort (including negligence), product liability or any other legal theory.\n\n5.2 Cap on Liability\n\nUnder no circumstances will yurts parties be liable to you for more than the greater of (a) $100, and (b) the remedy or penalty imposed by the statute under which such claim arises. The foregoing cap on liability shall not apply to liability of a yurts party for (a) death or personal injury caused by a yurts party’s negligence; or for (b) any injury caused by a yurts party’s fraud or fraudulent misrepresentation.\n\n5.3 Basis of the Bargain\n\nThe limitations of damages set forth above are fundamental elements of the basis of the bargain between yurts and you. Certain jurisdictions do not allow the exclusion or limitation of certain damages. If these laws apply to you, some or all of the above exclusions or limitations may not apply to you, and you might have additional rights.\n\n6. Term and Termination\n\n6.1 Term\n\nThe Terms of Use commence on the date when you accept them (as described in the preamble above) and remain in full force and effect while you use Yurts Properties, unless terminated earlier in accordance with the Terms of Use. Either party may terminate these Terms of Use upon notice to the other party.\n\n6.2 Effect of Termination\n\nUpon termination of these Terms of Use, your right to use Yurts Properties will automatically terminate immediately. All provisions of the Terms of Use, which by their nature should survive, shall survive termination of these Terms of Use, including without limitation, ownership provisions, warranty disclaimers, and limitation of liability.\n\n7. International Users\n\nYurts Properties can be accessed from countries around the world and may contain references to services and content that are not available in your country. These references do not imply that Yurts intends to announce such services or content in your country. Yurts Properties are controlled and offered by Yurts from its facilities in the United States of America. Yurts makes no representations that Yurts Properties are appropriate or available for use in other locations. Those who access or use Yurts Properties from other jurisdictions do so at their own volition and are responsible for compliance with local law.\n\n8. General Provisions\n\n8.1 Electronic Communications\n\nThe communications between you and Yurts use electronic means, whether you visit Yurts Properties or send Yurts e-mails, or whether Yurts posts notices on Yurts Properties or communicates with you via e-mail. For contractual purposes, you (1) consent to receive communications from Yurts in an electronic form; and (2) agree that all terms and conditions, agreements, notices, disclosures, and other communications that Yurts provides to you electronically satisfy any legal requirement that such communications would satisfy if it were to be in writing. The foregoing does not affect your statutory rights.\n\n8.2 Assignment\n\nThe Terms of Use, and your rights and obligations hereunder, may not be assigned, subcontracted, delegated or otherwise transferred by you without Yurts’ prior written consent, and any attempted assignment, subcontract, delegation, or transfer in violation of the foregoing will be null and void.\n\n8.3 Force Majeure\n\nYurts shall not be liable for any delay or failure to perform resulting from causes outside its reasonable control, including, but not limited to, acts of God, war, terrorism, riots, embargos, acts of civil or military authorities, fire, floods, accidents, strikes or shortages of transportation facilities, fuel, energy, labor or materials.\n\n8.4 Governing Law\n\nThe Terms of Use and any action related thereto will be governed and interpreted by and under the laws of Washington, D.C., consistent with the Federal Arbitration Act, without giving effect to any principles that provide for the application of the law of another jurisdiction. The United Nations Convention on Contracts for the International Sale of Goods does not apply to this Agreement.\n\n8.5 Notice\n\nWhere Yurts requires that you provide an e-mail address, you are responsible for providing Yurts with your most current e-mail address. In the event that the last e-mail address you provided to Yurts is not valid, or for any reason is not capable of delivering to you any notices required/ permitted by the Terms of Use, Yurts’ dispatch of the e-mail containing such notice will nonetheless constitute effective notice. You may give notice to Yurts by making a submission via our “Contact” page at https://www.yurts.ai/contact. Such notice shall be deemed given when receipt of submission is confirmed by Yurts.\n\n8.6 Waiver\n\nAny waiver or failure to enforce any provision of the Terms of Use on one occasion will not be deemed a waiver of any other provision or of such provision on any other occasion.\n\n8.7 Severability\n\nIf any provision of the Terms of Use is, for any reason, held to be invalid or unenforceable, the other provisions of the Terms of Use will remain enforceable, and the invalid or unenforceable provision will be deemed modified so that it is valid and enforceable to the maximum extent permitted by law.\n\n8.8 Entire Agreement\n\nThe Terms of Use are the final, complete and exclusive agreement of the parties with respect to the subject matter hereof and supersedes and merges all prior discussions between the parties with respect to such subject matter.",
      "# [Oracle and Yurts Collaborate to Bring Secure Generative AI Solutions to Defense and Intelligence Sectors by Yurts AI on 2024-10-23](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html)\nLeveraging Oracle Cloud Infrastructure (OCI) and Yurts' pioneering GenAI platform, the collaboration streamlines operations and enhances data management with the full benefits of Cloud and AI.\n\nSAN FRANCISCO, Oct. 23, 2024 /PRNewswire/ -- Yurts, the secure and private Generative AI (GenAI) integration platform that empowers people to do their best work, announced a collaboration with Oracle, the cloud technology company that provides organizations around the world with computing infrastructure and software to help them innovate, unlock efficiencies and becomes more effective to bring Yurt's advanced, secure generative artificial intelligence (GenAI) solutions to the defense and intelligence sectors. This collaboration leverages Oracle Cloud Infrastructure (OCI) and Yurts' pioneering GenAI platform to deliver secure private GenAI capabilities designed to enhance mission-critical decision-making and operational efficiency.\n\n\"Oracle Cloud Infrastructure combined with Yurts' secure and innovative GenAI platform allows greater cost controls and security for defense and intelligence agencies as they utilize and scale GenAI,\" said Peter Guerra, Group Vice President of data and AI, Oracle. \"Our collaboration aims to empower agencies with the tools needed to make swift, informed decisions, allowing them to stay ahead in a rapidly evolving landscape in secure and competitive ways.\"\n\nYurts' platform enables warfighters and support personnel to quickly find information across a variety of mission critical systems, and employ GenAI based techniques for creation of new documents and insights. Yurts can be used to embed GenAI Chat and Search Assistants directly into mission critical systems, modernizing existing workflows and legacy applications.\n\n\"At Yurts, we want to empower organizations with a secure and flexible GenAI platform that gives them control over how they use, integrate, and scale GenAI for operational excellence,\" said Ben Van Roo, Co-Founder and CEO, Yurts. \"The Defense and Intelligence Communities have spent billions of dollars developing IT infrastructure – much of it built on Oracle solutions. The Yurts and Oracle collaboration is a natural way to rapidly modernize this infrastructure with GenAI.\"\n\nOracle's long history of supporting U.S. national security, coupled with its comprehensive cloud services, offers a unique environment for deploying Yurts' GenAI solutions. This relationship helps ensure that defense and intelligence agencies can leverage leading cloud infrastructure, cloud applications, and AI while meeting stringent security and sovereignty requirements.\n\nTogether, Oracle and Yurts will provide support and deployment services, allowing defense and intelligence agencies to integrate Yurts' advanced AI capabilities into their existing operations.\n\nAbout Yurts\n\nBorn out of working with the Department of Defense, Yurts is a secure and private GenAI integration platform that empowers people to do their best work. Yurts transforms knowledge management and mission critical workflows at scale through a highly adaptable GenAI platform that augments workforce efficiency across applications and data stores. Yurts is built for security, cost controls, and operational efficiency, deployable in IL-2 through IL-6 environments. To learn more visit Yurts.ai\n\nAbout Oracle PartnerNetwork\n\nOracle PartnerNetwork (OPN) is Oracle's partner program designed to enable partners to accelerate the transition to cloud and drive superior customer business outcomes. The OPN program allows partners to engage with Oracle through track(s) aligned to how they go to market: Cloud Build for partners that provide products or services built on or integrated with Oracle Cloud; Cloud Sell for partners that resell Oracle Cloud technology; Cloud Service for partners that implement, deploy and manage Oracle Cloud Services; Industry Healthcare for partners that provide commercially available products and/or services built with Oracle Cloud and Oracle Health technologies; and License & Hardware for partners that build, service or sell Oracle software licenses or hardware products. Customers can expedite their business objectives with OPN partners who have achieved Expertise in a product family or cloud service. To learn more visit: http://www.oracle.com/partnernetwork\n\nTrademark\n\nOracle, Java, MySQL and NetSuite are registered trademarks of Oracle Corporation. NetSuite was the first cloud company—ushering in the new era of cloud computing.\n\nLearn more about Yurts for Government\n\nLearn more about Yurts Platform\n\nLearn more about Yurts Products\n\nSOURCE Yurts AI",
      "# [Redhorse announces strategic partnership with Yurts AI to deploy secure Generative AI solutions – Redhorse Corporation by Josef Buford on 2024-02-21](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/)\nARLINGTON, VA February 21, 2024 – Redhorse, a leader in technology-driven, mission-focused solutions for the federal government, is thrilled to announce a new partnership with Yurts, a pioneer in secure generative artificial intelligence solutions.\n\nAs federal agencies face increasing demands for modernization and efficiency, the need to deploy AI solutions with tangible impact has never been greater. Yurts, known for its comprehensive generative AI platform, excels at modernizing knowledge-driven enterprise workflows, ensuring operational efficiency, flexibility, and uncompromised privacy – essential features for federal applications.\n\nRedhorse has been at the forefront of DoD AI adoption, supporting important efforts such as Project Maven, the Joint Artificial Intelligence Center (JAIC), and the DoD Chief Digital and Artificial Intelligence Office (CDAO) from day one. Redhorse’s ability to understand the mission problem, identify use cases, rapidly prototype solutions and integrate them into mission-critical applications, combined with Yurts turnkey platform, gives federal customers a proven pathway to harnessing generative AI in support of their mission.\n\n“Partnering with Yurts aligns perfectly with our values and mission to provide cutting-edge, secure technology solutions,” said Matt Teschke, CTO of Redhorse. “Yurts’ expertise in deploying solutions for classified use cases accelerates adoption of this transformative technology across our customers while adhering to their stringent security standards.” Through this partnership, Redhorse and Yurts together will bring this revolutionary technology to our industry and our customers, enhancing the mission to support and elevate workflow efficiency.\n\nRedhorse is excited to develop mission-focused capabilities atop the Yurts platform, showcasing the innovative strengths and versatility of both companies in addressing complex challenges for the government.\n\n“Yurts is excited to partner with Redhorse and deliver mission outcomes for the federal government,” stated Ben Van Roo, Co-Founder and CEO of Yurts. “From critical missions to the modernization of legacy technologies, we believe generative AI will advance federal government in its journey towards technological empowerment and enhanced decision-making.”\n\n# # # # # #\n\nAbout Redhorse Corporation\n\nRedhorse Corporation is a technology driven company that delivers innovative data science and digital transformation solutions enabling mission success for national security, intelligence community, and federal civilian customers. We are focused on transforming the way the government interacts with data and technology to improve mission results. Redhorse is backed by Blue Delta Capital Partners, a leading venture capital firm focused on the U.S. Federal Government market.\n\nAbout Yurts\n\nBorn out of working with the Department of Defense, Yurts is a secure and private GenAI integration platform that empowers people to do their best work. Yurts transforms knowledge management and mission critical workflows at scale through a highly adaptable, secure GenAI platform that augments critical workflows across applications and data stores.",
      "# [Monitor performance and accuracy of enterprise RAG by Alec Hoyland](https://www.yurts.ai/blog/chat-metrics-for-enterprise-scale-rag)\nEnsuring the efficiency and accuracy of your retrieval-augmented generation (RAG) system is paramount. So you’ve put the work in — hosted an LLM inference server, created a vector database and document store, built a document ingestion pipeline, and connected it all to a user interface. Your RAG workflow is running smoothly: accepting user queries, returning contextual documents from your document store, and generating an LLM response. But how do you know that your responses are good? What happens if you change your prompt or model? Is there an improvement or degradation in your end-to-end RAG workflow?\n\nAt Yurts, we know deploying an effective RAG pipeline means more than just connecting components. It’s about ensuring every change improves functionality without degrading performance. That’s why our on-premises solutions—whether in private VPCs of major providers like GCP, OCI, and AWS, or even on bare metal—come with comprehensive dashboards to meticulously track your RAG system’s performance. Dive in as we reveal cutting-edge metrics that bring clarity and precision to your chat evaluations.\n\nWhile there are plenty of open-source resources for testing document retrieval against a gold-standard dataset with labeled data (such as the excellent RAGAS package), Yurts saw a major lack in tooling for quantifying the end-to-end chat performance of our RAG system across both the retrieval and generation steps of RAG. Instead of testing against a gold-standard dataset, we wanted to create metrics for evaluating chat performance on real-world customer data in production. Our chat metrics evaluation suite runs over each chat message in our production and development environments, logging the metrics live to our data dashboard.\n\nEach chat metric accepts a data structure containing all the metadata created for a chat message, most importantly the user query, retrieved context, and generated response. Each metric then returns a numerical result, typically a score between 0 and 1. Importantly, none of these metrics require labeled data and we don’t use a bigger LLM like GPT-4 to evaluate our RAG performance. They work on real-world data live in production using small embedding and encoder/decoder models.\n\nBelow, we describe what some of our metrics compute and how we interpret them.\n\nThe Query-Context Agreement metric answers the question, “Is the retrieved context relevant to the user’s query?” We use a cross-encoder model to compute an agreement score between a sentence embedding of the query and a sentence embedding of each sentence of the context, taking the mean and standard deviation.\n\nThe Query-Response Agreement metric determines how relevant the response was to the user query. We use a small LLM to generate questions that can be answered using the response only and then take the mean and standard deviation of similarity scores between embeddings of the user query and the generated questions. This returns a value between 0 and 1 that describes how well the response answers the original user question.\n\nWe use the Response-Context Agreement metric to evaluate how well the generated response used the context in its answer. We don’t look for exact matches between the context and the generation since we want the LLM to paraphrase or synthesize information if that would make a better response. Instead, this metric computes a pairwise cosine similarity matrix between embeddings of the response and context sentences and then uses the Hungarian algorithm to find the optimal bipartite matching (i.e., the optimal one-to-one mapping between response and context sentences). The idea is that each sentence of context should approximately map to one sentence in the response.\n\nHallucinations exist in any LLM system. While we have taken significant steps to mitigate hallucinations in our generated responses, they still appear from time to time. For this reason, we implemented inline hallucination flagging, and we report hallucinations as a metric as well, counting the number of hallucinated entities relative to the number of entities in the response. For more information, read our blog post on hallucination flagging.\n\nWe expose some of our metrics directly to users on the Yurts platform UI, while others are run as a nightly cron job and stored in our database. We visualize all our metrics in our data dashboard, available to power-users in on-premise deployments of the Yurts platform. One particularly salient use-case is A/B testing of a new model or prompt: How does changing the prompt or model improve or degrade the quality of the RAG system? Those questions can be easily answered via the data dashboard, enabling power-users to self-manage and customize the platform to their use-cases and their data.",
      "# [Yurts Secures $40M In Series B Funding To Accelerate Growth for Mission-Critical Defense, Government, and Enterprise Systems by Yurts AI on 2024-12-03](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html)\nThe funding round, led by XYZ Venture Capital, expands Yurts' impact of empowering users by unlocking workflows with efficient, highly secure AI solutions.\n\nSAN FRANCISCO, Dec. 3, 2024 /PRNewswire/ -- Yurts, a leader in secure and trusted generative AI (GenAI) integration at scale for defense, government, and enterprise customers, announced today a $40 million Series B funding round led by XYZ Venture Capital, with participation from Glynn Capital, Nava Ventures, Bloomberg Beta, and Mango Capital. Yurts will use this funding to accelerate its growth and capabilities in leading an industry shift from experimental GenAI use to deep integration across mission-critical systems, unlocking real value within secure environments.\n\nRecently, Yurts delivered the first AI platform for the United States Department of Defense (DOD) on a secret-level network, providing new insights and superior decision-making capabilities for operational leaders and field personnel. Yurts has also won several additional enterprise deployments and government contracts, delivering a critical integration layer between models and internal applications that unlocks new workflows within high-security environments.\n\n\"As GenAI adoption matures, the challenge is no longer about demos and pilots; it's about delivering tangible results,\" said Ben Van Roo, Co-Founder and CEO of Yurts. \"For both the DOD and large enterprises, this means connecting AI to the systems that matter most—your systems of record and mission-critical applications. Yurts is purpose-built to meet this need, securely integrating AI where it can truly transform operations.\"\n\nYurts has emerged as a trusted AI partner not just in the public sector but also in commercial enterprises. Large organizations in industries such as manufacturing and aerospace face similar challenges: integrating AI into legacy systems to unlock productivity, reduce costs, and provide users with a trusted resource that removes barriers to getting things done. Yurts's approach is uniquely designed to address these parallels, combining precision, scalability, and compliance in secure environments. Importantly, Yurts does not train on a company's proprietary data and can be deployed on-premise, ensuring maximum security and control for organizations handling sensitive information.\n\nYurts's AI integration platform has been deployed in high-security settings across unclassified, sensitive, and secret environments, ensuring compliance with Department of Defense standards for sensitive data. With contracts spanning the U.S. Army, U.S. Air Force, Department of Energy, and SOCOM, Yurts is trusted to deliver AI solutions that strengthen mission-critical systems. Nearly 25% of Yurts's workforce holds active security clearances, underscoring the company's deep expertise in high-security environments.\n\n\"Yurts has broken out as a clear leader in the category of AI integration with their emphasis on deploying and scaling a solution grounded in data with a security-first framework,\" says Ross Fubini, Managing Partner at XYZ Venture Capital, who led the deal. \"Founders Ben Van Roo, Jason Schnitzer, and Guru Raghavan have built an AI platform that can be deeply integrated within high-security environments. This is a significant catalyst for both Yurts and the military, enabling the seamless integration of advanced AI capabilities into critical national security workflows. The company is positioned to meet the current and future need for AI head-on, and we're proud to support them in this mission.\"\n\nWhile Yurts's primary focus remains on the DOD and national security, its solutions are equally transformative for enterprises. A recent expansion of Yurts's partnership with Oracle highlights the company's ability to support commercial customers in modernizing their systems of record with AI, ensuring that GenAI delivers real, actionable value in complex, high-stakes environments.\n\n\"Defense and enterprise organizations face the same fundamental challenge: how to connect AI to their existing systems to unlock new workflows and insights,\" added Van Roo. \"This is where Yurts comes in. We provide the secure, integrated foundation that makes AI usable and transformative—not just theoretical.\"\n\nThe Series B funding brings Yurts's total investment to $58 million, enabling the company to scale operations, expand its team, and deepen its focus on connecting GenAI to mission-critical systems. With a proven track record in both the public and private sectors, Yurts is poised to redefine how organizations harness the power of AI in high-security environments.\n\n\"Right now, GenAI is only scratching the surface in terms of value for users. Yurts is bridging the gap between humans, GenAI, and the systems that matter most in meaningful and adaptable ways,\" said Van Roo. \"Over the past two years, we've developed technologies that move GenAI beyond experimentation, making it usable, secure, and impactful for the most critical and complex missions. Looking ahead, we're focused on expanding these capabilities with our customers in the DOD, government, and commercial sectors—ensuring AI is flexible enough to meet their needs today and evolve with them for the future.\"\n\nAbout Yurts\n\nYurts delivers secure, production-ready AI solutions designed to transform mission-critical workflows in defense, government, and enterprise environments. Founded by Ben Van Roo, Jason Schnitzer, and Guruprasad Raghavan, Yurts originated from a strategic collaboration with the Department of Defense. Its AI integration platform connects models to high-security systems of record, enabling organizations to unlock operational insights, enhance decision-making, and achieve unprecedented productivity. Learn more atwww.yurts.ai.\n\nAbout XYZ Venture Capital\n\nXYZ Venture Capital is a San Francisco and New York-based firm specializing in early-stage investments in transformative technologies. Founded by Ross Fubini, XYZ has backed companies like Anduril, Verkada, and Apex Space, focusing on overlooked industries poised for disruption. Learn more atxyz.vc.\n\nSOURCE Yurts AI",
      "# [Unveiling the Future: AI Collaboration Takes Flight: Startup Connect Meeting Recap! – Startup Monterey Bay by Alex Verdugo on 2024-06-19](https://www.startupmontereybay.com/unveiling-the-future-ai-collaboration-takes-flight-startup-connect-meeting-recap/)\nJune 11th, 2024\n\nMarina, Ca.\n\nBy Denise Silva\n\nThe Monterey Bay DART and the Institute for Innovation & Economic Development (iiED) held an engaging Startup Connect meetup on Tuesday, June 11th. The discussion went beyond AI and delved into the future. Craig Vachon, CEO at AI Redefined and Jason Schnitzer, CTO & Founder at Yurts AI explored how AI development and deployment could revolutionize different sectors. They stressed the importance of building trust, ensuring safety, and upholding ethical considerations throughout the process. Imagine enhanced enterprise search and data management that intuitively anticipates industry needs, surfacing the correct information at the right time. Pilot training is revolutionized with AI-powered simulations that push boundaries and enhance skills.\n\nJason Schnitzer, CTO & Founder at Yurts AI, a company that has received $18 million in Series A funding, discussed how his company uses AI for mission-critical systems to ensure security and reliability in national security and regulated industries.\n\nCraig Vachon, CEO at AI Redefined discussed optimizing training programs with AI-powered pilot training platforms developed by the DoD in partnership with leading companies (Joby, Archer) to address scaling challenges and personalize learning. He also touched on similar advancements in AI-assisted training applied to diverse fields, from aviation to professional development. He discussed next-generation AI tools and how advanced AI apprenticeship models can train AI faster with less data, leading to a new era of AI development.\n\nThis isn’t science fiction; it’s the future that AI is creating. The conversations during the meetup focused on the potential of AI-powered tools such as decision optimization agents and operator assistants. Both speakers mentioned that industry experts anticipate that Language Model Models (LLMs) will evolve from managing knowledge to optimizing decision-making processes. This transition is expected to significantly impact businesses across various sectors due to the future of AI.\n\nThe fundamental insight? AI is not a replacement for us but a partner in our endeavors. Collaboration is the cornerstone for ensuring this transformative technology’s responsible development and deployment.",
      "# [Roadmap: Defense Tech by Christine Deakers on 2024-01-29](https://www.bvp.com/atlas/roadmap-defense-tech)\nFor years, people thought defense was not a viable market for startups. The prevailing belief was that the Department of Defense (DOD) was limited to the realm of the major primes, including names such as Boeing, Lockheed Martin, Northrop Grumman, Raytheon, and General Dynamics. But the future of defense in the United States is undergoing massive technological transformation.\n\nSo what’s changed exactly? Mainly, the DOD now contracts with startups in all technology areas impacting national security, including horizontal domains (e.g., info & analytics, data & systems) and vertical threat vectors, across space, air, land, and sea.\n\nIn this roadmap, we outline how we view the defense tech landscape, why and how entrepreneurs can serve this massive customer, and promising areas for entrepreneurship.\n\nDefining defense tech\n\nAs an umbrella category, defense tech is much broader than rockets, tanks, and aircraft carriers. Defense tech includes everything that the DOD and the broader national security infrastructure touches—including the systems infrastructure, communications and intelligence technology, cybersecurity, advanced manufacturing, as well as the innovation leveraged on the battlefield and beyond.\n\nAt Bessemer, we define defense tech as any business that requires the DOD and defense as a core pillar of growth for the company.\n\nThis assumes the product can be dual use, government only, or currently commercial only but will expand to also be government-focused in the future. Ultimately, this involves a defense-specific product and defense specific go-to-market and sales teams. Read more on our theses here.\n\nSo why now?\n\nThe DOD has new ambitions to overcome the proverbial “valley of death”—the long gap between when a technology is first developed and tested to the time when funds are available in the budget to produce and acquire it. As U.S. Defense Secretary Lloyd Austin said The Pentagon has great potential to become “a true innovation ecosystem.” Defense technology plays a core role in this generational paradigm shift and so technology businesses should seriously consider adding the DOD as a potential new customer.\n\nStartups can play a role in protecting democracy.\n\nIn 2024, it’s a clear imperative that as geopolitical conflicts around the world intensify, promoting greater innovation within the DOD is an intrinsic part of protecting our country and its allies. Collaborating with emerging startups to gain new solutions is a strategic way for our nation to escape the perilous tendency toward all-out war when a dominant power is challenged by an emerging one (a.k.a. the “Thucydides Trap”). Emerging startups play a significant role in keeping the U.S. clear of this trap, as innovation has historically played an inextricable role in protecting democracy.\n\nFive market opportunities for defense technology startups\n\nMany of the incumbent defense industry businesses need no introduction. They are household names like Boeing, General Dynamics, Lockheed Martin, Northrop Grumman, and Raytheon Technologies. Several of these primes have dominated the industry for decades, some even for close to a century, and currently bring in tens to hundreds of billions in annual revenue.\n\nHowever, within the last decade, a string of trailblazing startups have risen to challenge the prime incumbents. Several of these newcomers have successfully attained public as well as M&A exits for their venture investors including the likes of Palantir and Rocket Lab. Both make the case that younger defense technology businesses can scale effectively to achieve strong fundamentals and attain robust valuation multiples.\n\nFollowing in the footsteps of these examples, a diverse ecosystem of defense tech startups has cropped up in recent years, fueled by strong market demand and visionary founders excited to make an impact on national security.\n\nBessemer’s defense tech market map\n\nAs we interviewed founders and experts navigating the massive transitions happening in the defense industry, we have identified five key theses we are particularly excited about investing behind:\n\n1. Cutting-edge AI/ML solutions will be the next frontier of national security\n\nThe defense community is not sitting idly by as the AI revolution sweeps the consumer and commercial industries by storm. The DOD mapped and released its formal AI adoption strategy last year. Advancements and applications of artificial intelligence and machine learning will be essential for the national agenda and the defense community’s day-to-day work. This could look like:\n\nProductivity gains from automation of manual tasks\n\nHigher quality output documents and work products\n\nFaster speed to assessment which is critical in real-time situations\n\nMore accurate insights to drive decisions\n\nInternal DOD champions acknowledge that startups are not only driving the best innovations in the space, but are also the ones with the willingness and courage to disrupt the status quo in order to drive meaningful improvement. Across the department, we’ve already witnessed the embrace of AI/ML applications across various use cases such as Vannevar Labs for foreign text workflows, government sales automation Dextral.ai for government procurement and sales automation, Axion Ray for automation of engineering and quality analytics, and Yurts.ai for enterprise AI across search and documentation.\n\n2. The DOD is embracing the modern data and AI infrastructure stack alongside new network infrastructure innovations\n\nThe success of any modern organization, commercial or federal, is tied to the insights gleaned or products built from its data. The modern data stack is fundamental in the emerging realm of defense tech since intelligence is derived from data of all modalities (video, image, text, speech, etc.).\n\nVarious branches of the government are making major investments to modernize their data and AI infrastructure stack with key requirements across both cloud as well as on-premise deployments. Startups such as Enabled Intelligence for data labeling, Unstructured.io providing ETL for LLMs, and TurbineOne’s MLOps platform are at the frontlines of equipping the defense community with the foundation to leverage the most cutting-edge tools to unlock the most value from their data troves. Similarly, on the network infrastructure side, startups such as Aalyria are pioneering new ways to deliver, connect, and orchestrate networks across different entities.\n\n3. Renewed focus on best-in-class cybersecurity solutions as table stakes\n\nBest-in-class cybersecurity has become synonymous with strong national security in the digital age and the imperative to advance cybersecurity given novel threats continues to grow. But significant headway has been made. For instance, early in 2022, the Office of Management and Budget issued a White House Memorandum setting forth a Federal zero trust architecture (ZTA) strategy, requiring agencies to meet specific cybersecurity standards and objectives by the end of 2024. That same year, the Biden Administration issued Executive Order 14028 on Improving the Nation’s Cybersecurity.\n\nProtection across all potential legacy and new attack surfaces cannot be understated and we see several technology leaders step in to help. From Bastille Technologies for wireless threat intelligence and Claroty for industry cybersecurity, to Defense Unicorns providing DevSecOps software for air-gapped networks and Virtru for zero-trust data-centric security, numerous startups are driving innovation, reinforcing the Government's defenses against increasingly sophisticated and persistent threat campaigns.\n\n4. The next generation of defense tech giants will be built upon the foundation of verticalized solutions\n\nAt Bessemer, we’ve seen the impact of vertical software transforming every industry, having spent over a decade investing in vertical SaaS leaders such as Procore, Shopify, Toast, among many other leaders. Every commercial industry has specific requirements that may not be fully served by horizontal solutions. With this in mind, we see a similar pattern emerging within the DOD ecosystem. Each branch has specific needs and unique hardware and software stacks, which invite emerging defense tech startups to enter the market by providing purpose-built solutions for vertical threat vectors before leaping across to new verticals and teams. From ShieldAI for AI-piloted aircrafts, to Modern Intelligence providing an all-platform all-sensor maritime awareness solution, to Picogrid offering land-based solutions to connect fragmented defense systems, we expect to see verticalized solutions for different slices of the DOD grow in the coming years.\n\n5. We’re in the early days of autonomous systems reaching its full potential in the defense industry\n\nAs highlighted earlier, autonomous technologies have emerged as a key paradigm for competitive advantage during warfare, and it’s still very early days within the defense tech industry. As the DOD continues exploring this technological paradigm, we expect more interest in startups innovating within the autonomous robotics and technology space.\n\nThe rise of defense tech decacorn Anduril is a testament to the adoption of unmanned aerial vehicles (UAVs), and we see many startups following suit, such as Skydio providing autonomous AI-powered drones, Saildrone for uncrewed surface vehicles, and Primodial Labs building voice-controlled autonomy software.\n\nThese aforementioned businesses are just a few examples of how the defense industry is adopting autonomous technology for the battlefield and beyond. As another example, Hadrian is redefining modern manufacturing and Varda is the world’s first orbital manufacturing and reentry platform.\n\nCase study: Evolving defense technology in Ukraine\n\nRapid deployment of advanced technology onto battlefields during conflicts between countries (rather than non-states) represents a revolution in the conduct of military operations. Ukraine illustrates this new reality and how the systems of defense have evolved in recent years. Ukraine is a case study showcasing three areas of defense tech that will need significant and immediate attention: 1) UAVs, 2) cybersecurity, 3) and mass communications and social media.\n\nUAVs: Drones have proven essential for reconnaissance, targeting, and conducting strikes. They can attack one another if needed, and also assist in the movement of supplies and soldiers. Ukraine's armed forces have lost 10,000 drones each month due to Russian electronic warfare (EW). Clearly, today’s conflicts use huge numbers of unmanned aerial systems.\n\nCybersecurity: In Ukraine, cyberspace has also emerged as a crucial battleground for offensive operations. This was exemplified by a recent cyberattack on the country's largest telecom provider, Kyivstar, which marked one of the most significant cyber events in European history. The attack severely disrupted Internet and mobile communications for millions of people, highlighting the growing importance of digital domains in modern conflicts.\n\nMass communications: Social media and news platforms have become fiercely contested arenas too, where the very rapid spread of misinformation and disinformation are menaces to society. How information spreads, and ensuring that it is factual, impacts democracy on a fundamental level. We see an opportunity for entrepreneurs to build solutions that address social and as well as financial fraud, which includes preventing and mitigating social engineering, cybercrimes, including propaganda and novel threats of modern war.\n\nOver 30 U.S. startups have already deployed products in Ukraine, but the need for better technical solutions only grows in the evolving world of military operations. As the nature of conflicts changes, the government must stay on the cutting edge. In this period of rising geopolitical tension and conflict, it seems inevitable that U.S. defense spending will rise significantly in the years ahead.\n\nOur guiding principles on how we will invest in defense technology\n\nAs we survey the landscape of defense tech, there are five qualities and dynamics we look for when investing in these founders and their businesses.\n\n1. High “defense IQ”—While investors have traditionally preferred to invest in dual-use technologies, we are excited to back the frontier of entrepreneurs monetizing mostly (or even solely) via the government. Empirically, higher levels of government concentration demand a higher ability to navigate the complexities of government procurement processes. What this means is that the founding team should have a high “defense IQ” — it earns the company respect and enables federal salespeople to speak the language of contracting officers. A high defense IQ can look like a number of different things, from prior military service in active duty, to career service on the civilian side, to relations with defense agencies from outside the government (e.g., from a prior defense-focused investing role).\n\nDefense IQ earns a startup respect with contracting officers.\n\n2. Expansive TAM—The US defense budget for 2024 is $886 billion, so capturing even a small slice of this market would represent massive potential for the new wave of defense tech startups. That said, the defense budget is sliced and diced across a number of different technological focus areas and shared among the dozens of agencies in the DOD. We’re excited to back companies that can sell technologies solving needs shared across multiple branches of the DOD. Many of these companies can also sell to other liberal governments across the world. For instance, the AUKUS (Australia, UK, and US) partnership involves strategic cooperation on technologies like cybersecurity and AI.\n\n3. Contracts as sticky, large sources of revenue—The holy grail for startups is to get on a DOD Program of Record (PoR). A PoR is an explicit line item in the DOD budget earmarking funds (often on the order of tens of millions of dollars, at least) for the startup’s technology. A PoR is also incredibly sticky, meaning that the funds are typically renewed year-after-year. Beyond the immediate financial windfall, however, being on a PoR also provides unparalleled validation and credibility. Such recognition not only signifies a strong vote of confidence from a defense agency but also opens the door to substantial, sustained funding for other agencies and partners. The fastest time to a PoR is roughly three to four years.\n\nAnother type of contract attractive to startups is the Indefinite Delivery, Indefinite Quantity (IDIQ) contract. Unlike traditional fixed-price contracts, where the government specifies a set quantity of items or a precise scope of work, an IDIQ contract allows for variations in the amount and timing of orders over a specified period. Under an IDIQ contract, the government agrees to purchase goods or services as needed, up to a predetermined maximum value or quantity. Startups under an IDIQ essentially have a hunting license over the duration of the IDIQ to find defense agencies that suffer from the problems outlined in the IDIQ and serve those needs without initiating a new procurement process each time. IDIQs can be awarded exclusively to one vendor, or to many qualified vendors.\n\nPoRs and IDIQs are merely two types of contracts that DOD awards. Others include cooperative research and development agreements (CRADAs) and OTAs (discussed above). Alternatively, companies might not sell directly to the DOD at all, choosing to act instead as a subcontractor to the large defense primes.\n\n4. Non-dilutive funding—The government is also a great source of non-dilutive funding for startups. The most prominent are Small Business Innovation Research (SBIR) grants, of which there are three “phases.”\n\nPhase I: The goal of a Phase I is to prove the feasibility of a proposed innovation. It typically involves a relatively short-term effort to conduct research and demonstrate the concept's viability. Phase I SBIRs typically last for less than 1 year and award less than $250K.\n\nPhase II: If a company successfully completes Phase I and demonstrates a technology’s feasibility, Phase II SBIRs aim to further develop the innovation through more comprehensive R&D, testing, and prototype development. More mature technologies and companies can go Direct to Phase II (D2P2), without first having to go through Phase I.\n\nPhase III: Only about 5% of companies graduate from Phase II to Phase III SBIRs, posing another “valley of death” in selling to defense. However, unlike the previous phases, Phase III is technically not a direct part of the SBIR program. Instead, it represents the transition of the technology into the commercial market. Funding for Phase III is actually expected to come from sources other than the SBIR program (e.g., government contracts or private investment).\n\nSome defense agencies also have their own specific programs, too. For example, the Air Force has its Strategic Funding Increase (STRATFI) and Tactical Funding Increase (TACFI) programs, which allocate up to $15 million to companies hoping to cross the valley of death from Phase II to Phase III SBIRs.\n\n5. Early traction in selling to the DOD—As mentioned, selling to the government is hard, and the level of difficulty can vary across companies. For example, while all companies need FedRAMP certification, companies that are munitions-adjacent must also comply with the International Trade in Arms Regulation, a more onerous process. Some companies may need federal salespeople or forward-deployed engineers who have Secret / Top-Secret clearance from the FBI. Bessemer does not rule out investments based on these types of sales friction; we especially like teams who have made significant headway in wading through the thicket of regulations and processes required to sell their products.\n\nSelling to the government\n\nThere are complexities and potential risks when selling to the government; many businesses don’t want to take on that additional baggage. However, we think that might be a short-sided approach — the rewards can greatly outweigh the risks.\n\nFor defense tech founders, here are three cons and five pros to adopting a business-to-government (B2G) go-to-market model —\n\nCons of a B2G model\n\nLong sales cycles: Making a deal can take a long time, years even, to land a large, multi-million-dollar contract.\n\nUnpredictability: Government contracts are lumpy, bumpy, and unpredictable. This leads to revenue streams that are hard to forecast, with often very large Q3 results, since the US government fiscal year ends in September.\n\nRed tape: Every three letter government agency has cumbersome levels of bureaucracy. In addition, its political headwinds and various partisanship impacts deal flow and sales cycles.\n\nThink of the DOD as the best beta customer you’ve ever had.\n\nPros of a B2G model\n\nMarket size: From a financial perspective, the U.S. military/intelligence complex is the world’s largest customer with a $886 billion defense budget for 2024 with dozens of branches each acting as independent Fortune 100 companies.\n\nStrong retention: The DOD is a strong brand and a high-retention customer with no credit risk and a high resilience to economic cycles. And once you’re in, it’s straight-forward to expand your contract (high net dollar retention).\n\nProduct innovation: Think of the DOD as the best beta customer you’ve ever had. The government can help you develop and refine your product with unique sources of funding—usually in the form of non-dilutive grants.\n\nGTM distribution advantages: As the DOD budgets become more receptive to working with startups, businesses building out cutting edge technology with defense applications can benefit from securing government contracts as a means to gain market leadership and elbow-out the competitors.\n\nProcurement breakthroughs for startups: Emerging defense startups like SpaceX and Palantir have challenged traditional Defense Department contracting, leading to greater competition and innovation. SpaceX sued the U.S. Air Force in 2014 over exclusive contracts awarded to ULA for national security launches, resulting in policy changes that ended ULA's monopoly. Palantir also sued the U.S. Army in 2016 for excluding commercial solutions in its procurement process, winning the case and forcing the Army to revise its acquisition strategy. These actions have opened doors for more startups to engage with the Department of Defense.\n\nDefense contracting has become more startup-friendly due to new government initiatives and technologies simplifying the process.\n\nOther Transaction Agreements (OTAs) have been key, especially since their expanded use post-2015, in enabling nontraditional contractors to more easily sell to the government. Additionally, initiatives have led to the creation of organizations like the Defense Innovation Unit, AFWERX, and NAVAL X, starting from 2015 onwards, which foster collaboration among private companies and the DOD, streamlining startup engagement with the defense sector.\n\nSo founders, considering these points, could a B2G model be your next avenue of growth?\n\nThe next generation of defense technology\n\nThe recent headway Silicon Valley upstarts have with the DOD does not change the fact that building an enduring defense tech business does not come without significant challenges and pitfalls. Indeed, as the Pentagon and even other investors have recently noted, the influx of capital into defense tech startups must come with realistic expectations. We remain intellectually honest that building an enduring defense tech startup is very hard. R&D obstacles, commercialization challenges, friction in scaling a go-to-market strategy, financing risks, and beyond — what defense tech founders face, at times, can still seem Sisyphean.\n\nWhat defense tech founders face can seem Sisyphean.\n\nYet, as investors in this complex ecosystem, we know how important it is for defense founders to have proper resources and a network of support to drive innovation, secure contracts, and contribute to our country’s agenda.\n\nThis is why we’ve created Bessemer’s Defense Tech Advisory Board including renowned experts such as:\n\nDr. Ray Johnson (CEO, Technology Innovation Institute, and former SVP and CTO, Lockheed Martin Corporation)\n\nLori Garver (former Deputy Administrator of NASA)\n\nRet. Major General Kim Crider (former Chief Technology and Innovation Officer for the United States Space Force and former Chief Data Officer of the United Space Air Force)\n\nRet. Lt. Gen. S. Clinton Hinote (former Deputy Chief of Staff, Strategy, Integration, and Requirements for the United States Air Force)\n\nForrest Underwood (Founder, United States Space Force Reservist, and former Chief Growth officer of True Anomaly)\n\nMatthew J. Kohler (former 3-Star Vice Admiral, former Director of Naval Intelligence, Director of Navy Information Warfare, Deputy Navy Chief Information Officer, Deputy Commander, 10th Fleet/Fleet Cyber Command)\n\nJoshua Marcuse (Director of Strategic Initiatives & Responsible AI Lead for Google Public Sector, and former Executive Director of the Defense Innovation Board, Department of Defense)\n\nGiven our long track record of partnering with companies at the intersection of defense and deep technology, including Skybox Imaging, Rocket Lab, Endgame, Spire Global, Claroty, and Virtru, we have various sales playbooks as well as metrics benchmarking reports specific to defense tech to help go-to-market teams navigate the federal sales landscape. In addition, we can offer a unique talent network for startups to leverage when building out their teams.",
      "# [Solution Providers at KMWorld 2024](https://www.kmworld.com/Conference/2024/Showcase.aspx)\nCoveo powers the digital experiences of the world’s most innovative brands serving millions of people and billions of interactions across every digital experience. After a decade of enriching our market-leading platform with forward-thinking global enterprises, we know what it takes to gain a trusted AI-experience advantage.\n\nWe strongly believe that the future is business-to-person, that experience is today’s competitive front line, a make or break for every business.\n\nFor enterprises to achieve this AI-experience advantage at scale, it is imperative to have an Enterprise Spinal and composable ability to deliver AI semantic search and generative experiences at each customer and employee interaction.\n\nOur single SaaS AI platform and robust suite of AI & GenAI models are designed to transform the total experience from CX to EX across websites, ecommerce, service, and workplace. Powering individualized, trusted, and connected experiences across every interaction to delight customers and augment employees, and drive superior business outcomes.\n\nOur platform is certified ISO 27001 certified, HIPAA compliant, SOC2 compliant, and 99.999% SLA resilient. We are a Salesforce Summit ISV Partner, an SAP? Endorsed App, and an Adobe Gold Partner.\n\nPryon turns vast quantities of critical, fragmented, and rapidly-changing content into accurate, timely, and verifiable answers via the world's first enterprise-grade Knowledge AI Platform. Using best-in-class retrieval technology, Pryon securely extracts answers from all forms of content, including audio, images, text, and video, stored in a myriad of sources. Pryon’s Knowledge AI platform is intuitive to use, is accessible via API from any system, and can be deployed in a matter of weeks in the cloud or on-premises. Created by the AI pioneers instrumental in developing Alexa, Siri, and Watson, Pryon is trusted by leading enterprises such as Dell, NVIDIA, Westinghouse, and World Economic Forum. By reducing the distance between people and answers, Pryon builds high-performing, resilient, and responsive organizations.\n\nSinequa transforms how work gets done. Sinequa’s Assistants augment your company by augmenting employees with a knowledgeable, accurate, secure work partner so they are more effective, more informed, more productive, and less stressed. Best of all, Sinequa Assistants streamline workflows and automatically navigate the chaotic enterprise information landscape, so that employees can skip the grind and focus on doing the kind of work that makes the most impact. Sinequa’s Assistants achieve this by combining the power of comprehensive enterprise search with the ease of generative AI in a configurable and easily managed Assistant framework, for an accurate, traceable, and fully secure conversational experience. Deploy an out-of-the-box Assistant or configure a tailored experience and specialized workflow to augment your people and your company. For more information, visit www.sinequa.com.\n\nEvalueserve, a global leader in integrated research, insights, and analytics, empowers organizations to transform data into decisive action, navigate complex challenges, and uncover new opportunities. By seamlessly blending cutting-edge AI technology with deep industry expertise, we help our clients stay ahead of the competition. Our AI-enabled solutions, delivered across 15+ industries in 45+ countries, drive innovation and help maintain a competitive advantage. With over 5,000 domain experts and 20+ years of experience in Knowledge Management, Evalueserve serves Tier-1 Management Consulting firms, Big 4 Accounting and Advisory firms, Global Asset and Wealth Management firms, and Fortune 1000 companies. Our unique approach combines seasoned KM professionals with our AI-enabled platform, Publishwise, to provide tailored solutions that address your specific needs. Choose Evalueserve to unlock the full potential of your data and drive your organization towards sustainable growth and success.\n\nKMWorld is the leading information provider serving the Knowledge Management systems market. We inform our more than 45,000 subscribers about the components and processes — and related success stories — that together offer solutions for improving your business performance. With access to many of the most knowledgeable writers and analysts in the industry, KMWorld also offers a number of special publications, including: the KMWorld Best Practices White Papers series — delivering high-value, educational content from industry-leading solutions providers, free from marketing hype and distraction; the KMWorld Buyer's Guide — a print and electronic resource that will shorten your search for a vendor or simply help identify sources for KM tools.",
      "# [(ART)ificial Intelligence from Madrona's IA Summit](https://www.nyse.com/insights/artificial-intelligence)\nThe NYSE sent a crew to Madrona’s IA Summit in Seattle, where we had a chance to meet the leaders of exciting companies in AI and ask them to share questions and prompts on a variety of thought-provoking topics. But this isn't just another Q&A series, we took those answers and transformed them into art – using AI, of course.*\n\nWhat you see is the work of (ART)ificial Intelligence.\n\n*All art generated with a 3rd party AI application",
      "# [Washington Headquarters Services](https://www.cbinsights.com/company/washington-headquarters-services)\nYurts Secures $40 Million to Revolutionize AI for the Department of Defense\n\nyasmeeta December 4, 2024 Yurts, an AI integration platform focused on high-security businesses, has raised $40 million in Series B funding to enhance its role as a key AI assistant for the Department of Defense (DoD). The funding round, led by XYZ Venture Capital, pushes the company’s total investment to $58.35 million. Yurts, founded in August 2022, is already making strides with notable contracts, including a $16 million agreement with the United States Special Operations Command, and collaborations with the U.S. Army, Air Force, and Department of Energy. Co-founder Ben Van Roo, whose family has deep ties to the Air Force, steered toward a tech-centric path after his vision fell short of pilot requirements. “My whole family was in the Air Force,” Van Roo noted, adding, “my vision wasn’t quite there.” Instead, he leaned on his background in machine learning and military research to launch Yurts, which now employs 50 people, about a quarter with security clearance. The platform supports tasks ranging from pulling data from legacy reports to brainstorming applications for military technology, making it the first of its kind on a secret Department of Defense network. Van Roo’s journey includes prior roles at the RAND Corporation, where he tackled military supply chain issues, and Primer.ai, a defense-focused AI firm. His realization in 2017 of AI’s potential in securely modernizing legacy systems laid the groundwork for Yurts’ vision. “These models were going to keep getting better,” Van Roo said, “but someone’s going to have to say, how do we roll this out to tens of thousands of people in a very secure environment?” Yurts’ founders, including former Meta engineer Jason Schnitzer and research scientist Guruprasad Raghavan, aim to position the platform as a critical tool for the DoD, alongside the Pentagon’s in-house AI chatbot development efforts. However, competition looms, with companies like Ask Sage and Primer.ai also vying for similar roles in military AI integration. Despite the rivalry, Van Roo remains optimistic about the broader possibilities for enterprise-ready AI. “I’m confident that in the next 10 years, we’re probably going to get a pretty big next step-jump in the model space,” he said. “But I think that we have a long way to go to really achieve the value we can in enterprises.” Featured image courtesy of yurts.ai",
      "# [We’ve come a long way from RPA: How AI agents are revolutionizing automation by Rohan Sharma, Zenolabs, Rohan Sharma on 2024-12-16](https://venturebeat.com/ai/weve-come-a-long-way-from-rpa-how-ai-agents-are-revolutionizing-automation/)\nIn the past year, the race to automate has intensified, with AI agents emerging as the ultimate game-changers for enterprise efficiency. While generative AI tools have made significant strides over the past three years — acting as valuable assistants in enterprise workflows — the spotlight is now shifting to AI agents capable of thinking, acting and collaborating autonomously. For enterprises preparing to embrace the next wave of intelligent automation, understanding the leap from chatbots to retrieval-augmented generation (RAG) applications to autonomous multi-agent AI is crucial. As Gartner noted in a recent survey, 33% of enterprise software applications will include agentic AI by 2028, up from less than 1% in 2024.\n\nAs Google Brain founder Andrew Ng aptly stated: “The set of tasks that AI can do will expand dramatically because of agentic workflows.” This marks a paradigm shift in how organizations view the potential of automation, moving beyond predefined processes to dynamic, intelligent workflows.\n\nThe limitations of traditional automation\n\nDespite their promise, traditional automation tools are constrained by rigidity and high implementation costs. Over the past decade, robotic process automation (RPA) platforms like UiPath and Automation Anywhere have struggled with workflows lacking clear processes or relying on unstructured data. These tools mimic human actions but often lead to brittle systems that require costly vendor intervention when processes change.\n\nCurrent gen AI tools, such as ChatGPT and Claude, have advanced reasoning and content generation capabilities but fall short of autonomous execution. Their dependency on human input for complex workflows introduces bottlenecks, limiting efficiency gains and scalability.\n\nThe emergence of vertical AI agents\n\nAs the AI ecosystem evolves, a significant shift is occurring toward vertical AI agents — highly specialized AI systems designed for specific industries or use cases. As Microsoft founder Bill Gates said in a recent blog post: “Agents are smarter. They’re proactive — capable of making suggestions before you ask for them. They accomplish tasks across applications. They improve over time because they remember your activities and recognize intent and patterns in your behavior. “\n\nUnlike traditional software-as-a-service (SaaS) models, vertical AI agents do more than optimize existing workflows; they reimagine them entirely, bringing new possibilities to life. Here’s what makes vertical AI agents the next big thing in enterprise automation:\n\nElimination of operational overhead: Vertical AI agents execute workflows autonomously, eliminating the need for operational teams. This is not just automation; it’s a complete replacement of human intervention in these domains.\n\nUnlocking new possibilities: Unlike SaaS, which optimized existing processes, vertical AI fundamentally reimagines workflows. This approach brings entirely new capabilities that didn’t exist before, creating opportunities for innovative use cases that redefine how businesses operate.\n\nBuilding strong competitive advantages: AI agents’ ability to adapt in real-time makes them highly relevant in today’s fast-changing environments. Regulatory compliance, such as HIPAA, SOX, GDPR, CCPA and new and forthcoming AI regulations can help these agents build trust in high-stakes markets. Additionally, proprietary data tailored to specific industries can create strong, defensible moats and competitive advantages.\n\nEvolution from RPA to multi-agent AI\n\nThe most profound shift in the automation landscape is the transition from RPA to multi-agent AI systems capable of autonomous decision-making and collaboration. According to a recent Gartner survey, this shift will enable 15% of day-to-day work decisions to be made autonomously by 2028. These agents are evolving from simple tools into true collaborators, transforming enterprise workflows and systems. This reimagination is happening at multiple levels:\n\nSystems of record: AI agents like Lutra AI and Relevance AI integrate diverse data sources to create multimodal systems of record. Leveraging vector databases like Pinecone, these agents analyze unstructured data such as text, images and audio, enabling organizations to extract actionable insights from siloed data seamlessly.\n\nWorkflows: Multi-agent systems automate end-to-end workflows by breaking complex tasks into manageable components. For example: Startups like Cognition automate software development workflows, streamlining coding, testing and deployment, while Observe.AI handles customer inquiries by delegating tasks to the most appropriate agent and escalating when necessary.\n\nReal-world case study: In a recent interview, Lenovo’s Linda Yao said, “With our gen AI agents helping support customer service, we’re seeing double-digit productivity gains on call handling time. And we’re seeing incredible gains in other places too. We’re finding that marketing teams, for example, are cutting the time it takes to create a great pitch book by 90% and also saving on agency fees.”\n\nReimagined architectures and developer tools: Managing AI agents requires a paradigm shift in tooling. Platforms like AI Agent Studio from Automation Anywhere enable developers to design and monitor agents with built-in compliance and observability features. These tools provide guardrails, memory management and debugging capabilities, ensuring agents operate safely within enterprise environments.\n\nReimagined co-workers: AI agents are more than just tools — they are becoming collaborative co-workers. For example, Sierra leverages AI to automate complex customer support scenarios, freeing up employees to focus on strategic initiatives. Startups like Yurts AI optimize decision-making processes across teams, fostering human-agent collaboration. According to McKinsey, “60 to 70% of the work hours in today’s global economy could theoretically be automated by applying a wide variety of existing technology capabilities, including gen AI.”\n\nFuture outlook: As agents gain better memory, advanced orchestration capabilities and enhanced reasoning, they will seamlessly manage complex workflows with minimal human intervention, redefining enterprise automation.\n\nThe accuracy imperative and economic considerations\n\nAs AI agents progress from handling tasks to managing workflows and entire jobs, they face a compounding accuracy challenge. Each additional step introduces potential errors, multiplying and degrading overall performance. Geoffrey Hinton, a leading figure in deep learning, warns: “We should not be afraid of machines thinking; we should be afraid of machines acting without thinking.” This highlights the critical need for robust evaluation frameworks to ensure high accuracy in automated processes.\n\nCase in point: An AI agent with 85% accuracy in executing a single task achieves only 72% overall accuracy when performing two tasks (0.85 × 0.85). As tasks combine into workflows and jobs, accuracy drops further. This leads to a critical question: Is deploying an AI solution that’s only 72% correct in production acceptable? What happens when accuracy declines as more tasks are added?\n\nAddressing the accuracy challenge\n\nOptimizing AI applications to reach 90 to 100% accuracy is essential. Enterprises cannot afford subpar solutions. To achieve high accuracy, organizations must invest in:\n\nRobust evaluation frameworks: Define clear success criteria and conduct thorough testing with real and synthetic data.\n\nContinuous monitoring and feedback loops: Monitor AI performance in production and utilize user feedback for improvements.\n\nAutomated Optimization Tools: Employ tools that auto-optimize AI agents without relying solely on manual adjustments.\n\nWithout strong evaluation, observability, and feedback, AI agents risk underperforming and falling behind competitors who prioritize these aspects.\n\nLessons learned so far\n\nAs organizations update their AI roadmaps, several lessons have emerged:\n\nBe agile: The rapid evolution of AI makes long-term roadmaps challenging. Strategies and systems must be adaptable to reduce over-reliance on any single model.\n\nFocus on observability and evaluations: Establish clear success criteria. Determine what accuracy means for your use case and identify acceptable thresholds for deployment.\n\nAnticipate cost reductions: AI deployment costs are projected to decrease significantly. A recent study by a16Z found that the cost of LLM inference has dropped by a factor of 1,000 in three years; the cost is decreasing by 10X every year. Planning for this reduction opens doors to ambitious projects that were previously cost-prohibitive.\n\nExperiment and iterate quickly: Adopt an AI-first mindset. Implement processes for rapid experimentation, feedback and iteration, aiming for frequent release cycles.\n\nConclusion\n\nAI agents are here as our coworkers. From agentic RAG to fully autonomous systems, these agents are poised to redefine enterprise operations. Organizations that embrace this paradigm shift will unlock unparalleled efficiency and innovation. Now is the time to act. Are you ready to lead the charge into the future?",
      "# [Engineering flexible machine learning systems by traversing functionally invariant paths by Surya Narayanan on 2024-10-03](https://www.nature.com/articles/s42256-024-00902-x)\nArtificial neural networks now achieve human-level performance on machine learning tasks ranging from natural language understanding and image recognition to game playing and protein structure prediction. Recently, transformer-based models with self-attention have emerged as the state-of-the-art architecture across data modalities and task paradigms including natural language understanding, computer vision, audio processing, biological sequence analysis and context-sensitive reasoning1,2,3,4. Although transformer models can exhibit emergent behaviours including zero-shot task performance, models are commonly fine-tuned to increase performance and human accessibility4,5,6. In the ‘foundation model’ paradigm3, transformers with 108 to 1012 parameters are, first, pre-trained over large datasets on self-supervised tasks such as masked language modelling, causal language modelling or image masking5,6,7,8. Following self-supervised training, models are fine-tuned to increase performance on specific applications including question/answer or instruction following. Networks can be further sparsified or quantized to reduce memory and computation requirements in deployment environments.\n\nDue to the central role of model adaptation for foundation model optimization and deployment, many algorithms have emerged for updating model weights to increase performance without experiencing a catastrophic loss of the knowledge gained during self-supervised pre-training. However, a challenge is that in artificial neural networks, network function is encoded in the mathematical weights that determine the strength of connections between neural units (Fig. 1a,b). Gradient descent procedures train networks to solve problems by adjusting the weights of a network based on an objective function that encodes the performance of a network on a specific task. Learning methods, like backpropagation and low-rank adaptation (LoRA)9 gradient descent, adjust the network weights to define a single, optimal weight configuration to maximize performance on a task-specific objective function using training data. However, for all the current methods, network training alters network weights, inevitably resulting in the loss of information gained from previous training tasks or pre-training.\n\nAlthough many methods have been developed to achieve network adaptation without information loss, methods remain primarily grounded in empirical results. The machine learning community would benefit from mathematical tools that provide general insights and unification of model adaptation strategies within a common theoretical framework. Methods like LoRA, orthogonal gradient descent (OGD), relevance mapping networks (RMNs) and elastic weight consolidation (EWC) propose different criteria for updating weights in directions that do not impact performance on previously learned tasks. Yet, most current methods are based on local heuristics, for example, selecting gradient steps that are orthogonal to gradient steps taken for previously learned tasks. As in continual learning (CL) paradigms, sparsification frameworks execute heuristic prune/fine-train cycles to discover a compact, core subnetwork capable of executing the desired behaviour with decreased memory, power and computational requirements. Mathematical tools that provide a deeper insight into how the global, geometric structure of weight space enables or complicates adaptation might provide both conceptual principles and new algorithms.\n\nUnlike contemporary artificial neural nets, neural networks in the human brain perform multiple functions and can flexibly switch between different functional configurations based on context, goals or memory10. Neural networks in the brain are hypothesized to overcome the limitations of a single, optimal weight configuration and perform flexible tasks by continuously ‘drifting’ their neural firing states and neural weight configurations, effectively generating large ensembles of degenerate networks11,12,13,14,15. Fluctuations might enable flexibility in biological systems by allowing neural networks to explore a series of network configurations and responding to sensory input.\n\nHere we develop a geometric framework and algorithm that mimics aspects of biological neural networks by using differential geometry to construct path-connected sets of neural networks that solve a given machine learning task. Conceptually, we consider path-connected sets of neural networks, rather than single networks (isolated points in weight space) to be the central objects of study and application. By building sets of networks rather than single networks, we search within a submanifold of weight space for networks that solve a given machine learning problem and accommodate a broad range of secondary goals. Historically, results in theoretical machine learning and information geometry have pointed to the geometry of a model’s loss landscape as a potential resource for model adaptation. An emergent property of over-parameterized models is the existence of parameter degeneracy where multiple settings of the model parameters can achieve identical performance on a given task. Geometrically, parameter degeneracy leads16 to ‘flat’ objective functions17,18,19 along which network weights can be modified without loss of performance. To discover invariant subspaces, we introduce a Riemannian metric into weight space—a tensor that measures (at every point in parameter space) the change in the model output given an infinitesimal movement in model parameters. The metric provides a mathematical tool for identifying low-dimensional subspaces in weight space where parameter changes have little impact on how a neural network transforms input data. Riemannian metrics are widely used in physical theories to study the dynamics of particles on curved manifolds and spacetimes. Geometrically, the metric discovers flat directions in weight space along which we can translate a neural network without changing functional performance.\n\nUsing the Riemannian weight-space metric, we develop an algorithm that constructs functionally invariant paths (FIPs) in weight space that maintain network performance and ‘search out’ for other networks that satisfy additional objectives. The algorithm identifies long-range paths in weight space that can integrate new functionality without information loss. We apply the FIP framework to natural language (bidirectional encoder representations from transformers (BERT)), vision transformers (ViT and DeIT) and convolutional neural network (CNN) architectures. Our framework generates results that meet or exceed state-of-the-art performance for adaptation and sparsification tasks on academic-grade hardware. Our approach provides mathematical machinery that yields insights into how low-dimensional geometric structures can be harnessed for model adaptation without information loss. More broadly, we consider language models as objects acted on by transformations in series and we show that the transformations of models are intrinsically non-Abelian. The unified framework provides a general attack on a range of model adaptation problems and reveals connections between the mathematical theory of differential geometries and the emergent properties of large language and vision models.\n\nWe develop a mathematical framework that allows us to define and explore path-connected sets of neural networks that have divergent weight values but similar outputs on training data. We view the weight space of a neural network as a Riemannian manifold equipped with a local distance metric20,21. Using differential geometry, we construct paths through weight space that maintain the functional performance of a neural network and adjust the network weights to flow along a secondary goal (Fig. 1a). The secondary goal can be general; therefore, the framework can be applied to train networks on new classification tasks, sparsify networks and mitigate adversarial fragility.\n\nThe defining feature of a Riemannian manifold is the existence of a local distance metric. We construct a distance metric in weight space that defines the distance between two nearby networks to be their difference in output. We consider a neural network to be a smooth function f(x; w) that maps an input vector \\({\\bf{x}}\\in {{\\mathbb{R}}}^{{\\rm{k}}}\\) to an output vector \\(f({\\bf{x}};{\\bf{w}})={\\bf{y}}\\in {{\\mathbb{R}}}^{{\\rm{m}}}\\), where the map is parameterized by a vector of weights \\({\\bf{w}}\\in {{\\mathbb{R}}}^{{\\rm{n}}}\\) that are typically set in training to solve a specific task. We refer to \\(W={{\\mathbb{R}}}^{n}\\) as the weight space of the network, and we refer to \\({\\mathcal{Y}}={{\\mathbb{R}}}^{m}\\) as the output space (Fig. 1b,c)22. For pedagogical purposes, we will consider the action of f on a single input x. Supplementary Note 1 shows that our results naturally extend to an arbitrary number of inputs xi.\n\nWe initially ask how the output f(x; w) of a given neural network changes for small changes in network weights. Given a neural network with weights wt and fixed input x, we can compute the output of the perturbed network wt + dw for an infinitesimal weight perturbation dw as follows:\n\n$$f({\\bf{x}},{{\\bf{w}}}_{{\\bf{t}}}+{\\bf{dw}})\\approx f({\\bf{x}},{{\\bf{w}}}_{{\\bf{t}}})+{{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}\\,{\\bf{dw}},$$\n\n(1)\n\nwhere \\({{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}\\) is the Jacobian of f(x, wt) for a fixed \\({\\bf{x}},{J}_{ij}=\\frac{\\partial {f}_{i}}{\\partial {w}_{j}}\\), evaluated at wt.\n\nThus, the total change in network output for a given weight perturbation dw is\n\n$$\\begin{array}{rcl}|\\; f({\\bf{x}},{{\\bf{w}}}_{{\\bf{t}}}+{\\bf{dw}})-f({\\bf{x}},{{\\bf{w}}}_{{\\bf{t}}}){| }^{2}&=&{{\\bf{dw}}}^{{{\\rm{T}}}}\\,(\\;{{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}{({\\bf{x}})}^{{\\rm{T}}}\\,{{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}}))\\,{\\bf{dw}}\\\\ | {\\langle {\\bf{dw}},{\\bf{dw}}\\rangle }_{{{\\bf{g}}}_{{{\\bf{w}}}_{{\\bf{t}}}}}{| }^{2}&=&{{\\bf{dw}}}^{{{\\rm{T}}}}\\,{{\\bf{g}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}})\\,{\\bf{dw}}\\end{array},$$\n\n(2)\n\nwhere \\({{\\bf{g}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}})={{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}{({\\bf{x}})}^{{{\\rm{T}}}}\\,{{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}})\\) is the metric tensor evaluated at the point wt ∈ W for a single data point x. The metric tensor is an n × n symmetric matrix that allows us to compute the change in network output given the movement of the network along any direction in weight space as \\({\\langle {\\bf{dw}},{\\bf{dw}}\\rangle }_{{{\\bf{g}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}})}\\). As we move through the weight space, the metric tensor W continuously changes, allowing us to compute the infinitesimal change in network output and move along a path γ(t) as the tangent vector \\(\\psi (t)=\\frac{\\,\\text{d}\\gamma (t)}{\\text{d}\\,t}\\).\n\nWe can extend the metric construction to cases in which we consider a set of N training data points X and view g as the mean of the metrics derived from individual training examples, such that \\({{\\bf{g}}}_{{\\bf{w}}({\\bf{X}})}={\\Sigma }_{i = 1}^{N}{{\\bf{g}}}_{{\\bf{w}}}({{\\bf{x}}}_{{\\bf{i}}})/N\\) for xi ∈ X or in expectation, \\({{\\bf{g}}}_{{\\bf{w}}}={{\\mathbb{E}}}_{x \\approx {p}_{{\\rm{data}}}(x)}[{{\\bf{g}}}_{{\\bf{w}}({\\bf{x}})}]\\), and gw(X) remains n × n (Supplementary Note 1). For a single data point, our construction of gw is identical to the neural tangent kernel (NTK), which is constructed as a kernel function of pairs of data points, \\(\\varTheta ({x}_{i},{x}_{j})=J{({x}_{i})}^{{{\\rm{T}}}}J({x}_{j})\\) (ref. 23), so that Θ(xi, xi) = gi(xi) (refs. 23,24,25,26). However, we distinguish our interpretation of g as a distance metric on W, the network parameter space from the NTK as a matrix-valued kernel function on data points xi and xj. The NTK Θ(xi, xj) arises through the analysis of the dynamics of a neural network under a gradient flow of the mean squared error. The NTK is interpreted as a kernel function defined on pairs of data points xi and xj, providing an analogy between the training dynamics of a neural network and kernel-based learning methods. Alternately, we interpret gw as a metric on a Riemannian parameter manifold (W, gw). At each point in the weight space, the metric defines the length, \\({\\langle {\\bf{dw}},{\\bf{dw}}\\rangle }_{{{\\bf{g}}}_{{\\bf{w}}}}\\), of a local perturbation to network weights dw as the perturbation’s impact on the functional output of the network (Fig. 1b,c) averaged over all the data points in X. The metric motivates the construction and analysis of network paths in weight space and consideration of properties including velocity, acceleration and notion of a geodesic path in weight space.\n\nAt every point in the weight space, the metric allows us to discover directions dw of movement that have a large or small impact on the output of a network. As we move along a path γ(t) ⊂ W in weight space, we sample a series of neural networks over time t. Using the metric, we can define a notion of ‘output velocity’ as \\({\\bf{v}}=\\frac{\\,\\text{d}\\,f({\\bf{x}},\\gamma (t))}{\\,\\text{dt}\\,}\\), which quantifies the distance a network moves in output space for each local movement along the weight-space path γ(t). We seek to identify FIPs in weight space along which the output velocity is minimized for a fixed magnitude change in weight. To do so, we solve the following optimization problem:\n\n$$\\begin{array}{c}{\\psi }^{* }(t)=\\mathop{{\\mathrm{argmin }}}\\limits_{\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}}{\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\right\\rangle }_{{{\\bf{g}}}_{\\gamma ({\\bf{t}})}}\\\\ \\,\\text{such that}\\,\\,{\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\right\\rangle }_{I}=\\epsilon \\end{array},$$\n\n(3)\n\nwhere we attempt to find a direction ψ*(t) along which to perturb the network, such that it is ϵ units away from the base network in the weight space (in the Euclidean sense, \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{I}=\\epsilon\\)) and minimize the distance moved in the networks’ output space, given by \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{\\gamma }({\\bf{t}})}\\). Here I is an identity matrix, with the inner product \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{I}\\) capturing the Euclidean distance in weight space27. The optimization problem is a quadratic program at each point in weight space. The metric g is a matrix that takes on a specific value at each point in weight space, and we aim to identify vectors \\({{\\bf{\\psi }}}^{* }(t)=\\frac{{\\rm{d}}\\gamma (t)}{{\\rm{d}}t}\\) that minimize the change in the functional output of the network.\n\nWe will often amend the optimization problem with a second objective function L(x, w). We can enumerate paths that minimize the functional velocity in the output space and move along the gradient of the second objective (∇wL). We define a path-finding algorithm that identifies a direction ψ*(t) in the weight space by minimizing the functional velocity in the output space and moves along the gradient of the second objective (∇wL):\n\n$$\\begin{array}{rcl}&&{\\psi }^{* }(t)=\\mathop{{\\mathrm{argmin }}}\\limits_{\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}}\\left({\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\right\\rangle }_{{{\\bf{g}}}_{\\gamma (t)}}+\\beta {\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},{\\nabla }_{{\\bf{w}}}L\\right\\rangle }_{I}\\right)\\\\ &&\\,\\text{such that}\\,{\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\right\\rangle }_{I}=\\epsilon \\end{array} ,$$\n\n(4)\n\nwhere the first term \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{\\gamma (t)}}\\) identifies functionally invariant directions, the second term \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},{\\nabla }_{{\\bf{w}}}L\\rangle }_{I}\\) biases the direction of motion along the gradient of a second objective and β weighs the relative contribution of the two terms. When L = 0, the algorithm merely constructs paths in weight space that are approximately isofunctional (θ*(t) = ψ*(t)), that is, the path is generated by steps in the weight space comprising networks with different weight configurations and preserving the input–output map. L(x, w) can also represent the loss function of a second task, for example, a second input classification problem. In this case, we identify vectors that simultaneously maintain performance on an existing task (via term 1) as well as improve performance on a second task by moving along the negative gradient of the second-task loss function ∇wL. We consider constructing FIPs with different objective functions (L(x, w)) similar to applying different ‘operations’ to neural networks that identify submanifolds in the weight space of the network accomplishing distinct tasks of interest.\n\nTo approximate the solution to equation (4), in large neural networks, we developed a numerical strategy that samples points in an ϵ ball around a given weight configuration, and then performs gradient descent to identify vectors θ*(t). We note that the performance of a neural network on a task is typically evaluated using a loss function \\(L:{{\\mathbb{R}}}^{m}\\to {\\mathbb{R}}\\), so that \\(L(\\;f({\\bf{x}};{\\bf{w}}))\\in {\\mathbb{R}}\\). Networks with a constant functional output f(x, w) along a path γ(t) will also have constant loss L(f(γ(t); w)). As gradient descent training minimizes the loss by finding \\(\\frac{\\partial L}{\\partial {w}_{i}}=0\\), the evaluation of loss curvature requires second-order methods to discover flat or functionally invariant subspaces. We find that working directly with f(x; w) allows us to identify functionally invariant subspaces through first-order quantities \\(\\frac{\\partial {f}_{i}}{\\partial {w}_{j}}={J}_{ij}\\), and thus, we can compute the metric using the output of automatic differentiation procedures commonly used in training. Working with f(x, w) instead of L also provides additional resolution in finding invariant subspaces since f(x; w) is often a vector-valued versus scalar-valued function.\n\nWe note that the mathematical framework provides avenues for immediate generalization to consider paths of constant velocity, paths that induce a constant rate of performance change; such paths are known as geodesics28. On any Riemannian manifold, we can define geodesic paths emanating from a point xp as paths of constant velocity \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{\\gamma (t)}}={v}_{0}\\) (Supplementary Note 4.1) that satisfy the following geodesic equation:\n\n$$\\frac{{{\\rm{d}}}^{2}{w}_{\\eta }}{{\\rm{d}}{t}^{2}}+{\\varGamma }_{\\mu \\nu }^{\\eta }\\frac{{\\rm{d}}{w}_{\\mu }}{{\\rm{d}}t}\\frac{{\\rm{d}}{w}_{\\nu }}{{\\rm{d}}t}=0,$$\n\n(5)\n\nwhere \\({\\varGamma }_{\\mu \\nu }^{\\eta }\\) specifies the Christoffel symbols (\\({\\varGamma }_{\\mu \\nu }^{\\eta }={\\sum }_{r}\\frac{1}{2}{g}_{\\eta r}^{-1}\\left(\\frac{\\partial {g}_{r\\mu }}{\\partial {x}^{\\nu }}+\\right.\\)\\(\\left.\\frac{\\partial {g}_{r\\nu }}{\\partial {x}^{\\mu }}-\\frac{\\partial {g}_{\\mu \\nu }}{\\partial {x}^{r}}\\right)\\)) on the weight manifold. Such geodesic paths have a constant, potentially non-zero, rate of performance decay on the previous task during adaptation. The Christoffel symbols record infinitesimal changes in the metric tensor (g) along a set of directions on the manifold (Supplementary Information). Since the computation and memory for evaluating Christoffel symbols scales as a third-order polynomial of network parameters (\\({\\mathcal{O}}({n}^{3})\\)), we propose the optimization equation (4) for evaluating ‘approximate’ geodesics in the manifold.\n\nFIP enables CL with ViT vision transformers\n\nThe FIP framework allows us to address a series of model adaptation goals within a common geometric framework. To demonstrate CL, we applied the FIP to adapt the ViT vision image transformer and BERT language model in CL without catastrophic forgetting. We train a neural network on a base task and modulate the weights in the network to accommodate additional tasks by solving the optimization problem in equation (4), setting L(x, w) as the classification loss function specified by the additional task, whereas \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{{\\rm{Task}}1}}\\) measures the distance moved in the networks’ output using the metric from the initial task (in equation (4)). To accommodate the additional tasks, we append output nodes to the base network and solve the optimization problem for a fixed value of β by simultaneously minimizing the distance moved in the networks’ output space (Fig. 1c, light-blue arrow) corresponding to the first task and maximizing alignment with the gradient of L(x, w) encoding the classification loss from the second task. In this manner, we construct an FIP (Fig. 5a, purple dotted line) in weight space generating a network that performs both Task 1 and Task 2.\n\nWe used a standard CL task30 (Fig. 2a). We split the Canadian Institute for Advanced Research (CIFAR)-100 dataset into a series of subtasks in which each subtask requires the network to identify ten object categories (Fig. 2a). Previously, the state-of-the-art performance for this task was achieved by the ResNet CNN30. ViT networks can potentially realize vast performance gains over ResNet architectures as the baseline performance for ResNet is ~80% accuracy. We observed that ViT exhibits 94.5% accuracy when fine-tuned on the CIFAR-100 dataset8,31 for generative replay, achieving a CIFAR-100 CL accuracy of ~80%.\n\nWe applied the FIP algorithm to achieve CL on SplitCIFAR using both ViT-B (86M parameters) and ViT-H (632M parameters) architectures. In each case, a single task requires the network to learn to recognize 10 CIFAR classes where we used 5,000 images (total, 6,000 images) per class with a batch size of 512. We used a single NVIDIA RTX2060 6 GB for ViT-B and RTX3090 24 GB for ViT-H (Fig. 2b). After continually training 5 SplitCIFAR subtasks, ViT-B achieved a mean performance of 91.2% and ViT-H achieved 89.3% compared with 94.5% performance for ViT-B that was simultaneously trained on all the 50 CIFAR classes without CL (Fig. 2b,c). Training for ViT-B using an NVIDIA RTX2060 6 GB machine took ~3.5 h for each subtask with the FIP and ~2.5 h with fine tuning. Training for ViT-H using an NVIDIA RTX3090 24 GB machine took ~4.8 h for each subtask with the FIP and ~3.9 h with standard fine tuning.\n\nThus, the FIP procedure enables ViT-B and ViT-H to learn new tasks without information loss and achieves a higher performance than CL methods that have been conventionally applied to the ResNet network31. The strength of our method is that it can be applied to fine-tune any existing transformer or CNN architecture.\n\nComparison of FIP with LoRA on CL with ViT\n\nThe LoRA approach to network fine tuning was recently introduced to enable the fine tuning of large transformer networks including GPT-3 (ref. 32). To fine-tune pre-trained networks on new tasks, LoRA forces weight updates W0 to a network to be low rank through a matrix factorization strategy, where W0 is generated as the product W0 = AB of matrices A and B with inner dimension r; here r is set to be a number much smaller than network size k (r ≪ k).\n\nAlthough not explicitly designed to alleviate catastrophic forgetting, LoRA is discussed in many venues including HuggingFace (HF) as a technique that mitigates catastrophic forgetting. Further, LoRA is widely applied for fine-tuning tasks on large networks in industrial settings and therefore represents an important comparison point for FIP. We applied LoRA to iteratively learn components of the SplitCIFAR task (Fig. 2) using ViT-H (640M parameters) spanning a range of r = rank(W0) from 1 to 256. We found that LoRA exhibits signatures of catastrophic forgetting independent of rank in these tests (Fig. 2e,f). When ViT-H is trained to achieve 99% accuracy on Task 1 (CIFAR-0:9 task), the network loses accuracy on Task 1 as it is trained via LoRA on Task 2 (CIFAR-10:19 task) (Fig. 2e,f and Extended Data Table 1). Following the application of LoRA, ViT-H achieves 96.6% accuracy on Task 2 for r = 256 at the expense of 0% accuracy on Task 1 (Fig. 2e,f and Extended Data Table 1). When rank = 1, the LoRA accuracy was limited to 10% on Task 2 and still lost accuracy on Task 1 (Task 1 accuracy, 0%). Thus, LoRA fine tuning leads to a collapse in accuracy on Task 1 when fine-tuned to perform an additional task.\n\nPerformance of FIP on CL with CNN architectures\n\nIn addition to transformers, the FIP framework can also be applied to CNN architectures, which provides a helpful point of comparison with previous CL methods. On image analysis tasks like CIFAR-10, transformers like ViT outperform CNN architectures on classification accuracy metrics. However, CNNs are widely used in computer vision and have been the architecture used for most prior CL work. We applied FIP to ResNet18 to study CL on SplitCIFAR and compared with RES-CIFAR30, EWC33, RMN30, generative replay31 and gradient episodic memory (GEM)34. We found that the FIP could achieve CL with accuracy that meets or exceeds other state-of-the-art approaches (Fig. 2f, Extended Data Table 2 and Supplementary Fig. 2), with RMN achieving 80% accuracy on SplitCIFAR compared with 82% for FIP on ResNet14. In general, the global accuracy of the resulting CNN was lower than the transformer ViT, consistent with the network’s relative performance on the baseline CIFAR task. The results demonstrate that FIP performs well on transformer and CNN architectures and on par or above other state-of-the-art approaches. Although the FIP algorithm has conceptual similarities with EWC, the mathematical generality of the FIP allows the approach to scale to perform multiple iterative incremental learning tasks and to explicitly construct FIPs that traverse the weight space (Fig. 2d).\n\nFIP enables CL with BERT NLP transformer\n\nNext, we demonstrated the flexibility of the FIP approach by using the method to fine-tine the BERT network on the Internet Movie Database (IMDb) sentiment analysis task following initial training on Yelp full-five-star review prediction task (Fig. 3). The BERT network has a total of 12 layers, or transformer blocks, with 12 self-attention heads in each layer and a total of 110M parameters5. Training BERT to detect customer opinions of a product based on text reviews left on websites like Yelp or IMDb results in catastrophic forgetting, especially when sequentially training on multiple user-review datasets (say, Yelp reviews followed by IMDb) (Fig. 3a). The FIP maintains BERT performance on Yelp reviews (at 70%; blue) and increasing its accuracy on IMDb review classification (from 0% to 92%; orange) (Fig. 3b). Potentially, BERT has as an initial accuracy of 0% on IMDb due to differences in the outputs for each task, which are binary for IMDb but five-star scoring for Yelp. The FIP in BERT weight space (Fig. 3) is much longer than the route taken by conventional training, enabling the global exploration of the BERT weight landscape to identify networks that simultaneously maintain performance on Yelp reviews and learn the IMDb sentiment classification. Conventional fine tuning of BERT on IMDb reviews increases its performance on sentiment classification on IMDb (from 0% to 92%; orange) and abruptly forgets the sentiment analysis on Yelp reviews (dropping from an accuracy of 69.9% to 17%; blue) within 30 training steps (Fig. 3b). We also compared the performance of FIP with LoRA on the natural language processing (NLP) training task (Fig. 3d–f). We found that LoRA exhibits a considerable performance decay on the Yelp task and learning IMDb across ranks (Fig. 3d,f). LoRA also exhibits anticorrelation between Yelp and IMDb accuracy across training epochs (Fig. 3d). We also found that the FIP algorithm generally induces more extensive weight change than LoRA measured by the Frobenius norm of weight updates for both approaches (Fig. 3e).\n\nNeural network sparsification with FIP algorithm\n\nThe critical aspects of the FIP framework are that the framework generalizes and addresses a broad range of machine learning meta-problems by considering a more general set of secondary objective functions. In particular, we next apply the FIP framework to perform sparsification, reducing the number of non-zero weights, which is important for reducing the memory and computational footprint of a network35. To sparsify neural networks, we solve equation (4), the core FIP optimization problem, with a secondary loss function L(wt, w, p) that measures the Euclidean distance between a network and its p-sparse projection obtained by setting p% of the networks’ weights to zero (Fig. 4a).\n\nUsing the framework, we sparsified the vision transformer DeIT, which has been used for benchmarking sparsification methods36 on vision transformers. The paradigm uses the ImageNet 1,000-object image classification task (ImageNet1K dataset), and attempts to sparsify DeIT. DeIT-Base (DeIT-B) is an 86M parameter transformer model that was derived from ViT37. We use the FIP algorithm to set the weight parameters to zero without loss of performance on the ImageNet1K classification task. The simplicity of the FIP algorithm allowed us to achieve an entire range of target sparsities ranging from 0% to 80%. We found that FIP had performance very near to that of the SViT network at the benchmark of 40% sparsity, with FIP performing at 80.22% and SViT performing at 81.56% accuracy (Fig. 4b(i)), with compute times given (Fig. 4b(ii)) on an NVIDIA RTX3090 24 GB. Additionally, we applied FIP to perform the sparsificaiton of CNN architectures (Supplementary Fig. 3) for the Modified National Institute of Standards and Technology (MNIST) and CIFAR tasks, showing that the FIP can also achieve high sparsification values and maintain accuracy in the ResNet and LeNet CNN architectures (Supplementary Fig. 3).\n\nThen, we applied FIP to sparsify the BERT base from 0% to 80% sparsity for all the general language understanding evaluation (GLUE) NLP tasks. For this task, we obtained an NVIDIA A100 machine from PaperSpace. The GLUE benchmark consists of three categories of natural language understanding tasks: (1) single-sentence tasks (corpus of linguistic acceptability (CoLA) and Stanford sentiment (SST-2)), (2) similarity and paraphrase tasks (Microsoft research paraphrase corpus (MRPC), Quora question pairs (QQPs) and Semantic Text Similarity Benchmark (STS-B)) and (3) inference tasks (multi-genre natural language inference (MNLI), question-answering natural language inference (QNLI) and recognizing textual entailment (RTE)). Again, because of its ease of use and efficiency, we were able to span the entire range of sparsities identifying differential performance across GLUE tasks (Fig. 4c and Supplementary Fig. 4). FIP was able to generate sparse versions of BERT that had 81.65% accuracy at 50% sparsity on the SST-2 task. We provide compute times in seconds for the sparsification of BERT on MRPC, which efficiently runs on an NVIDIA A100 machine (Fig. 4d).\n\nFIP ensemble confers robustness against adversarial attack\n\nThe path-connected sets of networks generated by the FIP can also be applied to perform inference and increase the robustness of inference tasks to data perturbation. Although deep CNNs have achieved remarkable performance on image recognition tasks, human-imperceptible additive perturbations, known as adversarial attacks, can be applied to an input image and induce catastrophic errors in deep neural networks (Fig. 5b). The FIP algorithm provides an efficient strategy to increase network robustness and mitigate adversarial failure by generating path-connected sets of networks with diverse weights. We then apply the path-connected network sets to perform robust image classification by averaging their output.\n\nTo demonstrate that the FIP algorithm can mitigate adversarial attacks, we trained a 16-layered CNN—VGG16—with 130M parameters to classify CIFAR-10 images with 92% test accuracy. We, then, generated adversarial test images using the projected gradient descent (PGD) attack strategy. On adversarial test images, the performance of VGG16 dropped to 37% (Fig. 5b and Supplementary Fig. 1). To mitigate the adversarial performance loss, we applied the FIP algorithm to generate an ensemble of functionally invariant networks by setting L = 0 in the optimization problem in equation (4) and setting \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{{\\rm{CIFAR}}10}}\\) to be the distance moved in the networks’ output space for CIFAR-10 images. We use the FIP ensemble to classify images by summing the ‘softmaxed’ outputs of the ensemble.\n\nUsing an ensemble of ten networks sampled along an FIP, we achieve an accuracy of 55.61 ± 1.1%, surpassing the performance of the DeepNet ensemble (composed of 10 independently trained deep networks) by 20.62% (Fig. 5c). The FIP ensemble’s adversarial performance also surpasses other state-of-the-art ensemble approaches including adaptive diversity-promoting (43.84 ± 7.8%) ensemble and the fast geometric ensembling (41.7 ± 0.34) method. The two factors contributing to the FIP ensemble’s robustness are (1) high intra-ensemble weight diversity, calculated by the representation diversity score; and (2) low coherence with a trained surrogate network (used to generate adversarial images) (Fig. 5e,f). FIP networks have a higher representation diversity score in their early processing layers, from layer 1 to layer 6, compared with the DeepNet ensemble, indicating that individual networks in the FIP ensemble extract different sets of local features from the adversarial image, preventing networks from relying on similar spurious correlations for image classification. We speculate that weight/parameter diversity in the FIP ensemble leads to differential susceptibility to adversarial examples but consistent performance on training and test examples. The approach has analogies with the model soup approaches explored in ref. 38.\n\nGenerating path-connected sets of language models\n\nConceptually, the most important aspect of the FIP framework is that it unifies a series of machine learning meta-tasks (CL and sparsification) into a single mathematical framework. Mathematically, when we solve equation (4) with a given secondary loss function, we move an existing network w(0) along a path in weight space generating a new network w(t) in which the parameter t increments the length of a path. Each additional loss function generates a new transformation of a base network, for example, generating a network adjusted to accommodate an additional data analysis problem or a secondary objective like sparsification. Network transformation maps can be iterated and applied to generate a family of neural networks optimized for distinct subtasks. The resulting path-connected set of neural networks can then be queried for networks that achieve specific user goals or solve additional machine learning problems.\n\nThe problem of customization is particularly important for transformer networks4,39,40,41. Transformers like BERT and Roberta are typically trained on generic text corpus like the common crawl, and the specialization of networks on specific domains is a major goal3,32. We applied the iterative FIP framework to generate a large number of NLP networks customized for different subtasks and sparsification goals. Transformer networks incorporate layers of attention heads that provide contextual weight for positions in a sentence. Transformer networks are often trained on a generic language processing task like sentence completion in which the network must infer missing or masked words in a sentence. Models are then fine-tuned for specific problems including sentiment analysis, question answering, text generation and general language understanding39. Transformer networks are large containing hundreds of millions of weights, and therefore, model customization can be computationally intensive.\n\nWe applied the FIP framework to perform a series of model customization tasks through the iterative application of FIP transformations on distinct goals. The BERT network has a total of 12 layers, or transformer blocks, with 12 self-attention heads in each layer and a total of 110M parameters5. Using the FIP framework, we sequentially applied two operations (CL and compression (Co)) to BERT models trained on a range of language tasks, by constructing FIPs in the BERT weight space using different objective functions (L(x, w)) and solving the optimization problem in equation (4) (Fig. 6).\n\nWe demonstrated that we could apply the CL and Co operations in sequence. Beginning with the BERT base model, we applied the FIP model to generate networks that could perform Yelp and IMDb sentiment analysis, and then compressed the resulting networks to generate six distinct networks with sparsity ranging from 10% to 60%, where all the sparsified networks maintained performance on the sentiment analysis tasks (Fig. 6a). We, then, performed the same operations, but changed the order of operations (Fig. 6b). The models generated through the application of CLCo(w) and CoCL(w) achieved similar functional performance in terms of sparsification and task performance but had distinct weight configurations.\n\nIn total, we used the FIP framework to generate networks using a set of different natural language tasks and Co tasks, yielding a path-connected set of 300 BERT models (Fig. 6c). The 300 networks define a submanifold of weight space that contains models customized for distinct subtasks. Then, the submanifold provides a computational resource for solving new problems. We can query the resulting FIP submanifold with unseen data by using perplexity as a measure of a networks intrinsic ability to separate an unseen dataset. Using perplexity, we queried the FIP submanifold of BERT networks with IMDb data and WikiText data. We found that the distinct language datasets achieve minimal perplexity on different classes of networks. WikiText obtains optimal performance on CoCL networks and IMDb achieves optimal performance on CLCo networks. These results demonstrate that the FIP framework can generate diverse sets of neural networks by transforming networks using distinct meta-tasks. The submanifolds of weight space can then be inexpensively queried to identify networks pre-optimized for new machine learning problems.\n\nThe major contribution of our framework is that it provides a unified theoretical and mathematical framework through which a set of problems can be addressed across a variety of neural network architectures. To the best of our knowledge, no single mathematical framework has been applied to address the set of machine learning meta-problems and diversity of neural network architectures that we address with the FIP framework. Further, with the rise of transformer models, we have seen the emergence of architecture-specific strategies for sparsification and CL. We provide a unified framework that can achieve a similar quality of results across different classes of architectures (CNN and transformers) and across different transformer variants. Although representation learning frameworks have been pursued in fields including reinforced learning42,43, our work develops a geometric framework that identifies invariant subspaces within the parameter space for distinct auxiliary tasks. We demonstrate that the framework scales to transformer models with hundreds of millions of parameters. Therefore, our framework provides a unified theoretical and mathematical model for connecting the geometry of parameter space with different model subtasks as well as practically scaling to provide results in line with the state-of-the-art, more specific approaches. The FIP is also related to Jacobian regularization approaches that have been explored to stabilize model training and prevent over-fitting44. Here we review some of the specific approaches that have been studied for CL, sparsification and adversarial robustness.\n\nCL and catastrophic forgetting\n\nCL has been studied extensively in the machine learning literature45,46,47 for classical CNN as well as vision and language transformers48,49. A wide variety of approaches have been developed to train neural networks on a sequence of tasks without the loss of prior task performance including regularization-based methods, weight parameter isolation methods and replay-based methods. Many classic CL/catastrophic forgetting (CF) approaches were developed for CNN architectures with <100M parameters. With the emergence of transformer models for NLP and computer vision, approaches have become more model specific with approaches such as regularization-based methods and parameter isolation methods. Regularization-based methods assign constraints to prevent parameter changes to important parameters from prior tasks. The FIP framework can be viewed as a generalized regularization framework that applies at any point in the parameter space. Methods like EWC33, OGD50, RMN30 and synaptic intelligence51 penalize the movement of parameters that are important for solving previous tasks to mitigate catastrophic forgetting. RMN identifies the relevant units in the pre-trained model that are most important for the new task using a thresholding strategy. OGD constrains movement in the parameter space to move in a subspace that is orthogonal to gradients from prior tasks. OGD was applied to CL tasks on the MNIST data50 on a small, three-layer multi-layer perceptron. The OGD method requires knowledge of prior task gradients and is a local method, like EWC. Although (locally in the parameter space) it makes sense to constrain changes in the network parameters along the orthogonal subspace, there is no mathematical reason that long-range updates should satisfy this constraint. Past gradient directions become less meaningful as we move away from an initial trained network and begin traversing long-range paths in the parameter space in search of good networks. By using a metric tensor construction that is defined at every point in the parameter space, the FIP framework can traverse long-range paths in the parameter space, sometimes making weight updates that are, in fact, not orthogonal to gradients.\n\nReplay-based methods store and replay past data or apply generative models to replay data during training to mitigate catastrophic forgetting52,53. Regularization-based methods including EWC constrain the learning of important parameters from previous tasks by assigning constraints to prevent parameter changes. Architecture expansion or dynamic architecture methods like progressive neural networks54, dynamically expandable networks55 and super-masks in position56 adapt, grow or mask the model’s architecture, respectively, allowing specialization without interfering with previous knowledge. Parameter isolation methods: these methods isolate specific parameters or subsets of parameters to be task specific, preventing interference with previous knowledge. Examples include the context-dependent gating approach or the learning-without-forgetting method. Instead of modifying the learning objective or replaying data, various methods use different model components for different tasks. In progressive neural networks, dynamically expandable networks and reinforced CL (RCL) the model is expanded for each new task.\n\nLow-rank fine tuning with LoRA\n\nLoRA32 was designed to enable the computationally efficient adaptation of large transformer models by forcing weight updates to be low ranked. LoRA achieves impressive performance on the fine tuning of very large models including GPT-3 (175B). LoRA achieves its performance by introducing a low-rank structure heuristic into the weight update through matrix factorization, forcing ΔW = AB, where A and B have an inner dimension r, and thus controlling the rank of W to be r. We view FIP and LoRA as complementary methods and seek to incorporate low-rank constraints into new versions of the FIP algorithm.\n\nSparsification methods\n\nSparsity methods for neural networks aim to reduce the number of parameters or activations in a network, thereby improving efficiency and reducing memory requirements. Unstructured pruning techniques apply strategies based on network weights or weight gradients to remove weights that do not contribute to network performance. Unstructured sparsity methods seek to remove weights at any position in the network. The lottery ticket hypothesis (LTH) demonstrated that dense networks often contain sparse subnetworks, named winning tickets, that can achieve high accuracy when isolated from the dense network57. LTH methods discover these sparse networks through an empirical pruning procedure. Unstructured pruning methods remove inconsequential weight elements using criteria including weight magnitude, gradient and Hessian47,58,59. Recent strategies60,61 dynamically extract and train sparse subnetworks instead of training the full models. Evolutionary strategies including the sparse evolutionary training procedure62,63 begin with sparse topologies (for example, Erdős–Rényi generated graphs) in training and optimize topology and network weights during training. Historically, sparsity methods have been applied to convolutional and multi-layer perceptron architectures. Recent frameworks have been introduced for the sparsification of transformer architectures. For example, a vision transformer sparsification strategy SViTE36 was developed that uses model training integrated with prune/grow strategies, achieving the sparsification of the ViT family of transformers. The sparsification of BERT64 was explored by identifying specific internal network topology that can achieve high performance on NLP tasks with sparse weight distribution through empirical investigation and ablation experiments.\n\nRobustness to adversarial attack\n\nFinally, we demonstrate that the FIP can generate ensembles of networks with good performance in adversarial attack paradigms. Like CL and sparsificaiton, adversarial attack mitigation has been addressed by a wide range of methods including augmented training with adversarial examples65, through the use of diversified network ensembles66, as well as through re-coding of the input67. We demonstrate that the FIP framework can generate network ensembles that have intrinsic resistance to adversarial attack compared with base networks.\n\nIn the main text, we have introduced a geometric framework to solve three core challenges in modern machine learning, namely, (1) alleviating catastrophic forgetting, (2) network sparsification and (3) increasing robustness against adversarial attacks. We will describe the datasets, parameters/hyperparameters used for the algorithms and the pseudo-code for each of the core challenges addressed in the main text.\n\nCatastrophic forgetting\n\nDatasets and preprocessing\n\nThe models were tested on two paradigms:\n\nSplitCIFAR100: ten sequential-task paradigm, where the model is exposed to ten tasks, sampled from the CIFAR-100 dataset. The CIFAR-100 dataset contains 50,000 RGB images for 100 classes of real-life objects in the training set, and 10,000 images in the testing set. Each task requires the network to identify images from ten non-overlapping CIFAR-100 classes.\n\nWe performed two operations, namely, (1) network Co and (2) CL on BERT, fine-tuned on different language datasets, downloaded from the HF website.\n\nWikipedia: the Wikipedia English datasets are downloaded from https://huggingface.co/datasets/wikipedia. We used the Wikipedia dataset on the masked language model (MLM) task.\n\nYelp reviews: the Yelp review dataset is obtained from HF, downloaded from https://huggingface.co/datasets/yelp_review_full.\n\nIMDb reviews: the IMDb review dataset is obtained from HF, downloaded from https://huggingface.co/datasets/imdb.\n\nGLUE dataset: the GLUE dataset is obtained from HF, downloaded from https://huggingface.co/datasets/glue. The GLUE tasks performed in this paper are (1) QQPs, (2) SST-2, (3) CoLA, (4) RTE, (5) MNLI, (6) MRPC and (7) QNLI.\n\nParameters used\n\nFIP for CL: η = 2 × 10–5, λ = 1, n memories from previous task = 2,000/650,000 = (0.8% previous dataset); optimizer used, AdamW.\n\nFIP for BERT sparsification: η = 2 × 10–5, λ = 1; optimizer used, AdamW. Final (desired) network sparsities for the GLUE task: task (p% sparse): RTE (60% sparse), CoLA (50% sparse), STS-B (50% sparse), QNLI (70% sparse), SST-2 (60% sparse), MNLI (70% sparse), QQP (90% sparse) and MRPC (50% sparse). Final (desired) network sparsities for Wikipedia sentence completion: [10%, 20%…90%].\n\nNetwork architectures\n\nAll state-of-art methods for alleviating CF (presented in the main text) in the two-task and five-task paradigm used the same network architectures: the ViT-Base and ViT-Huge transformer variants described at https://huggingface.co/docs/transformers/model_doc/vit. BERT is a popular transformer model with 12 layers (transformer blocks), each with a hidden size of 768, 12 self-attention heads in each layer with a total of 110M parameters (https://huggingface.co/docs/transformers/model_doc/bert). BERT has been pre-trained on 45 GB of Wikipedia data, using the MLM task and next-sentence prediction.\n\nSentence completion (masking) tasks\n\nFor the masking tasks (where 15% of the words in the input sentence are masked (or blanked)), the BERT network has an MLM head appended to the network. The MLM head produces a three-dimensional tensor as the output, where the dimensions correspond to (1) the number of sentences in a single batch (batch-size), (2) number of blanked-out words in a sentence and (3) number of tokens in the BERT vocabulary (30,000 tokens).\n\nSentence classification tasks\n\nFor the sentence classification task, a sentence classifier head was appended to the BERT architecture. Here the classifier head produces a two-dimensional output tensor, where the dimensions correspond to (1) batch-size and (2) number of unique classes in the classification problem.\n\nPseudo-code: FIP construction for CF problems\n\nAlgorithm 1\n\nFIP construction for CF problems:\n\nRequire λ; η, step-size hyperparameters; NT, number of sequential tasks\n\n1: procedure FIP-CF(λ, η, NT)\n\n2: random initialize w0\n\n3: Bi←{}∀i = 1, 2…NT ⊳ buffer with nmem memories from previous tasks\n\n4: 1 for i←1 to NT do\n\n5: wi←wi−1\n\n6: (x, t)←Task i ⊳ minibatch of images (x) and target labels (t) from task i\n\n7: Bi←Bi ∪ x ⊳ update buffer\n\n8: CEloss←Cross-Entropy(f(x, wi), t) ⊳ classification loss for new task\n\n9: Yloss←0\n\n10: for j←1 to i – 1 do\n\n11: Yloss += Ydist(f(x, wi), f(Bj, wi−1)) ⊳ distance moved in output space (Y)\n\n12: end for\n\n13: S←CEloss + λ × Yloss ⊳ construct FIP with direction from loss gradient\n\n14: \\({{\\bf{w}}}_{{\\bf{i}}}\\leftarrow {{\\bf{w}}}_{{\\bf{i}}}-\\eta {\\nabla }_{{{\\bf{w}}}_{{\\bf{i}}}}S\\)\n\n15: end for\n\n16: return wi\n\n17: end procedure\n\nCode specifications\n\nAll the code was written in the PyTorch framework, and the automatic differentiation package was extensively used for constructing the computational graphs and computing gradients for updating the network parameters. The code for constructing the FIPs for the 2-task and 20-task paradigm was run on Caltech’s high-performance computing cluster using a single GPU for a total time of 1 h and 10 h, respectively.\n\nParameters used\n\nThe parameters used for the current state-of-art methods across different models and datasets have been selected after grid search to maximize accuracy.\n\nFIP for 2-task paradigm: η = 0.01; optimizer used, Adam; weight-decay = 2 × 10–4, λ = 1, n memories from previous task = 500/60,000 (0.8% of the previous dataset).\n\nEWC for 2-task paradigm: optimizer used, Adam; EWC regularization coefficient (λ) = 5,000, learning rate = 0.001, batch-size = 128, number of data samples from previous task to construct the Fisher metric = 500.\n\nFIP for 20-task paradigm: η = 0.01; optimizer used, Adam; weight-decay = 2 × 10–4, λ = 1, n memories from previous task = 250/2,500 (10% of the previous tasks).\n\nGEM for 20-task paradigm: n memories from previous task = 250, learning rate = 0.01, number of epochs (per task) = 20, memory strength = 0.5, batch-size = 128.\n\nEWC for 20-task paradigm: optimizer used, Adam; EWC++, α = 0.9, λ = 5,000, learning rate = 0.001, Fisher metric update after 50 training iterations and batch-size = 128.\n\nImplementation of other CF methods\n\nWe implemented the EWC method by adapting the code available at https://github.com/moskomule/ewc.pytorch. The GEM method was applied by adapting the code available at https://github.com/facebookresearch/GradientEpisodicMemory.\n\nLoRA: LoRA training for the model was done using the PEFT library71. We instantiate the base language model (for example, model trained on the Yelp dataset). We create a LoRAConfig object, where we can specify the following parameters: LoRA rank (ranks of 1, 4, 8, 16, 32), LoRA α (scaling factor): (usually we use α = rank × 2). Target modules: ‘query’ and ‘value’ in the attention layer (across all the layers of the network) and LoRA dropout = 0.1. In the LoRA experiments, we explored a variety of different learning rates to stabilize training including 10−6→10−5. For ViT experiments, we use a ramping procedure with a learning rate that starts at 1 × 10–3 until it reaches the maximum peak at 1 and then decreases.\n\nExample parameter settings for LoRA on NLP for BERT are as follows.\n\nLoRA training with rank = 16, α = 32; learning rate = 3 × 10–5\n\nLoRA training with rank = 16, α = 32; learning rate = 1 × 10–5\n\nLoRA training with rank = 16, α = 32; each step corresponds to 400 samples at learning rate = 1 × 10–5\n\nLoRA training with rank = 16, α = 32; each step corresponds to 1,600 samples at learning rate = 1 × 10–5\n\nLoRA training with rank = 16, α = 32; each step corresponds to 1,600 samples at learning rate = 2 × 10–6 (initial training steps)\n\nPost-convergence: LoRA training with rank = 4, α = 8; each step corresponds to 1,600 samples at learning rate = 2 × 10–6\n\nNetwork sparsification\n\nDatasets and preprocessing\n\nThe models were sparsified using a well-known image dataset, ImageNet1K (https://huggingface.co/datasets/imagenet-1k), which contains 1,000 object classes and contains 1,281,167 training images, 50,000 validation images and 100,000 test images.\n\nNetwork architectures\n\nWe used the DeIT vision transformer from Meta for demonstrating the strategy for constructing FIP in weight space. The network and variants are described at https://huggingface.co/docs/transformers/model_doc/deit. As described, the base DeIT (86M parameters) achieves top-1 accuracy of 83.1% (single-crop evaluation) on ImageNet with no external data.\n\nWe also used the BERT dataset available at https://huggingface.co/docs/transformers/model_doc/bert.\n\nPseudo-code: FIP construction for network sparsification\n\nAlgorithm 2\n\nFIP construction for network sparsification:\n\nRequire: λ, η\n\nRequire: p, final desired network sparsity (in percentage)\n\nRequire: wt, network trained on MNIST or CIFAR-10 dataset\n\n1: procedure FIP-Sparse(λ, η, p, wt)\n\n2: w←wt\n\n3: while (∣∣w∣∣0/∣∣wt∣∣0) NOT (1 − p/100) ⊳ until w not in p% sparse submanifold\n\n4: wp←project(w, p) ⊳ set p% of smallest weights to zero\n\n5: L(w)←∣∣w − wp∣∣2\n\n6: x←dataset(MNIST or CIFAR) ⊳ sample minibatch of images from the dataset\n\n7: OPloss←odist(f(x, w), f(x, wt)) ⊳ distance moved in the output space\n\n8: S←OPloss + λ × L(w)\n\n9: w←w − η∇wS ⊳ constructing FIP towards sparse submanifold\n\n10: end while\n\n11: return w\n\n12: end procedure\n\nCode specifications\n\nAll the code was written in the PyTorch framework, and the automatic differentiation package was extensively used for constructing the computational graphs and computing gradients for updating the network parameters. The code for constructing the FIPs to the p% sparse submanifolds was run on Caltech’s high-performance computing cluster using a single GPU for a total time ranging between 2 h and 6 h for final network sparsities below 80%, and between 24 h and 30 h for identifying high-performance networks in submanifolds with larger than 80% sparsity.\n\nParameters used\n\nFIP for network sparsification: λ = 1, η = 0.01; optimizer used, Adam (β = (0.9, 0.999)); final (desired) network sparsities for LeNet-300-100 on MNIST: p = [20%, 67%, 89%, 96%, 98.7%, 99%, 99.1%, 99.4%]; final (desired) network sparsities for ResNet20 on CIFAR-10: p = [20%, 36%, 49%, 59%, 67%, 79%, 83%, 89%, 93%, 95%].\n\nLTH (for LeNet-MNIST): batch-size = 128, model-init = kaiming-normal, batchnorm-init = uniform, pruning-strategy = sparse-global, pruning-fraction = 0.2, pruning-layers-to-ignore = fc.weight, optimizer-name = sgd, learning rate = 0.1, training-steps = 40 epochs. LTH (for ResNet20-CIFAR-10): batch-size = 128, model-init = kaiming-normal, batchnorm-init = uniform, pruning-strategy = sparse-global, pruning-fraction = 0.2, optimizer-name = sgd, learning rate = 0.1, training-steps = 160 epochs, momentum = 0.9, gamma = 0.1, weight-decay ≥ 0.0001.\n\nImplementation of other sparsification methods\n\nWe implemented the LTH for sparsifying both LeNet-300-100 trained on MNIST and ResNet20 trained on CIFAR-10. To do so, we adapted code from https://github.com/facebookresearch/open_lth.\n\nAdversarial robustness\n\nDatasets and preprocessing\n\nThe models were trained on the CIFAR-10 dataset and the adversarial examples were generated on the same using the PGD method.\n\nCIFAR-10: the CIFAR-10 training dataset contains 50,000 RGB images of 10 classes of natural images (like trucks, horses, birds and ships). The test set contains 10,000 additional images from each of the 10 classes.\n\nNetwork architecture\n\nFor the adversarial robustness section, we used the VGG16 network72, which has 16 layers, and a total of 138M trainable parameters.\n\nGenerating an adversarial attack\n\nWe used the PGD method to generate CIFAR-10 data samples that are imperceptibly similar to their original images for humans, but cause performance loss to deep networks. The PGD attack computes the best direction (in image space) to perturb the image such that it maximizes the trained networks’ loss on the image and constraining the Linf norm of the perturbation.\n\nThe procedure for generating adversarial inputs is detailed below:\n\nRandomly initialize a VGG16 network and train it on CIFAR-10 (trained network = wt).\n\nTake a single image input (x) from the CIFAR-10 dataset and pass it through the trained network, and calculate the gradient of the classification loss (cross-entropy (C)) with respect to the input (grad = ∇xC(wt, x, y)).\n\nConstruct an adversarial input (x′) by taking multiple steps (S) in the image input space, where the adversary is within an ϵl∞ bound. xt+1 = ∏x+S(xt + αsgn(∇xC(wt, x, y))). Here we take as many steps (S) as required until the adversarial input (xt+1) exits the ϵl∞ bound. We choose ϵ = 0.3 and α = 2/255 for generating CIFAR-10 adversarial examples against VGG16 networks.\n\nRepresentation diversity score\n\nWe compute the representation diversity score for both ensembles (FIP and DeepNet) by evaluating the standard deviation of the L2 norm of the network’s activation across all the networks in the ensemble along each layer for a set of image inputs.\n\nCoherence between two models\n\nWe compute the overlap of the adversarial subspace between networks in the FIP ensemble and the trained surrogate network by evaluating the cosine distance between the gradients of the loss function of the FIP networks and the trained surrogate network with respect to an input (x).\n\nSay, the gradients of the loss function with respect to input (x) for the two models are Jx(θ0, x, y) and Jx(θ1, x, y). The cosine distance between the gradients is evaluated as follows, where CS indicates cosine similarity.\n\n$${\\mathrm{CS}}({\\nabla}_{x}\\;{J}_{0},{\\nabla}_{x}\\;{J}_{1})\\left.\\right)=\\frac{ < {\\nabla}_{x}\\;{J}_{0},{\\nabla}_{x}\\;{J}_{1} > }{| {\\nabla}_{x}\\;{J}_{0}| | {\\nabla}_{x}\\;{J}_{1}| }.$$\n\n(6)\n\nThe cosine distance between the gradients provides a quantitative measure for how likely an adversarial input that affects the surrogate network would attack the model sampled along an FIP.\n\nTo evaluate the coherence across all the sampled models in the FIP and a trained surrogate network, we measure the maximum cosine similarity between all pairs of gradient vectors in the set.\n\n$${\\max }_{a\\in 1\\ldots N}{\\mathrm{CS}}({\\nabla}_{x}\\;{J}_{a},{\\nabla}_{x}\\;{J}_{\\rm{s}})\\left.\\right).$$\n\n(7)\n\nHere Ja refers to the gradient of N networks sampled along the FIP for a single input (x), and Js refers to the gradient of the trained surrogate network for the input (x).\n\nPseudo-code: FIP for adversarial robust ensembles\n\nAlgorithm 3\n\nFIP for adversarially robust ensembles\n\nRequire: η, step size; wt, network trained on CIFAR-10 dataset; ϵl∞ of adversary perturbation\n\nRequire: δ, permissible change in output distance; max-iter, number of steps in the FIP\n\n1: procedure FIP-ensemble(η, wt, δ, ϵ)\n\n2: w←wt\n\n3: ii←0 ⊳ setting counter = 0\n\n4: F←{} ⊳ list of networks in the FIP ensemble\n\n5: while ii ≤ max-iter\n\n6: (x, y)←dataset(CIFAR-10) ⊳ sample minibatch of images from dataset\n\n7: S←odist(f(x, w), f(x, wt)) ⊳ output-space distance for varying network weights\n\n8: w←w − η∇wS ⊳ construct undirected FIP\n\n9: x′←x + εsgn(∇xC(w, x, y))\n\n10: H←odist(f(x, w), f(x′, w)) ⊳ output-space distance for perturbed input\n\n11: if H ≤ δ then\n\n12: F←F ∪ w\n\n13: end if\n\n14: ii←ii + 1\n\n15: end while\n\n16: return F ⊳ returning FIP ensemble with adversarial robustness\n\n17: end procedure\n\nCode specifications\n\nAll the code was written in the PyTorch framework, and the automatic differentiation package was extensively used for constructing the computational graphs and computing gradients for updating the network parameters. The code for constructing the undirected FIPs in the weight space, followed by sampling a small subset of networks along the FIP, was run on Caltech’s high-performance computing cluster using a single GPU for a total time ranging between 2 h and 6 h.\n\nParameters used\n\nTo generate ensembles of deep networks, we selected parameters after a grid search to maximize robustness against adversarial failure.\n\nFIP ensemble: η = 0.01, ϵ = 0.3, minibatch size = 100, δ = 35 (inputs to the FIP construction/ensemble pseudo-code detailed above).\n\nAdaptive diversity-promoting ensemble: α = 2, β = 0.5 (α and β are parameters maximizing the diversity of ensemble); optimizer used, SGD; momentum = 0.9, learning rate = 0.05, weight-decay = 2 × 10–4, batch-size = 128, num-networks-per-ensemble = 3, 5 and 10 (three different ensembles).\n\nFast geometric ensembling: model, VGG16; epochs = 40, weight-decay = 3 × 10–4, learning-rate-1 = 0.5 × 10–2, learning-rate-2 = 1 × 10–2, cycles = 2.\n\nImplementation of other ensemble generation methods for adversarial robustness\n\nWe generated ensembles of deep networks (VGG16) using three state-of-art methods. The first method, ‘DeepNet ensemble’, was constructed by training multiple independently initialized VGG16 networks. The second method called adaptive diversity promoting is obtained by adapting the code available at https://github.com/P2333/Adaptive-Diversity-Promoting. The third method called fast geometric ensembling is obtained by adapting the code taken from this repository: https://github.com/timgaripov/dnn-mode-connectivity.\n\nFIP for multiple ‘operations’ on BERT language model\n\nWe scale our FIP geometric framework to perform multiple operations (like CL and Co) on BERT language models that are very large and are capable of parsing large amounts of text scraped from different internet sources (like, Wikipedia, Yelp, IMDb and so on).\n\nDatasets and preprocessing\n\nWe performed two operations, namely, (1) network Co and (2) CL on BERT, fine tuned on different language datasets, downloaded from the HF website.\n\nWikipedia: the Wikipedia English datasets are downloaded from https://huggingface.co/datasets/wikipedia. We used the Wikipedia dataset on the MLM task.\n\nYelp reviews: the Yelp review datasets are obtained from HF, downloaded from https://huggingface.co/datasets/yelp_review_fullhttps://huggingface.co/datasets/yelp_review_full.\n\nIMDb reviews: the IMDb review datasets are obtained from HF, downloaded from https://huggingface.co/datasets/imdb.\n\nGLUE dataset: the GLUE dataset is obtained from HF, downloaded from https://huggingface.co/datasets/gluehttps://huggingface.co/datasets/glue. The GLUE tasks performed in this paper are (1) QQPs, (2) SST-2, (3) CoLA, (4) RTE, (5) MNLI, (6) MRPC and (7) QNLI.\n\nNetwork architecture\n\nBERT is a popular transformer model having 12 layers (transformer blocks), each with a hidden size of 768, comprising 12 self-attention heads in each layer having a total of 110M parameters5. BERT has been pre-trained on 45 GB of Wikipedia data, using the MLM task, and next-sentence prediction.\n\nSentence completion (masking) tasks\n\nFor the masking tasks (where 15% of the words in the input sentence are masked (or blanked)), the BERT network has an MLM head appended to the network. The MLM head produces a three-dimensional tensor as the output, where the dimensions correspond to (1) the number of sentences in a single batch (batch-size), (2) number of blanked-out words in a sentence and (3) number of tokens in the BERT vocabulary (30,000 tokens).\n\nSentence classification tasks\n\nFor the sentence classification task, a sentence classifier head was appended to the BERT architecture. Here the classifier head produces a two-dimensional output tensor, where the dimensions correspond to (1) batch-size and (2) number of unique classes in the classification problem.\n\nCode specifications\n\nAll the code was written in the PyTorch framework, and the automatic differentiation package was extensively used for constructing the computational graphs and computing gradients for updating the network parameters. The code for constructing the FIPs in the BERT weight space for CL on Yelp and IMDb sentiment analysis and for BERT sparsification was run on Caltech’s high-performance computing cluster using two GPUs for a total time of 2 h and 6–30 h, respectively.\n\nParameters used\n\nFIP for CL: η = 2 × 10–5, λ = 1, n memories from previous task = 2,000/650,000 (0.8% of the previous dataset). Optimizer used, AdamW.\n\nFIP for BERT sparsification: η = 2 × 10–5, λ = 1. Optimizer used, AdamW. Final (desired) network sparsities for the GLUE task: task (p% sparse): RTE (60% sparse), CoLA (50% sparse), STS-B (50% sparse), QNLI (70% sparse), SST-2 (60% sparse), MNLI (70% sparse), QQP (90% sparse), MRPC (50% sparse). Final (desired) network sparsities for Wikipedia sentence completion: [10%, 20%…90%].\n\nFIP length\n\nThe FIP length is evaluated by sampling a large number of networks along the FIP, and summing the Euclidean distance between all the consecutive pairs of networks. Say, the weights of the networks sampled along the FIP are denoted by w1, w2, w3…wn.\n\n$$\\,\\text{FIP-length}\\,=\\mathop{\\Sigma }\\limits_{i = 2}^{n}| | {{\\bf{w}}}_{{\\bf{i}}}-{{\\bf{w}}}_{{\\bf{i}}-{\\bf{1}}}| {| }_{2}$$\n\nPerplexity score: language models\n\nPerplexity is an evaluation metric used to measure how ‘surprised’ a language model is when it encounters a new task. That is, a higher perplexity implies more surprise, suggesting that the language model does not have much insight into how language works. Mathematically, we define perplexity as the exponential of the cross-entropy loss on the evaluation dataset:\n\n$$\\,\\text{PPL}\\,(\\theta )=\\exp \\left[\\mathop{\\Sigma }\\limits_{i = 1}^{{n}_{e}}l(\\theta ,{x}_{i})\\right],$$\n\nwhere θ is the parameter of the BERT model and x1, x2…\\({x}_{{n}_{\\rm{e}}}\\) are the ne inputs from the evaluation dataset. l(θ, xi) evaluates the cross-entropy loss of a BERT model parameterized by θ for a single input xi.\n\nConstructing FIP ensemble for adversarial robustness\n\nSelection criteria for FIP ensemble\n\nHaving constructed an FIP in the weight space, beginning from a deep network trained on CIFAR-10, we introduce the selection criteria to sample diverse networks along the FIP to construct the FIP ensemble. As we want the FIP ensemble to be robust to adversarial input perturbation, we generate random perturbations in the image space (within an ϵl∞ ball) and compute the distance moved in the networks’ output space for a small perturbation in the image space.\n\nWe record the distance moved in the networks’ output space (across all the networks in the constructed FIP) and plot a distribution of the distance moved in the output space for a small perturbation in the image input space. We find that some networks along the FIP exhibit smaller perturbation in the output space and have a narrower distribution across 10k perturbed training inputs, whereas others exhibit larger perturbation in the output space. We choose networks that exhibit a smaller perturbation in the output space for constructing the FIP ensemble.",
      "# [The Science of Consciousness Conference](https://consciousness.arizona.edu/)\n"
    ],
    "# Comprehensive Analyst Report on Yurts.ai\n\n## Company Overview\n\nYurts.ai, founded in August 2022, is a secure and private Generative AI (GenAI) integration platform that focuses on enhancing mission-critical workflows, particularly within the defense and government sectors. The company was born out of collaborations with the Department of Defense (DoD) and aims to transform knowledge management and operational efficiency through its adaptable GenAI platform [(Yurts AI, PR Newswire, 2024-10-23)](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html). As of December 2024, Yurts has secured a total of $58 million in funding, including a recent $40 million Series B round led by XYZ Venture Capital [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html).\n\nYurts employs approximately 50 people, with about 25% holding active security clearances, indicating a strong focus on high-security environments [(Yurts AI, Washington Headquarters Services, 2024-12-04)](https://www.cbinsights.com/company/washington-headquarters-services). The company's leadership includes co-founders Ben Van Roo, Jason Schnitzer, and Guruprasad Raghavan, who bring extensive experience in machine learning and military research [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html).\n\n## Product Overview\n\nYurts.ai's platform is designed to integrate GenAI capabilities into existing systems, particularly for defense and intelligence applications. The platform allows users to quickly access information across various mission-critical systems and utilize GenAI techniques for document creation and insights generation [(Yurts AI, PR Newswire, 2024-10-23)](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html). It is built to operate securely in environments classified from IL-2 to IL-6, ensuring compliance with stringent security requirements [(Yurts AI, PR Newswire, 2024-10-23)](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html).\n\n### Key Features\n\n- **Integration with Legacy Systems**: Yurts.ai provides a critical integration layer that connects AI models to internal applications, facilitating the modernization of legacy systems [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html).\n  \n- **Performance Monitoring**: The platform includes comprehensive dashboards to track the performance of retrieval-augmented generation (RAG) systems, ensuring that changes improve functionality without degrading performance [(Yurts AI, Monitor performance and accuracy of enterprise RAG, 2024-12-16)](https://venturebeat.com/ai/weve-come-a-long-way-from-rpa-how-ai-agents-are-revolutionizing-automation/).\n\n- **Adversarial Robustness**: Yurts.ai's framework is designed to enhance the robustness of AI models against adversarial attacks, making it suitable for high-stakes environments [(Yurts AI, Monitor performance and accuracy of enterprise RAG, 2024-12-16)](https://venturebeat.com/ai/weve-come-a-long-way-from-rpa-how-ai-agents-are-revolutionizing-automation/).\n\n## Recent Developments\n\n### Partnerships and Collaborations\n\n1. **Oracle Collaboration**: In October 2024, Yurts announced a partnership with Oracle to deliver secure GenAI solutions to the defense and intelligence sectors. This collaboration leverages Oracle Cloud Infrastructure to enhance operational efficiency and decision-making capabilities for defense agencies [(Yurts AI, PR Newswire, 2024-10-23)](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html).\n\n2. **Redhorse Partnership**: In February 2024, Yurts formed a strategic partnership with Redhorse Corporation to deploy secure GenAI solutions for federal agencies. This partnership aims to modernize knowledge-driven enterprise workflows while ensuring operational efficiency and privacy [(Redhorse Corporation, 2024-02-21)](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/).\n\n### Funding Events\n\nYurts.ai successfully raised $40 million in a Series B funding round in December 2024, which will be used to accelerate growth and enhance its capabilities in integrating GenAI into mission-critical systems [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html). This funding round was led by XYZ Venture Capital, with participation from several other investors, bringing the total investment to $58 million [(Yurts AI, Washington Headquarters Services, 2024-12-04)](https://www.cbinsights.com/company/washington-headquarters-services).\n\n## Executive Insights\n\nBen Van Roo, Co-Founder and CEO of Yurts, emphasized the company's commitment to delivering tangible results in AI integration, stating, \"As GenAI adoption matures, the challenge is no longer about demos and pilots; it's about delivering tangible results\" [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html). His background in military research and machine learning positions him well to lead Yurts in addressing the complex needs of defense and government clients.\n\n## Market Position and Scale\n\nYurts.ai is positioned as a leader in the secure AI integration space, particularly within the defense sector. The company has secured contracts with various branches of the U.S. military, including the Army, Air Force, and Special Operations Command, indicating a strong foothold in the government market [(Yurts AI, PR Newswire, 2024-12-03)](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html). The company's focus on high-security environments and compliance with DoD standards further enhances its market credibility.\n\n## Conclusion\n\nYurts.ai is rapidly establishing itself as a key player in the secure AI integration market, particularly for defense and government applications. With significant funding, strategic partnerships, and a robust product offering, the company is well-positioned to capitalize on the growing demand for secure and efficient AI solutions in mission-critical environments. Prospective candidates and investors should consider Yurts.ai's innovative approach and strong leadership as indicators of its potential for growth and impact in the industry."
  ],
  "lineage": {
    "run_at": "2024-12-21T15:19:43.841850",
    "git_sha": "b66763b"
  }
}