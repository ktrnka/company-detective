{
  "summary_markdown": "# About Yurts.ai\n\nYurts.ai is a company specializing in secure generative artificial intelligence (GenAI) solutions, particularly for defense, government, and enterprise customers. Founded in 2022 by Ben Van Roo, Jason Schnitzer, and Guruprasad Raghavan, Yurts emerged from a strategic partnership with the Department of Defense (DoD). The company focuses on integrating AI into mission-critical workflows, aiming to modernize enterprise knowledge management and workflows through a highly adaptable and secure GenAI platform [(Buford, Redhorse Corporation, 2024-02-21)](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/).\n\nYurts recently raised $40 million in Series B funding led by XYZ Ventures, Glynn Capital, and Nava Ventures, bringing its total funding to $58 million. This funding is intended to enhance its capabilities and accelerate the integration of GenAI into mission-critical systems [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/). The company has secured significant contracts, including a $16 million deal with U.S. Special Operations, highlighting its strong presence in the defense sector [(Leadiq, 2024)](https://leadiq.com/c/yurts/63617f9bd4454f2aa396b5ff).\n\nYurts serves a diverse clientele, including Fortune companies and government agencies, with a particular focus on the Department of Defense. The platform is designed to meet stringent security standards, making it suitable for classified use cases. The company promotes a vibrant and collaborative work environment, emphasizing continuous learning, autonomy, and employee well-being.\n\n# Key Personnel\n\n- **Ben Van Roo**: CEO & Co-Founder, with a background in national security and data science. He has expressed a commitment to advancing federal government capabilities through generative AI [(Buford, Redhorse Corporation, 2024-02-21)](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/).\n\n- **Jason Schnitzer**: CTO & Co-Founder, experienced in production engineering and platform development.\n\n- **Guruprasad Raghavan**: Lead Research Scientist & Co-Founder, specializing in algorithms and strategies for AI.\n\n# News\n\n## Funding and Growth\n\nYurts recently closed a $40 million Series B funding round led by XYZ Venture Capital, with participation from several other investors. This funding will be used to enhance its capabilities and accelerate the integration of GenAI into mission-critical systems [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/).\n\n## Strategic Partnerships\n\nYurts has established strategic partnerships to enhance its offerings and expand its market reach. Notably, it has partnered with Redhorse Corporation to deploy secure generative AI solutions for federal agencies [(Buford, Redhorse Corporation, 2024-02-21)](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/). Additionally, Yurts has expanded its partnership with Oracle, further demonstrating its capability to support commercial customers in modernizing their systems with AI [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/).\n\n## Product and Services\n\nYurts.ai offers a comprehensive AI platform designed to transform knowledge management and mission-critical workflows at scale. The platform features several key functionalities, including enterprise search, natural language processing, and embedded AI assistants. Yurts emphasizes security, particularly in high-stakes environments, by ensuring that its AI solutions do not train on proprietary data and can be deployed on-premise [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/).\n\n## Market Position\n\nYurts is positioned to redefine how organizations harness AI, particularly in sectors where security and compliance are paramount. With nearly 25% of its employees holding active security clearances, the company underscores its expertise in high-security environments [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/).\n\nIn conclusion, Yurts.ai is at the forefront of integrating generative AI into mission-critical workflows, particularly within the defense and government sectors. With significant funding, strategic partnerships, and a robust product offering, Yurts is well-positioned for growth and innovation in the AI landscape.",
  "target": [
    "Yurts.ai",
    "Yurts.ai",
    "yurts.ai",
    null,
    false,
    false
  ],
  "webpage_result": {
    "summary_markdown": "# Yurts Enterprise AI Summary\n\n## Company Overview\n\nYurts is an innovative enterprise-ready Generative AI (GenAI) platform founded in 2022 by Ben Van Roo, Jason Schnitzer, and Guruprasad Raghavan. The company emerged from a strategic partnership with the Department of Defense, focusing on delivering secure and scalable AI solutions tailored for mission-critical environments. Yurts aims to transform knowledge management and enterprise workflows, enhancing efficiency through integration across diverse applications and data stores.\n\n## Company History\n\n- **Founded**: 2022\n- **Funding**: Recently raised $40M in Series B funding led by XYZ Ventures, Glynn Capital, and Nava Ventures to enhance its mission-critical AI capabilities for defense and enterprise sectors.\n\n## Leadership Team\n\n- **Ben Van Roo**: CEO & Co-Founder, with a background in national security and data science.\n- **Jason Schnitzer**: CTO & Co-Founder, experienced in production engineering and platform development.\n- **Guruprasad Raghavan**: Lead Research Scientist & Co-Founder, specializing in algorithms and strategies for AI.\n\n## Services and Products\n\nYurts offers a range of services and products designed to enhance enterprise operations:\n\n- **AI Assistants**: Context-rich AI assistants that integrate seamlessly with existing applications and data sources.\n  \n- **Yurts Platform**: A secure, adaptable platform featuring:\n  \n  - Secure deployment and real-time monitoring\n  - Context-aware search capabilities\n  - Integration with legacy applications\n  - Stringent access controls for data security\n\n- **Enterprise Solutions**: \n  - **Search**: Query multiple applications to break down data silos.\n  - **Chat**: Natural language processing to refine queries.\n  - **Report Generation**: Create personalized reports using proprietary data.\n  - **Embedded Assistant**: Deploy AI within enterprise applications for a consistent experience.\n\n## Customers\n\nYurts serves a diverse clientele, including Fortune companies and government agencies, particularly within the Department of Defense. The platform is designed to meet stringent security standards, making it suitable for classified use cases.\n\n## Company Culture\n\nYurts promotes a vibrant and collaborative work environment, emphasizing:\n\n- Continuous learning and discovery\n- Autonomy and empowerment for employees\n- A supportive atmosphere where colleagues are friends\n- Commitment to employee well-being and work-life balance\n\n## Security and Privacy\n\nYurts prioritizes security and privacy, with credentials from the Departments of Defense and Energy. The platform includes enhanced privacy features that allow users to control data visibility and access.\n\n## Conclusion\n\nYurts is redefining how enterprises harness AI to maximize productivity and performance, focusing on secure, scalable solutions that integrate seamlessly into existing workflows. The company is committed to innovation and excellence in the field of enterprise AI.\n\nFor more information, visit [Yurts AI](https://www.yurts.ai/).",
    "page_markdowns": [
      "# [AI That Knows Your Enterprise by Mark Allen https:, yurts.ai, mark-allen, Ben Van Roo https:, ben-van-roo](https://www.yurts.ai/)\nAI Assistant\n\nContext-rich AI assistants in the apps you use everyday\n\nSeamlessly integrate AI assistants with your trusted data sources and embed within your applications for a consistent, intuitive experience across teams and customer experiences.\n\nYurts Platform\n\nBuilt for Success, Customized For You\n\nFeatures like secure deployment, real-time monitoring, context-aware search, integrations with legacy applications, and stringent access controls make up a platform designed to be efficient, trustworthy, and secure for enterprise and government use.\n\nSecurity and Privacy\n\nYour Data Deserves Mission Critical Security\n\nWith credentials from the departments of defense and energy, Yurts takes security seriously. Enhanced privacy features put you in charge of who sees what, when, where, and how.",
      "# [Yurts Enterprise AI](https://www.yurts.ai/archive)\nWhen you visit or interact with our sites, services or tools, we or our authorized service providers may use cookies for storing information to help provide you with a better, faster and safer experience and for marketing purposes.",
      "# [Generative AI for Government](https://www.yurts.ai/government)\nRELIABLE AND SECURE\n\nYurts is proud to deploy its transformative GenAI platform across the DoD, with production-ready deployments on Game Warden's ATO. Yurts recently received \"Awardable\" status in the Tradewinds Solutions Marketplace, ensuring fast and seamless integrations for government agencies.\n\n“Yurts’ expertise in deploying solutions for classified use cases accelerates adoption of this transformative technology across our customers while adhering to their stringent security standards.”\n\nMatt Teschke\n\nCTO of RedHorse",
      "# [Yurts Enterprise AI](https://www.yurts.ai/about)\nbridging ai and fortune companies\n\nYurts serves as a bridge for Fortune companies aiming to integrate AI, enhancing their security and privacy measures. Its unique value is in addressing AI challenges, such as secure connections across systems, that have hindered its adoption in the global workforce.\n\nConnecting any system enhancing adoption\n\nYurts fosters broad adoption by connecting with any system, transforming knowledge bases into searchable repositories, and upholding high security standards. Its evolving models allow customization to optimize cost, privacy, and performance.\n\nFounded in 2022, Yurts is an enterprise-ready GenAI platform on a mission to deliver secure and scalable GenAI solutions that transform mission-critical systems. Co-founded by Ben Van Roo, Jason Schnitzer, and Guruprasad Raghavan, the company emerged from a strategic partnership with the Department of Defense to create a secure and private platform tailored for mission-critical environments.\n\nBy transforming knowledge management and enterprise workflows at scale, Yurts empowers organizations to achieve unmatched efficiency through integration across diverse applications and data stores. Yurts is redefining the way enterprises harness the power of AI to maximize productivity and performance.\n\nYurts raises $40M in Series B! On a mission for secure, scalable GenAI to transform mission-critical systems. Read more about the announcement here.\n\nBen Van Roo\n\nCEO & Founder\n\nBen is the CEO/Co-Founder of Yurts. Ben served as the EVP of National Security at Primer AI, VP of Data Science at Chegg, and was a Researcher at RAND working with the DOD. Ben has spent his career building technology companies serving the Public and the Private sector.\n\nJason Schnitzer\n\nCTO & Founder\n\nAs CTO at Yurts, Jason supports the tech org. His journey includes roles in Production Engineering at Meta, VP on Infra at Looker, and CTO at Chegg. Throughout his career, Jason's passion has remained constant: building platforms, products, and teams.\n\nGuruprasad Raghavan\n\nLead Research Scientist & Founder\n\nGuru pursues a mix of pure & applied research to develop algorithms and strategies that power Yurts' platform. He derives most of his inspiration from the workings of the human brain and dreams to have Yurts's platform as adaptable, reliable and self-healing as the biological brain! He has his PhD from Caltech in Computational neuroscience.\n\nAre you ready to transform the way work gets done? Join a forward-thinking team where colleagues are friends, and our customers are our biggest advocates. Together, let's build the future by integrating AI into everyday tools, data, and workflows to simplify work processes.\n\nCheck it out",
      "# [Yurts Enterprise AI by Mark Allen https:, yurts.ai, mark-allen, Ben Van Roo https:, ben-van-roo](https://www.yurts.ai/products)\nMission Critical GenAI At Scale\n\nTransform knowledge management and mission critical workflows at scale through a highly adaptable, secure, Gen AI platform.\n\nRequest Demo\n\nSearch\n\nQuery multiple applications at once\n\nBreak down data silos to harness the knowledge within your documents, apps, and daily operations.\n\nLearn More\n\nChat\n\nRefine queries with natural language\n\nDig deeper into data sources. Ask questions via Chat to refine searches.\n\nWrite\n\nGenerate reports using the best data available\n\nCreate personalized, context-rich reports and summaries using your own proprietary data.\n\nEMBEDDED ASSISTANT\n\nDeploy AI where you need it most\n\nEmbed your assistant into your favorite enterprise apps, giving you a consistent AI experience everywhere you go.\n\nLearn More\n\nENTERPRISE SEARCH\n\nMake decisions with confidence\n\nYurts leverages proprietary Retrieval Augmented Generation (RAG) models to ensure our platform serves your the most relevant and recent enterprise data.\n\nLearn More",
      "# [The Bridge to Enterprise AI by yurts.ai, ben-van-roo, maddie-wolf, guruprasad-raghavan-phd, mark-allen, Kartik Gupta https:, kartik-gupta](https://www.yurts.ai/blog)\nFueling the Future of Mission-Critical AI: Announcing Yurts' $40M Series B\n\n2024-12-02\n\nYurts raises $40M Series B led by XYZ Ventures, Glynn Capital, and Nava Ventures. This funding boosts our mission-critical AI for defense and enterprise sectors, achieving reliable, impactful real-world deployments.\n\nBen Van Roo\n\nhttps://yurts.ai/team/\n\nben-van-roo\n\nhttps://yurts.ai/team/\n\nHow Yurts Enterprise AI Can Boost Your Sales Performance: 4 Key Ways\n\nMaddie Wolf\n\nhttps://yurts.ai/team/\n\nmaddie-wolf\n\nhttps://yurts.ai/team/\n\n2023-12-20\n\nYou Are More Than a Prompt, and Your Company Needs More Than a LLM\n\nBen Van Roo\n\nhttps://yurts.ai/team/\n\nben-van-roo\n\nhttps://yurts.ai/team/\n\n2023-09-18\n\nNavigating the Challenges of Fine Tuning and Catastrophic Forgetting\n\nGuruprasad Raghavan\n\nhttps://yurts.ai/team/\n\nguruprasad-raghavan-phd\n\nhttps://yurts.ai/team/\n\n2024-03-24\n\nWhy Yurts? Flexible, Secure, and Innovative AI Solution\n\nDiscover why Yurts embraces flexibility, security, and innovation in AI. Learn how it integrates seamlessly with existing systems, enhancing workflows without costly overhauls, and fostering collaboration.\n\n2024-11-22\n\nBen Van Roo\n\nhttps://yurts.ai/team/\n\nben-van-roo\n\nhttps://yurts.ai/team/",
      "# [Current Job Openings](https://www.yurts.ai/careers)\nI've lost five pounds and gained the respect of my family since joining! Not a joke! Yurts has enabled me to take ownership of and work on engineering problems that are genuinely interesting to explain to others (who isn't fascinated by at least one modern AI app?) while allowing me the time and flexibility to take care of my family and myself. Not easy to find at a tech company, but much appreciated!\n\nWorking at Yurts means being surrounded by highly skilled and friendly people. The environment here is one of continuous learning and discovery, with excellent autonomy for those who seek challenges and growth. People here are fantastic, the space is full of technical challenges that are so rewarding to solve with this team, and lil yurty is the best company mascot!\n\nYurts is an exceptional company that blends a vibrant, creative, and busy environment with a commitment to autonomy and employee well-being. With outstanding leadership, Yurts fosters a culture of hard work and dedication, yet remains considerate and kind to its team members. It's a place where people are empowered to work independently while enjoying a fun, collaborative atmosphere.\n\nI love working at Yurts because it provides me the opportunity to see an organization's processes improve with our technology. There is nothing like helping someone realize that there is a solution to speed up their critical workflows, help them to be more accurate, and ultimately allow them to do less of what they hate and more of what they love about their job!",
      "# [Generative AI for Enterprise](https://www.yurts.ai/enterprise)\nSTREAMLINE ENTERPRISE OPERATIONS\n\nYurts delivers intelligent AI solutions that enable seamless efficiency and optimize customer experiences in large-scale enterprises. We empower any team across any industry with a unified, comprehensive AI platform for smarter, faster operations.",
      "# [Yurts Enterprise AI by Mark Allen https:, yurts.ai, mark-allen, Ben Van Roo https:, ben-van-roo](https://www.yurts.ai/pricing)\n“\n\nWorking with Yurts is a win-win knowing that they have a full stack platform that scales to 1000s of users and runs in the most secure environments.\n\nMatt Teschke, CTO Redhorse",
      "# [Yurts Enterprise AI by Mark Allen https:, yurts.ai, mark-allen, Ben Van Roo https:, ben-van-roo](https://www.yurts.ai/platform)\n“Yurts’ expertise in deploying solutions for classified use cases accelerates adoption of this transformative technology across our customers while adhering to their stringent security standards.”\n\nMatt Teschke\n\nCEO of Redhorse\n\ninnovate and scale at the pace of ai\n\nEnsure your AI models remain up-to-date and cost-efficient, maintaining peak performance aligned with evolving business and tech changes. Flexibility and control so AI works for you.\n\nmonitor and adapt in real-time\n\nBalance costs, control usage. Gain insights into generative AI usage, capacity, and latency by tracking key metrics to optimize results.\n\n‍\n\nIdentify trends to enhance efficiency and adapt to technological changes.\n\nintegrations and embedded experiences\n\nSeamlessly integrate and leverage AI insights across various platforms and legacy applications—ensuring a cohesive and efficient workflow.\n\n‍\n\nEmbed wherever your people work and tailor the user experience.\n\nsecurity and access control\n\nSafeguard sensitive data through stringent and granular access controls, deploy in your datacenter, your VPC (Virtual Private Cloud), and across various public clouds.\n\nLearn More",
      "# [Explore product videos and demos](https://www.yurts.ai/video)\nWhen you visit or interact with our sites, services or tools, we or our authorized service providers may use cookies for storing information to help provide you with a better, faster and safer experience and for marketing purposes."
    ],
    "search_results": [
      {
        "title": "AI That Knows Your Enterprise | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/",
        "snippet": "Yurts Enterprise AI connects you to your data. Unlock efficiency and automation with secure, context-aware AI—embedded directly into your work environment.",
        "formattedUrl": "https://www.yurts.ai/"
      },
      {
        "title": "Blog Archive | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/archive",
        "snippet": "Yurts Build-a-Bot: Your Powerful Enterprise AI Platform Simplified ... Explore Yurts Build-a-Bot—your one-stop tool for building seamless AI applications without ...",
        "formattedUrl": "https://www.yurts.ai/archive"
      },
      {
        "title": "Generative AI for Government | Yurts enterprise AI",
        "link": "https://www.yurts.ai/government",
        "snippet": "Yurts amplifies your unit's productivity by automating repetitive documentation, enabling soldiers to be fully committed to mission success.",
        "formattedUrl": "https://www.yurts.ai/government"
      },
      {
        "title": "About | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/about",
        "snippet": "Yurts is on a mission, to connect people to their best work. An AI-powered platform where the everyday worker becomes the architect of their productivity.",
        "formattedUrl": "https://www.yurts.ai/about"
      },
      {
        "title": "Products | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/products",
        "snippet": "Discover Yurts Enterprise AI. Enhance efficiency and decision-making with secure AI platforms, assistants, search, chat, and analytics tools.",
        "formattedUrl": "https://www.yurts.ai/products"
      },
      {
        "title": "The Bridge to Enterprise AI | Blog | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/blog",
        "snippet": "Why Yurts? Flexible, Secure, and Innovative AI Solution. Discover why Yurts embraces flexibility, security, and innovation in AI. Learn how it integrates ...",
        "formattedUrl": "https://www.yurts.ai/blog"
      },
      {
        "title": "Careers at Yurts | Current Job Openings",
        "link": "https://www.yurts.ai/careers",
        "snippet": "Join The Yurts Team. Be a part of the team that is bridging the gap between AI and real-world problems. We have a mission-focused culture, remote work, ...",
        "formattedUrl": "https://www.yurts.ai/careers"
      },
      {
        "title": "Generative AI for Enterprise | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/enterprise",
        "snippet": "Yurts delivers intelligent AI solutions that enable seamless efficiency and optimize customer experiences in large-scale enterprises. We empower any team across ...",
        "formattedUrl": "https://www.yurts.ai/enterprise"
      },
      {
        "title": "Pricing | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/pricing",
        "snippet": "Scalable costs combining a flat platform fee and per-user charges, with optimized resource usage and custom quotations.",
        "formattedUrl": "https://www.yurts.ai/pricing"
      },
      {
        "title": "Platform Overview | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/platform",
        "snippet": "Yurts' expertise in deploying solutions for classified use cases accelerates adoption of this transformative technology across our customers.",
        "formattedUrl": "https://www.yurts.ai/platform"
      },
      {
        "title": "Explore product videos and demos | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/video",
        "snippet": "Yurts, a powerful generative AI solution, securely connects across systems, fostering enterprise adoption. It integrates with company data, making knowledge ...",
        "formattedUrl": "https://www.yurts.ai/video"
      },
      {
        "title": "Generative AI for Manufacturing | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/manufacturing",
        "snippet": "Discover Yurts for manufacturing. Enhance automation, improve maintenance, streamline support, and boost R&D with secure, collaborative GenAI solutions.",
        "formattedUrl": "https://www.yurts.ai/manufacturing"
      },
      {
        "title": "Generative AI for Aerospace | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/aerospace",
        "snippet": "Enhance Aerospace with Yurts: Automate workflows, speed up decisions, drive R&D, and unify data for seamless, efficient, and innovative aerospace projects.",
        "formattedUrl": "https://www.yurts.ai/aerospace"
      },
      {
        "title": "Request a Demo | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/contact",
        "snippet": "Contact us for a demo to find out how Yurts AI automates Enterprise workflow.",
        "formattedUrl": "https://www.yurts.ai/contact"
      },
      {
        "title": "AI Assistant | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/ai-assistant",
        "snippet": "Yurts AI Assistant: Enhance productivity with seamless integration. Embed in apps for intuitive use. Optimize reporting and elevate customer interactions.",
        "formattedUrl": "https://www.yurts.ai/ai-assistant"
      },
      {
        "title": "Privacy Policy 2024 | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/privacy-policy",
        "snippet": "Sep 27, 2024 ... This Privacy Policy describes how Yurts Technologies, Inc. (Yurts, “we\", “us” or \"our\") processes personal information that we collect through our digital ...",
        "formattedUrl": "https://www.yurts.ai/privacy-policy"
      },
      {
        "title": "Government Defense | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/government-defense",
        "snippet": "Yurts offers a scalable GenAI platform for government defense, boosting mission-critical deployment, operational decision, & intelligent military analytics.",
        "formattedUrl": "https://www.yurts.ai/government-defense"
      },
      {
        "title": "Yurts Newsroom | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/press-release",
        "snippet": "Yurts Secures $40M In Series B Funding To Accelerate Growth for Mission-Critical Defense, Government, and Enterprise Systems. The funding round, led by XYZ ...",
        "formattedUrl": "https://www.yurts.ai/press-release"
      },
      {
        "title": "Government Civilian | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/government-civilian",
        "snippet": "By leveraging Yurts to identify and address challenges proactively, agencies can preempt service disruptions in their mission-critical tasks.",
        "formattedUrl": "https://www.yurts.ai/government-civilian"
      },
      {
        "title": "Yurts | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/yurts",
        "snippet": "Yurts is the go-to solution for Fortune companies to safely navigate and implement enterprise AI, streamline complex tasks, and boost business efficiency.",
        "formattedUrl": "https://www.yurts.ai/team/yurts"
      },
      {
        "title": "Why Yurts? | Flexible, Secure, & Innovative AI Solutions",
        "link": "https://www.yurts.ai/blog/why-yurts",
        "snippet": "Dec 23, 2024 ... Flexibility: Adapt to your unique needs with an LLM-agnostic platform and deployment options; Security: Ensure data protection with enterprise- ...",
        "formattedUrl": "https://www.yurts.ai/blog/why-yurts"
      },
      {
        "title": "Generative AI for Supply Chain | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/supply-chain-management",
        "snippet": "Enhance supply chain efficiency with Yurts. Get custom recommendations, automated workflows, and improved support. Streamline your supply chain with GenAI.",
        "formattedUrl": "https://www.yurts.ai/supply-chain-management"
      },
      {
        "title": "Mark Allen | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/mark-allen",
        "snippet": "Mark Allen, Head of Solutions and Analytics launches the Yurts product in the commercial space.",
        "formattedUrl": "https://www.yurts.ai/team/mark-allen"
      },
      {
        "title": "Security and Privacy | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/security-and-privacy",
        "snippet": "Yurts: Secure AI Solutions - Prioritizing stringent security, trusted by Defense & Energy Departments. Discover our enterprise-level security commitments.",
        "formattedUrl": "https://www.yurts.ai/security-and-privacy"
      },
      {
        "title": "Maddie Wolf | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/maddie-wolf",
        "snippet": "Meet Yurts blog contributor Maddie leads operations at Yurts. She knows that “operations” can mean pretty much anything.",
        "formattedUrl": "https://www.yurts.ai/team/maddie-wolf"
      },
      {
        "title": "Mike Tong | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/mike-tong",
        "snippet": "Mike Tong, Sr. ML Engineer - Federal Mike Tong, Sr. Applied ML Engineer at Yurts. Innovator in AI and pet care. Dedicated to solving real-world problems ...",
        "formattedUrl": "https://www.yurts.ai/team/mike-tong"
      },
      {
        "title": "Jessica Agarwal | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/jessica-agarwal",
        "snippet": "Jessica Agarwal, VP of Marketing passionate about building human-centric experiences. .",
        "formattedUrl": "https://www.yurts.ai/team/jessica-agarwal"
      },
      {
        "title": "Chris Jung | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/chris-jung",
        "snippet": "Chris Jung, Chief of Staff runs internal business operations at Yurts..",
        "formattedUrl": "https://www.yurts.ai/team/chris-jung"
      },
      {
        "title": "Mike Mascari | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/mike-mascari",
        "snippet": "Mike Mascari, Sr. Customer Success Manager, Federal former Intelligence, Surveillance, & Reconnaissance (ISR) aircraft operator working with USSOCOM, ...",
        "formattedUrl": "https://www.yurts.ai/team/mike-mascari"
      },
      {
        "title": "Jason Schnitzer | Author | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/team/jason-schnitzer",
        "snippet": "Jason Schnitzer, CTO and Founder leading teams through tech transformations & key software projects..",
        "formattedUrl": "https://www.yurts.ai/team/jason-schnitzer"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Yurts (@yurtsai) / X](https://x.com/yurtsai?lang=en)\n\n# Job boards\n- [Engineering Manager, Applied Machine Learning - Yurts | Built In](https://builtin.com/job/engineering-manager-applied-machine-learning/3755288) (Jan 9, 2025)\n- [Head of Federal Sales - Yurts | Built In](https://builtin.com/job/head-federal-sales/3643919) \n\n# App stores\n- [AWS Marketplace: Yurts AI](https://aws.amazon.com/marketplace/seller-profile?id=seller-arsg6hmpabjvo)\n\n# Product reviews\n- No detailed product reviews found in the search results.\n\n# News articles (most recent first, grouped by event)\n### Funding and Partnerships\n- [Yurts Secures $40 Million to Revolutionize AI for the Department of ...](https://nextunicorn.ventures/yurts-secures-40-million-to-revolutionize-ai-for-the-department-of-defense/) (Dec 4, 2024)\n- [Yurts Secures $16M Contract with SOCOM to Integrate Large ...](https://www.prnewswire.com/news-releases/yurts-secures-16m-contract-with-socom-to-integrate-large-language-models-in-defense-enterprises-302007065.html) (Dec 6, 2023)\n- [Yurts Secures $40M In Series B Funding To Accelerate Growth for ...](https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html) (Dec 3, 2024)\n- [Redhorse announces strategic partnership with Yurts AI to deploy ...](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/) (Feb 21, 2024)\n- [Oracle and Yurts Collaborate to Bring Secure Generative AI ...](https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html) (Oct 23, 2024)\n\n### General News\n- [NVIDIA's Anthony Robbins Secures 7th Wash100 Award for ...](https://executivebiz.com/2024/02/nvidias-anthony-robbins-secures-7th-wash100-award-for-continuing-efforts-to-promote-ai-in-government/) (Feb 7, 2024)\n- [Chegg Embraced AI. ChatGPT Ate Its Lunch Anyway | WIRED](https://www.wired.com/story/chegg-embraced-ai-chatgpt-ate-its-lunch-anyway/) (Jun 5, 2023)\n\n# Key employees (grouped by employee)\n### Ben Van Roo\n- [You Have Nothing to Fear (From AI) – But Fear Itself – A Risk ...](https://insnerds.com/insights/you-have-nothing-to-fear-from-ai-but-fear-itself-a-risk-robots-podcast-conversation-with-ben-van-roo-ceo-of-yurts-ai) (Nov 12, 2023)\n- [GPT-4 is the Death Star - by Ben Van Roo](https://benvanroo.substack.com/p/gpt-4-is-the-death-star) (Jan 30, 2023)\n\n### Guruprasad Raghavan\n- [Exploring the Mind-Brain interface | Conscious Living](https://consciousliving.sites.stanford.edu/news/exploring-mind-brain-interface) (Apr 28, 2023)\n\n### Jason Schnitzer\n- [Unveiling the Future: AI Collaboration Takes Flight: Startup Connect ...](https://www.startupmontereybay.com/unveiling-the-future-ai-collaboration-takes-flight-startup-connect-meeting-recap/) (Jun 19, 2024)\n\n### Other Employees\n- [Chris Jung | Author | Yurts Enterprise AI](https://www.yurts.ai/team/chris-jung)\n- [Jessica Agarwal | Author | Yurts Enterprise AI](https://www.yurts.ai/team/jessica-agarwal)\n- [Maddie Wolf | Author | Yurts Enterprise AI](https://www.yurts.ai/team/maddie-wolf)\n- [Mark Allen | Author | Yurts Enterprise AI](https://www.yurts.ai/team/mark-allen)\n- [Mike Mascari | Author | Yurts Enterprise AI](https://www.yurts.ai/team/mike-mascari)\n- [Mike Tong | Author | Yurts Enterprise AI](https://www.yurts.ai/team/mike-tong)\n\n# Other pages on the company website\n- [About | Yurts Enterprise AI](https://www.yurts.ai/about)\n- [Yurts Newsroom | Yurts Enterprise AI](https://www.yurts.ai/press-release)\n- [Generative AI for Aerospace | Yurts Enterprise AI](https://www.yurts.ai/aerospace)\n- [Generative AI for Government | Yurts enterprise AI](https://www.yurts.ai/government)\n- [Generative AI for Manufacturing | Yurts Enterprise AI](https://www.yurts.ai/manufacturing)\n\n# Other\n- [Yurts Company Overview, Contact Details & Competitors | LeadIQ](https://leadiq.com/c/yurts/63617f9bd4454f2aa396b5ff) (Dec 3, 2024)\n- [Yurts Technologies - Crunchbase Company Profile & Funding](https://www.crunchbase.com/organization/yurts-technologies-inc) (Dec 3, 2024)\n- [Yurts AI Teams With Lambda to Build an Air-Gapped Large ...](https://www.prnewswire.com/news-releases/yurts-ai-teams-with-lambda-to-build-an-air-gapped-large-language-model-llm-solution-for-enterprise-301817798.html) (May 8, 2023)",
  "crunchbase_markdown": null,
  "customer_experience_result": {
    "output_text": "# Positive Aspects of Yurts.ai\n\n- \"What’s attractive about this service is the access to tons of models, the pre canned prompts and plug ins, and easy data model management.\" [(leightjhou, Reddit, 2024-09-27)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/)\n- \"Yurts AI. IL-2 through IL-6, lots of users in the DOD. Can run on any cloud and bare metal, lots of different models, plug-ins, etc.\" [(Material_Reporter_27, Reddit, 2024-11-21)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/ly8p64m/)",
    "intermediate_steps": [
      "- \"What’s attractive about this service is the access to tons of models, the pre canned prompts and plug ins, and easy data model management.\" [(leightjhou, Reddit, 2024-09-27)](cache://reddit/1)\n- \"Yurts AI. IL-2 through IL-6, lots of users in the DOD. Can run on any cloud and bare metal, lots of different models, plug-ins, etc.\" [(Material_Reporter_27, Reddit, 2024-11-21)](cache://reddit/2)",
      "```markdown\n```\n"
    ],
    "url_to_review": {},
    "review_markdowns": [
      "# Post ID 1fqyzfl: Ask Sage alternatives? with +1 score by [(leightjhou, Reddit, 2024-09-27)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/)\nI’m looking for any Ask Sage alternatives I should look at. What’s attractive about this service is the access to tons of models, the pre canned prompts and plug ins, and easy data model management. We don’t have a big dev team so something like this would get us off the ground faster. Any suggestions?\n\n\n## Comment ID ly8p64m with +2 score by [(Material_Reporter_27, Reddit, 2024-11-21)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/ly8p64m/) (in reply to ID 1fqyzfl):\nYurts AI.  IL-2 through IL-6, lots of users in the DOD. Can run on any cloud and bare metal, lots of different models, plug-ins, etc.\n\n## Comment ID lp93aqg with +1 score by [(None, Reddit, 2024-09-27)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/lp93aqg/) (in reply to ID 1fqyzfl):\n[deleted]\n\n### Comment ID lp93vwd with +1 score by [(leightjhou, Reddit, 2024-09-27)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/lp93vwd/) (in reply to ID lp93aqg):\nNothing specific yet. I’m just curious if there are alternatives to look at before I go down the rabbit hole with sage\n\n## Comment ID lq23bqa with +1 score by [(leightjhou, Reddit, 2024-10-02)](https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/lq23bqa/) (in reply to ID 1fqyzfl):\nBump",
      "# Post ID 1fs4ta3: Best LLM for quick on prem/hybrid RAG in regulated industry  with +7 score by [(None, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/)\n[deleted]\n\n## Comment ID lphqwhc with +2 score by [(e278e, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphqwhc/) (in reply to ID 1fs4ta3):\nWhat business uses/ solutions are you attempting to solve?  \n\n1. Chat with machinery manuals or medical records?  I need more information of the data please.\n2.  Can you give me a few examples of questions people may ask?\n\nData sources?\n\n### Comment ID lphtdt5 with +1 score by [(Informal-Fondant-855, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphtdt5/) (in reply to ID lphqwhc):\nYes. Chat with unstructured and structured docs, and find them based on keyword\n\n#### Comment ID lpjop6p with +2 score by [(Able-Tip240, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lpjop6p/) (in reply to ID lphtdt5):\nMistral and Llama3 I've had good luck with.\n\n#### Comment ID lpjuwd2 with +1 score by [(e278e, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lpjuwd2/) (in reply to ID lphtdt5):\nIf you want to just vectorize all the documents and pray for the best then that's simple, and you will rely on just similarity search.  Generally chunking is what causes the most information because it breaks the flow of everything. \n\nDepending on the source, I like to clean the data as much as possible. and extract the important stuff.  Or break it down by sections and topics, so those chunks are closer together.  I store the important topics and questions into json to create a library of information about everything.  Then if you want to go a step further and specialized knowledge is important.  then a graph representation usually helps (graph rag)\n\nAt the core, it is about language compression and ideas.  A one sentence with zero information does not help me if you are asking for guidance.\n\n## Comment ID lphv6mv with +1 score by [(passing_marks, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphv6mv/) (in reply to ID 1fs4ta3):\nFastest way might be to go ahead with Co-pilot studio or maybe setup Logic Apps, you have enough control and can make some iterations and improvements while still being a bit flexible.\nAlthough you might have something ready as a PoC, a week time is too little to have something that works well for structured and unstructured data.\n\n### Comment ID lphvzw2 with +1 score by [(Informal-Fondant-855, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphvzw2/) (in reply to ID lphv6mv):\nSo Co-Pilot studio looped in to azure/LogicApps? Interesting. What if I need to have permission controls on folder locks that are individualized for users?\n\n#### Comment ID lphwetb with +1 score by [(passing_marks, Reddit, 2024-09-29)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lphwetb/) (in reply to ID lphvzw2):\nSorry I meant either of them, not co-pilot studio in logic apps.\nThere are AI connectors and examples on LogicApps to do RAG by MS, you can check out them to see if it fits your short to medium term plans.\n\n## Comment ID lq4ulh5 with +1 score by [(Jdonavan, Reddit, 2024-10-03)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lq4ulh5/) (in reply to ID 1fs4ta3):\nUse GPT via Azure Open AI services and be done with it.  Easy Peasy.  \n\nFor a vector DB, Weaviate has on-prem installations and is quite good.\n\n### Comment ID lq57mgm with +1 score by [(Informal-Fondant-855, Reddit, 2024-10-03)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lq57mgm/) (in reply to ID lq4ulh5):\nNo file indexing? Seems costly if 500 users are searching across the sea of millions of docs?\n\n#### Comment ID lq5arfz with +1 score by [(Jdonavan, Reddit, 2024-10-03)](https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/lq5arfz/) (in reply to ID lq57mgm):\n???  I’m not sure I follow.  Do you understand how RAG is implemented?",
      "# Post ID 1hzxy26: Whoever this person is I agree with them with +8608 score by [(Enough_Shoulder_8938, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/)\n\n\n## Comment ID m6tm40q with +275 score by [(SchrodingersEgg, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tm40q/) (in reply to ID 1hzxy26):\nI applied to a job back in late March, didn’t get a notice of rejection until last week. Ghosting is rude but at least I’m used to it, but I can’t for the life of me figure out why it took nearly a year for them to get back to me on this\n\n### Comment ID m6tulug with +72 score by [(Long-Photograph49, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tulug/) (in reply to ID m6tm40q):\nAt a guess, they were either struggling to fill it so left it open in their HRIS system or canceled the position but forgot to close the requisition.  With either of those, if they didn't move candidates to the correct status to send the rejection email, nothing would have happened until they moved the requisition to either filled or closed/canceled, at which point anyone not in the hired or selected status would have received the automated rejection email.\n\n#### Comment ID m6tzx6j with +82 score by [(freerangetacos, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tzx6j/) (in reply to ID m6tulug):\nIn other words: incompetence.\n\n#### Comment ID m6w1pbv with +7 score by [(Effective_Will_1801, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6w1pbv/) (in reply to ID m6tulug):\n>at which point anyone not in the hired or selected status would have received the automated rejection email.\n\nGiven this is handled automatically it's bizarre that so many people get ghosted. Perhaps it is because they aren't real jobs so are never filled or canceled.\n\n### Comment ID m6u484q with +24 score by [(youareceo, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6u484q/) (in reply to ID m6tm40q):\nDon't you love it when the computer closing the file cares more about you than the humans? ffs\n\n### Comment ID m6vq9g7 with +6 score by [(None, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vq9g7/) (in reply to ID m6tm40q):\n[removed]\n\n#### Comment ID m6yw6yu with +6 score by [(hearingxcolors, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6yw6yu/) (in reply to ID m6vq9g7):\nOoh, I didn't know that website existed. Thanks for sharing! Hope it blows up and more people post their experiences being ghosted by prospective employees. \n\nPerhaps if the website gets big enough, companies will be more inclined to actually follow-up with a simple fucking *\"We regret to inform you that you were not selected for the role, but we wish you the best in all your future endeavors.\"* Literally would take 3 minutes of one person's time if they used a bot to blast that email out to everyone that submitted an application that wasn't hired, and it's the least they could do.\n\n#### Comment ID m6vrfuz with +3 score by [(No_Parsnip_2406, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vrfuz/) (in reply to ID m6vq9g7):\nDone\n\n### Comment ID m6wny27 with +2 score by [(rx-pulse, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6wny27/) (in reply to ID m6tm40q):\nManagement shakeup may have happened. Not defending it, but have seen it happen at my own place. Usually some hotshot C level with more ego than brains has some grand idea, enough influence, and for one reason or another, decides to do a hiring freeze in the middle of the job posting. A bunch of time is spent trying to figure out what is needed to execute his idea and after finally going through it, eliminate/resume job postings where they left off.\n\n## Comment ID m6thgrl with +731 score by [(Zro6, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6thgrl/) (in reply to ID 1hzxy26):\nSame companies will cry and whine when you don't give them 2+ weeks' notice and say you're hurting the company\n\n### Comment ID m6tz99u with +226 score by [(Schneefs, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tz99u/) (in reply to ID m6thgrl):\nYou are forgetting that their time is more valuable than yours.  \n/s\n\n### Comment ID m6u1v7a with +79 score by [(CRM_CANNABIS_GUY, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6u1v7a/) (in reply to ID m6thgrl):\nIt’s not about you the “employee” it’s about them the business. Working for a large company is one step away from a form of slavery. Trading your “lifetime” for money. All you need to survive is dependent upon them allowing you to work there. They fire you with no severance and you got SHIT 💩 absolutely nothing!\n\n#### Comment ID m6vveyq with +26 score by [(WanderingBraincell, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vveyq/) (in reply to ID m6u1v7a):\nI'm (hopefully) subtly letting the casuals know that the quicker they work the less money they get as we send people home if there's not enough work. so if they need the cash, chill tf out and take it easy. if they want the arvo off, go ham.\n\n### Comment ID m6yzwej with +11 score by [(Careless_Money7027, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6yzwej/) (in reply to ID m6thgrl):\nThe company I work for tried their hardest to convince me during orientation/ on boarding that it would be in my best interest to sign away a federally protected labor right... for the needs of the business.\n\nETA: this is Costco\n\n### Comment ID m6ykbbj with +16 score by [(Ok-Condition8011, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6ykbbj/) (in reply to ID m6thgrl):\nThere is no law on the books requiring you to give two weeks.  If they have really mistreated you you can say “For the next two weeks you’ll notice I’m not here”\n\n#### Comment ID m71ciqp with +3 score by [(Ele_Of_Light, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m71ciqp/) (in reply to ID m6ykbbj):\nIt's a silent but loud rule... they will screw you if you don't cater to them by saying it's me it's not you... \"my twist on the sad joke\" but if you don't bend over they will screw you but if you do the same they will screw you. If you don't give 2 weeks your gone... they will and yes its real.... blacklist you... I gave a 1 week notice and I can't work there now. However they can fire you instantly with no notice... how is that fair.\n\n#### Comment ID m7240eu with +1 score by [(Fasting_Fashion, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m7240eu/) (in reply to ID m6ykbbj):\nBrilliant phrasing! I'm stealing that.\n\n## Comment ID m6tqu45 with +160 score by [(bunkscudda, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tqu45/) (in reply to ID 1hzxy26):\nI once applied for a job and made it through a couple rounds of cuts. Zoom interview and then two separate in person interviews (each taking about half a day). I was told i was one of three final candidates and i should hear from them soon on the decision. Nothing. I emailed a week later just to check in. Nothing. I emailed again another week later asking simply if the position had been filled. Nothing.\n\n**Eight months later** i get a email. Its the company offering me the job. They totally acted as if it had been a week since my last interview. “We’re happy to inform you that you have been chosen for the position, please contact *somedude* to assist in setting you up”\n\nI never replied. They sent two followup emails too and by the last one they seemed pretty upset i wasnt responding to them.\n\n### Comment ID m6trhcp with +114 score by [(chiobsidian, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6trhcp/) (in reply to ID m6tqu45):\nWait 8 months and then respond\n\n#### Comment ID m6trnk1 with +60 score by [(bunkscudda, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6trnk1/) (in reply to ID m6trhcp):\nShouldve thought of that. “Great, i can start tomorrow!”\n\n#### Comment ID m6wfa1k with +4 score by [(0pinions0pinions, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6wfa1k/) (in reply to ID m6trhcp):\n😭😭😭😭😭 classic\n\n### Comment ID m6u04m1 with +37 score by [(Puzzleheaded_Data829, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6u04m1/) (in reply to ID m6tqu45):\nCue the “but…but…but we invested all this time into you” tears from HR.\n\n#### Comment ID m6v8ckc with +13 score by [(theskysthelimit000, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6v8ckc/) (in reply to ID m6u04m1):\nThat's always what they think. I haven't heard or seen from HR since I've been hired 10 months ago.\n\n### Comment ID m6v97by with +25 score by [(Enough_Shoulder_8938, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6v97by/) (in reply to ID m6tqu45):\n8 months! That is insane. I’ve had a rejection email take 6 months, and even that I laughed at because it was so absurdly late\n\n### Comment ID m6vpg0b with +25 score by [(hollowgraham, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vpg0b/) (in reply to ID m6tqu45):\nThe candidate they hired didn't work out.\n\n#### Comment ID m78e1i0 with +2 score by [(Illustrious_Price_46, Reddit, 2025-01-15)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m78e1i0/) (in reply to ID m6vpg0b):\nThis\n\n## Comment ID m6u8kkm with +87 score by [(CalmPanic402, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6u8kkm/) (in reply to ID 1hzxy26):\nI applied, interviewed, didn't hear shit back for over a month.\n\nFinally they called back to give me the offer, but guess what, I already took another offer.  They still hit me up with \"well, if you weren't interested, you should have let us know.\"  No bitch, if you liked me as a candidate *you* should have let me know.  I was interested, until you dropped the ball.\n\n### Comment ID m6x05aq with +8 score by [(Jenn-H1989, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6x05aq/) (in reply to ID m6u8kkm):\nYou can’t be serious…is this the netherworld we’re living in right now??\n\n## Comment ID m6tu4xq with +61 score by [(Dragonfrog23, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tu4xq/) (in reply to ID 1hzxy26):\nThe most frustrating replies are those that come six months later and insist on immediate action\n\n## Comment ID m6tv6nh with +53 score by [(CasualPlantain, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tv6nh/) (in reply to ID 1hzxy26):\nDuring my job hunt I was so sick of the one-way professionalism. I could bend over backwards to do whatever a job asked of me on time, but of 15+ in-person applications, exactly one gave me a proper rejection instead of just going radio silent. It was just ridiculous.\n\n### Comment ID m6w653m with +21 score by [(None, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6w653m/) (in reply to ID m6tv6nh):\n[removed]\n\n#### Comment ID m723u8f with +3 score by [(Sparramusic, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m723u8f/) (in reply to ID m6w653m):\nInsanely good, you mean.  Of hundreds, probably thousands of applications at this point in my career, I could probably count on my fingers the ones who actually sent a rejection notice.\n\n\nAs much as I like the idea of holding companies accountable, I don't have the time or energy in the middle of a job search to report all the ones that ghost me at some point in the application process.\n\n## Comment ID m6tv0m7 with +35 score by [(kirator117, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tv0m7/) (in reply to ID 1hzxy26):\nI do an interview, they try to call me 7 months later, was in a flight and couldn't take the call. When I land, see a mail where they ask me if I can contact them because their interested in my profile to fulfil a job and are in a hurry.\n\nThis was almost 2 months ago. I'm just thinking if wait 7 months to do the call, or never do it\n\n### Comment ID m78e9zs with +2 score by [(Illustrious_Price_46, Reddit, 2025-01-15)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m78e9zs/) (in reply to ID m6tv0m7):\nNever is the best option, if they are reaching out months later then the person(s) they hired didn’t work out and you are next on the list.\n\n#### Comment ID m79djup with +1 score by [(kirator117, Reddit, 2025-01-15)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m79djup/) (in reply to ID m78e9zs):\nI just think the same\n\n## Comment ID m6u7b19 with +27 score by [(Bitchimightbe420, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6u7b19/) (in reply to ID 1hzxy26):\nI had one company fly me out and we had a delay I ended up not getting to do the first half of the interview from the flight delay, the interviewer gave me 5 minutes and I got an auto reply about a week after that I had been rejected, and my reply thanking them and asking them for feedback was met with silence.\n\nThey just tried to recruit me again. lol\n\n## Comment ID m6untvv with +16 score by [(SparkdaKirin, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6untvv/) (in reply to ID 1hzxy26):\nI showed up fifteen minutes early to an interview, told the guy at the front why I was there, sat nearby because it's a very small store and I'm in view of everything. Manager walks out, calls the guy who's interview is an hour after mine. I leave and not ten minutes later he's calling me frantically asking where I am\n\n### Comment ID m6v87u9 with +2 score by [(Enough_Shoulder_8938, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6v87u9/) (in reply to ID m6untvv):\nSorry to hear that\n\n## Comment ID m6uw9ux with +15 score by [(izzyscifi, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6uw9ux/) (in reply to ID 1hzxy26):\nIt took a company four months to get back to me about a position. I have moved 8 hours away from the city the job was in. Good job idiots\n\n### Comment ID m6v80tt with +17 score by [(Enough_Shoulder_8938, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6v80tt/) (in reply to ID m6uw9ux):\nI am particularly cranky about this issue because I’ve been applying to state jobs and they are notorious for taking ages to get a position filled, but even though I knew this going in, it still pisses me off when I submit a resume and SIX WEEKS later I get an email that they are forwarding my resume to the hiring manager, and now it’s been another 3 weeks since then and… crickets. 🖕🏼\n\n## Comment ID m6uci3p with +16 score by [(HanakusoDays, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6uci3p/) (in reply to ID 1hzxy26):\nHappened to me after 3 interviews including the CEO.   Radio silence. Damn shame, i woulda killed in that job.\n\n## Comment ID m6vi7xw with +13 score by [(ResurrectedWolf, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vi7xw/) (in reply to ID 1hzxy26):\nThe amount of applications I've filled out is over 1000. I lost count. The jobs range from retail to state and federal positions - some aligned with my degree and some did not. The amount of responses I received? Not even 20. I'm not exaggerating. That includes me reaching out if I hadn't heard anything from them on the date they claimed they would contact me. \n\nIt's so disheartening and disrespectful.\n\n## Comment ID m6tvg32 with +25 score by [(TrueAkagami, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tvg32/) (in reply to ID 1hzxy26):\nHad this happen before.  Knew someone at the company I was applying to.  I was more than qualified for it as I was currently doing the job for another org.  Went through the interview process and they seemed impressed.  The person I knew there thought I was getting it for sure.  Heard nothing after a week, called the hiring manager and HR and couldn't get in contact with them.  Left a couple voice messages.  Said even if it's a No, please call back.  Nothing.  I talked to the person I knew there and she was confused too.  They ended up hiring someone with no experience.  Eventually my contact there left, so dodges a bullet it seems.\n\n## Comment ID m6vewn9 with +10 score by [(Trinket_Crinkle, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vewn9/) (in reply to ID 1hzxy26):\nI was complaining about the amount of ghosting throughout the entire process of trying to find a new job and she told me that she read something that companies get tax breaks when they're hiring so they will constantly have \"job openings\" but never contact you.\n\n## Comment ID m6thjpt with +34 score by [(jeffcgroves, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6thjpt/) (in reply to ID 1hzxy26):\nAgreed. I'm almost wondering if you could pass a law saying that, if they don't send you a rejection letter in a reasonable amount of time, they have to start paying you the salary for the job you applied to until they do. Ghosting could be considered a breach of promise\n\n### Comment ID m6u2gqh with +12 score by [(DazB1ane, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6u2gqh/) (in reply to ID m6thjpt):\nThat only applies if they’ve been promised the job and permanently altered an aspect of their life due to that promise\n\n#### Comment ID m6u410m with +5 score by [(jeffcgroves, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6u410m/) (in reply to ID m6u2gqh):\nYes, which is why we'd need a law with statutory damages. I'm not sure a civil suit in absence of a law would work\n\n## Comment ID m6uw5z7 with +9 score by [(None, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6uw5z7/) (in reply to ID 1hzxy26):\nI've interviewed 4 or 5 times in the past 3 months with no call backs from a single person. I'm feeling super stuck right now\n\n## Comment ID m6vzfsl with +8 score by [(AnarchistHistorian, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vzfsl/) (in reply to ID 1hzxy26):\nSome months ago I went to a group job interview in a hotel (had to take a bus the previous day cause it was on a different but nearby town) they told us that they were desperate to find people (the usual shit) even telling us to ask friends and relatives that wanted to work there. Everything seemed to be fine, I logged in their website, sent all the documents, signed all the shit they emailed me. Not a single contact since that email. When you're job hunting that silence feels specially frustrating.\n\n## Comment ID m6vf3zl with +8 score by [(Ok-Highway-5247, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vf3zl/) (in reply to ID 1hzxy26):\nI’ve been ghosted by so many managers. A quick email, text message, is all I need.\n\n### Comment ID m6vf64e with +2 score by [(Enough_Shoulder_8938, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vf64e/) (in reply to ID m6vf3zl):\nRight? So we can move on!\n\n#### Comment ID m6vf85d with +2 score by [(Ok-Highway-5247, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vf85d/) (in reply to ID m6vf64e):\nA “Thanks” would be enough. Silence is terrible.\n\n## Comment ID m6uczp1 with +8 score by [(EvilKatta, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6uczp1/) (in reply to ID 1hzxy26):\nI don't think anyone gives actionable feedback after the interview. If they give feedback, they only give the feedback that minimizes their liability. Believing it and following it may be detrimental.\n\n## Comment ID m6uknko with +8 score by [(pheonixblade9, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6uknko/) (in reply to ID 1hzxy26):\ncompanies often ghost because they have other candidates they want to hire more than you, and they don't want you to move on and apply to other companies.\n\nobviously you should keep applying until you get your first paycheck, but logic does not always apply in corporate settings.\n\n## Comment ID m6wcdnc with +5 score by [(None, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6wcdnc/) (in reply to ID 1hzxy26):\nI applied to Google Fiber last year as a door-to-door salesperson. They said I would hear from them by the end of the week. I never heard anything. Like a month later, they called me to tell me to apply to the role via a 3rd party. Lmao. What?\n\n## Comment ID m6wrrx1 with +5 score by [(Trace_Reading, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6wrrx1/) (in reply to ID 1hzxy26):\noh but WE'RE the ones that are supposed to chase the job's metaphorical skirt and call them back after the interview to THANK THEM.  Nuh uh.  You are looking for US.  YOU make the effort, job, YOU do the outreach.\n\n## Comment ID m6yb5wf with +3 score by [(Wolf_2063, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6yb5wf/) (in reply to ID 1hzxy26):\nJust saying \"you're not hired\" is better than nothing.\n\n### Comment ID m6yp32a with +2 score by [(Enough_Shoulder_8938, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6yp32a/) (in reply to ID m6yb5wf):\nExactly\n\n## Comment ID m6zfri9 with +4 score by [(whereisbeezy, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6zfri9/) (in reply to ID 1hzxy26):\nI've had two interviews before the new year and I've yet to hear from either of them.\n\nTo be fair, I'm in LA and there's kind of a lot happening at the moment.\n\n## Comment ID m6vv388 with +7 score by [(melodypowers, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vv388/) (in reply to ID 1hzxy26):\nI absolutely agree with the need for rejection letters. \n\nBut I was told clearly by HR that I couldn't provide any feedback to candidates about why we went with someone else as it could potentially open up some liability. For example, even saying we went with someone whose experience better fit our needs could be spun as discriminatory. \n\nIt sucks. There have been candidates who I would have liked to give feedback to. \n\nBut there is no excuse ever in not sending a standard rejection.\n\n## Comment ID m6tobw8 with +7 score by [(Original-Usernam3, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tobw8/) (in reply to ID 1hzxy26):\nThere is no right company then because every single one of them will ghost you (assuming you made it past the initial screening).\n\n## Comment ID m6tki1b with +22 score by [(Eli_Yitzrak, Reddit, 2025-01-12)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6tki1b/) (in reply to ID 1hzxy26):\nYou are 100% NOT due ANY feedback, however a definitive no should be the minimum\n\n### Comment ID m6v9sxl with +3 score by [(Enough_Shoulder_8938, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6v9sxl/) (in reply to ID m6tki1b):\nI’ll agree with you there. I’ve never really expected to get feedback about my interview. But I do get salty about getting ghosted over and over\n\n## Comment ID m6ue0q3 with +3 score by [(masaccio87, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6ue0q3/) (in reply to ID 1hzxy26):\nWow - this is, like, the *opposite* of r/linkedinlunatics\n\n### Comment ID m6v8d57 with +2 score by [(Enough_Shoulder_8938, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6v8d57/) (in reply to ID m6ue0q3):\nRight? 😃\n\n## Comment ID m6uyk44 with +3 score by [(mar421, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6uyk44/) (in reply to ID 1hzxy26):\nRed flags are if they take 45 mins to get a manger to interview you. Then ghost you for three days.\n\n## Comment ID m6wdrtc with +3 score by [(ChestNok, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6wdrtc/) (in reply to ID 1hzxy26):\nI'm a simple man: I see any recruiter trying to ghost me after an interview or even without giving an initial feedback for my application - I schedule a weekly email with a polite follow up.\nTry to ghost me now, bia\n\n## Comment ID m74llhm with +3 score by [(MisterPiggins, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m74llhm/) (in reply to ID 1hzxy26):\nIt's insane the shit employers can pull on applicants.\n\n## Comment ID m6ufu6e with +2 score by [(Anemic_Zombie, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6ufu6e/) (in reply to ID 1hzxy26):\nI don't work in recruiting, and I'm sure that it has its own hurdles I'm unaware of, but you're only building goodwill and positive reputation by not being a dick\n\n## Comment ID m6w9124 with +2 score by [(KC_Saber, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6w9124/) (in reply to ID 1hzxy26):\nBeen there. I definitely agree\n\n## Comment ID m6xipz9 with +2 score by [(Extra-Sherbert-8608, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6xipz9/) (in reply to ID 1hzxy26):\nTake it a step further and block those recruiters. Never will get your time again\n\n## Comment ID m6y6p8q with +2 score by [(LexsZoo, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6y6p8q/) (in reply to ID 1hzxy26):\nOmg I've been mad for months. I interviewed for a job in August and dead ass at the end of the interview HR person says \"you might not hear for 2-3 weeks, but if you don't hear, no news is good news! So if I don't get back to you it's probably because I'm onboarding you.\" And then I never heard anything. After a month I reached out, and then again at a month and a half. But at that point I was like???? I assume we're not onboarding?????\n\n## Comment ID m6ymh7f with +2 score by [(thelaw_iamthelaw, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6ymh7f/) (in reply to ID 1hzxy26):\nNormalize calling them out when they don't reply. Who cares about burning that bridge. You don't wanna work for people that pull those stunts. Make them scared to ghost candidates.\n\n## Comment ID m6zssp4 with +2 score by [(Remarkable-Average60, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6zssp4/) (in reply to ID 1hzxy26):\nAgreed\n\n## Comment ID m703mbs with +2 score by [(EscapeAromatic8648, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m703mbs/) (in reply to ID 1hzxy26):\nThis is just dating advice reframed isn't it?\n\n## Comment ID m73glu2 with +2 score by [(the_surfing_unicorn, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m73glu2/) (in reply to ID 1hzxy26):\nAlso if you send me a job offer a month later, I'm not taking it\n\n## Comment ID m73rbl7 with +2 score by [(D_dUb420247, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m73rbl7/) (in reply to ID 1hzxy26):\nYeah I’m done with jobs that aren’t transparent about your role or pay. Why would you jeopardize other potential better jobs by gambling? Stop giving these businesses your time and efforts.\n\n## Comment ID m74gtcb with +2 score by [(Baptism-Of-Fire, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m74gtcb/) (in reply to ID 1hzxy26):\nWe get thousands of applications for every job we list. It’s insane. High level, low level, no way there’s enough time to handhold every person like this. And this is a small company\n\n## Comment ID m75sgdj with +2 score by [(rydawg2727, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m75sgdj/) (in reply to ID 1hzxy26):\nWhen i applied to the job i have now, i had applied to a different one prior… they had me in for an interview and then did the “we’ll call you if we feel you a good fit the position” well, a week later i got hired by the job i work now… that job called three months later wanting to know what my availability was… i told them i was not available as i had been hired by a different company since i’d not heard anything from them. The lady pretty much just hung up after that lol… imo… i think i probably also dodged a bullet with that job lol…\n\n## Comment ID m6vpvcg with +3 score by [(None, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vpvcg/) (in reply to ID 1hzxy26):\n[removed]\n\n### Comment ID m6vs07r with +2 score by [(No_Parsnip_2406, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6vs07r/) (in reply to ID m6vpvcg):\nYou are a hero\n\n## Comment ID m6w39k7 with +2 score by [(galactus417, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6w39k7/) (in reply to ID 1hzxy26):\nI use to hire in retail. For the first few group interviews I made it a point to buck the norm and call back all thoses people that didn't make the cut. Many I didn't have much feedback for. I could only hire 2 of the 10 that showed up. A lot of people got defensive and started personal attacks as soon as I gave my feedback. (Me: You didn't have the product knowledge we were looking for. Them: How the fuck would you know!? You didn't hire me. Now my dogs going to starve. Thanks asshole!) It was messy, took a lot of time, and ultimately, I don't think it was doing much good. So I stopped calling people back. Does that make me a bad guy?\n\n## Comment ID m6wzt3s with +1 score by [(Jenn-H1989, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6wzt3s/) (in reply to ID 1hzxy26):\nA rejection is only fine if it’s a real rejection…aka not from fake job postings where you have no intention of hiring.\n\n## Comment ID m6x21zn with +1 score by [(International-Belt13, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6x21zn/) (in reply to ID 1hzxy26):\nWell…the firm I work for (Market leading financial services) is terrible for this.  It’s not the manager’s however, rather it’s the internal gears turning very very slowly.  I reach out to individuals pretty quickly but I always tell them in interviews that if they haven’t heard anything within two weeks it’s probably that they are still in the running and not to give up if they are interested.\n\n## Comment ID m6xrygl with +1 score by [(shyguy9654, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6xrygl/) (in reply to ID 1hzxy26):\nI applied for a job in May. They said they would call later that day or the next day. 6 months later I got a call from the place where I applied. I didn't respond. Just let it rang\n\n## Comment ID m6ydcvk with +1 score by [(knightoffire55, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6ydcvk/) (in reply to ID 1hzxy26):\nRejection can sometimes be the same as silence. A rejection is often just the ATS sending out automated e-mails when the position is closed or you've been removed from the candidate list.\n\n## Comment ID m6yr0lk with +1 score by [(SoundlessScream, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6yr0lk/) (in reply to ID 1hzxy26):\nlinkedin is a hell website\n\n## Comment ID m75ursj with +1 score by [(redhotmericapepper, Reddit, 2025-01-14)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m75ursj/) (in reply to ID 1hzxy26):\nRude isn't the metaphor I'd use, as it's nowhere near colorful enough....but it fits ok I guess.\n\n## Comment ID m7a9p32 with +1 score by [(ThunderDU, Reddit, 2025-01-15)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m7a9p32/) (in reply to ID 1hzxy26):\nThis might be boomer antidote I feel like they would understand this. Can some folks test with their boomers and report back?\n\n## Comment ID m8zphly with +1 score by [(Vivid-Shock139, Reddit, 2025-01-24)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m8zphly/) (in reply to ID 1hzxy26):\nDude this is the truth. Im so fucking sick and tired of literal radio silence. It makes me feel like all the time and energy I put in is worthless. But I can't exactly live without a source of income, now can I? I don't qualify for unemployment anyway, and despite multiple attempts to get my phone plan put on temporary connection assistance (it's $25 a month...) I keep. Getting. Ignored. I've got fuckin' $14 to my name right now man. \n\nI just did a second round interview for some marketing firm and totally bombed the interview. I know they won't be going with me. But this is after both interviewers were late (20+ minutes the first time, and almost 10 minutes the second) and every time I asked a question about the position it was just \"oh you'll hear about it in the next interview if you get selected\" as if them telling me where their office is located is a fucking crime because the listing didn't have an address, I didn't find anything online, and NONE of the phone numbers that called me for the job were even a little bit local. \n\nI'm so close to throwing in the towel of trying to put my mental and physical health first and just taking some shitty job in food service again so I can eat. Even if I know I'll be miserable and even that will probably take 2-3 months minimum. Oh well. Thanks trump!\n\n## Comment ID m6u3zra with +1 score by [(youareceo, Reddit, 2025-01-13)](https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/m6u3zra/) (in reply to ID 1hzxy26):\nGod level"
    ],
    "sources": {
      "steam_url": null,
      "steam_reviews": null,
      "google_play_url": null,
      "google_play_reviews": null,
      "apple_store_url": null,
      "apple_reviews": null,
      "reddit_urls": [
        "https://www.reddit.com/r/generativeAI/comments/1fqyzfl/ask_sage_alternatives/",
        "https://www.reddit.com/r/LLMDevs/comments/1fs4ta3/best_llm_for_quick_on_premhybrid_rag_in_regulated/",
        "https://www.reddit.com/r/antiwork/comments/1hzxy26/whoever_this_person_is_i_agree_with_them/"
      ],
      "reddit_search_url": "https://www.google.com/search?q=site%3Areddit.com+%22Yurts.ai%22+related%3Ayurts.ai+"
    }
  },
  "glassdoor_result": null,
  "news_result": [
    [
      "Yurts.ai",
      "Yurts.ai",
      "yurts.ai",
      null,
      false,
      false
    ],
    [
      {
        "title": "Products | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/products",
        "snippet": "Dec 16, 2024 ... CompanyCareersBlogVideosIn the News. Contact. info@yurts.ai · LinkedIn logo · X (formerly Twitter) logo · Privacy PolicyTerms of Use. © Yurts. 2024, San ...",
        "formattedUrl": "https://www.yurts.ai/products"
      },
      {
        "title": "Yurts Secures $40M In Series B Funding To Accelerate Growth for ...",
        "link": "https://www.prnewswire.com/news-releases/yurts-secures-40m-in-series-b-funding-to-accelerate-growth-for-mission-critical-defense-government-and-enterprise-systems-302320856.html",
        "snippet": "Dec 3, 2024 ... Learn more at xyz.vc. SOURCE Yurts AI. WANT YOUR COMPANY'S NEWS FEATURED ON PRNEWSWIRE.COM?",
        "formattedUrl": "https://www.prnewswire.com/news.../yurts-secures-40m-in-series-b-funding..."
      },
      {
        "title": "Privacy Policy 2024 | Yurts Enterprise AI",
        "link": "https://www.yurts.ai/privacy-policy",
        "snippet": "Sep 27, 2024 ... We may send you Yurts-related or other direct marketing communications. ... info@yurts.ai · LinkedIn logo · X (formerly Twitter) logo · Privacy PolicyTerms of ...",
        "formattedUrl": "https://www.yurts.ai/privacy-policy"
      },
      {
        "title": "Redhorse announces strategic partnership with Yurts AI to deploy ...",
        "link": "https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/",
        "snippet": "Feb 21, 2024 ... ... News. Redhorse announces strategic partnership with Yurts AI to deploy secure Generative AI solutions. Home / News / Redhorse announces strategic partnership ...",
        "formattedUrl": "https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yu..."
      },
      {
        "title": "Oracle and Yurts Collaborate to Bring Secure Generative AI ...",
        "link": "https://www.prnewswire.com/news-releases/oracle-and-yurts-collaborate-to-bring-secure-generative-ai-solutions-to-defense-and-intelligence-sectors-302283793.html",
        "snippet": "Oct 23, 2024 ... Oracle and Yurts Collaborate to Bring Secure Generative AI Solutions to Defense and Intelligence Sectors. Yurts AI White Horizontal Version Logo (PRNewsfoto/ ...",
        "formattedUrl": "https://www.prnewswire.com/news.../oracle-and-yurts-collaborate-to-bring-..."
      },
      {
        "title": "Yurts: Defense-Focused GenAI Company Closes $40 Million (Series ...",
        "link": "https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/",
        "snippet": "Dec 3, 2024 ... Large organizations in industries such as manufacturing and aerospace face similar challenges: integrating AI ... Yurts's AI integration platform has been ...",
        "formattedUrl": "https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million..."
      },
      {
        "title": "Yurts Company Overview, Contact Details & Competitors | LeadIQ",
        "link": "https://leadiq.com/c/yurts/63617f9bd4454f2aa396b5ff",
        "snippet": "Dec 3, 2024 ... Yurts AI has teamed with Lambda to create an air-gapped large language model (LLM) stack solution for enterprise. May 08, 2023 | www.prnewswire.com ...",
        "formattedUrl": "https://leadiq.com/c/yurts/63617f9bd4454f2aa396b5ff"
      },
      {
        "title": "Yurts Technologies - Crunchbase Company Profile & Funding",
        "link": "https://www.crunchbase.com/organization/yurts-technologies-inc",
        "snippet": "Dec 3, 2024 ... Recent News & Activity. News• Dec 10, 2024. Yahoo ... info@yurts.ai; Phone Number +1 608-217-7409. Yurts is a Generative AI platform that is enterprise-ready.",
        "formattedUrl": "https://www.crunchbase.com/organization/yurts-technologies-inc"
      },
      {
        "title": "Invest and Sell Yurts Stock - Forge",
        "link": "https://forgeglobal.com/yurts_stock/",
        "snippet": "Dec 3, 2024 ... in 2022 and is headquartered in San Francisco, CA. yurts.ai. Sector. Enterprise Software. Subsector. Data Intelligence. Founded. 2022. Post-Money Valuation 3.",
        "formattedUrl": "https://forgeglobal.com/yurts_stock/"
      },
      {
        "title": "Unveiling the Future: AI Collaboration Takes Flight: Startup Connect ...",
        "link": "https://www.startupmontereybay.com/unveiling-the-future-ai-collaboration-takes-flight-startup-connect-meeting-recap/",
        "snippet": "Jun 19, 2024 ... Craig Vachon, CEO at AI Redefined and Jason Schnitzer, CTO & Founder at Yurts AI explored how AI development and deployment could revolutionize different ...",
        "formattedUrl": "https://www.startupmontereybay.com/unveiling-the-future-ai-collaboration-..."
      },
      {
        "title": "NVIDIA's Anthony Robbins Secures 7th Wash100 Award for ...",
        "link": "https://executivebiz.com/2024/02/nvidias-anthony-robbins-secures-7th-wash100-award-for-continuing-efforts-to-promote-ai-in-government/",
        "snippet": "Feb 7, 2024 ... ... Yurts AI for “helping to broaden the usability of generative AI outside a traditional data center or cloud.” Robbins' organization also works to encourage ...",
        "formattedUrl": "https://executivebiz.com/.../nvidias-anthony-robbins-secures-7th-wash100-a..."
      },
      {
        "title": "Enterprise Solutions Showcase - Solution Providers at KMWorld 2024",
        "link": "https://www.kmworld.com/Conference/2024/Showcase.aspx",
        "snippet": "Mar 26, 2024 ... Yurts AI. Yurts delivers intelligent AI solutions that enable seamless ... news, trends analysis, case studies, and market research to professionals in ...",
        "formattedUrl": "https://www.kmworld.com/Conference/2024/Showcase.aspx"
      },
      {
        "title": "Engineering Manager, Applied Machine Learning - Yurts | Built In",
        "link": "https://builtin.com/job/engineering-manager-applied-machine-learning/3755288",
        "snippet": "Jan 9, 2025 ... ... AI innovation. Role Overview: As an Engineering Manager in Applied Machine Learning at Yurts.ai, you'll be a vital leader driving the direction and impact ...",
        "formattedUrl": "https://builtin.com/job/engineering-manager-applied-machine.../3755288"
      },
      {
        "title": "(ART)ificial Intelligence from Madrona's IA Summit",
        "link": "https://www.nyse.com/insights/artificial-intelligence",
        "snippet": "Nov 15, 2024 ... Co-Founder & CEO, Yurts AI. posterUrl. Betsabeh Madani-Hermann. VP & Global Head of Research, Philips. posterUrl. Cody Coleman. CEO & Co-Founder, Coactive AI.",
        "formattedUrl": "https://www.nyse.com/insights/artificial-intelligence"
      },
      {
        "title": "Compare Cody vs. Yurts in 2025",
        "link": "https://slashdot.org/software/comparison/Cody-vs-Yurts/",
        "snippet": "Dec 4, 2024 ... News · Compare Business Software · Thought Leadership; Connect; Privacy; More. Add ... www.yurts.ai/. Product Features. AI Assistants · AI Productivity · AI Tools ...",
        "formattedUrl": "https://slashdot.org/software/comparison/Cody-vs-Yurts/"
      },
      {
        "title": "We've come a long way from RPA: How AI agents are ...",
        "link": "https://venturebeat.com/ai/weve-come-a-long-way-from-rpa-how-ai-agents-are-revolutionizing-automation/",
        "snippet": "Dec 15, 2024 ... For example, Sierra leverages AI to automate complex customer support scenarios, freeing up employees to focus on strategic initiatives. Startups like Yurts AI ...",
        "formattedUrl": "https://venturebeat.com/.../weve-come-a-long-way-from-rpa-how-ai-agents..."
      },
      {
        "title": "Engineering flexible machine learning systems by traversing ...",
        "link": "https://www.nature.com/articles/s42256-024-00902-x",
        "snippet": "Oct 3, 2024 ... Related work. The major contribution of our framework is that it provides ... Yurts AI, San Francisco, CA, USA. Guruprasad Raghavan. Alexandria University ...",
        "formattedUrl": "https://www.nature.com/articles/s42256-024-00902-x"
      },
      {
        "title": "Orbital Insight company information, funding & investors | Dealroom.co",
        "link": "https://app.dealroom.co/companies/orbital_insight",
        "snippet": "May 29, 2024 ... News · Deep Dives · Knowledge base · Companies · Orbital Insight. Orbital Insight. Save ... yurts ai. & 6 more. Related Content. Climate tech. Read more ...",
        "formattedUrl": "https://app.dealroom.co/companies/orbital_insight"
      },
      {
        "title": "Startup Monterey Bay | April 26th marks an exciting milestone! Join ...",
        "link": "https://www.instagram.com/startup_montereybay/p/C6MFGAGLayD/",
        "snippet": "Apr 25, 2024 ... ... Yurts AI explored how AI development and deployment could revolutionize different sectors. ... Exciting News! Get ready to join us for an incredible ...",
        "formattedUrl": "https://www.instagram.com/startup_montereybay/p/C6MFGAGLayD/"
      },
      {
        "title": "The Science of Consciousness Conference",
        "link": "https://consciousness.arizona.edu/",
        "snippet": "Dec 18, 2024 ... Community News - SUMMER 2025 - Rome, Italy. Faith, Science, Mysticism - Rome ITALY ... (Yurts AI) (Catalina J). Dual Aspect Monism - Michael Silberstein ...",
        "formattedUrl": "https://consciousness.arizona.edu/"
      }
    ],
    [
      "# [Yurts Enterprise AI by Mark Allen https:, yurts.ai, mark-allen, Ben Van Roo https:, ben-van-roo](https://www.yurts.ai/products)\nMission Critical GenAI At Scale\n\nTransform knowledge management and mission critical workflows at scale through a highly adaptable, secure, Gen AI platform.\n\nRequest Demo\n\nSearch\n\nQuery multiple applications at once\n\nBreak down data silos to harness the knowledge within your documents, apps, and daily operations.\n\nLearn More\n\nChat\n\nRefine queries with natural language\n\nDig deeper into data sources. Ask questions via Chat to refine searches.\n\nWrite\n\nGenerate reports using the best data available\n\nCreate personalized, context-rich reports and summaries using your own proprietary data.\n\nEMBEDDED ASSISTANT\n\nDeploy AI where you need it most\n\nEmbed your assistant into your favorite enterprise apps, giving you a consistent AI experience everywhere you go.\n\nLearn More\n\nENTERPRISE SEARCH\n\nMake decisions with confidence\n\nYurts leverages proprietary Retrieval Augmented Generation (RAG) models to ensure our platform serves your the most relevant and recent enterprise data.\n\nLearn More",
      "# [Privacy Policy 2024](https://www.yurts.ai/privacy-policy)\n‍\n\nAbout\n\nThis Privacy Policy describes how Yurts Technologies, Inc. (\"Yurts\", “we\", “us” or \"our\") processes personal information that we collect through our digital properties that link to this Privacy Policy, including our website (collectively, the “Service”), as well as through social media, our marketing activities, and other activities described in this Privacy Policy. Yurts may provide additional or supplemental privacy policies to individuals depending upon the context at the time we collect personal information.\n\nYurts provides a comprehensive AI platform for its enterprise customers that modernizes enterprise knowledge and workflows. This Privacy Policy does not apply to personal information, if any, that we may process on behalf of our enterprise customers (such as businesses, government entities, and other organizations) while providing the platform and other services to them. Our use of information that we process on behalf of our enterprise customers may be governed by our agreements with such customers. If you have questions regarding your personal information that we process on behalf of an enterprise customer, please direct your question to that enterprise customer.\n\nWe designed our websites, AI platform and services for enterprise customers and their representatives. We do not offer products or services for use by individuals for their personal, familial or household purposes. Accordingly, we treat all personal information that we collect as described in this Privacy Policy as pertaining to individuals in their capacities as representatives of the relevant enterprise and not their individual capacities.\n\n‍\n\nPersonal information we collect\n\nInformation you provide to us or that we generate about you. Personal information you may provide to us through the Service or otherwise or that we generate about you may include:\n\nContact data, such as your first and last name, salutation, email address, mailing address, professional title and company name, and phone number.\n\nCommunications data based on our exchanges with you, including when you contact us through the Service, contact forms, social media, email or otherwise.\n\nMarketing data, such as your preferences for receiving our marketing communications and details about your engagement with them.\n\nOther data not specifically listed here such as that entered in freeform text, which we will use as described in this Privacy Policy or as otherwise disclosed at the time of collection. We ask that you not provide us with any confidential, sensitive or otherwise proprietary information through the Service.\n\nThird-party sources. We may combine personal information we receive from you with personal information we obtain from other sources, such as:\n\nPublic sources, such as government agencies, public records, social media platforms, and other publicly available sources.\n\nPrivate sources, such as data providers and social media platforms.\n\nMarketing partners, such as joint marketing partners and event co-sponsors.\n\nAutomatic data collection. We, our service providers, and our business partners may automatically log information about you, your computer or mobile device, and your interaction over time with the Service, our communications and other online services, such as:\n\nDevice data, such as your computer or mobile device’s operating system type and version, manufacturer and model, browser type, screen resolution, RAM and disk size, CPU usage, device type (e.g., phone, tablet), IP address, unique identifiers (including identifiers used for advertising purposes), language settings, mobile device carrier, radio/network information (e.g., Wi-Fi, LTE, 3G), and general location information such as city, state or general geographic area.\n\nOnline activity data, such as pages or screens you viewed, how long you spent on a page or screen, the website you visited before browsing to the Service, navigation paths between pages or screens, information about your activity on a page or screen, access times and duration of access, and whether you have opened our emails or clicked links within them.\n\nCommunication interaction data such as your interactions with our email or other communications (e.g., whether you open and/or forward emails) – we may do this through use of pixel tags (which are also known as clear GIFs), which may be embedded invisibly in our emails.\n\nCookies and similar technologies. Some of the automatic collection described above is facilitated by the following technologies:\n\nCookies, which are text files that websites store on a visitor‘s device to uniquely identify the visitor’s browser or to store information or settings in the browser for the purpose of helping you navigate between pages efficiently, remembering your preferences, enabling functionality, helping us understand user activity and patterns, and facilitating analytics and online advertising.\n\nLocal storage technologies, like HTML5, that provide cookie-equivalent functionality but can store larger amounts of data on your device outside of your browser in connection with specific applications.\n\nWeb beacons, also known as pixel tags or clear GIFs, which are used to demonstrate that a webpage or email was accessed or opened, or that certain content was viewed or clicked.\n\nChat technologies, such as those provided by us or another party that employ cookies and other software code to operate the chat features that you can use to communicate with us through the Service. To operate the chat features, we and the relevant other party may access and use information about webpages visited on our website, your IP address, your general geographic information (e.g., city, state), and other personal information you share through online chats for the purposes described in this Privacy Policy.\n\n‍\n\nData about others. We may offer features that help users invite their contacts to use the Service, and we may collect contact details about these invitees so we can deliver their invitations. Please do not refer someone to us or share their contact details with us unless you have their permission to do so.\n\n‍\n\nHow we use your personal information\n\nWe may use your personal information for the following purposes or as otherwise described at the time of collection:\n\nService delivery and operations. We may use your personal information to:\n\nprovide, operate and improve the Service and our business;\n\npersonalizing the Service, including remembering the devices from which you have previously logged in and remembering your selections and preferences as you navigate the Service;\n\nfacilitate Service features such as chat functionality;\n\ncommunicate with you about the Service, including by sending announcements, updates, security alerts, and support and administrative messages;\n\ncommunicate with you about events in which you participate;\n\nunderstand your needs and interests, and personalize your experience with the Service and our communications; and\n\nprovide support for the Service, and respond to your requests, questions and feedback.\n\nResearch and development. We may use your personal information for research and development purposes, including to analyze and improve the Service and our business. As part of these activities, we may create aggregated, de-identified and/or anonymized data from personal information we collect. We make personal information into de-identified or anonymized data by removing information that makes the data personally identifiable to you. We may use this de-identified or anonymous data and share it with third parties for our lawful business purposes, including to analyze and improve the Service and promote our business.\n\nMarketing. We may collect and use your personal information for marketing purposes:\n\nDirect marketing. We may send you Yurts-related or other direct marketing communications. You may opt-out of our marketing communications as described in the Opt-out of marketing section below.\n\nService improvement and analytics. We may use your personal information to analyze your usage of the Service, improve the Service, improve the rest of our business, help us understand user activity on the Service, including which pages are most and least visited and how visitors move around the Service, as well as user interactions with our emails, and to develop new products and services.\n\nCompliance and protection. We may use your personal information to:\n\ncomply with applicable laws, lawful requests, and legal process, such as to respond to subpoenas or requests from government authorities;\n\nprotect our, your or others’ rights, privacy, safety or property (including by making and defending legal claims);\n\naudit our internal processes for compliance with legal and contractual requirements or our internal policies;\n\nenforce the terms and conditions that govern the Service; and\n\nprevent, identify, investigate and deter fraudulent, harmful, unauthorized, unethical or illegal activity, including cyberattacks and identity theft.\n\nWith your consent. In some cases, we may specifically ask for your consent to collect, use or share your personal information, such as when required by law.\n\nCookies and similar technologies. In addition to the other uses included in this section, we may use the Cookies and similar technologies described above for the following purposes:\n\nTechnical operation. To allow the technical operation of the Service.\n\nFunctionality. To enhance the performance and functionality of our services.\n\nAnalytics. To help us understand user activity on the Service, including which pages are most and least visited and how visitors move around the Service, as well as user interactions with our emails.\n\nCookies may also be used by our online data partners or vendors to associate these activities with other personal information they or others have about you, including by association with your email or home address. We (or service providers on our behalf) may then send communications and marketing to these email or home addresses. You may opt out of receiving this advertising by visiting https://app.retention.com/optout\n\n‍\n\nHow we share your personal information\n\nWe may share your personal information with the following parties and as otherwise described in this Privacy Policy or at the time of collection.\n\nService providers. Third parties that provide services on our behalf or help us operate the Service or our business (such as hosting, information technology, customer support, chat providers, email delivery, consumer research, marketing, and website analytics).\n\nThird parties designated by you. We may share your personal data with third parties where you have instructed us or provided your consent to do so. We will share personal information that is needed for these other companies to provide the services that you have requested. We do not control how these third parties may use your personal information.\n\nProfessional advisors. Professional advisors, such as lawyers, auditors, bankers and insurers, where necessary in the course of the professional services that they render to us.\n\nAuthorities and others. Law enforcement, government authorities, and private parties, as we believe in good faith to be necessary or appropriate for the compliance and protection purposes described above.\n\nBusiness transferees. We may disclose personal information in the context of actual or prospective business transactions (e.g., investments in or financings of Yurts, or the sale, transfer or merger of all or part of our business, assets or shares), for example, we may need to share certain personal information with prospective counterparties and their advisers. We may also disclose your personal information to an acquirer, successor, or assignee of Yurts as part of any merger, acquisition, sale of assets, or similar transaction, and/or in the event of an insolvency, bankruptcy, or receivership in which personal information is transferred to one or more third parties as one of our business assets.\n\n‍\n\nYour choices\n\nYou may have the following choices with respect to your personal information.\n\nOpt-out of marketing communications. You may opt-out of marketing-related emails by following the opt-out or unsubscribe instructions at the bottom of the email, or by contacting us. Please note that if you choose to opt-out of marketing-related emails, you may continue to receive service-related and other non-marketing emails.\n\nCookies. Most browsers let you remove or reject cookies. To do this, follow the instructions in your browser settings. Many browsers accept cookies by default until you change your settings. Please note that if you set your browser to disable cookies, the Service may not work properly. For more information about cookies, including how to see what cookies have been set on your browser and how to manage and delete them, visit www.allaboutcookies.org. You can also configure your device to prevent images from loading to prevent web beacons from functioning.\n\nDo Not Track. Some Internet browsers may be configured to send “Do Not Track” signals to the online services that you visit. We currently do not respond to “Do Not Track” or similar signals. To find out more about “Do Not Track,” please visit http://www.allaboutdnt.com.\n\nDeclining to provide information. We need to collect personal information to provide certain services. If you do not provide the information we identify as required or mandatory, we may not be able to provide those services.\n\n‍\n\nOther sites and services\n\nThe Service may contain links to websites, mobile applications, and other online services operated by third parties. In addition, our content may be integrated into web pages or other online services that are not associated with us. These links and integrations are not an endorsement of, or representation that we are affiliated with, any third party. We do not control websites, mobile applications or online services operated by third parties, and we are not responsible for their actions. We encourage you to read the privacy policies of the other websites, mobile applications and online services you use.\n\n‍\n\nSecurity\n\nWe employ a number of technical, organizational and physical safeguards designed to protect the personal information we collect. However, security risk is inherent in all internet and information technologies, and we cannot guarantee the security of your personal information.\n\n‍\n\nInternational data transfer\n\nWe are headquartered in the United States and may use service providers that operate in other countries. Your personal information may be transferred to the United States or other locations where privacy laws may not be as protective as those in your state, province, or country.\n\n‍\n\nChildren\n\nThe Service is not intended for use by anyone under 18 years of age. If you are a parent or guardian of a child from whom you believe we have collected personal information in a manner prohibited by law, please contact us. If we learn that we have collected personal information through the Service from a child without the consent of the child’s parent or guardian as required by law, we will comply with applicable legal requirements to delete the information.\n\n‍\n\nChanges to this Privacy Policy\n\nWe reserve the right to modify this Privacy Policy at any time. If we make material changes to this Privacy Policy, we will notify you by updating the date of this Privacy Policy and posting it on the Service or other appropriate means. Any modifications to this Privacy Policy will be effective upon our posting the modified version (or as otherwise indicated at the time of posting). In all cases, your use of the Service after the effective date of any modified Privacy Policy indicates your acceptance of the modified Privacy Policy.\n\n‍\n\nHow to contact us",
      "# [Redhorse announces strategic partnership with Yurts AI to deploy secure Generative AI solutions – Redhorse Corporation by Josef Buford on 2024-02-21](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/)\nARLINGTON, VA February 21, 2024 – Redhorse, a leader in technology-driven, mission-focused solutions for the federal government, is thrilled to announce a new partnership with Yurts, a pioneer in secure generative artificial intelligence solutions.\n\nAs federal agencies face increasing demands for modernization and efficiency, the need to deploy AI solutions with tangible impact has never been greater. Yurts, known for its comprehensive generative AI platform, excels at modernizing knowledge-driven enterprise workflows, ensuring operational efficiency, flexibility, and uncompromised privacy – essential features for federal applications.\n\nRedhorse has been at the forefront of DoD AI adoption, supporting important efforts such as Project Maven, the Joint Artificial Intelligence Center (JAIC), and the DoD Chief Digital and Artificial Intelligence Office (CDAO) from day one. Redhorse’s ability to understand the mission problem, identify use cases, rapidly prototype solutions and integrate them into mission-critical applications, combined with Yurts turnkey platform, gives federal customers a proven pathway to harnessing generative AI in support of their mission.\n\n“Partnering with Yurts aligns perfectly with our values and mission to provide cutting-edge, secure technology solutions,” said Matt Teschke, CTO of Redhorse. “Yurts’ expertise in deploying solutions for classified use cases accelerates adoption of this transformative technology across our customers while adhering to their stringent security standards.” Through this partnership, Redhorse and Yurts together will bring this revolutionary technology to our industry and our customers, enhancing the mission to support and elevate workflow efficiency.\n\nRedhorse is excited to develop mission-focused capabilities atop the Yurts platform, showcasing the innovative strengths and versatility of both companies in addressing complex challenges for the government.\n\n“Yurts is excited to partner with Redhorse and deliver mission outcomes for the federal government,” stated Ben Van Roo, Co-Founder and CEO of Yurts. “From critical missions to the modernization of legacy technologies, we believe generative AI will advance federal government in its journey towards technological empowerment and enhanced decision-making.”\n\n# # # # # #\n\nAbout Redhorse Corporation\n\nRedhorse Corporation is a technology driven company that delivers innovative data science and digital transformation solutions enabling mission success for national security, intelligence community, and federal civilian customers. We are focused on transforming the way the government interacts with data and technology to improve mission results. Redhorse is backed by Blue Delta Capital Partners, a leading venture capital firm focused on the U.S. Federal Government market.\n\nAbout Yurts\n\nBorn out of working with the Department of Defense, Yurts is a secure and private GenAI integration platform that empowers people to do their best work. Yurts transforms knowledge management and mission critical workflows at scale through a highly adaptable, secure GenAI platform that augments critical workflows across applications and data stores.",
      "# [Yurts: Defense-Focused GenAI Company Closes $40 Million (Series B) by Amit Chowdhry on 2024-12-03](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/)\nYurts, a leader in secure and trusted generative AI (GenAI) integration at scale for defense, government, and enterprise customers, announced a $40 million Series B funding round led by XYZ Venture Capital, with participation from Glynn Capital, Nava Ventures, Bloomberg Beta, and Mango Capital.\n\nYurts will utilize this funding to accelerate its growth and capabilities in leading an industry shift from experimental GenAI use to deep integration across mission-critical systems, unlocking real value within secure environments. And Yurts had recently delivered the first AI platform for the US Department of Defense (DoD) on a secret-level network, offering new insights and superior decision-making capabilities for operational leaders and field personnel.\n\nThe company has emerged as a trusted AI partner in the public sector and commercial enterprises. Large organizations in industries such as manufacturing and aerospace face similar challenges: integrating AI into legacy systems to unlock productivity, reduce costs, and provide users with a trusted resource that removes barriers to getting things done.\n\nYurts’s approach is uniquely designed to address these parallels, combining precision, scalability, and compliance in secure environments. Importantly, Yurts does not train on a company’s proprietary data, but it can be deployed on-premise, ensuring maximum security and control for organizations handling sensitive information.\n\nYurts’s AI integration platform has been deployed in many high-security settings across unclassified, sensitive, and secret environments, ensuring compliance with Department of Defense standards for sensitive data. With contracts spanning the U.S. Army, U.S. Air Force, Department of Energy, and SOCOM, Yurts is trusted to deliver AI solutions that strengthen mission-critical systems. Nearly 25% of Yurts’s workforce holds active security clearances, underscoring the company’s deep expertise in high-security environments.\n\nEven though Yurts’s primary focus remains on the DoD and national security, its solutions are equally important for enterprises. A recent expansion of Yurts’s partnership with Oracle highlights the company’s ability to support commercial customers in modernizing their systems of record with AI, ensuring that GenAI delivers real, actionable value in complex, high-stakes environments.\n\nThe Series B funding round brings Yurts’s total investment to $58 million, enabling the company to scale operations, expand its team, and deepen its focus on connecting GenAI to mission-critical systems. With a proven track record in both the public and private sectors, Yurts is poised to redefine how organizations harness the power of AI in high-security environments.\n\nKEY QUOTES:\n\n“As GenAI adoption matures, the challenge is no longer about demos and pilots; it’s about delivering tangible results. For both the DOD and large enterprises, this means connecting AI to the systems that matter most—your systems of record and mission-critical applications. Yurts is purpose-built to meet this need, securely integrating AI where it can truly transform operations.”\n\n“Defense and enterprise organizations face the same fundamental challenge: how to connect AI to their existing systems to unlock new workflows and insights. This is where Yurts comes in. We provide the secure, integrated foundation that makes AI usable and transformative—not just theoretical.”\n\n“Right now, GenAI is only scratching the surface in terms of value for users. Yurts is bridging the gap between humans, GenAI, and the systems that matter most in meaningful and adaptable ways. Over the past two years, we’ve developed technologies that move GenAI beyond experimentation, making it usable, secure, and impactful for the most critical and complex missions. Looking ahead, we’re focused on expanding these capabilities with our customers in the DOD, government, and commercial sectors—ensuring AI is flexible enough to meet their needs today and evolve with them for the future.”\n\nBen Van Roo, Co-Founder and CEO of Yurts\n\n“Yurts has broken out as a clear leader in the category of AI integration with their emphasis on deploying and scaling a solution grounded in data with a security-first framework. Founders Ben Van Roo, Jason Schnitzer, and Guru Raghavan have built an AI platform that can be deeply integrated within high-security environments. This is a significant catalyst for both Yurts and the military, enabling the seamless integration of advanced AI capabilities into critical national security workflows. The company is positioned to meet the current and future need for AI head-on, and we’re proud to support them in this mission.”",
      "# [Yurts Company Overview, Contact Details & Competitors](https://leadiq.com/c/yurts/63617f9bd4454f2aa396b5ff)\nRecent Funding Yurts Technologies Inc. recently secured $40M in Series B funding, indicating financial stability and potential for investment in AI solutions.\n\nGovernment Contracts Yurts Technologies Inc. signed a $16M contract with U.S. Special Operations, showcasing a strong foothold in the defense sector for AI integration.\n\nStrategic Partnerships Yurts Technologies Inc. established partnerships with companies like Carahsoft Technology and Lambda Inc., suggesting collaboration opportunities for AI solutions.\n\nIndustry Recognition Yurts Technologies Inc. is trusted by secure organizations and recognized for AI security, making it an attractive choice for businesses seeking reliable AI platforms.",
      "# [Unveiling the Future: AI Collaboration Takes Flight: Startup Connect Meeting Recap! – Startup Monterey Bay by Alex Verdugo on 2024-06-19](https://www.startupmontereybay.com/unveiling-the-future-ai-collaboration-takes-flight-startup-connect-meeting-recap/)\nJune 11th, 2024\n\nMarina, Ca.\n\nBy Denise Silva\n\nThe Monterey Bay DART and the Institute for Innovation & Economic Development (iiED) held an engaging Startup Connect meetup on Tuesday, June 11th. The discussion went beyond AI and delved into the future. Craig Vachon, CEO at AI Redefined and Jason Schnitzer, CTO & Founder at Yurts AI explored how AI development and deployment could revolutionize different sectors. They stressed the importance of building trust, ensuring safety, and upholding ethical considerations throughout the process. Imagine enhanced enterprise search and data management that intuitively anticipates industry needs, surfacing the correct information at the right time. Pilot training is revolutionized with AI-powered simulations that push boundaries and enhance skills.\n\nJason Schnitzer, CTO & Founder at Yurts AI, a company that has received $18 million in Series A funding, discussed how his company uses AI for mission-critical systems to ensure security and reliability in national security and regulated industries.\n\nCraig Vachon, CEO at AI Redefined discussed optimizing training programs with AI-powered pilot training platforms developed by the DoD in partnership with leading companies (Joby, Archer) to address scaling challenges and personalize learning. He also touched on similar advancements in AI-assisted training applied to diverse fields, from aviation to professional development. He discussed next-generation AI tools and how advanced AI apprenticeship models can train AI faster with less data, leading to a new era of AI development.\n\nThis isn’t science fiction; it’s the future that AI is creating. The conversations during the meetup focused on the potential of AI-powered tools such as decision optimization agents and operator assistants. Both speakers mentioned that industry experts anticipate that Language Model Models (LLMs) will evolve from managing knowledge to optimizing decision-making processes. This transition is expected to significantly impact businesses across various sectors due to the future of AI.\n\nThe fundamental insight? AI is not a replacement for us but a partner in our endeavors. Collaboration is the cornerstone for ensuring this transformative technology’s responsible development and deployment.",
      "# [NVIDIA's Anthony Robbins Secures 7th Wash100 Award for Continuing Efforts to Promote AI in Government by Jerry Petersen on 2024-02-07](https://executivebiz.com/2024/02/nvidias-anthony-robbins-secures-7th-wash100-award-for-continuing-efforts-to-promote-ai-in-government/)\nExecutive Mosaic is pleased to announce that NVIDIA Federal Vice President Anthony Robbins has once again been named a winner of the Wash100 Award, an honor conferred annually to the GovCon industry’s 100 most influential and impactful leaders.\n\nThe Popular Vote Competition of the 2024 Wash100 Award runs through April 30, 2024. Click here to vote for Anthony Robbins as one of your favorite GovCon industry leaders!\n\n2024 marks the 6th straight year that Robbins is part of the list of honorees. It is also his 7th win overall. This year, he is being recognized for his continuing work in promoting the adoption and use of artificial intelligence in the government sector.\n\n“NVIDIA is one of the companies driving the ever-evolving artificial intelligence conversation, and as VP of the company’s federal arm, Anthony is leading NVIDIA’s collaboration with key government agencies, which is especially critical in this era of AI development,” said Jim Garrettson, CEO of Executive Mosaic.\n\n“Anthony works tirelessly to catalyze IT transformation within the federal ecosystem using advanced AI technologies, deep learning, GPU computing and more. Anthony’s continued vision and leadership make him a repeat Wash100 winner,” added Garrettson, founder of the Wash100 Award.\n\n“Every industry has awoken to AI,” Robbins says on LinkedIn, citing how the technology has changed or will change internet companies, startups, transportation and manufacturing. The NVIDIA executive goes on to explain how graphics processing units, his company’s most recognizable product, has facilitated deep learning by taking advantage of immense computational power to allow deep neural networks to discover patterns in copious amounts of data. This GPU-driven computing model “set off a string of ‘superhuman’ achievements in image and speech recognition and sparked the era of AI computing,” Robbins says.\n\nTo promote the use of AI in government would necessarily involve collaborating with agencies. One example is NVIDIA’s partnership with the National Science Foundation, which recently launched the National Artificial Intelligence Research Resource pilot program, whose aim is to improve access to the tools required for the generation of innovations in AI. The company is supporting NAIRR by committing to provide $30 million in technologies over two years with the aim of expanding the program’s scale.\n\nNVIDIA’s efforts to encourage AI use also benefit from the support of its “ecosystem of partners,” which includes Yurts AI and Lambda, the latter of which counts the Department of Defense among its customers. In May last year, the two technology companies teamed up to develop a platform that would provide advanced language processing capabilities, enabling generative AI at the edge.\n\nFor that technology, Yurts AI, a member of the NVIDIA Inception program, developed a large language model that would run on a workstation provided by Lambda. The workstation was powered by NVIDIA GPUs.\n\nCommenting on the collaboration, Robbins pointed out the challenge of running LLMs at secure edge locations and lauded Yurts AI for “helping to broaden the usability of generative AI outside a traditional data center or cloud.”\n\nRobbins’ organization also works to encourage partners in their efforts with AI by honoring them with Partner of the Year awards. The aforementioned Lambda, for example, was recently named 2023 NVIDIA Solution Integration Partner of the Year in the Americas for having provided various industries, including the federal and public sectors, with end-to-end NVIDIA offerings.\n\nAnother example is Microway, a company that delivers NVIDIA-powered systems and AI deployments. Microway’s work in 2022 with customers in the public sector domain earned it the honor of being named the 2023 NVIDIA Public Sector Partner of the Year in the Americas.\n\nRegarding the partnership award, Robbins commented, “Microway’s expertise in providing custom-built AI systems using NVIDIA technology is helping government agencies and enterprises solve their hardest problems, improve energy efficiency and discovery, and make communities safer and more connected.”\n\nExecutive Mosaic congratulates Anthony Robbins and his team at NVIDIA for this latest honor.",
      "# [Solution Providers at KMWorld 2024](https://www.kmworld.com/Conference/2024/Showcase.aspx)\nCoveo powers the digital experiences of the world’s most innovative brands serving millions of people and billions of interactions across every digital experience. After a decade of enriching our market-leading platform with forward-thinking global enterprises, we know what it takes to gain a trusted AI-experience advantage.\n\nWe strongly believe that the future is business-to-person, that experience is today’s competitive front line, a make or break for every business.\n\nFor enterprises to achieve this AI-experience advantage at scale, it is imperative to have an Enterprise Spinal and composable ability to deliver AI semantic search and generative experiences at each customer and employee interaction.\n\nOur single SaaS AI platform and robust suite of AI & GenAI models are designed to transform the total experience from CX to EX across websites, ecommerce, service, and workplace. Powering individualized, trusted, and connected experiences across every interaction to delight customers and augment employees, and drive superior business outcomes.\n\nOur platform is certified ISO 27001 certified, HIPAA compliant, SOC2 compliant, and 99.999% SLA resilient. We are a Salesforce Summit ISV Partner, an SAP? Endorsed App, and an Adobe Gold Partner.\n\nPryon turns vast quantities of critical, fragmented, and rapidly-changing content into accurate, timely, and verifiable answers via the world's first enterprise-grade Knowledge AI Platform. Using best-in-class retrieval technology, Pryon securely extracts answers from all forms of content, including audio, images, text, and video, stored in a myriad of sources. Pryon’s Knowledge AI platform is intuitive to use, is accessible via API from any system, and can be deployed in a matter of weeks in the cloud or on-premises. Created by the AI pioneers instrumental in developing Alexa, Siri, and Watson, Pryon is trusted by leading enterprises such as Dell, NVIDIA, Westinghouse, and World Economic Forum. By reducing the distance between people and answers, Pryon builds high-performing, resilient, and responsive organizations.\n\nSinequa transforms how work gets done. Sinequa’s Assistants augment your company by augmenting employees with a knowledgeable, accurate, secure work partner so they are more effective, more informed, more productive, and less stressed. Best of all, Sinequa Assistants streamline workflows and automatically navigate the chaotic enterprise information landscape, so that employees can skip the grind and focus on doing the kind of work that makes the most impact. Sinequa’s Assistants achieve this by combining the power of comprehensive enterprise search with the ease of generative AI in a configurable and easily managed Assistant framework, for an accurate, traceable, and fully secure conversational experience. Deploy an out-of-the-box Assistant or configure a tailored experience and specialized workflow to augment your people and your company. For more information, visit www.sinequa.com.\n\nEvalueserve, a global leader in integrated research, insights, and analytics, empowers organizations to transform data into decisive action, navigate complex challenges, and uncover new opportunities. By seamlessly blending cutting-edge AI technology with deep industry expertise, we help our clients stay ahead of the competition. Our AI-enabled solutions, delivered across 15+ industries in 45+ countries, drive innovation and help maintain a competitive advantage. With over 5,000 domain experts and 20+ years of experience in Knowledge Management, Evalueserve serves Tier-1 Management Consulting firms, Big 4 Accounting and Advisory firms, Global Asset and Wealth Management firms, and Fortune 1000 companies. Our unique approach combines seasoned KM professionals with our AI-enabled platform, Publishwise, to provide tailored solutions that address your specific needs. Choose Evalueserve to unlock the full potential of your data and drive your organization towards sustainable growth and success.\n\nKMWorld is the leading information provider serving the Knowledge Management systems market. We inform our more than 45,000 subscribers about the components and processes — and related success stories — that together offer solutions for improving your business performance. With access to many of the most knowledgeable writers and analysts in the industry, KMWorld also offers a number of special publications, including: the KMWorld Best Practices White Papers series — delivering high-value, educational content from industry-leading solutions providers, free from marketing hype and distraction; the KMWorld Buyer's Guide — a print and electronic resource that will shorten your search for a vendor or simply help identify sources for KM tools.",
      "# [Engineering Manager, Applied Machine Learning - Yurts](https://builtin.com/job/engineering-manager-applied-machine-learning/3755288)\nAbout Us:\n\nLet’s be real—AI isn’t magic; it’s a tool, and it’s only as powerful as the systems, workflows, and most importantly the people powering it. Yurts is unlocking all of that unstructured, hard-to-find, disconnected data and turning it into a secure knowledge management platform that’s actually designed to serve people—wherever they work.\n\nBorn from a partnership with the Department of Defense to meet the demands of mission-critical environments, Yurts is redefining how teams harness AI for productivity and performance. Named after the resilient, adaptable yurt, our platform is designed to work with the systems you use—not replace them.\n\nIn collaboration with Nvidia, HPE, and Oracle we offer secure, innovative solutions, including air-gapped deployments for defense, a full ML ops analytics framework to drive cost efficiencies and a world-class proprietary RAG system serving answers you can trust. Yurts unifies applications, data, and workflows protecting investments and saving customers money.\n\nWe’re looking for bold thinkers and doers to join us in redefining how teams harness AI for productivity and performance. Be part of building solutions that elevate both technology and the people who use it. Together, we’ll shape the next generation of secure, human-centered AI innovation.\n\nRole Overview:\n\nAs an Engineering Manager in Applied Machine Learning at Yurts.ai, you'll be a vital leader driving the direction and impact of small, dedicated teams focused on applied machine learning and information retrieval to power the Yurts RAG platform. In this role, you’ll work closely with cross-functional teams—including go-to-market and product design—to ensure our technical roadmap is closely aligned with the strategic objectives of the business. This involves tackling complex technical challenges in enterprise workflows and data, fostering a culture that prioritizes collaboration, innovation, and calculated risk-taking.\n\nThe ideal candidate will bring a strong background in machine learning engineering, with proven technical expertise in developing, deploying and supporting sophisticated, large-scale ML solutions. You will manage and support a team of senior-level engineers utilizing a range of machine learning tools and the latest knowledge management techniques to solve real-world business problems. Your team will develop algorithmic solutions and work in distributed computing production environments, integrating ML models into end-user-facing systems and applications.\n\nSuccess in this role will require close collaboration with both technical and non-technical partners, including design and product teams, to build features that reflect a deep understanding of user needs and how they engage with algorithmically driven aspects of the product.\n\nKey Responsibilities:\n\nLead and support ICs working on applied machine learning and information retrieval to power customer-facing systems and applications.\n\nOversee all stages of ML project development, from research and prototyping to production deployment, ensuring timely delivery and high-quality execution.\n\nCollaborate with go-to-market teams to align roadmap with business goals.\n\nDive deep into technical challenges surrounding complex enterprise workflows and data.\n\nRecruit, mentor, and retain high-performing engineers, fostering a culture of innovation and collaboration.\n\nDrive innovation in 0->1 product areas, exploring and implementing new machine learning technologies and techniques.\n\nLeverage passion for generative AI and enterprise nuances to deliver solutions that enhance user experience.\n\nScale teams and management processes as the company grows rapidly.\n\nRequirements:\n\n2+ years of experience hiring and leading teams as an engineering manager.\n\nPrevious experience driving the development of applied ML applications.\n\nDemonstrable expertise with natural language processing and machine learning techniques.\n\nStrong software engineering background as an individual contributor, with experience tackling complex technical challenges in enterprise product development.\n\nExcitement and curiosity for 0->1 product development, with a track record of turning innovative ideas into successful features.\n\nKnowledge and experience in generative AI and its various applications.\n\nPreferred Qualifications:\n\nKnowledge and experience in generative AI and its various applications.\n\nAdditional Information:\n\nThis is a hybrid role\n\nYurts.ai is an equal-opportunity employer and values diversity in its workforce.\n\nEqual Opportunity Statement\n\nYurts provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",
      "# [(ART)ificial Intelligence from Madrona's IA Summit](https://www.nyse.com/insights/artificial-intelligence)\nThe NYSE sent a crew to Madrona’s IA Summit in Seattle, where we had a chance to meet the leaders of exciting companies in AI and ask them to share questions and prompts on a variety of thought-provoking topics. But this isn't just another Q&A series, we took those answers and transformed them into art – using AI, of course.*\n\nWhat you see is the work of (ART)ificial Intelligence.\n\n*All art generated with a 3rd party AI application",
      "# [Compare Cody vs. Yurts in 2025](https://slashdot.org/software/comparison/Cody-vs-Yurts/)\nAverage Ratings 0 Ratings\n\nTotal\n\nease\n\nfeatures\n\ndesign\n\nsupport\n\nNo User Reviews. Be the first to provide a review:\n\nWrite a Review\n\nAverage Ratings 0 Ratings\n\nTotal\n\nease\n\nfeatures\n\ndesign\n\nsupport\n\nNo User Reviews. Be the first to provide a review:\n\nWrite a Review\n\nAPI Access\n\nHas API\n\nAPI Access\n\nHas API\n\nIntegrations\n\nGemini 1.5 Flash\n\nGemini 1.5 Pro\n\nGemini 2.0 Flash\n\nGemini Advanced\n\nGemini Nano\n\nGemini Pro\n\nGoogle Drive\n\nJira\n\nMicrosoft OneDrive\n\nMicrosoft Outlook\n\nMicrosoft SharePoint\n\nMicrosoft Word\n\nNotion\n\nPowerPoint\n\nQuickwork\n\nSalesforce\n\nSlack\n\nWorkday HCM\n\nZendesk\n\nIntegrations\n\nGemini 1.5 Flash\n\nGemini 1.5 Pro\n\nGemini 2.0 Flash\n\nGemini Advanced\n\nGemini Nano\n\nGemini Pro\n\nGoogle Drive\n\nJira\n\nMicrosoft OneDrive\n\nMicrosoft Outlook\n\nMicrosoft SharePoint\n\nMicrosoft Word\n\nNotion\n\nPowerPoint\n\nQuickwork\n\nSalesforce\n\nSlack\n\nWorkday HCM\n\nZendesk\n\nPricing Details\n\n$29 per month\n\nFree Trial\n\nFree Version\n\nPricing Details\n\nNo price information available.\n\nFree Trial\n\nFree Version\n\nDeployment\n\nSaaS\n\niPhone\n\niPad\n\nAndroid\n\nWindows\n\nMac\n\nLinux\n\nDeployment\n\nSaaS\n\niPhone\n\niPad\n\nAndroid\n\nWindows\n\nMac\n\nLinux\n\nSupport\n\nPhone Support\n\n24/7 Live Support\n\nOnline\n\nSupport\n\nPhone Support\n\n24/7 Live Support\n\nOnline\n\nTraining\n\nDocumentation\n\nWebinars\n\nLive Online\n\nIn Person\n\nTraining\n\nDocumentation\n\nWebinars\n\nLive Online\n\nIn Person\n\nVendor Details\n\nCompany Name\n\nCody\n\nCountry\n\nUnited States\n\nWebsite\n\nwww.meetcody.ai/\n\nVendor Details\n\nCompany Name\n\nYurts\n\nFounded\n\n2022\n\nCountry\n\nUnited States\n\nWebsite\n\nwww.yurts.ai/\n\nProduct Features\n\nArtificial Intelligence\n\nChatbot\n\nFor Healthcare\n\nFor Sales\n\nFor eCommerce\n\nImage Recognition\n\nMachine Learning\n\nMulti-Language\n\nNatural Language Processing\n\nPredictive Analytics\n\nProcess/Workflow Automation\n\nRules-Based Automation\n\nVirtual Personal Assistant (VPA)\n\nKnowledge Management\n\nArtificial Intelligence (AI)\n\nCataloging / Categorization\n\nCollaboration\n\nContent Management\n\nDecision Tree\n\nDiscussion Boards\n\nFull Text Search\n\nKnowledge Base Management\n\nSelf Service Portal\n\nAlternatives\n\nTagore AI\n\nFactly Media & Research",
      "# [We’ve come a long way from RPA: How AI agents are revolutionizing automation by Rohan Sharma, Zenolabs, Rohan Sharma on 2024-12-16](https://venturebeat.com/ai/weve-come-a-long-way-from-rpa-how-ai-agents-are-revolutionizing-automation/)\nIn the past year, the race to automate has intensified, with AI agents emerging as the ultimate game-changers for enterprise efficiency. While generative AI tools have made significant strides over the past three years — acting as valuable assistants in enterprise workflows — the spotlight is now shifting to AI agents capable of thinking, acting and collaborating autonomously. For enterprises preparing to embrace the next wave of intelligent automation, understanding the leap from chatbots to retrieval-augmented generation (RAG) applications to autonomous multi-agent AI is crucial. As Gartner noted in a recent survey, 33% of enterprise software applications will include agentic AI by 2028, up from less than 1% in 2024.\n\nAs Google Brain founder Andrew Ng aptly stated: “The set of tasks that AI can do will expand dramatically because of agentic workflows.” This marks a paradigm shift in how organizations view the potential of automation, moving beyond predefined processes to dynamic, intelligent workflows.\n\nThe limitations of traditional automation\n\nDespite their promise, traditional automation tools are constrained by rigidity and high implementation costs. Over the past decade, robotic process automation (RPA) platforms like UiPath and Automation Anywhere have struggled with workflows lacking clear processes or relying on unstructured data. These tools mimic human actions but often lead to brittle systems that require costly vendor intervention when processes change.\n\nCurrent gen AI tools, such as ChatGPT and Claude, have advanced reasoning and content generation capabilities but fall short of autonomous execution. Their dependency on human input for complex workflows introduces bottlenecks, limiting efficiency gains and scalability.\n\nThe emergence of vertical AI agents\n\nAs the AI ecosystem evolves, a significant shift is occurring toward vertical AI agents — highly specialized AI systems designed for specific industries or use cases. As Microsoft founder Bill Gates said in a recent blog post: “Agents are smarter. They’re proactive — capable of making suggestions before you ask for them. They accomplish tasks across applications. They improve over time because they remember your activities and recognize intent and patterns in your behavior. “\n\nUnlike traditional software-as-a-service (SaaS) models, vertical AI agents do more than optimize existing workflows; they reimagine them entirely, bringing new possibilities to life. Here’s what makes vertical AI agents the next big thing in enterprise automation:\n\nElimination of operational overhead: Vertical AI agents execute workflows autonomously, eliminating the need for operational teams. This is not just automation; it’s a complete replacement of human intervention in these domains.\n\nUnlocking new possibilities: Unlike SaaS, which optimized existing processes, vertical AI fundamentally reimagines workflows. This approach brings entirely new capabilities that didn’t exist before, creating opportunities for innovative use cases that redefine how businesses operate.\n\nBuilding strong competitive advantages: AI agents’ ability to adapt in real-time makes them highly relevant in today’s fast-changing environments. Regulatory compliance, such as HIPAA, SOX, GDPR, CCPA and new and forthcoming AI regulations can help these agents build trust in high-stakes markets. Additionally, proprietary data tailored to specific industries can create strong, defensible moats and competitive advantages.\n\nEvolution from RPA to multi-agent AI\n\nThe most profound shift in the automation landscape is the transition from RPA to multi-agent AI systems capable of autonomous decision-making and collaboration. According to a recent Gartner survey, this shift will enable 15% of day-to-day work decisions to be made autonomously by 2028. These agents are evolving from simple tools into true collaborators, transforming enterprise workflows and systems. This reimagination is happening at multiple levels:\n\nSystems of record: AI agents like Lutra AI and Relevance AI integrate diverse data sources to create multimodal systems of record. Leveraging vector databases like Pinecone, these agents analyze unstructured data such as text, images and audio, enabling organizations to extract actionable insights from siloed data seamlessly.\n\nWorkflows: Multi-agent systems automate end-to-end workflows by breaking complex tasks into manageable components. For example: Startups like Cognition automate software development workflows, streamlining coding, testing and deployment, while Observe.AI handles customer inquiries by delegating tasks to the most appropriate agent and escalating when necessary.\n\nReal-world case study: In a recent interview, Lenovo’s Linda Yao said, “With our gen AI agents helping support customer service, we’re seeing double-digit productivity gains on call handling time. And we’re seeing incredible gains in other places too. We’re finding that marketing teams, for example, are cutting the time it takes to create a great pitch book by 90% and also saving on agency fees.”\n\nReimagined architectures and developer tools: Managing AI agents requires a paradigm shift in tooling. Platforms like AI Agent Studio from Automation Anywhere enable developers to design and monitor agents with built-in compliance and observability features. These tools provide guardrails, memory management and debugging capabilities, ensuring agents operate safely within enterprise environments.\n\nReimagined co-workers: AI agents are more than just tools — they are becoming collaborative co-workers. For example, Sierra leverages AI to automate complex customer support scenarios, freeing up employees to focus on strategic initiatives. Startups like Yurts AI optimize decision-making processes across teams, fostering human-agent collaboration. According to McKinsey, “60 to 70% of the work hours in today’s global economy could theoretically be automated by applying a wide variety of existing technology capabilities, including gen AI.”\n\nFuture outlook: As agents gain better memory, advanced orchestration capabilities and enhanced reasoning, they will seamlessly manage complex workflows with minimal human intervention, redefining enterprise automation.\n\nThe accuracy imperative and economic considerations\n\nAs AI agents progress from handling tasks to managing workflows and entire jobs, they face a compounding accuracy challenge. Each additional step introduces potential errors, multiplying and degrading overall performance. Geoffrey Hinton, a leading figure in deep learning, warns: “We should not be afraid of machines thinking; we should be afraid of machines acting without thinking.” This highlights the critical need for robust evaluation frameworks to ensure high accuracy in automated processes.\n\nCase in point: An AI agent with 85% accuracy in executing a single task achieves only 72% overall accuracy when performing two tasks (0.85 × 0.85). As tasks combine into workflows and jobs, accuracy drops further. This leads to a critical question: Is deploying an AI solution that’s only 72% correct in production acceptable? What happens when accuracy declines as more tasks are added?\n\nAddressing the accuracy challenge\n\nOptimizing AI applications to reach 90 to 100% accuracy is essential. Enterprises cannot afford subpar solutions. To achieve high accuracy, organizations must invest in:\n\nRobust evaluation frameworks: Define clear success criteria and conduct thorough testing with real and synthetic data.\n\nContinuous monitoring and feedback loops: Monitor AI performance in production and utilize user feedback for improvements.\n\nAutomated Optimization Tools: Employ tools that auto-optimize AI agents without relying solely on manual adjustments.\n\nWithout strong evaluation, observability, and feedback, AI agents risk underperforming and falling behind competitors who prioritize these aspects.\n\nLessons learned so far\n\nAs organizations update their AI roadmaps, several lessons have emerged:\n\nBe agile: The rapid evolution of AI makes long-term roadmaps challenging. Strategies and systems must be adaptable to reduce over-reliance on any single model.\n\nFocus on observability and evaluations: Establish clear success criteria. Determine what accuracy means for your use case and identify acceptable thresholds for deployment.\n\nAnticipate cost reductions: AI deployment costs are projected to decrease significantly. A recent study by a16Z found that the cost of LLM inference has dropped by a factor of 1,000 in three years; the cost is decreasing by 10X every year. Planning for this reduction opens doors to ambitious projects that were previously cost-prohibitive.\n\nExperiment and iterate quickly: Adopt an AI-first mindset. Implement processes for rapid experimentation, feedback and iteration, aiming for frequent release cycles.\n\nConclusion\n\nAI agents are here as our coworkers. From agentic RAG to fully autonomous systems, these agents are poised to redefine enterprise operations. Organizations that embrace this paradigm shift will unlock unparalleled efficiency and innovation. Now is the time to act. Are you ready to lead the charge into the future?",
      "# [Engineering flexible machine learning systems by traversing functionally invariant paths by Surya Narayanan on 2024-10-03](https://www.nature.com/articles/s42256-024-00902-x)\nArtificial neural networks now achieve human-level performance on machine learning tasks ranging from natural language understanding and image recognition to game playing and protein structure prediction. Recently, transformer-based models with self-attention have emerged as the state-of-the-art architecture across data modalities and task paradigms including natural language understanding, computer vision, audio processing, biological sequence analysis and context-sensitive reasoning1,2,3,4. Although transformer models can exhibit emergent behaviours including zero-shot task performance, models are commonly fine-tuned to increase performance and human accessibility4,5,6. In the ‘foundation model’ paradigm3, transformers with 108 to 1012 parameters are, first, pre-trained over large datasets on self-supervised tasks such as masked language modelling, causal language modelling or image masking5,6,7,8. Following self-supervised training, models are fine-tuned to increase performance on specific applications including question/answer or instruction following. Networks can be further sparsified or quantized to reduce memory and computation requirements in deployment environments.\n\nDue to the central role of model adaptation for foundation model optimization and deployment, many algorithms have emerged for updating model weights to increase performance without experiencing a catastrophic loss of the knowledge gained during self-supervised pre-training. However, a challenge is that in artificial neural networks, network function is encoded in the mathematical weights that determine the strength of connections between neural units (Fig. 1a,b). Gradient descent procedures train networks to solve problems by adjusting the weights of a network based on an objective function that encodes the performance of a network on a specific task. Learning methods, like backpropagation and low-rank adaptation (LoRA)9 gradient descent, adjust the network weights to define a single, optimal weight configuration to maximize performance on a task-specific objective function using training data. However, for all the current methods, network training alters network weights, inevitably resulting in the loss of information gained from previous training tasks or pre-training.\n\nAlthough many methods have been developed to achieve network adaptation without information loss, methods remain primarily grounded in empirical results. The machine learning community would benefit from mathematical tools that provide general insights and unification of model adaptation strategies within a common theoretical framework. Methods like LoRA, orthogonal gradient descent (OGD), relevance mapping networks (RMNs) and elastic weight consolidation (EWC) propose different criteria for updating weights in directions that do not impact performance on previously learned tasks. Yet, most current methods are based on local heuristics, for example, selecting gradient steps that are orthogonal to gradient steps taken for previously learned tasks. As in continual learning (CL) paradigms, sparsification frameworks execute heuristic prune/fine-train cycles to discover a compact, core subnetwork capable of executing the desired behaviour with decreased memory, power and computational requirements. Mathematical tools that provide a deeper insight into how the global, geometric structure of weight space enables or complicates adaptation might provide both conceptual principles and new algorithms.\n\nUnlike contemporary artificial neural nets, neural networks in the human brain perform multiple functions and can flexibly switch between different functional configurations based on context, goals or memory10. Neural networks in the brain are hypothesized to overcome the limitations of a single, optimal weight configuration and perform flexible tasks by continuously ‘drifting’ their neural firing states and neural weight configurations, effectively generating large ensembles of degenerate networks11,12,13,14,15. Fluctuations might enable flexibility in biological systems by allowing neural networks to explore a series of network configurations and responding to sensory input.\n\nHere we develop a geometric framework and algorithm that mimics aspects of biological neural networks by using differential geometry to construct path-connected sets of neural networks that solve a given machine learning task. Conceptually, we consider path-connected sets of neural networks, rather than single networks (isolated points in weight space) to be the central objects of study and application. By building sets of networks rather than single networks, we search within a submanifold of weight space for networks that solve a given machine learning problem and accommodate a broad range of secondary goals. Historically, results in theoretical machine learning and information geometry have pointed to the geometry of a model’s loss landscape as a potential resource for model adaptation. An emergent property of over-parameterized models is the existence of parameter degeneracy where multiple settings of the model parameters can achieve identical performance on a given task. Geometrically, parameter degeneracy leads16 to ‘flat’ objective functions17,18,19 along which network weights can be modified without loss of performance. To discover invariant subspaces, we introduce a Riemannian metric into weight space—a tensor that measures (at every point in parameter space) the change in the model output given an infinitesimal movement in model parameters. The metric provides a mathematical tool for identifying low-dimensional subspaces in weight space where parameter changes have little impact on how a neural network transforms input data. Riemannian metrics are widely used in physical theories to study the dynamics of particles on curved manifolds and spacetimes. Geometrically, the metric discovers flat directions in weight space along which we can translate a neural network without changing functional performance.\n\nUsing the Riemannian weight-space metric, we develop an algorithm that constructs functionally invariant paths (FIPs) in weight space that maintain network performance and ‘search out’ for other networks that satisfy additional objectives. The algorithm identifies long-range paths in weight space that can integrate new functionality without information loss. We apply the FIP framework to natural language (bidirectional encoder representations from transformers (BERT)), vision transformers (ViT and DeIT) and convolutional neural network (CNN) architectures. Our framework generates results that meet or exceed state-of-the-art performance for adaptation and sparsification tasks on academic-grade hardware. Our approach provides mathematical machinery that yields insights into how low-dimensional geometric structures can be harnessed for model adaptation without information loss. More broadly, we consider language models as objects acted on by transformations in series and we show that the transformations of models are intrinsically non-Abelian. The unified framework provides a general attack on a range of model adaptation problems and reveals connections between the mathematical theory of differential geometries and the emergent properties of large language and vision models.\n\nWe develop a mathematical framework that allows us to define and explore path-connected sets of neural networks that have divergent weight values but similar outputs on training data. We view the weight space of a neural network as a Riemannian manifold equipped with a local distance metric20,21. Using differential geometry, we construct paths through weight space that maintain the functional performance of a neural network and adjust the network weights to flow along a secondary goal (Fig. 1a). The secondary goal can be general; therefore, the framework can be applied to train networks on new classification tasks, sparsify networks and mitigate adversarial fragility.\n\nThe defining feature of a Riemannian manifold is the existence of a local distance metric. We construct a distance metric in weight space that defines the distance between two nearby networks to be their difference in output. We consider a neural network to be a smooth function f(x; w) that maps an input vector \\({\\bf{x}}\\in {{\\mathbb{R}}}^{{\\rm{k}}}\\) to an output vector \\(f({\\bf{x}};{\\bf{w}})={\\bf{y}}\\in {{\\mathbb{R}}}^{{\\rm{m}}}\\), where the map is parameterized by a vector of weights \\({\\bf{w}}\\in {{\\mathbb{R}}}^{{\\rm{n}}}\\) that are typically set in training to solve a specific task. We refer to \\(W={{\\mathbb{R}}}^{n}\\) as the weight space of the network, and we refer to \\({\\mathcal{Y}}={{\\mathbb{R}}}^{m}\\) as the output space (Fig. 1b,c)22. For pedagogical purposes, we will consider the action of f on a single input x. Supplementary Note 1 shows that our results naturally extend to an arbitrary number of inputs xi.\n\nWe initially ask how the output f(x; w) of a given neural network changes for small changes in network weights. Given a neural network with weights wt and fixed input x, we can compute the output of the perturbed network wt + dw for an infinitesimal weight perturbation dw as follows:\n\n$$f({\\bf{x}},{{\\bf{w}}}_{{\\bf{t}}}+{\\bf{dw}})\\approx f({\\bf{x}},{{\\bf{w}}}_{{\\bf{t}}})+{{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}\\,{\\bf{dw}},$$\n\n(1)\n\nwhere \\({{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}\\) is the Jacobian of f(x, wt) for a fixed \\({\\bf{x}},{J}_{ij}=\\frac{\\partial {f}_{i}}{\\partial {w}_{j}}\\), evaluated at wt.\n\nThus, the total change in network output for a given weight perturbation dw is\n\n$$\\begin{array}{rcl}|\\; f({\\bf{x}},{{\\bf{w}}}_{{\\bf{t}}}+{\\bf{dw}})-f({\\bf{x}},{{\\bf{w}}}_{{\\bf{t}}}){| }^{2}&=&{{\\bf{dw}}}^{{{\\rm{T}}}}\\,(\\;{{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}{({\\bf{x}})}^{{\\rm{T}}}\\,{{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}}))\\,{\\bf{dw}}\\\\ | {\\langle {\\bf{dw}},{\\bf{dw}}\\rangle }_{{{\\bf{g}}}_{{{\\bf{w}}}_{{\\bf{t}}}}}{| }^{2}&=&{{\\bf{dw}}}^{{{\\rm{T}}}}\\,{{\\bf{g}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}})\\,{\\bf{dw}}\\end{array},$$\n\n(2)\n\nwhere \\({{\\bf{g}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}})={{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}{({\\bf{x}})}^{{{\\rm{T}}}}\\,{{\\bf{J}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}})\\) is the metric tensor evaluated at the point wt ∈ W for a single data point x. The metric tensor is an n × n symmetric matrix that allows us to compute the change in network output given the movement of the network along any direction in weight space as \\({\\langle {\\bf{dw}},{\\bf{dw}}\\rangle }_{{{\\bf{g}}}_{{{\\bf{w}}}_{{\\bf{t}}}}({\\bf{x}})}\\). As we move through the weight space, the metric tensor W continuously changes, allowing us to compute the infinitesimal change in network output and move along a path γ(t) as the tangent vector \\(\\psi (t)=\\frac{\\,\\text{d}\\gamma (t)}{\\text{d}\\,t}\\).\n\nWe can extend the metric construction to cases in which we consider a set of N training data points X and view g as the mean of the metrics derived from individual training examples, such that \\({{\\bf{g}}}_{{\\bf{w}}({\\bf{X}})}={\\Sigma }_{i = 1}^{N}{{\\bf{g}}}_{{\\bf{w}}}({{\\bf{x}}}_{{\\bf{i}}})/N\\) for xi ∈ X or in expectation, \\({{\\bf{g}}}_{{\\bf{w}}}={{\\mathbb{E}}}_{x \\approx {p}_{{\\rm{data}}}(x)}[{{\\bf{g}}}_{{\\bf{w}}({\\bf{x}})}]\\), and gw(X) remains n × n (Supplementary Note 1). For a single data point, our construction of gw is identical to the neural tangent kernel (NTK), which is constructed as a kernel function of pairs of data points, \\(\\varTheta ({x}_{i},{x}_{j})=J{({x}_{i})}^{{{\\rm{T}}}}J({x}_{j})\\) (ref. 23), so that Θ(xi, xi) = gi(xi) (refs. 23,24,25,26). However, we distinguish our interpretation of g as a distance metric on W, the network parameter space from the NTK as a matrix-valued kernel function on data points xi and xj. The NTK Θ(xi, xj) arises through the analysis of the dynamics of a neural network under a gradient flow of the mean squared error. The NTK is interpreted as a kernel function defined on pairs of data points xi and xj, providing an analogy between the training dynamics of a neural network and kernel-based learning methods. Alternately, we interpret gw as a metric on a Riemannian parameter manifold (W, gw). At each point in the weight space, the metric defines the length, \\({\\langle {\\bf{dw}},{\\bf{dw}}\\rangle }_{{{\\bf{g}}}_{{\\bf{w}}}}\\), of a local perturbation to network weights dw as the perturbation’s impact on the functional output of the network (Fig. 1b,c) averaged over all the data points in X. The metric motivates the construction and analysis of network paths in weight space and consideration of properties including velocity, acceleration and notion of a geodesic path in weight space.\n\nAt every point in the weight space, the metric allows us to discover directions dw of movement that have a large or small impact on the output of a network. As we move along a path γ(t) ⊂ W in weight space, we sample a series of neural networks over time t. Using the metric, we can define a notion of ‘output velocity’ as \\({\\bf{v}}=\\frac{\\,\\text{d}\\,f({\\bf{x}},\\gamma (t))}{\\,\\text{dt}\\,}\\), which quantifies the distance a network moves in output space for each local movement along the weight-space path γ(t). We seek to identify FIPs in weight space along which the output velocity is minimized for a fixed magnitude change in weight. To do so, we solve the following optimization problem:\n\n$$\\begin{array}{c}{\\psi }^{* }(t)=\\mathop{{\\mathrm{argmin }}}\\limits_{\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}}{\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\right\\rangle }_{{{\\bf{g}}}_{\\gamma ({\\bf{t}})}}\\\\ \\,\\text{such that}\\,\\,{\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\right\\rangle }_{I}=\\epsilon \\end{array},$$\n\n(3)\n\nwhere we attempt to find a direction ψ*(t) along which to perturb the network, such that it is ϵ units away from the base network in the weight space (in the Euclidean sense, \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{I}=\\epsilon\\)) and minimize the distance moved in the networks’ output space, given by \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{\\gamma }({\\bf{t}})}\\). Here I is an identity matrix, with the inner product \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{I}\\) capturing the Euclidean distance in weight space27. The optimization problem is a quadratic program at each point in weight space. The metric g is a matrix that takes on a specific value at each point in weight space, and we aim to identify vectors \\({{\\bf{\\psi }}}^{* }(t)=\\frac{{\\rm{d}}\\gamma (t)}{{\\rm{d}}t}\\) that minimize the change in the functional output of the network.\n\nWe will often amend the optimization problem with a second objective function L(x, w). We can enumerate paths that minimize the functional velocity in the output space and move along the gradient of the second objective (∇wL). We define a path-finding algorithm that identifies a direction ψ*(t) in the weight space by minimizing the functional velocity in the output space and moves along the gradient of the second objective (∇wL):\n\n$$\\begin{array}{rcl}&&{\\psi }^{* }(t)=\\mathop{{\\mathrm{argmin }}}\\limits_{\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}}\\left({\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\right\\rangle }_{{{\\bf{g}}}_{\\gamma (t)}}+\\beta {\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},{\\nabla }_{{\\bf{w}}}L\\right\\rangle }_{I}\\right)\\\\ &&\\,\\text{such that}\\,{\\left\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\right\\rangle }_{I}=\\epsilon \\end{array} ,$$\n\n(4)\n\nwhere the first term \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{\\gamma (t)}}\\) identifies functionally invariant directions, the second term \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},{\\nabla }_{{\\bf{w}}}L\\rangle }_{I}\\) biases the direction of motion along the gradient of a second objective and β weighs the relative contribution of the two terms. When L = 0, the algorithm merely constructs paths in weight space that are approximately isofunctional (θ*(t) = ψ*(t)), that is, the path is generated by steps in the weight space comprising networks with different weight configurations and preserving the input–output map. L(x, w) can also represent the loss function of a second task, for example, a second input classification problem. In this case, we identify vectors that simultaneously maintain performance on an existing task (via term 1) as well as improve performance on a second task by moving along the negative gradient of the second-task loss function ∇wL. We consider constructing FIPs with different objective functions (L(x, w)) similar to applying different ‘operations’ to neural networks that identify submanifolds in the weight space of the network accomplishing distinct tasks of interest.\n\nTo approximate the solution to equation (4), in large neural networks, we developed a numerical strategy that samples points in an ϵ ball around a given weight configuration, and then performs gradient descent to identify vectors θ*(t). We note that the performance of a neural network on a task is typically evaluated using a loss function \\(L:{{\\mathbb{R}}}^{m}\\to {\\mathbb{R}}\\), so that \\(L(\\;f({\\bf{x}};{\\bf{w}}))\\in {\\mathbb{R}}\\). Networks with a constant functional output f(x, w) along a path γ(t) will also have constant loss L(f(γ(t); w)). As gradient descent training minimizes the loss by finding \\(\\frac{\\partial L}{\\partial {w}_{i}}=0\\), the evaluation of loss curvature requires second-order methods to discover flat or functionally invariant subspaces. We find that working directly with f(x; w) allows us to identify functionally invariant subspaces through first-order quantities \\(\\frac{\\partial {f}_{i}}{\\partial {w}_{j}}={J}_{ij}\\), and thus, we can compute the metric using the output of automatic differentiation procedures commonly used in training. Working with f(x, w) instead of L also provides additional resolution in finding invariant subspaces since f(x; w) is often a vector-valued versus scalar-valued function.\n\nWe note that the mathematical framework provides avenues for immediate generalization to consider paths of constant velocity, paths that induce a constant rate of performance change; such paths are known as geodesics28. On any Riemannian manifold, we can define geodesic paths emanating from a point xp as paths of constant velocity \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{\\gamma (t)}}={v}_{0}\\) (Supplementary Note 4.1) that satisfy the following geodesic equation:\n\n$$\\frac{{{\\rm{d}}}^{2}{w}_{\\eta }}{{\\rm{d}}{t}^{2}}+{\\varGamma }_{\\mu \\nu }^{\\eta }\\frac{{\\rm{d}}{w}_{\\mu }}{{\\rm{d}}t}\\frac{{\\rm{d}}{w}_{\\nu }}{{\\rm{d}}t}=0,$$\n\n(5)\n\nwhere \\({\\varGamma }_{\\mu \\nu }^{\\eta }\\) specifies the Christoffel symbols (\\({\\varGamma }_{\\mu \\nu }^{\\eta }={\\sum }_{r}\\frac{1}{2}{g}_{\\eta r}^{-1}\\left(\\frac{\\partial {g}_{r\\mu }}{\\partial {x}^{\\nu }}+\\right.\\)\\(\\left.\\frac{\\partial {g}_{r\\nu }}{\\partial {x}^{\\mu }}-\\frac{\\partial {g}_{\\mu \\nu }}{\\partial {x}^{r}}\\right)\\)) on the weight manifold. Such geodesic paths have a constant, potentially non-zero, rate of performance decay on the previous task during adaptation. The Christoffel symbols record infinitesimal changes in the metric tensor (g) along a set of directions on the manifold (Supplementary Information). Since the computation and memory for evaluating Christoffel symbols scales as a third-order polynomial of network parameters (\\({\\mathcal{O}}({n}^{3})\\)), we propose the optimization equation (4) for evaluating ‘approximate’ geodesics in the manifold.\n\nFIP enables CL with ViT vision transformers\n\nThe FIP framework allows us to address a series of model adaptation goals within a common geometric framework. To demonstrate CL, we applied the FIP to adapt the ViT vision image transformer and BERT language model in CL without catastrophic forgetting. We train a neural network on a base task and modulate the weights in the network to accommodate additional tasks by solving the optimization problem in equation (4), setting L(x, w) as the classification loss function specified by the additional task, whereas \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{{\\rm{Task}}1}}\\) measures the distance moved in the networks’ output using the metric from the initial task (in equation (4)). To accommodate the additional tasks, we append output nodes to the base network and solve the optimization problem for a fixed value of β by simultaneously minimizing the distance moved in the networks’ output space (Fig. 1c, light-blue arrow) corresponding to the first task and maximizing alignment with the gradient of L(x, w) encoding the classification loss from the second task. In this manner, we construct an FIP (Fig. 5a, purple dotted line) in weight space generating a network that performs both Task 1 and Task 2.\n\nWe used a standard CL task30 (Fig. 2a). We split the Canadian Institute for Advanced Research (CIFAR)-100 dataset into a series of subtasks in which each subtask requires the network to identify ten object categories (Fig. 2a). Previously, the state-of-the-art performance for this task was achieved by the ResNet CNN30. ViT networks can potentially realize vast performance gains over ResNet architectures as the baseline performance for ResNet is ~80% accuracy. We observed that ViT exhibits 94.5% accuracy when fine-tuned on the CIFAR-100 dataset8,31 for generative replay, achieving a CIFAR-100 CL accuracy of ~80%.\n\nWe applied the FIP algorithm to achieve CL on SplitCIFAR using both ViT-B (86M parameters) and ViT-H (632M parameters) architectures. In each case, a single task requires the network to learn to recognize 10 CIFAR classes where we used 5,000 images (total, 6,000 images) per class with a batch size of 512. We used a single NVIDIA RTX2060 6 GB for ViT-B and RTX3090 24 GB for ViT-H (Fig. 2b). After continually training 5 SplitCIFAR subtasks, ViT-B achieved a mean performance of 91.2% and ViT-H achieved 89.3% compared with 94.5% performance for ViT-B that was simultaneously trained on all the 50 CIFAR classes without CL (Fig. 2b,c). Training for ViT-B using an NVIDIA RTX2060 6 GB machine took ~3.5 h for each subtask with the FIP and ~2.5 h with fine tuning. Training for ViT-H using an NVIDIA RTX3090 24 GB machine took ~4.8 h for each subtask with the FIP and ~3.9 h with standard fine tuning.\n\nThus, the FIP procedure enables ViT-B and ViT-H to learn new tasks without information loss and achieves a higher performance than CL methods that have been conventionally applied to the ResNet network31. The strength of our method is that it can be applied to fine-tune any existing transformer or CNN architecture.\n\nComparison of FIP with LoRA on CL with ViT\n\nThe LoRA approach to network fine tuning was recently introduced to enable the fine tuning of large transformer networks including GPT-3 (ref. 32). To fine-tune pre-trained networks on new tasks, LoRA forces weight updates W0 to a network to be low rank through a matrix factorization strategy, where W0 is generated as the product W0 = AB of matrices A and B with inner dimension r; here r is set to be a number much smaller than network size k (r ≪ k).\n\nAlthough not explicitly designed to alleviate catastrophic forgetting, LoRA is discussed in many venues including HuggingFace (HF) as a technique that mitigates catastrophic forgetting. Further, LoRA is widely applied for fine-tuning tasks on large networks in industrial settings and therefore represents an important comparison point for FIP. We applied LoRA to iteratively learn components of the SplitCIFAR task (Fig. 2) using ViT-H (640M parameters) spanning a range of r = rank(W0) from 1 to 256. We found that LoRA exhibits signatures of catastrophic forgetting independent of rank in these tests (Fig. 2e,f). When ViT-H is trained to achieve 99% accuracy on Task 1 (CIFAR-0:9 task), the network loses accuracy on Task 1 as it is trained via LoRA on Task 2 (CIFAR-10:19 task) (Fig. 2e,f and Extended Data Table 1). Following the application of LoRA, ViT-H achieves 96.6% accuracy on Task 2 for r = 256 at the expense of 0% accuracy on Task 1 (Fig. 2e,f and Extended Data Table 1). When rank = 1, the LoRA accuracy was limited to 10% on Task 2 and still lost accuracy on Task 1 (Task 1 accuracy, 0%). Thus, LoRA fine tuning leads to a collapse in accuracy on Task 1 when fine-tuned to perform an additional task.\n\nPerformance of FIP on CL with CNN architectures\n\nIn addition to transformers, the FIP framework can also be applied to CNN architectures, which provides a helpful point of comparison with previous CL methods. On image analysis tasks like CIFAR-10, transformers like ViT outperform CNN architectures on classification accuracy metrics. However, CNNs are widely used in computer vision and have been the architecture used for most prior CL work. We applied FIP to ResNet18 to study CL on SplitCIFAR and compared with RES-CIFAR30, EWC33, RMN30, generative replay31 and gradient episodic memory (GEM)34. We found that the FIP could achieve CL with accuracy that meets or exceeds other state-of-the-art approaches (Fig. 2f, Extended Data Table 2 and Supplementary Fig. 2), with RMN achieving 80% accuracy on SplitCIFAR compared with 82% for FIP on ResNet14. In general, the global accuracy of the resulting CNN was lower than the transformer ViT, consistent with the network’s relative performance on the baseline CIFAR task. The results demonstrate that FIP performs well on transformer and CNN architectures and on par or above other state-of-the-art approaches. Although the FIP algorithm has conceptual similarities with EWC, the mathematical generality of the FIP allows the approach to scale to perform multiple iterative incremental learning tasks and to explicitly construct FIPs that traverse the weight space (Fig. 2d).\n\nFIP enables CL with BERT NLP transformer\n\nNext, we demonstrated the flexibility of the FIP approach by using the method to fine-tine the BERT network on the Internet Movie Database (IMDb) sentiment analysis task following initial training on Yelp full-five-star review prediction task (Fig. 3). The BERT network has a total of 12 layers, or transformer blocks, with 12 self-attention heads in each layer and a total of 110M parameters5. Training BERT to detect customer opinions of a product based on text reviews left on websites like Yelp or IMDb results in catastrophic forgetting, especially when sequentially training on multiple user-review datasets (say, Yelp reviews followed by IMDb) (Fig. 3a). The FIP maintains BERT performance on Yelp reviews (at 70%; blue) and increasing its accuracy on IMDb review classification (from 0% to 92%; orange) (Fig. 3b). Potentially, BERT has as an initial accuracy of 0% on IMDb due to differences in the outputs for each task, which are binary for IMDb but five-star scoring for Yelp. The FIP in BERT weight space (Fig. 3) is much longer than the route taken by conventional training, enabling the global exploration of the BERT weight landscape to identify networks that simultaneously maintain performance on Yelp reviews and learn the IMDb sentiment classification. Conventional fine tuning of BERT on IMDb reviews increases its performance on sentiment classification on IMDb (from 0% to 92%; orange) and abruptly forgets the sentiment analysis on Yelp reviews (dropping from an accuracy of 69.9% to 17%; blue) within 30 training steps (Fig. 3b). We also compared the performance of FIP with LoRA on the natural language processing (NLP) training task (Fig. 3d–f). We found that LoRA exhibits a considerable performance decay on the Yelp task and learning IMDb across ranks (Fig. 3d,f). LoRA also exhibits anticorrelation between Yelp and IMDb accuracy across training epochs (Fig. 3d). We also found that the FIP algorithm generally induces more extensive weight change than LoRA measured by the Frobenius norm of weight updates for both approaches (Fig. 3e).\n\nNeural network sparsification with FIP algorithm\n\nThe critical aspects of the FIP framework are that the framework generalizes and addresses a broad range of machine learning meta-problems by considering a more general set of secondary objective functions. In particular, we next apply the FIP framework to perform sparsification, reducing the number of non-zero weights, which is important for reducing the memory and computational footprint of a network35. To sparsify neural networks, we solve equation (4), the core FIP optimization problem, with a secondary loss function L(wt, w, p) that measures the Euclidean distance between a network and its p-sparse projection obtained by setting p% of the networks’ weights to zero (Fig. 4a).\n\nUsing the framework, we sparsified the vision transformer DeIT, which has been used for benchmarking sparsification methods36 on vision transformers. The paradigm uses the ImageNet 1,000-object image classification task (ImageNet1K dataset), and attempts to sparsify DeIT. DeIT-Base (DeIT-B) is an 86M parameter transformer model that was derived from ViT37. We use the FIP algorithm to set the weight parameters to zero without loss of performance on the ImageNet1K classification task. The simplicity of the FIP algorithm allowed us to achieve an entire range of target sparsities ranging from 0% to 80%. We found that FIP had performance very near to that of the SViT network at the benchmark of 40% sparsity, with FIP performing at 80.22% and SViT performing at 81.56% accuracy (Fig. 4b(i)), with compute times given (Fig. 4b(ii)) on an NVIDIA RTX3090 24 GB. Additionally, we applied FIP to perform the sparsificaiton of CNN architectures (Supplementary Fig. 3) for the Modified National Institute of Standards and Technology (MNIST) and CIFAR tasks, showing that the FIP can also achieve high sparsification values and maintain accuracy in the ResNet and LeNet CNN architectures (Supplementary Fig. 3).\n\nThen, we applied FIP to sparsify the BERT base from 0% to 80% sparsity for all the general language understanding evaluation (GLUE) NLP tasks. For this task, we obtained an NVIDIA A100 machine from PaperSpace. The GLUE benchmark consists of three categories of natural language understanding tasks: (1) single-sentence tasks (corpus of linguistic acceptability (CoLA) and Stanford sentiment (SST-2)), (2) similarity and paraphrase tasks (Microsoft research paraphrase corpus (MRPC), Quora question pairs (QQPs) and Semantic Text Similarity Benchmark (STS-B)) and (3) inference tasks (multi-genre natural language inference (MNLI), question-answering natural language inference (QNLI) and recognizing textual entailment (RTE)). Again, because of its ease of use and efficiency, we were able to span the entire range of sparsities identifying differential performance across GLUE tasks (Fig. 4c and Supplementary Fig. 4). FIP was able to generate sparse versions of BERT that had 81.65% accuracy at 50% sparsity on the SST-2 task. We provide compute times in seconds for the sparsification of BERT on MRPC, which efficiently runs on an NVIDIA A100 machine (Fig. 4d).\n\nFIP ensemble confers robustness against adversarial attack\n\nThe path-connected sets of networks generated by the FIP can also be applied to perform inference and increase the robustness of inference tasks to data perturbation. Although deep CNNs have achieved remarkable performance on image recognition tasks, human-imperceptible additive perturbations, known as adversarial attacks, can be applied to an input image and induce catastrophic errors in deep neural networks (Fig. 5b). The FIP algorithm provides an efficient strategy to increase network robustness and mitigate adversarial failure by generating path-connected sets of networks with diverse weights. We then apply the path-connected network sets to perform robust image classification by averaging their output.\n\nTo demonstrate that the FIP algorithm can mitigate adversarial attacks, we trained a 16-layered CNN—VGG16—with 130M parameters to classify CIFAR-10 images with 92% test accuracy. We, then, generated adversarial test images using the projected gradient descent (PGD) attack strategy. On adversarial test images, the performance of VGG16 dropped to 37% (Fig. 5b and Supplementary Fig. 1). To mitigate the adversarial performance loss, we applied the FIP algorithm to generate an ensemble of functionally invariant networks by setting L = 0 in the optimization problem in equation (4) and setting \\({\\langle \\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t},\\frac{{\\rm{d}}\\gamma }{{\\rm{d}}t}\\rangle }_{{{\\bf{g}}}_{{\\rm{CIFAR}}10}}\\) to be the distance moved in the networks’ output space for CIFAR-10 images. We use the FIP ensemble to classify images by summing the ‘softmaxed’ outputs of the ensemble.\n\nUsing an ensemble of ten networks sampled along an FIP, we achieve an accuracy of 55.61 ± 1.1%, surpassing the performance of the DeepNet ensemble (composed of 10 independently trained deep networks) by 20.62% (Fig. 5c). The FIP ensemble’s adversarial performance also surpasses other state-of-the-art ensemble approaches including adaptive diversity-promoting (43.84 ± 7.8%) ensemble and the fast geometric ensembling (41.7 ± 0.34) method. The two factors contributing to the FIP ensemble’s robustness are (1) high intra-ensemble weight diversity, calculated by the representation diversity score; and (2) low coherence with a trained surrogate network (used to generate adversarial images) (Fig. 5e,f). FIP networks have a higher representation diversity score in their early processing layers, from layer 1 to layer 6, compared with the DeepNet ensemble, indicating that individual networks in the FIP ensemble extract different sets of local features from the adversarial image, preventing networks from relying on similar spurious correlations for image classification. We speculate that weight/parameter diversity in the FIP ensemble leads to differential susceptibility to adversarial examples but consistent performance on training and test examples. The approach has analogies with the model soup approaches explored in ref. 38.\n\nGenerating path-connected sets of language models\n\nConceptually, the most important aspect of the FIP framework is that it unifies a series of machine learning meta-tasks (CL and sparsification) into a single mathematical framework. Mathematically, when we solve equation (4) with a given secondary loss function, we move an existing network w(0) along a path in weight space generating a new network w(t) in which the parameter t increments the length of a path. Each additional loss function generates a new transformation of a base network, for example, generating a network adjusted to accommodate an additional data analysis problem or a secondary objective like sparsification. Network transformation maps can be iterated and applied to generate a family of neural networks optimized for distinct subtasks. The resulting path-connected set of neural networks can then be queried for networks that achieve specific user goals or solve additional machine learning problems.\n\nThe problem of customization is particularly important for transformer networks4,39,40,41. Transformers like BERT and Roberta are typically trained on generic text corpus like the common crawl, and the specialization of networks on specific domains is a major goal3,32. We applied the iterative FIP framework to generate a large number of NLP networks customized for different subtasks and sparsification goals. Transformer networks incorporate layers of attention heads that provide contextual weight for positions in a sentence. Transformer networks are often trained on a generic language processing task like sentence completion in which the network must infer missing or masked words in a sentence. Models are then fine-tuned for specific problems including sentiment analysis, question answering, text generation and general language understanding39. Transformer networks are large containing hundreds of millions of weights, and therefore, model customization can be computationally intensive.\n\nWe applied the FIP framework to perform a series of model customization tasks through the iterative application of FIP transformations on distinct goals. The BERT network has a total of 12 layers, or transformer blocks, with 12 self-attention heads in each layer and a total of 110M parameters5. Using the FIP framework, we sequentially applied two operations (CL and compression (Co)) to BERT models trained on a range of language tasks, by constructing FIPs in the BERT weight space using different objective functions (L(x, w)) and solving the optimization problem in equation (4) (Fig. 6).\n\nWe demonstrated that we could apply the CL and Co operations in sequence. Beginning with the BERT base model, we applied the FIP model to generate networks that could perform Yelp and IMDb sentiment analysis, and then compressed the resulting networks to generate six distinct networks with sparsity ranging from 10% to 60%, where all the sparsified networks maintained performance on the sentiment analysis tasks (Fig. 6a). We, then, performed the same operations, but changed the order of operations (Fig. 6b). The models generated through the application of CLCo(w) and CoCL(w) achieved similar functional performance in terms of sparsification and task performance but had distinct weight configurations.\n\nIn total, we used the FIP framework to generate networks using a set of different natural language tasks and Co tasks, yielding a path-connected set of 300 BERT models (Fig. 6c). The 300 networks define a submanifold of weight space that contains models customized for distinct subtasks. Then, the submanifold provides a computational resource for solving new problems. We can query the resulting FIP submanifold with unseen data by using perplexity as a measure of a networks intrinsic ability to separate an unseen dataset. Using perplexity, we queried the FIP submanifold of BERT networks with IMDb data and WikiText data. We found that the distinct language datasets achieve minimal perplexity on different classes of networks. WikiText obtains optimal performance on CoCL networks and IMDb achieves optimal performance on CLCo networks. These results demonstrate that the FIP framework can generate diverse sets of neural networks by transforming networks using distinct meta-tasks. The submanifolds of weight space can then be inexpensively queried to identify networks pre-optimized for new machine learning problems.\n\nThe major contribution of our framework is that it provides a unified theoretical and mathematical framework through which a set of problems can be addressed across a variety of neural network architectures. To the best of our knowledge, no single mathematical framework has been applied to address the set of machine learning meta-problems and diversity of neural network architectures that we address with the FIP framework. Further, with the rise of transformer models, we have seen the emergence of architecture-specific strategies for sparsification and CL. We provide a unified framework that can achieve a similar quality of results across different classes of architectures (CNN and transformers) and across different transformer variants. Although representation learning frameworks have been pursued in fields including reinforced learning42,43, our work develops a geometric framework that identifies invariant subspaces within the parameter space for distinct auxiliary tasks. We demonstrate that the framework scales to transformer models with hundreds of millions of parameters. Therefore, our framework provides a unified theoretical and mathematical model for connecting the geometry of parameter space with different model subtasks as well as practically scaling to provide results in line with the state-of-the-art, more specific approaches. The FIP is also related to Jacobian regularization approaches that have been explored to stabilize model training and prevent over-fitting44. Here we review some of the specific approaches that have been studied for CL, sparsification and adversarial robustness.\n\nCL and catastrophic forgetting\n\nCL has been studied extensively in the machine learning literature45,46,47 for classical CNN as well as vision and language transformers48,49. A wide variety of approaches have been developed to train neural networks on a sequence of tasks without the loss of prior task performance including regularization-based methods, weight parameter isolation methods and replay-based methods. Many classic CL/catastrophic forgetting (CF) approaches were developed for CNN architectures with <100M parameters. With the emergence of transformer models for NLP and computer vision, approaches have become more model specific with approaches such as regularization-based methods and parameter isolation methods. Regularization-based methods assign constraints to prevent parameter changes to important parameters from prior tasks. The FIP framework can be viewed as a generalized regularization framework that applies at any point in the parameter space. Methods like EWC33, OGD50, RMN30 and synaptic intelligence51 penalize the movement of parameters that are important for solving previous tasks to mitigate catastrophic forgetting. RMN identifies the relevant units in the pre-trained model that are most important for the new task using a thresholding strategy. OGD constrains movement in the parameter space to move in a subspace that is orthogonal to gradients from prior tasks. OGD was applied to CL tasks on the MNIST data50 on a small, three-layer multi-layer perceptron. The OGD method requires knowledge of prior task gradients and is a local method, like EWC. Although (locally in the parameter space) it makes sense to constrain changes in the network parameters along the orthogonal subspace, there is no mathematical reason that long-range updates should satisfy this constraint. Past gradient directions become less meaningful as we move away from an initial trained network and begin traversing long-range paths in the parameter space in search of good networks. By using a metric tensor construction that is defined at every point in the parameter space, the FIP framework can traverse long-range paths in the parameter space, sometimes making weight updates that are, in fact, not orthogonal to gradients.\n\nReplay-based methods store and replay past data or apply generative models to replay data during training to mitigate catastrophic forgetting52,53. Regularization-based methods including EWC constrain the learning of important parameters from previous tasks by assigning constraints to prevent parameter changes. Architecture expansion or dynamic architecture methods like progressive neural networks54, dynamically expandable networks55 and super-masks in position56 adapt, grow or mask the model’s architecture, respectively, allowing specialization without interfering with previous knowledge. Parameter isolation methods: these methods isolate specific parameters or subsets of parameters to be task specific, preventing interference with previous knowledge. Examples include the context-dependent gating approach or the learning-without-forgetting method. Instead of modifying the learning objective or replaying data, various methods use different model components for different tasks. In progressive neural networks, dynamically expandable networks and reinforced CL (RCL) the model is expanded for each new task.\n\nLow-rank fine tuning with LoRA\n\nLoRA32 was designed to enable the computationally efficient adaptation of large transformer models by forcing weight updates to be low ranked. LoRA achieves impressive performance on the fine tuning of very large models including GPT-3 (175B). LoRA achieves its performance by introducing a low-rank structure heuristic into the weight update through matrix factorization, forcing ΔW = AB, where A and B have an inner dimension r, and thus controlling the rank of W to be r. We view FIP and LoRA as complementary methods and seek to incorporate low-rank constraints into new versions of the FIP algorithm.\n\nSparsification methods\n\nSparsity methods for neural networks aim to reduce the number of parameters or activations in a network, thereby improving efficiency and reducing memory requirements. Unstructured pruning techniques apply strategies based on network weights or weight gradients to remove weights that do not contribute to network performance. Unstructured sparsity methods seek to remove weights at any position in the network. The lottery ticket hypothesis (LTH) demonstrated that dense networks often contain sparse subnetworks, named winning tickets, that can achieve high accuracy when isolated from the dense network57. LTH methods discover these sparse networks through an empirical pruning procedure. Unstructured pruning methods remove inconsequential weight elements using criteria including weight magnitude, gradient and Hessian47,58,59. Recent strategies60,61 dynamically extract and train sparse subnetworks instead of training the full models. Evolutionary strategies including the sparse evolutionary training procedure62,63 begin with sparse topologies (for example, Erdős–Rényi generated graphs) in training and optimize topology and network weights during training. Historically, sparsity methods have been applied to convolutional and multi-layer perceptron architectures. Recent frameworks have been introduced for the sparsification of transformer architectures. For example, a vision transformer sparsification strategy SViTE36 was developed that uses model training integrated with prune/grow strategies, achieving the sparsification of the ViT family of transformers. The sparsification of BERT64 was explored by identifying specific internal network topology that can achieve high performance on NLP tasks with sparse weight distribution through empirical investigation and ablation experiments.\n\nRobustness to adversarial attack\n\nFinally, we demonstrate that the FIP can generate ensembles of networks with good performance in adversarial attack paradigms. Like CL and sparsificaiton, adversarial attack mitigation has been addressed by a wide range of methods including augmented training with adversarial examples65, through the use of diversified network ensembles66, as well as through re-coding of the input67. We demonstrate that the FIP framework can generate network ensembles that have intrinsic resistance to adversarial attack compared with base networks.\n\nIn the main text, we have introduced a geometric framework to solve three core challenges in modern machine learning, namely, (1) alleviating catastrophic forgetting, (2) network sparsification and (3) increasing robustness against adversarial attacks. We will describe the datasets, parameters/hyperparameters used for the algorithms and the pseudo-code for each of the core challenges addressed in the main text.\n\nCatastrophic forgetting\n\nDatasets and preprocessing\n\nThe models were tested on two paradigms:\n\nSplitCIFAR100: ten sequential-task paradigm, where the model is exposed to ten tasks, sampled from the CIFAR-100 dataset. The CIFAR-100 dataset contains 50,000 RGB images for 100 classes of real-life objects in the training set, and 10,000 images in the testing set. Each task requires the network to identify images from ten non-overlapping CIFAR-100 classes.\n\nWe performed two operations, namely, (1) network Co and (2) CL on BERT, fine-tuned on different language datasets, downloaded from the HF website.\n\nWikipedia: the Wikipedia English datasets are downloaded from https://huggingface.co/datasets/wikipedia. We used the Wikipedia dataset on the masked language model (MLM) task.\n\nYelp reviews: the Yelp review dataset is obtained from HF, downloaded from https://huggingface.co/datasets/yelp_review_full.\n\nIMDb reviews: the IMDb review dataset is obtained from HF, downloaded from https://huggingface.co/datasets/imdb.\n\nGLUE dataset: the GLUE dataset is obtained from HF, downloaded from https://huggingface.co/datasets/glue. The GLUE tasks performed in this paper are (1) QQPs, (2) SST-2, (3) CoLA, (4) RTE, (5) MNLI, (6) MRPC and (7) QNLI.\n\nParameters used\n\nFIP for CL: η = 2 × 10–5, λ = 1, n memories from previous task = 2,000/650,000 = (0.8% previous dataset); optimizer used, AdamW.\n\nFIP for BERT sparsification: η = 2 × 10–5, λ = 1; optimizer used, AdamW. Final (desired) network sparsities for the GLUE task: task (p% sparse): RTE (60% sparse), CoLA (50% sparse), STS-B (50% sparse), QNLI (70% sparse), SST-2 (60% sparse), MNLI (70% sparse), QQP (90% sparse) and MRPC (50% sparse). Final (desired) network sparsities for Wikipedia sentence completion: [10%, 20%…90%].\n\nNetwork architectures\n\nAll state-of-art methods for alleviating CF (presented in the main text) in the two-task and five-task paradigm used the same network architectures: the ViT-Base and ViT-Huge transformer variants described at https://huggingface.co/docs/transformers/model_doc/vit. BERT is a popular transformer model with 12 layers (transformer blocks), each with a hidden size of 768, 12 self-attention heads in each layer with a total of 110M parameters (https://huggingface.co/docs/transformers/model_doc/bert). BERT has been pre-trained on 45 GB of Wikipedia data, using the MLM task and next-sentence prediction.\n\nSentence completion (masking) tasks\n\nFor the masking tasks (where 15% of the words in the input sentence are masked (or blanked)), the BERT network has an MLM head appended to the network. The MLM head produces a three-dimensional tensor as the output, where the dimensions correspond to (1) the number of sentences in a single batch (batch-size), (2) number of blanked-out words in a sentence and (3) number of tokens in the BERT vocabulary (30,000 tokens).\n\nSentence classification tasks\n\nFor the sentence classification task, a sentence classifier head was appended to the BERT architecture. Here the classifier head produces a two-dimensional output tensor, where the dimensions correspond to (1) batch-size and (2) number of unique classes in the classification problem.\n\nPseudo-code: FIP construction for CF problems\n\nAlgorithm 1\n\nFIP construction for CF problems:\n\nRequire λ; η, step-size hyperparameters; NT, number of sequential tasks\n\n1: procedure FIP-CF(λ, η, NT)\n\n2: random initialize w0\n\n3: Bi←{}∀i = 1, 2…NT ⊳ buffer with nmem memories from previous tasks\n\n4: 1 for i←1 to NT do\n\n5: wi←wi−1\n\n6: (x, t)←Task i ⊳ minibatch of images (x) and target labels (t) from task i\n\n7: Bi←Bi ∪ x ⊳ update buffer\n\n8: CEloss←Cross-Entropy(f(x, wi), t) ⊳ classification loss for new task\n\n9: Yloss←0\n\n10: for j←1 to i – 1 do\n\n11: Yloss += Ydist(f(x, wi), f(Bj, wi−1)) ⊳ distance moved in output space (Y)\n\n12: end for\n\n13: S←CEloss + λ × Yloss ⊳ construct FIP with direction from loss gradient\n\n14: \\({{\\bf{w}}}_{{\\bf{i}}}\\leftarrow {{\\bf{w}}}_{{\\bf{i}}}-\\eta {\\nabla }_{{{\\bf{w}}}_{{\\bf{i}}}}S\\)\n\n15: end for\n\n16: return wi\n\n17: end procedure\n\nCode specifications\n\nAll the code was written in the PyTorch framework, and the automatic differentiation package was extensively used for constructing the computational graphs and computing gradients for updating the network parameters. The code for constructing the FIPs for the 2-task and 20-task paradigm was run on Caltech’s high-performance computing cluster using a single GPU for a total time of 1 h and 10 h, respectively.\n\nParameters used\n\nThe parameters used for the current state-of-art methods across different models and datasets have been selected after grid search to maximize accuracy.\n\nFIP for 2-task paradigm: η = 0.01; optimizer used, Adam; weight-decay = 2 × 10–4, λ = 1, n memories from previous task = 500/60,000 (0.8% of the previous dataset).\n\nEWC for 2-task paradigm: optimizer used, Adam; EWC regularization coefficient (λ) = 5,000, learning rate = 0.001, batch-size = 128, number of data samples from previous task to construct the Fisher metric = 500.\n\nFIP for 20-task paradigm: η = 0.01; optimizer used, Adam; weight-decay = 2 × 10–4, λ = 1, n memories from previous task = 250/2,500 (10% of the previous tasks).\n\nGEM for 20-task paradigm: n memories from previous task = 250, learning rate = 0.01, number of epochs (per task) = 20, memory strength = 0.5, batch-size = 128.\n\nEWC for 20-task paradigm: optimizer used, Adam; EWC++, α = 0.9, λ = 5,000, learning rate = 0.001, Fisher metric update after 50 training iterations and batch-size = 128.\n\nImplementation of other CF methods\n\nWe implemented the EWC method by adapting the code available at https://github.com/moskomule/ewc.pytorch. The GEM method was applied by adapting the code available at https://github.com/facebookresearch/GradientEpisodicMemory.\n\nLoRA: LoRA training for the model was done using the PEFT library71. We instantiate the base language model (for example, model trained on the Yelp dataset). We create a LoRAConfig object, where we can specify the following parameters: LoRA rank (ranks of 1, 4, 8, 16, 32), LoRA α (scaling factor): (usually we use α = rank × 2). Target modules: ‘query’ and ‘value’ in the attention layer (across all the layers of the network) and LoRA dropout = 0.1. In the LoRA experiments, we explored a variety of different learning rates to stabilize training including 10−6→10−5. For ViT experiments, we use a ramping procedure with a learning rate that starts at 1 × 10–3 until it reaches the maximum peak at 1 and then decreases.\n\nExample parameter settings for LoRA on NLP for BERT are as follows.\n\nLoRA training with rank = 16, α = 32; learning rate = 3 × 10–5\n\nLoRA training with rank = 16, α = 32; learning rate = 1 × 10–5\n\nLoRA training with rank = 16, α = 32; each step corresponds to 400 samples at learning rate = 1 × 10–5\n\nLoRA training with rank = 16, α = 32; each step corresponds to 1,600 samples at learning rate = 1 × 10–5\n\nLoRA training with rank = 16, α = 32; each step corresponds to 1,600 samples at learning rate = 2 × 10–6 (initial training steps)\n\nPost-convergence: LoRA training with rank = 4, α = 8; each step corresponds to 1,600 samples at learning rate = 2 × 10–6\n\nNetwork sparsification\n\nDatasets and preprocessing\n\nThe models were sparsified using a well-known image dataset, ImageNet1K (https://huggingface.co/datasets/imagenet-1k), which contains 1,000 object classes and contains 1,281,167 training images, 50,000 validation images and 100,000 test images.\n\nNetwork architectures\n\nWe used the DeIT vision transformer from Meta for demonstrating the strategy for constructing FIP in weight space. The network and variants are described at https://huggingface.co/docs/transformers/model_doc/deit. As described, the base DeIT (86M parameters) achieves top-1 accuracy of 83.1% (single-crop evaluation) on ImageNet with no external data.\n\nWe also used the BERT dataset available at https://huggingface.co/docs/transformers/model_doc/bert.\n\nPseudo-code: FIP construction for network sparsification\n\nAlgorithm 2\n\nFIP construction for network sparsification:\n\nRequire: λ, η\n\nRequire: p, final desired network sparsity (in percentage)\n\nRequire: wt, network trained on MNIST or CIFAR-10 dataset\n\n1: procedure FIP-Sparse(λ, η, p, wt)\n\n2: w←wt\n\n3: while (∣∣w∣∣0/∣∣wt∣∣0) NOT (1 − p/100) ⊳ until w not in p% sparse submanifold\n\n4: wp←project(w, p) ⊳ set p% of smallest weights to zero\n\n5: L(w)←∣∣w − wp∣∣2\n\n6: x←dataset(MNIST or CIFAR) ⊳ sample minibatch of images from the dataset\n\n7: OPloss←odist(f(x, w), f(x, wt)) ⊳ distance moved in the output space\n\n8: S←OPloss + λ × L(w)\n\n9: w←w − η∇wS ⊳ constructing FIP towards sparse submanifold\n\n10: end while\n\n11: return w\n\n12: end procedure\n\nCode specifications\n\nAll the code was written in the PyTorch framework, and the automatic differentiation package was extensively used for constructing the computational graphs and computing gradients for updating the network parameters. The code for constructing the FIPs to the p% sparse submanifolds was run on Caltech’s high-performance computing cluster using a single GPU for a total time ranging between 2 h and 6 h for final network sparsities below 80%, and between 24 h and 30 h for identifying high-performance networks in submanifolds with larger than 80% sparsity.\n\nParameters used\n\nFIP for network sparsification: λ = 1, η = 0.01; optimizer used, Adam (β = (0.9, 0.999)); final (desired) network sparsities for LeNet-300-100 on MNIST: p = [20%, 67%, 89%, 96%, 98.7%, 99%, 99.1%, 99.4%]; final (desired) network sparsities for ResNet20 on CIFAR-10: p = [20%, 36%, 49%, 59%, 67%, 79%, 83%, 89%, 93%, 95%].\n\nLTH (for LeNet-MNIST): batch-size = 128, model-init = kaiming-normal, batchnorm-init = uniform, pruning-strategy = sparse-global, pruning-fraction = 0.2, pruning-layers-to-ignore = fc.weight, optimizer-name = sgd, learning rate = 0.1, training-steps = 40 epochs. LTH (for ResNet20-CIFAR-10): batch-size = 128, model-init = kaiming-normal, batchnorm-init = uniform, pruning-strategy = sparse-global, pruning-fraction = 0.2, optimizer-name = sgd, learning rate = 0.1, training-steps = 160 epochs, momentum = 0.9, gamma = 0.1, weight-decay ≥ 0.0001.\n\nImplementation of other sparsification methods\n\nWe implemented the LTH for sparsifying both LeNet-300-100 trained on MNIST and ResNet20 trained on CIFAR-10. To do so, we adapted code from https://github.com/facebookresearch/open_lth.\n\nAdversarial robustness\n\nDatasets and preprocessing\n\nThe models were trained on the CIFAR-10 dataset and the adversarial examples were generated on the same using the PGD method.\n\nCIFAR-10: the CIFAR-10 training dataset contains 50,000 RGB images of 10 classes of natural images (like trucks, horses, birds and ships). The test set contains 10,000 additional images from each of the 10 classes.\n\nNetwork architecture\n\nFor the adversarial robustness section, we used the VGG16 network72, which has 16 layers, and a total of 138M trainable parameters.\n\nGenerating an adversarial attack\n\nWe used the PGD method to generate CIFAR-10 data samples that are imperceptibly similar to their original images for humans, but cause performance loss to deep networks. The PGD attack computes the best direction (in image space) to perturb the image such that it maximizes the trained networks’ loss on the image and constraining the Linf norm of the perturbation.\n\nThe procedure for generating adversarial inputs is detailed below:\n\nRandomly initialize a VGG16 network and train it on CIFAR-10 (trained network = wt).\n\nTake a single image input (x) from the CIFAR-10 dataset and pass it through the trained network, and calculate the gradient of the classification loss (cross-entropy (C)) with respect to the input (grad = ∇xC(wt, x, y)).\n\nConstruct an adversarial input (x′) by taking multiple steps (S) in the image input space, where the adversary is within an ϵl∞ bound. xt+1 = ∏x+S(xt + αsgn(∇xC(wt, x, y))). Here we take as many steps (S) as required until the adversarial input (xt+1) exits the ϵl∞ bound. We choose ϵ = 0.3 and α = 2/255 for generating CIFAR-10 adversarial examples against VGG16 networks.\n\nRepresentation diversity score\n\nWe compute the representation diversity score for both ensembles (FIP and DeepNet) by evaluating the standard deviation of the L2 norm of the network’s activation across all the networks in the ensemble along each layer for a set of image inputs.\n\nCoherence between two models\n\nWe compute the overlap of the adversarial subspace between networks in the FIP ensemble and the trained surrogate network by evaluating the cosine distance between the gradients of the loss function of the FIP networks and the trained surrogate network with respect to an input (x).\n\nSay, the gradients of the loss function with respect to input (x) for the two models are Jx(θ0, x, y) and Jx(θ1, x, y). The cosine distance between the gradients is evaluated as follows, where CS indicates cosine similarity.\n\n$${\\mathrm{CS}}({\\nabla}_{x}\\;{J}_{0},{\\nabla}_{x}\\;{J}_{1})\\left.\\right)=\\frac{ < {\\nabla}_{x}\\;{J}_{0},{\\nabla}_{x}\\;{J}_{1} > }{| {\\nabla}_{x}\\;{J}_{0}| | {\\nabla}_{x}\\;{J}_{1}| }.$$\n\n(6)\n\nThe cosine distance between the gradients provides a quantitative measure for how likely an adversarial input that affects the surrogate network would attack the model sampled along an FIP.\n\nTo evaluate the coherence across all the sampled models in the FIP and a trained surrogate network, we measure the maximum cosine similarity between all pairs of gradient vectors in the set.\n\n$${\\max }_{a\\in 1\\ldots N}{\\mathrm{CS}}({\\nabla}_{x}\\;{J}_{a},{\\nabla}_{x}\\;{J}_{\\rm{s}})\\left.\\right).$$\n\n(7)\n\nHere Ja refers to the gradient of N networks sampled along the FIP for a single input (x), and Js refers to the gradient of the trained surrogate network for the input (x).\n\nPseudo-code: FIP for adversarial robust ensembles\n\nAlgorithm 3\n\nFIP for adversarially robust ensembles\n\nRequire: η, step size; wt, network trained on CIFAR-10 dataset; ϵl∞ of adversary perturbation\n\nRequire: δ, permissible change in output distance; max-iter, number of steps in the FIP\n\n1: procedure FIP-ensemble(η, wt, δ, ϵ)\n\n2: w←wt\n\n3: ii←0 ⊳ setting counter = 0\n\n4: F←{} ⊳ list of networks in the FIP ensemble\n\n5: while ii ≤ max-iter\n\n6: (x, y)←dataset(CIFAR-10) ⊳ sample minibatch of images from dataset\n\n7: S←odist(f(x, w), f(x, wt)) ⊳ output-space distance for varying network weights\n\n8: w←w − η∇wS ⊳ construct undirected FIP\n\n9: x′←x + εsgn(∇xC(w, x, y))\n\n10: H←odist(f(x, w), f(x′, w)) ⊳ output-space distance for perturbed input\n\n11: if H ≤ δ then\n\n12: F←F ∪ w\n\n13: end if\n\n14: ii←ii + 1\n\n15: end while\n\n16: return F ⊳ returning FIP ensemble with adversarial robustness\n\n17: end procedure\n\nCode specifications\n\nAll the code was written in the PyTorch framework, and the automatic differentiation package was extensively used for constructing the computational graphs and computing gradients for updating the network parameters. The code for constructing the undirected FIPs in the weight space, followed by sampling a small subset of networks along the FIP, was run on Caltech’s high-performance computing cluster using a single GPU for a total time ranging between 2 h and 6 h.\n\nParameters used\n\nTo generate ensembles of deep networks, we selected parameters after a grid search to maximize robustness against adversarial failure.\n\nFIP ensemble: η = 0.01, ϵ = 0.3, minibatch size = 100, δ = 35 (inputs to the FIP construction/ensemble pseudo-code detailed above).\n\nAdaptive diversity-promoting ensemble: α = 2, β = 0.5 (α and β are parameters maximizing the diversity of ensemble); optimizer used, SGD; momentum = 0.9, learning rate = 0.05, weight-decay = 2 × 10–4, batch-size = 128, num-networks-per-ensemble = 3, 5 and 10 (three different ensembles).\n\nFast geometric ensembling: model, VGG16; epochs = 40, weight-decay = 3 × 10–4, learning-rate-1 = 0.5 × 10–2, learning-rate-2 = 1 × 10–2, cycles = 2.\n\nImplementation of other ensemble generation methods for adversarial robustness\n\nWe generated ensembles of deep networks (VGG16) using three state-of-art methods. The first method, ‘DeepNet ensemble’, was constructed by training multiple independently initialized VGG16 networks. The second method called adaptive diversity promoting is obtained by adapting the code available at https://github.com/P2333/Adaptive-Diversity-Promoting. The third method called fast geometric ensembling is obtained by adapting the code taken from this repository: https://github.com/timgaripov/dnn-mode-connectivity.\n\nFIP for multiple ‘operations’ on BERT language model\n\nWe scale our FIP geometric framework to perform multiple operations (like CL and Co) on BERT language models that are very large and are capable of parsing large amounts of text scraped from different internet sources (like, Wikipedia, Yelp, IMDb and so on).\n\nDatasets and preprocessing\n\nWe performed two operations, namely, (1) network Co and (2) CL on BERT, fine tuned on different language datasets, downloaded from the HF website.\n\nWikipedia: the Wikipedia English datasets are downloaded from https://huggingface.co/datasets/wikipedia. We used the Wikipedia dataset on the MLM task.\n\nYelp reviews: the Yelp review datasets are obtained from HF, downloaded from https://huggingface.co/datasets/yelp_review_fullhttps://huggingface.co/datasets/yelp_review_full.\n\nIMDb reviews: the IMDb review datasets are obtained from HF, downloaded from https://huggingface.co/datasets/imdb.\n\nGLUE dataset: the GLUE dataset is obtained from HF, downloaded from https://huggingface.co/datasets/gluehttps://huggingface.co/datasets/glue. The GLUE tasks performed in this paper are (1) QQPs, (2) SST-2, (3) CoLA, (4) RTE, (5) MNLI, (6) MRPC and (7) QNLI.\n\nNetwork architecture\n\nBERT is a popular transformer model having 12 layers (transformer blocks), each with a hidden size of 768, comprising 12 self-attention heads in each layer having a total of 110M parameters5. BERT has been pre-trained on 45 GB of Wikipedia data, using the MLM task, and next-sentence prediction.\n\nSentence completion (masking) tasks\n\nFor the masking tasks (where 15% of the words in the input sentence are masked (or blanked)), the BERT network has an MLM head appended to the network. The MLM head produces a three-dimensional tensor as the output, where the dimensions correspond to (1) the number of sentences in a single batch (batch-size), (2) number of blanked-out words in a sentence and (3) number of tokens in the BERT vocabulary (30,000 tokens).\n\nSentence classification tasks\n\nFor the sentence classification task, a sentence classifier head was appended to the BERT architecture. Here the classifier head produces a two-dimensional output tensor, where the dimensions correspond to (1) batch-size and (2) number of unique classes in the classification problem.\n\nCode specifications\n\nAll the code was written in the PyTorch framework, and the automatic differentiation package was extensively used for constructing the computational graphs and computing gradients for updating the network parameters. The code for constructing the FIPs in the BERT weight space for CL on Yelp and IMDb sentiment analysis and for BERT sparsification was run on Caltech’s high-performance computing cluster using two GPUs for a total time of 2 h and 6–30 h, respectively.\n\nParameters used\n\nFIP for CL: η = 2 × 10–5, λ = 1, n memories from previous task = 2,000/650,000 (0.8% of the previous dataset). Optimizer used, AdamW.\n\nFIP for BERT sparsification: η = 2 × 10–5, λ = 1. Optimizer used, AdamW. Final (desired) network sparsities for the GLUE task: task (p% sparse): RTE (60% sparse), CoLA (50% sparse), STS-B (50% sparse), QNLI (70% sparse), SST-2 (60% sparse), MNLI (70% sparse), QQP (90% sparse), MRPC (50% sparse). Final (desired) network sparsities for Wikipedia sentence completion: [10%, 20%…90%].\n\nFIP length\n\nThe FIP length is evaluated by sampling a large number of networks along the FIP, and summing the Euclidean distance between all the consecutive pairs of networks. Say, the weights of the networks sampled along the FIP are denoted by w1, w2, w3…wn.\n\n$$\\,\\text{FIP-length}\\,=\\mathop{\\Sigma }\\limits_{i = 2}^{n}| | {{\\bf{w}}}_{{\\bf{i}}}-{{\\bf{w}}}_{{\\bf{i}}-{\\bf{1}}}| {| }_{2}$$\n\nPerplexity score: language models\n\nPerplexity is an evaluation metric used to measure how ‘surprised’ a language model is when it encounters a new task. That is, a higher perplexity implies more surprise, suggesting that the language model does not have much insight into how language works. Mathematically, we define perplexity as the exponential of the cross-entropy loss on the evaluation dataset:\n\n$$\\,\\text{PPL}\\,(\\theta )=\\exp \\left[\\mathop{\\Sigma }\\limits_{i = 1}^{{n}_{e}}l(\\theta ,{x}_{i})\\right],$$\n\nwhere θ is the parameter of the BERT model and x1, x2…\\({x}_{{n}_{\\rm{e}}}\\) are the ne inputs from the evaluation dataset. l(θ, xi) evaluates the cross-entropy loss of a BERT model parameterized by θ for a single input xi.\n\nConstructing FIP ensemble for adversarial robustness\n\nSelection criteria for FIP ensemble\n\nHaving constructed an FIP in the weight space, beginning from a deep network trained on CIFAR-10, we introduce the selection criteria to sample diverse networks along the FIP to construct the FIP ensemble. As we want the FIP ensemble to be robust to adversarial input perturbation, we generate random perturbations in the image space (within an ϵl∞ ball) and compute the distance moved in the networks’ output space for a small perturbation in the image space.\n\nWe record the distance moved in the networks’ output space (across all the networks in the constructed FIP) and plot a distribution of the distance moved in the output space for a small perturbation in the image input space. We find that some networks along the FIP exhibit smaller perturbation in the output space and have a narrower distribution across 10k perturbed training inputs, whereas others exhibit larger perturbation in the output space. We choose networks that exhibit a smaller perturbation in the output space for constructing the FIP ensemble.",
      "# [Instagram](https://www.instagram.com/startup_montereybay/p/C6MFGAGLayD/)\n",
      "# [Center for CONSCIOUSNESS STUDIES](https://consciousness.arizona.edu/)\nThe Science of Consciousness 2025\n\n31st Annual TSC\n\nB A R C E L O N A July 6-11 - AC Marriott Forum Hotel\n\nWorkshops, Plenaries, Concurrents, Exhibits, Demos, Social, Poetry Slam, Dancing\n\nfollowed by and in concert with\n\n4th Annual FoC-25\n\nB A R C E L O N A July 11–13 - adjacent to AC Forum Marriott\n\nMusic, Art, Experiential, Inspiration, Spirituality, Education, Business, Evolution\n\nRegistration is Open\n\nhttps://tickets.thefestivalofconsciousness.org/tscc\n\nCombo Ticket - includes access to the Conference and the Festival\n\nStandard: 600 EUR - Student: 350 EUR - (Remote: 150 EUR avail in April)\n\nAbstracts - Submission due by Feb. 10th LINK\n\nThe Science of Consciousness (‘TSC’) conference is the world’s longest running inter-disciplinary gathering on the study of consciousness, the nature of existence and our place in the universe. TSC has alternated yearly since 1994 between Tucson, Arizona USA and elsewhere including Italy, Denmark, Japan, Sweden, Czech Republic, Hungary, Hong Kong, India, California, Switzerland, Finland, and in 2023 Taormina, on the island of Sicily. In 2025 TSC will be in Barcelona, Spain preceding and in conjunction with The Festival of Consciousness.\n\nWe are at a crossroads in the age-old study of consciousness. Over the past thirty years approaches to understanding consciousness have diverged along two distinct paths: 1) ‘neurocomputational’ views of the brain as a complex computer of simple neurons, a view compatible with AI systems becoming conscious, and 2) ‘funda-mental’ views in which consciousness is intrinsic to the universe, connected to the brain through quantum biology. Exploring the funda-mental view, TSC embraces neuroscience biology far more rigorously than AI-compatible simple neurons. Ironically, conscious AI may be most likely to occur in biomimetic quantum computers.\n\n2025 - Barcelona - PLENARY Sessions\n\nPlenary Program Schedule (July 7-July 11)\n\nMonday July 7\n\nPlenary 1 8:30 am - 10:40 am\n\nConsciousness and Reality\n\nSir Roger Penrose * Don Hoffman * Avshalom Elitzur\n\nPlenary 2 11:10 am – 12:35 pm\n\nAI, LLMs and Biomimetic Quantum Computing\n\nFarhan Lakhany * Anirban Bandyopadhyay\n\nPlenary 3 2:00 pm – 4:10 pm\n\nBrain Oscillations, Waves and Nested Scales\n\nEarl K Miller * Matthew Larkum * Sabine Kastner\n\nTuesday July 8\n\nPlenary 4 8:30 am - 10:40 am\n\nTheories of Consciousness and Brain Modulation\n\nRobert Lawrence Kuhn * Giulio Ruffini * Jay Sanguinetti\n\nPlenary 5 11:10 am – 12:35 pm\n\nAnesthesia and Consciousness\n\nMichael Wiest * TBA\n\nPlenary 6 2:00 pm – 4:10 pm\n\nPsychedelics and Consciousness\n\nWilliam Richards * Pär Halje * TBA\n\nWednesday July 9\n\nPlenary 7 8:30 am - 10:40 am\n\nConsciousness and Quantum Measurement\n\nIvette Fuentes * Thomas Brophy * Santosh Helekar\n\nPlenary 8 11:10 am – 12:35 pm\n\nConsciousness and Vibrations in Spacetime Geometry\n\nAnirban Bandyopadhyay * William Brown\n\nPlenary 9 2:00 pm – 4:10 pm\n\nQuantum Biology and SuperRadiance\n\nPhilip Kurian * Dante Lauretta * Anita Goel\n\nThursday July 10\n\nPlenary 10 8:30 am - 10:40 am\n\nEnergy, Information and Consciousness in the Universe\n\nNassim Haramein * Rupert Sheldrake * TBA\n\nPlenary 11 11:10 am – 12:35 pm\n\nEnd-of-Life Brain Activity\n\nJimo Borjigin * Alex Gomez-Marin\n\nPlenary 12 2:00 pm – 4:10 pm\n\nEvidence for Non-Local Consciousness and Extrasensory Perception\n\nDavid del Rosario * Javier Sierra * Dean Radin\n\nFriday July 11\n\nPlenary 13 9:00 am - 11:10 am\n\nProspects for Extraterrestrial Consciousness\n\nBrannon Wheeler * Ross Coulthart * TBA*\n\nPlenary 14 11:40 am – 13:00 pm\n\nQuantum Fields and Consciousness\n\nDeepak Chopra * Federico Faggin\n\nconference close\n\nWORKSHOPS - Sunday July 6 - updating descriptions\n\n- 3 parallel sessions - 9:00 am - 1:00 pm, 2:00 pm-6:00 pm & 1 Sunday evening session 7:00 pm -10:00 pm (speakers subject to change)\n\n9:00 am – 1:00 pm (Room 1)\n\nEducation and the Landscape Taxonomy of Consciousness Studies - Robert Lawrence Kuhn, Paavo Pylkkänen, Brian Lord, Jeffery Martin\n\n9:00 am – 1:00 pm (Room 2)\n\nIndian Knowledge Systems and Consciousness - Kunal Mooley, Laxmidhar Behera (R), Martin Fleming, M Coceal, Hide Saegusa,\n\n9:00 am – 1:00 pm (Main Ballroom)\n\nQuantum Biology - Travis Craddock, Philip Kurian, Aarat Kalra, Jack Tuszynski, Adrienne Vancura, Chayan Nandi, Dana Kippel\n\n1:00 pm – 2:00 pm – Break\n\n2:00 pm – 6:00 pm (Room 1)\n\nNonlocal Consciousness and Extrasensory Perception - Alex Gómez Marin, David del Rosario, Chris Roe, Dean Radin\n\n2:00 pm – 6:00 pm (Room 2)\n\nWomen in Consciousness Studies - Marjorie Woollacott, Joan Walton, Marina Weiler, Mona Sobhani, Allison Paradise, Laurel Waterman\n\nHow can we engage more women in consciousness studies scholarship and discourse, and what happens when we do? This workshop features female scholars from different disciplines sharing findings from their consciousness studies research. The theme of the value of women’s contributions to the field will be woven through the presentations and discussions. Do women’s perspectives, questions, approaches, and interpretations offer something potentially new or different to the study of consciousness? Do women have unique experiences of being consciousness researchers that may differ from men’s? If so, how can we bring these experiences into the field to enrich its scope and depth? This workshop will include research presentations by the panelists and dialogues about the future of women in consciousness studies research. Speakers in this workshop include Dr. Marjorie Woollacott (U Oregon, Inst. of Neuroscience), Dr. Joan Walton (York St. John U, Education), Dr. Marina Weiler (U Virginia, DOPS), Dr. Mona Sobhani (IONS), Allison Paradise (CEO, The Epicenter), and Laurel Waterman, PhD. Candidate (U Toronto, Curriculum and Pedagogy).\n\n2:00 pm – 6:00 pm (Main Ballroom)\n\nThe Varieties of 'BCI’ - Brain Computer Interfaces - G Ruffini, A Maiques, Z Cinker, Anirban Bandyopadhyay, Jay Sanguinetti, Brian Lord, Arnaud Delorme (Sponsored by Neuroelectrics, Starlab, PuzzleX, DDG, SEMA Lab, Sanmei)\n\n7:00 pm -10:00 pm (Main Ballroom)\n\nIs Consciousness Funda-Mental? - Nassim Haramein, William Brown, Don Hoffman, Thomas Brophy, (sponsored by ISF, IONS)\n\nABSTRACT SUBMISSIONS\n\nCALL FOR ABSTRACTS 2025 TSC - Abstract Submission LINK\n\nExtended deadline: Feb 10, 2025 Notifications - Feb 20, 2025\n\nConcurrent Sessions, Poster Sessions, Demos, Exhibitors, Experiential\n\nDocument\n\nADDITIONAL Conference Sessions 2025\n\nEarly Morning Experiential Sessions July 7-July 11, - 7:00 -8:15am\n\nConcurrent Sessions - Art Exhibits/DEMOS - Poster Sessions\n\nREGISTRATION PAYMENT SYSTEM - 2025\n\nCombo Ticket includes access to the TSC Conference and to the Festival of Consciousness\n\nStandard: 600 EUR - Student: 350 EUR\n\nRemote: 150 EUR - tickets avail in April\n\nConference / Festival - Dates\n\nTSC 2025 Conference - July 6-11, 2025 - AC Marriott Forum Hotel BCN\n\nFOC 2025 Festival - July 11-13, 2025 - next to the AC Marriott Forum Hotel BCN\n\nVenue / Hotel Reservation LinK 2025\n\nAC Marriott Forum Hotel, Barcelona (BCN)\n\nPasseig Taulat 278 Barcelona, 08019 Barcelona, Spain\n\nROOM RATE: 174 EUR per night\n\nBuffet Breakfast is included on the room rate per day; single occupancy; tax is not included\n\nGROUP BLOCK NAME/LINK:2025 The Science of Consciousness\n\nHotel Cancellation Policy\n\nThe deadline for securing block room rates is May 23. 2025 based on availability. If changes are made to your reserved room nights by May 23rd including any cancellations - refunds will be permitted. Regarding changes or canceled room nights made after May 23 – No refunds will be allowed.\n\nTable Exhibitors Indoor:\n\nlimited availability contact: center@arizona.edu\n\nCompanies: $3600\n\nNot for profit: $1800\n\nPayment via UA Foundation - Center for Consciousness Studies\n\nInstruction Letter Upon Request\n\ncenter@arizona.edu\n\nDocument\n\n2025 TSC - Barcelona - Confirmed Plenary Speakers\n\nAnirban Bandyopadhyay, Jiimo Borjigin, Thomas Brophy, William Brown, Deepak Chopra, RossCoulthart, Avshalom Elitzur, Federico Faggin, Ivette Fuentes, Anita Goel, Alex Gomez-Martin, Pär Halje, Stuart Hameroff, Nassim Haramein, Don Hoffman, Santosh Helekar, Sabine Kastner, Robert Lawrence Kuhn, Philip Kurian, Farhan Lakhany, Matthew Larkum, Dante Lauretta, Earl K. Miller, Sir Roger Penrose, Giulio Ruffini, Jay Sanguinetti, Rupert Sheldrake, Javier Sierra, Michael Wiest, Brannon Wheeler\n\n2025 TSC Conference Sponsors – updating\n\nInstituto de Neurociencia Avanzada de Barcelona (INAB) - The Festival of Consciousness - Closer to Truth - DDG - IONS - ISF - Neuroelectrics - PuzzleX - Sanmei - SEMA Lab - Starlab - Tiny Blue Dot Foundation - UA-AZ Astrobiology Center-UA-Center for Consciousness Studies\n\nSEMA Lab\n\nDDG Dodecanogram (DDG)\n\nFor sponsor or exhibitor information please email: center@arizona.edu Exhibitor/Demo tables available in the main lobby\n\nExecutive Committee 2025:\n\nStuart Hameroff - Dante Lauretta - Jay Sanguinetti - Brian Lord - Thomas Brophy - Claudia Weiss - Xavi Ginesta - Abi Behar Montefiore\n\nGeneral Program Committee 2025:\n\nThomas Bever - Robert Lawrence Kuhn - Adrienne Vancura - Alain Morin - Erika Cook - Justin Riddle - David del Rosario - Gina Poe Zena Cinker - Harald Atmanspacher - Paavo Pylkkanen - Travis Craddock\n\nContact/Info: center@arizona.edu\n\n__________________________________\n\nEU Travel – Visas and Travel Waiver Authorizations\n\nSummary of Travel Visa Waiver Authorization Requirements\n\nVisas are handled by the Embassy and Consulate of Spain in your area. They will provide you with a template form if they need the Conference organizers to provide a letter and signature. Send this form to:center@arizona.edu\n\nNew Requirements for Travel to Europe (EES and ETIAS) expected in 2025\n\nEntry/Exit System (EES)\n\nThe Entry/Exit System expected to launch in 2025\n\nThe Entry/Exit System (EES) is an automated IT system for registering non-EU nationals traveling for a short stay, each time they cross the external borders of any of the following European countries using the system:\n\nEuropean Travel Information and Authorization System (ETIAS)\n\nETIAS is not currently in operation and no applications are collected at this point. Expected Date of Operation - mid-2025\n\nIt is due to start 6 months after EES is launched.\n\nETIAS – European Travel Information and Authorization System\n\nThis is an expected upcoming new ONLINE travel authorization waiver that will affect all short-term travelers to the EU by mid-2025. Requests for Waivers will be handled via an online system by the traveler with a processing fee (EUR 7).\n\nYou will need an ETIAS waiver/authorization to travel to an ETIAS Member Country. The ETIAS is for citizens of countries outside the EU that don’t require a “visa” for short visits BUT who will need this TRAVEL WAIVERAUTHORIZATION – ETIAS. For example, travelers from the United States, Canada, Japan, Australia, and the United Kingdom will all need an ETIAS before authorization entering Schengen countries.\n\nPlease work with your travel agent and stay up to date with the EU official website and ETIAS tracking services. If the system becomes operational and affects your travel, you will need to take care of this potential requirement in order to enter the EU and travel between ETIAS countries.\n\nThe online Application template for ETIAS is posted on the EU website and while not operational at the time of this letter, various required questions are outlined. They state that it will take approximately 20 minutes to complete. The Application fee is EUR 7 collected online (debit or credit card). Authorizations should be immediate or within 96 hours pending any issues. ETIAS will send back a travel authorization tracking number that is linked to your passport. Once approved the ETIAS will be good for 3 years or until your passport expires if sooner. If you are expecting to apply for a new passport please do so as soon as possible.\n\nLINKS\n\nOfficial website for the European Union\n\nhttps://travel-europe.europa.eu/index_en\n\nNew Requirements for Travel to Europe\n\nhttps://travel-europe.europa.eu/index_en\n\nhttps://travel-europe.europa.eu/etias_en\n\nhttps://travel-europe.europa.eu/etias/what-etias_en\n\nProcessing the ETIAS application\n\nADDITIONAL HELP\n\nCIBTvisas is a private global company that is authorized to process visa applications and expedite passports at consulate and passport agencies for a fee. This might be a helpful option to explore.\n\nhttps://cibtvisas.com/worldwide-offices\n\n800-929-2428\n\nGraphic: 'Gaudi's Brain' -credit: ChatGPT/Xavi Ginesta\n\nADDITIONAL SPONSOR LOGOS - updating\n\nCenter for consciousness studies - CONTACT/Links\n\nCCS Website\n\nYouTube Channel - The Science of Consciousness Conferences & programs\n\nFacebook CCS-TSC\n\nJoin TSC E-list\n\ntelephone: 520-247-5785\n\nCenter email: center@arizona.edu\n\nAbi Behar Montefiore, Asst. Dir.; Sr. Prgm. Mgr.\n\nStuart Hameroff, Director - hameroff.arizona.edu\n\n# # #\n\nrecent media\n\nScience\n\nPop Mech Pro: Science\n\nThis Doctor Says He Knows How the Brain Creates Consciousness. New Evidence Suggests He’s On to Something.\n\nStuart Hameroff has faced three decades of criticism for his quantum consciousness theory, but new studies show the idea may not be as fringe as once believed.\n\nBy Darren Orf Published: Dec 18, 2024 5:13 PM EST\n\nNews Save the date: Tucson 2026\n\nThe Science of Consciousness | April 6-11, 2026\n\ncenter@arizona.edu Abstracts: Fall, 2025\n\nJoin TSC E-list / CCS-TSC Website / YouTube Channel - Archives | CCS-TSC\n\nCommunity News - SUMMER 2025 - Rome, Italy\n\nFaith, Science, Mysticism - Rome ITALY\n\nJune 17-20 2025\n\nFaith and Science Conference\n\nEnhanced by Art, Music and Interfaith Mysticism\n\nRome, Italy, Tuesday-Friday, June 17-20, 2025, The Jubilee Year\n\nConference Theme: A Journey into God’s Mystical Love - Fondazione Pro Musica e Arte Sacra, Via Paolo VI n. 29 (Piazza S. Pietro) Roma – Italia\n\nS. Hameroff, MD \"Consciousness and Free Will\" - Dr. Hameroff Is professor and director of the Center for Consciousness Studies at the University of Arizona. With Oxford Nobel Laureate, Sir Roger Penrose, he has proposed consciousness depends on quantum processes in microtubules, protein polymers inside brain neurons, connected to fluctuations in the fine scale structure of the universe. Hameroff has speculated consciousness precedes and persists after life, entangled in spacetime geometry.\n\nNEWS\n\nExploring the Quantum Orchestra - Stuart Hameroff\n\nQuantum Consciousness, Microtubules & the Brain\n\nFIRST PRINCIPLES FIRST\n\nTowards a Science of Mindful Agents, Societies and Observer Languages Dec 14, 2024\n\nASTROBIOLOGY and Consciousness Research\n\nOSIRIS-REx, 1 year later: Asteroid sample continues to provide clues about early solar system and origins of life on Earth\n\nU of A Regents Professor Dante Lauretta says he is \"amazed by the discoveries we've made\" since the OSIRIS-REx spacecraft delivered an asteroid sample to Earth last year. Read more\n\nProf. Lauretta is co-chair, Center for Consciousness Studies and AABC Director\n\n$1M gift will advance consciousness research at U of A Astrobiology Center\n\nThe Arizona Astrobiology Center received a $1 million gift from Eugene Jhong, a retired Google software developer, to support research on the origins of life and consciousness. Read more\n\nNEW - Articles, Meetings\n\nBennu holds the solar system's 'original ingredients,' might have been part of a wet world -Mikayla Mace Kelley, UA News, June 26, 2024\n\nOSIRIS-REx sample scientists took a deep dive into the rocks and dust returned from asteroid Bennu. They found that the sample is rich in carbon, nitrogen and organic compounds – essential components for life as we know it.\n\n\"Finally having the opportunity to delve into the OSIRIS-REx sample from Bennu after all these years is incredibly exciting,\" said Dante Lauretta, principal investigator for OSIRIS-REx and Regents Professor of planetary sciences in the University of Arizona Lunar and Planetary Laboratory. \"This breakthrough not only answers longstanding questions about the early solar system but also opens new avenues of inquiry into the formation of Earth as a habitable planet. The insights outlined in our overview paper have sparked further curiosity, driving our eagerness to explore deeper.\" More\n\n*****\n\nDante Lauretta - Keynote Speaker - The Science of Consciousness 2024\n\nPLENARY #11 - TSC - MOLECULES OF LIFE & CONSCIOUSNESS FROM THE ASTEROID BENNU - Video\n\nCalifornia Institute of Technology, Indian Institute of Technology Kanpur, IMICS are currently participating in the Consciousness & Reality (C&R) colloquium series - YouTube sessions with: Stuart Hameroff, Anesthetic action links consciousness to quantum vibrations\n\nplus: Christof Koch, Steven Laureys, Fiona Macpherson, Michael Levin, Donald Hoffman, Lee Smolin, Bernardo Kastrup, Jim Tucker, Anil Seth, Liad Mudrik, Sean Carroll\n\nTim Ventura, Oct 22, 2024\n\nDr. Stuart Hameroff discusses microtubules, biological quantum processing, ORCH OR theory, quantum consciousness, and a new study that supports the quantum basis of consciousness in the brain. Dr. Stuart Hameroff, an anesthesiologist and professor at the University of Arizona, author of the book “Ultimate Computing”, and lead organizer of the biannual Science of Consciousness conference. Dr. Hameroff is known for his role as the co-founder of the Orchestrated objective reduction model of consciousness, which he developed in conjunction with physicist Sir Roger Penrose in the early 1990’s.\n\nLINKS & RESOURCES: Stuart Hameroff Website (University of Arizona) https://hameroff.arizona.edu/\n\nStudy Supports Quantum Basis of Consciousness in the Brain https://neurosciencenews.com/quantum-...\n\nMicrotubule-Stabilizer Epothilone B Delays Anesthetic-Induced Unconsciousness in Rats https://www.eneuro.org/content/11/8/E...\n\nWellesley team’s new research on anesthesia unlocks important clues about the nature of consciousness https://www.wellesley.edu/news/welles...\n\nUltimate Computing https://www.amazon.com/Ultimate-Compu...\n\nShadows of the Mind: A Search for the Missing Science of Consciousness https://www.amazon.com/Shadows-Mind-M...\n\nTiny Blue Dot Foundation Request for Proposals Oct 2024-closed\n\nPast TSC Programs\n\n2024 THE SCIENCE OF CONSCIOUSNESS April 22-27, 2024 - 30th Annual - Tucson\n\nPlenary & Workshop Videos\n\n2024 The Science of Consciousness – Plenary, Keynote, Workshops PL1-PL14, WK1, WK2, Symposium - See the TSC YouTube Channel\n\n2024 TSC PLAYLIST YouTube - Conference Sessions\n\n2024 TSC Archived Historical - Promos and Interviews\n\n2024 TSC Remote Presenters\n\nInterviews Tucson 2024:\n\nCONSCIOUSNESS CENTRAL - Hosted by NICK DAY 2024 Interviews\n\nProgram 1 - Stuart Hameroff • Paavo Pylkkanen • Harald Atmanspacher • Jason Padgett\n\nProgram 2 - Donald Hoffman • Claudia Passos • Elizabeth Krasnodar • HIDE SAEGUSA\n\nProgram 3 - Susan Schneider • Thomas Brophy • Master Sha and his collaborators, quantum physicist Ruilin Xiu and physicians Peter Hudober and Consuelo Fernandez Finally Scott Olsen talks about the convergence of indigenous shamanic art with Western psychedelic imagery.\n\nProgram 4 -Jonathan Schooler & Tam Hunt • Susan Blackmore & Emily Troscianko • POSTER SESSION • Stuart Hameroff • DAN DENNETT (2004) • POETRY SLAM & END OF CONSCIOUSNESS PARTY\n\nProgram 5 -QUANTUM CONSCIOUSNESS SPECIAL: Stuart Hameroff • Anirban Bandyopadhyay • Santos Helekar\n\nCenter for consciousness studies - CONTACT/Links\n\nCCS Website\n\nYouTube Channel - The Science of Consciousness Conferences & programs\n\nFacebook CCS-TSC\n\nJoin TSC E-list\n\ntelephone: 520-247-5785\n\nCenter email: center@arizona.edu\n\nAbi Behar Montefiore, Asst. Dir.; Sr. Prgm. Mgr.\n\nStuart Hameroff, Director - hameroff.arizona.edu\n\nSeptember 21-22, 2024 HowTheLightGetsIn-London,\n\nQuantum collapse holds the key to consciousness - How consciousness is a quantum symphony IAI TV - Stuart Hameroff argues that by studying anesthesia we are able to understand what goes away in the brain when the light of consciousness is .....\n\nSat Sept 21 4:00 - 5:00 pm BST Debates - Quantum and the Unknowable Universe philosopher Slavoj Žižek, theoretical physicist Sabine Hossenfelder, and Nobel Prize winner Roger Penrose debate whether quantum mechanics has made the universe fundamentally unknowable.\n\nSat Sept 21 5:30-6:30 pm BST - The Divided Self - Joining live from the US via video link, neuroscientist and philosopher Sam Harris and Nobel Prize winner Roger Penrose discuss whether the self is divided.\n\nAugust 2024, Consciousness Pre-dates\n\nConsciousness came before life\n\nThe fundamental cause of evolution.\n\nHameroff, S. (2024, May 08). Consciousness came before life. IAI News. /articles/life-and-consciousness-what-are-they-auid-2836\n\nMost scientists and philosophers believe that life came before consciousness. Life appeared on Earth about 3.8 billion years ago; consciousness and feelings, it’s said, evolved later due to complex biological information processing, perhaps only recently in brains with language and tool-making abilities. In fact, though, there’s good reason to think that consciousness preceded life, and was central to making life and evolution possible. More\n\n’ alongside biologist Denis Noble and philosopher Antonella Tramacere, Stuart Hameroff debate at HowTheLightGetsIn Festival, May 24th-27th - 25 May 2024 Hay-on-Wye Stuart's X\n\nConsciousness Pre-Dates Life\n\nVIDEO-Hameroff\n\nMany scientists, operating with a materialist worldview, argue that consciousness emerges out of inanimate molecules. In contrast, Roger Penrose's longtime collaborator, Stuart Hameroff, puts forward the controversial case that consciousness precedes life and that we have evidence for this from a recent NASA experiment.\n\n\"Hameroff's theories are getting support from unlikely places.\" ‑ Discover Magazine\n\nTSC Conference 2024\n\nThe Science of Consciousness - Tucson 30th\n\nPlenary & Workshop Videos 2024\n\nDocument\n\n(This pdf was the printed version of the program)\n\nThere were several changes made late in the concurrent program. These changes are reflected on the web version outlined below (by day) to the extent we received the information.\n\nPROGRAM - Web version TSC 2024\n\nIt was thirty years ago today...\n\nThe Science of Consciousness 2024\n\nWORKSHOPS - MONDAY - April 22, 2024\n\n8:30 am to 12:30 pm (Kiva, Catalina KL, Catalina J, Exec. Board Room, Santa Rita, Sabino)\n\nQUANTUM BIOLOGY - Chair, Paige Derr (NIH/NCATS); Stuart Hameroff (U Arizona) Travis Craddock (NSU) Remote; Albert Siryaporn (UCI); Nirosha Murugan (Remote) , Manisha Patel, (UCSB), Philip Kurian (Howard U) Remote (Kiva)\n\nINDIAN KNOWLEDGE, HEALTH AND MEDICAL APPLICATIONS (“IKSHMA”) Chair: Martin Fleming (SPi) Remote from India: Co-Chair: Kunal Mooley (CalTech, IIT Mandi, IIT Kanpur; IMICS); Laxmidhar Behera (IIT Mandi), Rama Jayasundar (AIIMS Delhi). In person Tucson: Martin Fleming (SPi), Donald Hoffman (UC Irvine); Christopher Lord (Charles U-Prague); Venugopal Damerla (U Texas), Guruprasad Raghavan (Yurts AI) (Catalina J)\n\nDual Aspect Monism - Michael Silberstein (Elizabethtown College); William Seager, (U Toronto); Harald Atmanspacher (Collegium Helveticum-ETH Zurich) - Jeffrey Kripal (Rice U) (Catalina KL)\n\nDreamless Sleep - JF Pagel (U Colorado); Jerome Alonso (U Calgary); Antonio Zadra, (U Montreal); Gina Poe (UCLA) (Exec. board room)\n\n12:30-2:00 break\n\n2:00 pm to 5:30 pm - Monday Workshops, Continued\n\nNeurophysiology of Loss & Recovery of Consciousness - M. Bruce MacIver (Stanford U); Kathleen Vincent (Harvard U); Anthony Hudetz (U Michigan); Hyunwoo Jang (U Michigan) (Kiva)\n\nTerminal Lucidity - Chair: Marjorie Woollacott (U Oregon); Michael Nahm, (IFAP Freiburg); Natasha Tassell-Matamua (Massey U, NZ); Chris Roe (U Northampton); Maryne Mutis, U de Lorraine, Fr); Karalee Kothe, (U Colorado) (Catalina J)\n\nMeditation & Global Spiritual Practices -Thomas Brophy, (CIHS/IONS); Deepak Chopra, (Chopra Global) Jeffery Martin (CIHS); Helané Wahbeh (IONS); Garret Yount (IONS) Hidehiko Saegusa (IIT Mandi, U AZ, CIHS, AABC); Arnaud Delorme (IONS); Timothy Laporte (CIHS); Sean Esbjörn-Hargens (CIHS); Sohail Shakeri (CIHS); Remote: Dean Radin (IONS) (Catalina KL)\n\nEducation in Consciousness Studies - Laurel Waterman (U Toronto); Joan Walton (St. John U-York); Thomas Bever (U Arizona); Justin Riddle (FSU), Sue Blackmore (U Plymouth); Emily Troscianko (U Oxford) (Exec. board room)\n\nSYMPOSIUM-MONDAY EVENING April 22, 2024 - 7:00-10:00 pm - Refreshments\n\nIntegrated Information Theory of Consciousness - Symposium - Christof Koch (Allen Institute, Tiny Blue Dot Foundation, Seattle); Giulio Tononi, Melanie Boly & Matteo Grasso (U Wisconsin); Moderated by Paavo Pylkkänen (U Helsinki & U Skövde) (Kiva)\n\nTSC 2024 Tucson - Conference Sessions by Day\n\nTuesday, April 23, 2024\n\n7:30 - 8:15 am - Meditation Wellness Kickoff - Deepak Chopra - Kiva Plaza - Refreshments\n\nConference Opening\n\nPLENARY SESSIONS(Livestreamed) - Kiva\n\n8:30 am - 10:40 am - Plenary 1 'Detecting Consciousness' - STEVEN LAUREYS, CLAUDIA PASSOS, GINA POE\n\n11:10 am - 12:30 pm - Plenary 2 'Cortical Oscillations, Waves and Consciousness 1' - EARL K. MILLER, Keynote - remote\n\n12:30-2:00 break\n\n2:00 pm - 4:10 pm - Plenary 3 ‘Consciousness and Reality' - DONALD HOFFMAN, DEEPAK CHOPRA, PAAVO PYLKKÄNEN\n\n4:10-5:00 BREAK\n\nTuesday 4/23 C 1 - C 10 Concurrents\n\nC-1 IMPLICATIONS OF ARTIFICIAL INTELLIGENCE - Ken Mogi, Jonathan Erickson, Bill Mensch, Rizwan Virk, Maria Howard, JF Pagel (Chair)(Catalina J)\n\nC-2 PARAPSYCHOLOGY & NEAR-DEATH EXPERIENCES - Fr. Nathan Castle, O.P., Marina Weiler, Terri Gilbert, Birgitta Therner, Nicole Johnson (Grand Ballroom SALON D)\n\nC-3 EXPERIENTIAL APPROACHES TO CONSCIOUSNESS - Roger Russell, Igor Nazarov, Raul Valverde, Carlton 'Perk' Clark, Timothy Laporte, Rubin Naiman (Chair) (Santa Rita)\n\nC-4 PHILOSOPHY OF MIND - Scott Ventureya, Scott Olsen, Jonathan Shear (Chair), Gustavo Rocha, John Strozier, Patrick Schotanus (SALON E)\n\nC-5 REPRESENTATION AND ACCESS MODELS OF MIND - Roger C. Schriner, Susan Blackmore (Chair), Frank Heile, Matthew Williams, Roger Young, Rakenduvadhana Srinivasan (SALON F)\n\nC-6 GEOMETRY OF MIND - Mark Bailey/Susan Schneider,Andres Gomez-Emilsson, Elena Bezzubova, Uziel Awret (Chair), Jason Padgett (Executive Board Room)\n\nC-7 QUANTIFYING COGNITIVE STATES IN NEURAL DATA - Logan Trujillo (Chair), Dimitri Van De Ville, William Bosl, Kira Dolhan, Sandeep Gupta (Sabino)\n\nC-8 STUDYING SPIRITUALITY IN NEUROSCIENCE AND THERAPY - Stephen Zerfas, Marco Ruggiero (Chair), Master Zhi Gang Sha/Rulin Xiu, Olivia Giguere/Matthew Hicks, Kirit Goyal (SALON G)\n\nC-9 NEUROSCIENCE OF ALTERED STATES - Nicolas Glynos, Clayton Coleman, Nicholas Denomme (Chair), Gratiana Chen, Jeff Haller (SALON H)\n\nC-10 QUANTIFYING ALTERED STATES OF CONSCIOUSNESS - Robert Tromm,Marjorie Woollacott (Chair), Jessica Corneille, Sebastian Ehmann, Mona Letourneau (SALON I)\n\n6:30-9:00 pm Welcome Reception - Cascade Terrace\n\nWednesday April 24, 2024\n\nPLENARY SESSIONS - Kiva Ballroom\n\n8:30 am -10:40 am - Plenary 4 'Cortical Oscillations, Waves& Consciousness 2' - AndréBASTOS, PULIN GONG, DIMITRIS PINOTSIS\n\n11:10 am - 12:30 pm - Plenary 5 'The Global Brain' -SUSAN SCHNEIDER, Keynote\n\n12:30-2:00 break*\n\n*12:30-1:30 pm - Exhibitors & Demos\n\nArizona Astrobiology Center - ANT-NEURO, Inc. - AAPS - Academy for Advancement of Postmaterialist Sciences - COSMOintel - Journal of Consciousness Studies - Megahertz Brain Waves - PICER Institute - Radio Rumi Synaptic.care - Tao Academy - Timaeus Academy - Cusac.org - Fr. Nathan Castle - Ultrabandwidth Praxis\n\nafternoon plenary - wednesday\n\n2:00 pm - 4:10 pm - Plenary 6 'CONSCIOUSNESS IN RELIGION AND ALTERED STATES', tanya luhrmann, JUSTIN RIDDLE, GEORGE MASHOUR\n\nWednesday 4/24 C-11 - C-20\n\n5:00-7:00 pm Concurrent SeSSIONS & CHAIRS - WED 4/24 C-11 -C-20 20 min talks: 5 min Q&A - Breakout Rooms: Grand Ballroom Salons D,E,F, G,H,I, Catalina J, Catalina KL, Exec. Board Room, Santa Rita, Sabino\n\nC-11 ANOMALOUS COGNITION - Helané Wahbeh (Chair), James Lake, Christine Simmonds-Moore, Arnaud Delorme, Milena Braticevic(SALON D)\n\nC-12 CONSCIOUSNESS AND MENTAL HEALTH - Carsten Korth, Ingrid Fredriksson, Darja Kobal Grum, Jürgen Kornmeier (Chair), Criscillia Benford, Nina Carrubba (EXEC. BOARD ROOM)\n\nC-13 QUANTUM COM/PUTATION - James Tagg (Chair), Akihiro Nishiyama, Mauricio Garrido/Vasyl Semenov, Roumiana Tsenkova,Mithun Paul, Rachid Lopez (SANTA RITA)\n\nC-14 INTEGRATED INFORMATION THEORY - Brian Archibald, Kelvin McQueen, Garrett Mindt,Isaac David, Matteo Grasso (Chair)(SALON G)\n\nC-15 ARTIFICIAL INTELLIGENCE - William Robinson, Tam Hunt (Chair), Karina Vold, Aida Elamrani, Vickram Premakumar, Jay Myers (SALON H)\n\nC-16 TIME AND COGNITION - Laura Deutsch, Abdellatif Abujudeh, Joel Bennett (Chair), James Corrigan, Olivia Seidel (SALON I)\n\nC-17 SOCIAL IMPLICATIONS FOR UNDERSTANDINGCONSCIOUSNESS -Stephen Deiss, (Chair), Richard Morley, Steven Wingate, Seymen Atasoy,Staci Newmahr(SALON F)\n\nC-18 PHYSICS OF MIND - Florian Metzler, Gregory Horne, Amal Alachkar, William R Softky (Chair), Nir Lahav, Alon Retter, Xiaolin Ge(SABINO)\n\nC-19 NOVEL MODELS OF CONSCIOUSNESS - Donald Mender, Meijuan Lu, Christopher Tyler, Sean Clayton, Meir Weinstein, Deborah Kala Perkins (SANTA RITA)\n\nC-20 PSYCHOANALYSIS AND THE UNCONSCIOUS - Jenny Vanbergen, Teresa Nowak, Garrett Yount, Rocco Gennaro (Chair) AsherSoryl (SALON E)\n\nWEDNESDAY 4/24 7:00-9:00 pm - Reception, Cash Bar - (Catalina KL)\n\n7:00 PM - 10:00 PM - ART TECH DEMOS, EXHIBITS, POSTERS - (Grand Ballroom Lobby; GB- B)\n\n7:00 PM - 10:00 PM - POSTER SESSION 1 - WED\n\n1.0 - Philosophy - William J. Cox, Richard Gill, U.B. Lozano, Steve Kercel/Mona Letourneau, George Goutos, Ramanujam Prakash, JEFF SUGAR\n\n2.0 - Neuroscience - Kewei Chen, Ryo Sato, Pavel Kraikivski, Soosan Beheshti\n\n3.0 - Cognitive Science & Psychology - Antonio Zadra, Jin Ma, David Stone, Bruce Nappi, Malcolm Lett, Deni Van, Michael Kutch, Ruslana Remennikova/Bernard Beitman, Karalee Kothe\n\n4.0 - Physical & Biological Sciences - Richard Harrington, Peter Lugten, Steen Loeth, Steve Finette, Seungju Ahn, Georges Karma, Deanna Minich, James Beran, William Softky/Criscillia Benford\n\n5.0 - Experiential Approaches -Joel Bennett, James Driessen, PalashGoyal, Carl Flygt, Karalee Kothe\n\n6.0 - Culture & Humanities -OlgaColbert, Kevin Goodrich, Joan Walton, Laurel Waterman,Marianne Nell\n\nThursday, April 25, 2024\n\n7:15-8:15 am - Experiential Clinics\n\nPLENARY SESSIONS - Kiva Ballroom\n\n8:30 am -10:40 am - Plenary 7 'Mechanisms of Consciousness' - AARON SCHURGER, PIETER-JAN MAES, JEROME BUSEMEYER\n\n11:10 am - 12:30 pm- Plenary 8 'DoDecoGraphy ('DDG') – 12 Orders of Frequency Oscillations in EEG' -ANIRBAN BANDYOPADHYAY, Keynote\n\n*12:30-2:00 break\n\n*12:30-1:30 Exhibits & Demos GB Lobby\n\nArt-Tech\n\nafternoon plenary - thursday\n\n2:00 pm - 4:10 pm - Plenary 9 ‘Astrobiology and Astroconsciousness’ - CALEB SCHARF, PHILLIPE SCHMITT-KOPPLIN, STUART HAMEROFF - KIVA\n\nFree time\n\n6:30-9:00 PM - Optional Dinner - Ventana Terrace\n\nFRIDAY April 26, 2024\n\n7:15-8:15 am Early MORNING - Experiential Clinics\n\nSoul Sickness & Healing Techniques - Master Zhi Gang Sha, Peter Hudoba, Rulin Xiu - Catalina KL\n\nFeldenkrais Awareness through Movement® lessons. Roger Russell, Jeff Haller -Ventana 2nd Fl.\n\nTennisCentric - Mark Valladares - Loews Tennis Courts\n\nRumi Healing Meditation -Sohail Shakeri - Catalina J\n\nFinding and Clearing the Emotional Roots of your Suffering - Douglas Tataryn - Santa Rita\n\nFriday, April 26, 2024\n\nPLENARY SESSIONS - Kiva Ballroom\n\n8:30 am -10:40 am - Plenary 10 'Dual Aspect Monism' - HARALD ATMANSPACHER, BILL SEAGER, DEAN RICKLES\n\n11:10 am - 12:30 pm - Plenary 11 'Molecules of Life & Consciousness from theAsteroid Bennu’ - DANTE LAURETTA, Keynote\n\n*12:30-2:00 break\n\n2:00 pm - 4:10 pm - Plenary 12 'The Science of Consciousness - 30 Years On' - Panel: DAVID CHALMERS, SUSAN BLACKMORE, CHRISTOF KOCH, STUART HAMEROFF, PAAVO PYLKKÄNEN, Giulio Tononi\n\n*12:30-1:30 pm Exhibitor & Demos\n\nArizona Astrobiology Center - ANT-NEURO, Inc. - AAPS - Academy for Advancement of Postmaterialist Sciences - COSMOintel - Journal of Consciousness Studies - Megahertz Brain Waves - PICER Institute - Radio Rumi - Synaptic.care - Tao Academy Timaeus Academy - Cusac.org - Fr. Nathan Castle - Ultrabandwidth\n\n“The Artwork of Ayahuasquero, Pablo Amaringo” - GB Lobby\n\n“Sound Medicine® – Binaural Beats “ - Rincon\n\nAltered States...- Coronado\n\nafternoon plenary - friday\n\n2:00 pm - 4:10 pm - Plenary 12 'The Science of Consciousness - 30 Years On' - Panel: DAVID CHALMERS, SUSAN BLACKMORE, CHRISTOF KOCH, STUART HAMEROFF, PAAVO PYLKKÄNEN, Giulio Tononi\n\nFriday CONCURRENT Sessions 4/26 C-21-C-30\n\n5:00-7:00 pm - ConcurrentS - FRIDAY - C-21-C-30 20 min talks: 5 min Q&A - Breakout Rooms: Grand Ballroom Salons D,E,F, G,H,I, - Catalina J, Catalina KL, Exec. Board Room, Santa Rita, Sabino\n\nC-21 QUANTUM THEORIES OF MIND - Phillise Todd, Peter Lloyd, Thomas Brophy (Chair), Anatoly Goldstein, Ivan Kuznetsov, Natalia Cortes(CATALINA J)\n\nC-22 MULTISCALAR ELECTROPHYSIOLOGY - Asa Young, Bruce MacIver, Ryo Sato, Anthony Hudetz (Chair), Hide Saegusa (SALON D)\n\nC-23 PERCEPTION AND ATTENTIONAL CONTROL - Michael Silver, Cedric Cannard, Satya Pradhan, Nick Day (Chair), Sascha Seifert, Rahul Jain, Jeffery Martin(SALON E)\n\nC-24 CAUSALITY AND FREEWILL -Mihretu Guta, Edward Neafsey, Brian Key, Alain Morin, Lynn Rasmussen, John Sanfey (Chair)(SALON F)\n\nC-25 PHENOMENOLOGY OF MIND - Lukasz Kurowski, Jenny Simon (Chair), Abre Fournier, Soosan Beheshti, Makayla Vermette, Famira Racy (SALON G)\n\nC-26 PANPSYCHISM AND GLOBAL CONSCIOUSNESS - Scott Ventureyra, Anand Rangarajan, John Starrett, Todd Bureau (Chair) Ulf Holmberg (SALON H)\n\nC-27 NEUROSTIMULATION TO UNDERSTAND THE MIND - Sanjay Manchanda, Milan Pantovic, Brian Lord, Jay Sanguinetti, (Chair) (SABINO)\n\nC-28 MEDITATION PRACTICE TO UNDERSTAND THE MIND - Paul Dallaghan,PeterHudoba/Master Sha, DoroteWeyers-Lucci, Lavanya Rajesh Kumar, Sky Nelson (Chair) (SANTA RITA)\n\nC-30 ALTERNATIVE MOLECULAR MODELS OF MIND - Farzad Ahmadkhanlou, Noushin Nabavi, Afshin Lorestani, Charles Ernst, Rajnish Khanna (Chair) (EXEC BOARD ROOM)\n\nBREAK\n\n7:00-9:00 pm - Reception, Cash Bar - Catalina KL\n\n7:00 - 10:00 PM - FRIDAY - ART TECH DEMOS, EXHIBITS - Grand Ballroom Lobby & GB B\n\nPOSTER SESSION 2 - FRI - Grand Ballroom B\n\n1.0 - Philosophy - Elena Drăghici-Vasilescu, Rajnish Khanna, Aaron Schmidt, Richard Blum, Enrique Chiu Han, Hiroki Yamada, Ann Berger-Knorr, Chris Percy, Frank Warzik, Mukesh Chauhan, Rodrigo Marchioli\n\n2.0 - Neuroscience - Vipin Gupta,Scott Koshland, Anderson Rodriguez,Ludmila Vucolova\n\n3.0 - Cognitive Science and Psychology - James Rutherford, Cedric Cannard\n\n4.0 - Physical & Biological Sciences - Mark Rindner, AnatolyGoldstein, Surendra Pokharna, David Smolker, Anderson Rodriguez,Antonius Laurijssen, Seungju Ahn\n\n5.0 - Experiential Approaches - Sandro Guerra, Charles Davis, Barbara With, Dwight Holbrook, Christine Simmonds-Moore\n\n6.0 - Culture & Humanities - Steven Ferrara, Scott Lacy, Harland Harrison, Benjamin White\n\n10 pm - xxx - FRIDAY Poetry Slam - Zombie Blues - No-End of Consciousness Party - Kiva. refreshments/cash bar\n\nSaturday April 27, 2024\n\n7:15-8:15 am Early MORNING - Experiential Clinics\n\nPLENARY SESSIONS - Kiva Ballroom\n\n9:00 am - 10:30 am - Plenary 13 'Dimensions, Wavefunctions & Symmetryin the Brain' -ZIRUI HUANG, SANTOSH HELEKAR, SIR ROGER PENROSE\n\n11:00 am - 12:30 pm - Plenary 14 'Searching for Consciousness & Entanglement in Cerebral Organoids' ALYSSON MUOTRI, HARMUT NEVEN\n\n###\n\nSPONSORS TSC 2024 - Thank you.\n\nArizona Astrobiology Center - Alvin J. Clark Foundation - Anonymous\n\nTiny Blue Dot Foundation - University of Michigan - Google Quantum AI\n\nSociety for Mind-Matter Research - Sanmai Technologies\n\nRegistration:\n\nEVENTBRITE - TSC 2024 CONFERENCE REGISTRATION - Badges required - STANDARD $550 STUDENT $450 - Thur Dinner $95 -sold out (N/A) REMOTE $250 -Live streaming: 3 workshops and 14 plenary\n\nLOEWS - VENTANA CANYON RESORT - GROUP Block - $169 Per Night - Group: The Science of Consciousness (The Resort Fee ($34) Is WAIVED) Conference Registration is needed to secure group rate. Hotel Address: 7000 N. Resort Dr. Tucson AZ - Group Code: TSC330 - Group Rate EXTENSION based on availability. Group Rates Between: April 17 - May 1, 2024\n\nEXHIBITORS\n\nArizona Astrobiology Center ANT-NEURO North America, Inc.\n\nAAPS - Academy for the Advancement of Postmaterialist Sciences COSMOintel\n\nMegahertz Brain Waves Journal of Consciousness Studies Tao Academy - Master Dr. Sha\n\nTimaeus Academy Synaptic.care Ultrabandwidth Praxis Cusac.org Radio Rumi\n\nPICER Institute Psycheprimus Institute for Cognitum Engineering Research Ltd.\n\nFr. Nathan Castle - Gems4Life - Book Signings\n\nNew Releases - Display copies, signings - Additional Demos Lunch Time and at both Poster Sessions (Wed and Fri evenings)\n\nExperiential Sessions - early mornings\n\nTuesday 4/23-7:15-8:00am - Meditation Wellness - Kiva Plaza - Deepak Chopra\n\nWed, Thur, Fri, Sat 7:15-8:15 am\n\nTennisCentric - Mark Valladares -Tennis Courts (Wed, Thur, Fri, Sat) 7:15-8:15am\n\nGlobal Spiritual Meditation -Hidehiko Saegusa - Catalina KL - Thur 4/25 - 7:15-8:15am\n\nHealing Meditation - Sohail Shakeri - Wed, Thurs, Fri - 4/ 24, 25, 26 - 7:15-8:15am - (Catalina J)\n\nFeldenkrais Awareness through Movement® lessons - Roger Russell, Jeff Haller - Wed, Thur, Fri 4/24, 25, 26 - 7:15 - 8:15am - (Ventana 2nd fl.)\n\nSoul Sickness & Healing Techniques Master - Master Zhi Gang Sha, Peter Hudoba, Rulin Xiu - 7:15-8:15am - Locations: Wed 4/24 (Catalina KL) - Thur 4/25 (Exec Bd Rm) - Fri 4/26 (Catalina KL) - Sat 4/27 (Catalina J)\n\nFinding and Clearing the Emotional Roots of your Suffering - Douglas Tataryn - Santa RitaWed, Thurs, Fri - Apr 24,25 26\n\nVan Z'xhibit, Michael Kutch - outdoors daily - GB Lobby\n\nAdditional Thanks\n\nTSC Sponsors - Plenary/Keynote - Loews Ventana Canyon Resort Conference Team - Commotion Studios - UA BioMed - Exhibitors, Experiential Facilitators - Concurrent Speakers - Workshop Speakers, Poster Presenters - All Volunteers - AZ Cine - UA SBS - Herod Travel - Additional co-organizers: Thomas Brophy, IONS/CIHS; Justin Riddle, FSU; Hidehiko Saegusa, IIT Mandi, CIHS, UArizona,AABC U Michigan, George Mashour, Stuart Hameroff, Dante Lauretta, Abi Montefiore\n\n2024 TUCSON - 30th Annual\n\n(‘TSC’),April 22-27, 2024 at the beautiful Loews Ventana Canyon Resort in the hills above Tucson, Arizona. The conference is hosted and sponsored by the University of Arizona, Center for Consciousness Studies and co-sponsored by the University of Michigan, Center for Consciousness Science.\n\nConferences | since 1994\n\nThe Science of Consciousness (TSC) conferences are the pre-eminent world gatherings on all approaches to the profound and fundamental question of how the brain produces conscious experience, a question which addresses who we are, the nature of reality and our place in the universe. TSC conferences have been held in Tucson since 1994, (every 2 years) and are recognized around the world. TSC International held its first conference in 1995 and continues in alternate years.\n\n2024 Themes: Cortical Oscillations and Traveling Waves; Psychedelics, Psychoplastogens; Astrobiology, Astroconsciousness; Dual Aspect Monism; Megahertz EEG and DoDecoGraphy (DDG); Theories of Consciousness; Consciousness and Reality; Artificial Intelligence (AI) and Consciousness Detecting Consciousness; Microtubule Time Crystals; Searching for Consciousness and Entanglement in Cerebral Organoids; Brain Dimensions, Wavefunctions and Symmetry\n\nConference Activities and Social Events TSC 2024\n\nTSC 2024 will include plenary sessions, in-depth workshops, concurrent presentations, poster sessions, book and technology exhibits, health and wellness exhibitors. Free time for swimming, hiking, and other resort activities. Sabino Canyon is approx. 3 miles from the Resort. Welcome Reception (Tues); Dinner (Thurs optional-tickets required); Poetry Slam (Fri)\n\nThe Science of Consciousness Conferences | since 1994\n\nThe Science of Consciousness (TSC) conferences are the pre-eminent world gatherings on all approaches to the profound and fundamental question of how the brain produces conscious experience, a question which addresses who we are, the nature of reality and our place in the universe.\n\nTSC conferences have been held in Tucson since 1994, (every 2 years) and are recognized around the world. TSC International held its first conference in 1995 and continues in alternate years.\n\nBIOS 2024\n\nCONFERENCE CHAIRS\n\nSTUART HAMEROFF\n\nStuart Hameroff Co-Founder, Director, Center for Consciousness Studies; Co-Chair, The Science of Consciousness; Professor Emeritus, Departments of Anesthesiology and Psychology, U of Arizona, Stuart Hameroff MD is a clinical anesthesiologist and researcher on how the brain produces consciousness, and how anesthetics act to erase it. In medical school in the early 1970s, Hameroff became interested in consciousness, and in protein structures called microtubules inside brain neurons which he came to believe processed information supporting consciousness. In the mid- 1990s he teamed with Sir Roger Penrose to develop the controversial ‘Orch OR’ theory in which consciousness derives from “orchestrated” (“Orch”) microtubule quantum vibrations linked to processes in spacetime geometry, the fine scale structure of the universe, leading to “Penrose objective reduction” (“OR”, hence “Orch OR”). And he has further proposed the ‘microtubule quantum vibration’ theory of anesthetic action. Hameroff organizes the well-known conference series ‘The Science of Consciousness’, has written or edited 5 books and over a hundred scientific articles, and appeared in films and various TV shows about consciousness. With University of Arizona colleagues Jay Sanguinetti, John JB Allen and Shinzen Young, Hameroff is developing transcranial ultrasound (‘TUS’) for treatment of mental and cognitive dysfunction (TUS may resonate endogenous megahertz vibrations in brain microtubules). Penrose- Hameroff Orch OR is one of a group of major theories of consciousness in the Templeton World Charity Foundation project ‘Accelerating Research on Consciousness’ and is currently being tested experimentally. (Jan 2024 New Scientist Feature Cover on Quantum Consciousness, G. Musser) (Plen 12)\n\nhttps://hameroff.arizona.edu/\n\nGEORGE MASHOUR\n\nGeorge A. Mashour is an anesthesiologist and NIH-funded neuroscientist at the University of Michigan Medical School, where he serves as the Robert B. Sweet Professor and Chair of Anesthesiology. He founded and currently directs the Michigan Psychedelic Center, which is multidisciplinary and spans the University of Michigan. (Plen 6)\n\nConference Activities and Social Events TSC 2024\n\nTSC 2024 our 30th Annual will include plenary sessions, in-depth workshops, concurrent presentations, poster sessions, book and technology exhibits, health & wellness exhibitors, tenniscentric. Free time for swimming, hiking, and other resort activities. Sabino Canyon is approx 3 miles from the Resort.\n\n2024 Links\n\nABSTRACTS - closed\n\nREGISTRATION - Conference (Eventbrite)\n\nPlease be sure to secure your conference registration so we can coordinate with your hotel reservation. Early Conference Registration through Feb. 10\n\nLOEWS Ventana Canyon Resort - Group Reservation Link\n\nLOEWS Ventana Canyon Resort - Tucson $169 per night - Group Rate - The Deadline for this rate based on availability through March 29. Group Rates Cover Following Dates: April 17 through May 1, 2024 - Conference CODE: TSC330 Group Name: The Science of Consciousness. The Daily Resort Fee $34 is WAIVED for this group\n\nLoews Ventana Canyon, 7000 N. Resort Drive,Tucson,85750\n\n520-299-2020\n\nLoews Corporate 1-877-879-9979\n\nLoews Resort - See Video\n\nGROUP HOTEL BLOCK TSC - (LOEWS) - RESERVATION LINK - NOW OPEN\n\nNew Renovations (Canyon Grill, Pool, Barrista)\n\nVIDEO ARCHIVE: WATCH TSC YOUTUBE CHANNEL\n\nTSC CONFERENCES & PROGRAMS 2007-present\n\nArchives\n\n2022 The Science of Consciousness - Tucson\n\nSESSION VIDEOS 2022 TSC-CCS YouTube Channel\n\nProgram Book & Abstracts TSC 2022View\n\nGuest Interviews - TSC 2022 - Conscious Pictures\n\n20th Anniv and Assorted Videos\n\nRetroMix of TSC Conferences\n\nConsciousness Covid Online 2020\n\nPenrose 2021 Nobel Prize - Intro Reel for TSC online program\n\nInterview with Roger Penrose & Stuart Hameroff, ElsevierConnect, Feb 20, 2014\n\nElsevier Interview with Nobel prize candidate Sir Roger Penrose and Stuart Hameroff,Amsterdam, Feb 19, 2014\n\nJoin our E-list for Conference Updates\n\n2023 - Neuroscience Needs a Revolution to Understand Consciousness - ENCINITAS\n\nCalifornia - Summer Symposium August 18-20, 2023\n\n(co-sponsors: CIHS & CCS)\n\nPROGRAM - Document - AUG 16 Final Program.docx\n\nACCEPTED ABSTRACTS - Doc- AUG 16 Abstracts by Acceptance Type Aug 16 Final Report Encinitas.docx\n\nAUTHORS-AFFILIATIONS INDEX - Document - AUG 16 Final Presenters + Affiliations Report Encinitas.docx\n\nAbstract Submissions - Encinitas -closed Registration Eventbrite-closed\n\nVIDEOS. PLENARY TALKS SHOWCASE TALKS SHORT TALKS\n\nSee YouTube “Playlists”\n\nCenter for Consciousness Studies YouTube Channel:\n\nThe Science of Consciousness Conferences and Special Programs: 2007-2023\n\nThe Tucson Conferences - Biennial\n\nSince 1994, the biennial series \"Toward a Science of Consciousness\" conferences now \"The Science of Consciousness\" are a landmark of international, interdisciplinary events sponsored by the University of Arizona devoted entirely to unlocking the mysteries of consciousness. They have explored the whole spectrum of approaches from philosophy of mind and cognitive science, to neurobiology, pharmacology, and molecular dynamics, phenomenological accounts, and physics. The aim is tolay a sound scientific foundation for future research\n\nThe Science of Consciousness (TSC) conferences are the pre-eminent world gatherings on all approaches to the profound and fundamental question of how the brain produces conscious experience, a question which addresses who we are, the nature of reality and our place in the universe. TSC conferences have been held in Tucson since 1994, (every 2 years) and are recognized around the world. TSC International held its first conference in 1995 and continues in alternate years.\n\nVideos TSC and CCS Programs-Archive\n\nYouTube 1 The Science of Consciousness Conferences & Programs: 2010-2023\n\nChannel 2: UofA Consciousnessadditional 2012\n\nStuart Hameroff MD, Anesth CCS Director - COM-UA website\n\nAbi Behar Montefiore - asst dir, sr. program mgr\n\n520-247-5785 text/messages center@arizona.edu\n\nSUPPORT THE CENTER\n\nJOIN OUR E-LIST FOR CONFERENCE UPDATES\n\nTSC 2018\n\nJune 7th, 2023\n\n15:00 - University of Oxford\n\nTalk with Stuart Hameroff MD\n\nMathematical Institute, Univ of Oxford Room L3 - Woodstock Rd. Oxford\n\nNeuroscience needs a revolution\n\nStuart Hameroff MD - Professor, Anesthesiology and Psychology; Director, Center for Consciousness Studies, The University of Arizona, Tucson\n\nhttps://www.frontiersin.org/articles/10.3389/fnmol.2022.869935/full\n\nhttps://omcan.web.ox.ac.uk/event/neuroscience-needs-revolution.\n\nTaormina TSC - Sicily\n\nMay 22-28, 2023\n\nPalazzo dei Congressi\n\nMay 22-28, 2023 - TSC 2023 Taormina, Sicily, Italy\n\nNEW: Taormina Italy Videos\n\nhttps://youtube.com/@TSC2023-Taormina-qw2ie\n\nTaormina Italy - TSC 2023 -May 22-28 - The Science of Consciousness YouTube Videos\n\nPLENARY VIDEOS Taormina (31) - TSC 2023 Taormina YouTube - Videos Page\n\nSir Roger Penrose Taormina Plenary\n\nCONFERENCE PROGRAMCONFERENCE WEBSITE Program/Abstracts\n\nPalazzo dei Congressi\n\nThe Science of Consciousness (TSC) conferences have been held annually since 1994, alternating yearly between Tucson, Arizona in even-numbered years, and other locations around the world in odd-numbered years. TSC locations have included Italy, Denmark, Japan, Sweden, Czech Republic, Hungary, Hong Kong, India, California, Switzerland, and Finland. The 29th annual TSC will return to Italy, to beautiful Taormina, on the island of Sicily, May 22-28, 2023, organized by Italian professors Riccardo Manzotti (IULM U), Antonio Chella (U Palermo) and Pietro Perconti (U Messina). TSC 2023 Taormina will be co-sponsored by the Center for Consciousness Studies, The University of Arizona, Tucson, Stuart Hameroff, Director. The first overseas TSC Conference in 1995 was on the island of Ischia, near Naples, Italy, organized by Cloe Taddei-Ferretti. We are excited to be returning to Italy. Abstracts may be submitted for oral concurrent talks, or posters.\n\nTAORMINA TSC 2023 CONFERENCE PROGRAM\n\nWorkshopsKeynote and PlenariesConcurrents Posters\n\nContact: Registration - Anna Lucentini - tsc2023@bisazzagangi.it\n\nContact at CCS - Abi Behar Montefiore - center@arizona.edu -www.consciousness.arizona.edu\n\n* * * * *\n\nTHE SCIENCE OF CONSCIOUSNESS\n\n2022 Tucson Hybrid -TSC Apr 18-22\n\nSESSION VIDEOS 2022 TSC-CCS YouTube Channel\n\nProgram Book & Abstracts TSC 2022 View | Download\n\nGuest Interviews - TSC 2022 - Conscious Pictures\n\nWe held a 'hybrid' conference with both in-person, and remote online presentation and audience, live streamed. The live sessions and remote headquarters were held at Loews Ventana Canyon Resort, Tucson, Arizona\n\nTSC 2022 - Plenary 1 - Sleep, Wakefulness & Anesthesia Giancarlo Vanini, Matthew Larkum, Alex Proekt\n\nTSC 2022 - Plenary 2 - Keynote 1 - Brain & Consciousness Christof Koch\n\nTSC 2022 - Plenary 3 - Brain Connectivity Jean-Remi King, Zirui Huang, Anirban Bandyopadhyay\n\nTSC 2022 - Plenary 4 - Altered States of Consciousness Emma Huels, Charlotte Martial, Elizabeth Krasnoff\n\nTSC 2022 - Plenary 5 - Keynote 2 - Psychedelics Robin Carhart-Harris\n\nTSC2022 - Plenary 6 - Psychedelic Mechanisms George Mashour, Alex C. Kwan, Katrin Preller\n\nTSC 2022 - Plenary 7 - Time & Consciousness Daniel Sheehan, Paul Davies, Sir Roger Penrose\n\nTSC 2022 - Plen 8 Keynote 3 Avi Loeb\n\nTSC 2022 - Plenary 9 - Origins of Life Dante Lauretta, Sara Walker, Steen Rasmussen\n\nTSC 2022 - Plen 10 - Theories of Consciousness Biyu J. He, Yuri B. Saalmann, Lucia Melloni\n\nTSC 2022 - Plenary 11 - Keynote 4 David Chalmers\n\nTSC 2022 - Plenary 12 - Quantum Neuroscience Hartmut Neven, Aarat Kalra, Travis Craddock\n\nStuart Hameroff 2021 - Quantum biology and consciousness\n\nA 4-day online webinar with Sir Roger Penrose and guest speakers\n\nAbout the Webinar & Background links\n\nVideos (Day 1, 2, 3, 4) - YouTube\n\nSpeaker Bios & Abstracts\n\nProgram Schedule\n\nIntro Reel - Celebration Trailer - highlights\n\nRoger Penrose for the 4-day Symposium\n\nhosted by the Center for Consciousness Studies - 2021\n\nTHE SCIENCE OF CONSCIOUSNESS\n\nCovid Consciousness - Remote 2020\n\nSept 14-18, 2020\n\nThe Science of Consciousness Online Conference Sessions\n\nTSC 2020 - TSC Tucson Online Program | Abstracts\n\nVIDEOS - CCS-TSC YouTube VIDEO CHANNEL\n\nOpening \"Welcome\" Reel for Tucson Online 2020\n\nRetro Mix - TSC Over the Years...(Abi’s) 2020\n\nOnline\n\nSessions, Abstracts:\n\nhttps://eagle.sbs.arizona.edu/sc/abs_report_bysession.php?p=PL&nbsp; - Plenary\n\nhttps://eagle.sbs.arizona.edu/sc/abs_report_bysession.php?p=C&nbsp; - Concurrents\n\nhttps://eagle.sbs.arizona.edu/sc/abs_report_bysession.php?p=P&nbsp; - Posters\n\nhttps://eagle.sbs.arizona.edu/sc/abs_report_bysession.php?p=A&nbsp; - Art | Tech\n\nTHE SCIENCE OF CONSCIOUSNESS\n\nInterlaken Switzerland June 25-28, 2019\n\n2019 - TSC - Interlaken Switzerland\n\nTSC 2019 - Interlaken Program Abstracts\n\nTSC 2019 - Consciousness Central - Interviews\n\nTSC 2019 - VIDEOS\n\nTHE SCIENCE OF CONSCIOUSNESS - 2018\n\n2018 - The Science of Consciousness - Tucson\n\n2018 Conference Themes:\n\nAre We Living in a Matrix-like Simulation? - Artificial Intelligence/Machine Consciousness - Consciousness, Pain and Addiction - Gene Editing and Consciousness Binding, Integration and Synthesis of Consciousness - Brain Mapping and the Connectome Anterior and Posterior Cortex: What's 'Hot' and What's Not? - Anesthetic and Psychoactive Drugs, Language and Consciousness - Non-Invasive Brain Modulation, Origin and Evolution of Life and Consciousness - Panpsychism, Idealism and Spacetime Geometry\n\nQuantum Brain Biology - Time, Free Will and Consciousness\n\nEarly Center Videos/Podcasts through 2016\n\napple itunes podcasts are being uploaded to our YouTube Channel"
    ],
    "# Yurts.ai Company and Product Overview\n\n## Company Overview\n\nYurts Technologies, Inc., founded in 2022, is a pioneering company specializing in secure generative artificial intelligence (GenAI) solutions tailored for defense, government, and enterprise customers. The company emerged from its work with the Department of Defense (DoD) and has positioned itself as a leader in integrating AI into mission-critical workflows. Yurts aims to modernize enterprise knowledge management and workflows through a highly adaptable and secure GenAI platform [(Buford, Redhorse Corporation, 2024-02-21)](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/).\n\nYurts recently closed a $40 million Series B funding round led by XYZ Venture Capital, with participation from several other investors, bringing its total funding to $58 million. This funding will be used to enhance its capabilities and accelerate the integration of GenAI into mission-critical systems [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/). The company has also secured significant contracts, including a $16 million deal with U.S. Special Operations, showcasing its strong foothold in the defense sector [(Leadiq, 2024)](https://leadiq.com/c/yurts/63617f9bd4454f2aa396b5ff).\n\n## Product Overview\n\nYurts.ai offers a comprehensive AI platform designed to transform knowledge management and mission-critical workflows at scale. The platform features several key functionalities:\n\n- **Enterprise Search**: Yurts leverages proprietary Retrieval Augmented Generation (RAG) models to provide users with the most relevant and recent enterprise data, enabling confident decision-making [(Allen, Yurts.ai, 2024)](https://www.yurts.ai/products).\n  \n- **Natural Language Processing**: Users can refine queries using natural language, allowing for deeper insights into data sources and facilitating the generation of personalized, context-rich reports and summaries [(Allen, Yurts.ai, 2024)](https://www.yurts.ai/products).\n\n- **Embedded Assistant**: The platform allows for the deployment of AI assistants within various enterprise applications, ensuring a consistent AI experience across different environments [(Allen, Yurts.ai, 2024)](https://www.yurts.ai/products).\n\n- **Data Security**: Yurts emphasizes security, particularly in high-stakes environments, by ensuring that its AI solutions do not train on proprietary data and can be deployed on-premise, thus maintaining maximum control for organizations handling sensitive information [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/).\n\n## Strategic Partnerships\n\nYurts has established strategic partnerships to enhance its offerings and expand its market reach. Notably, it has partnered with Redhorse Corporation to deploy secure generative AI solutions for federal agencies, aligning with Redhorse's mission to modernize government operations through technology [(Buford, Redhorse Corporation, 2024-02-21)](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/). Additionally, Yurts has expanded its partnership with Oracle, further demonstrating its capability to support commercial customers in modernizing their systems with AI [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/).\n\n## Executive Insights\n\nBen Van Roo, Co-Founder and CEO of Yurts, expressed the company's commitment to advancing federal government capabilities through generative AI, stating, “From critical missions to the modernization of legacy technologies, we believe generative AI will advance federal government in its journey towards technological empowerment and enhanced decision-making” [(Buford, Redhorse Corporation, 2024-02-21)](https://redhorsecorp.com/redhorse-announces-strategic-partnership-with-yurts-ai-to-deploy-secure-generative-ai-solutions/). This sentiment reflects Yurts' focus on delivering tangible results and enhancing operational efficiency for its clients.\n\n## Employee and Market Scale\n\nYurts has rapidly grown its workforce, with nearly 25% of its employees holding active security clearances, underscoring its expertise in high-security environments [(Chowdhry, Pulse2, 2024-12-03)](https://pulse2.com/yurts-defense-focused-genai-company-closes-40-million-series-b/). The company is positioned to redefine how organizations harness AI, particularly in sectors where security and compliance are paramount.\n\n## Conclusion\n\nYurts.ai is at the forefront of integrating generative AI into mission-critical workflows, particularly within the defense and government sectors. With significant funding, strategic partnerships, and a robust product offering, Yurts is well-positioned for growth and innovation in the AI landscape. Prospective candidates and investors should consider the company's strong market presence and commitment to security and operational efficiency as key factors in their decision-making process."
  ],
  "lineage": {
    "run_at": "2025-02-04T18:53:27.222431",
    "git_sha": "08c0ab7"
  }
}