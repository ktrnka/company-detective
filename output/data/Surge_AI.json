{
  "summary_markdown": "# About Surge AI\n\nSurge AI is a data labeling company founded on January 1, 2020, and is based in San Francisco. The company specializes in providing high-quality training data for machine learning and artificial intelligence applications, with a particular focus on Natural Language Processing (NLP) and advanced labeling tasks. Surge AI operates primarily in the B2B sector, serving a diverse range of clients, including Fortune 500 technology companies, leading social media platforms, and AI startups and research institutions like Anthropic and Redwood Research [(Crunchbase, 2025)](https://www.crunchbase.com/organization/surge-ai-b4ea).\n\nSurge AI's primary product is its data annotation service, which supports the training of AI models by providing high-quality labeled data. The company employs a gig economy model, hiring contractors to perform data annotation tasks. This model allows Surge AI to scale its operations flexibly, responding to the fluctuating demand for AI training data [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\nThe company has raised a total of $25 million in funding as of July 1, 2020 [(Crunchbase, 2025)](https://www.crunchbase.com/organization/surge-ai-b4ea). While specific revenue figures are not publicly available, the company is part of a growing sector that has seen significant investment and interest.\n\nSurge AI's platform includes user-friendly labeling tools, a skilled workforce capable of handling tasks in over 30 languages, and modern APIs for seamless integration with existing systems. The company is known for its partnerships, such as working with Anthropic to enhance their LLMs through Reinforcement Learning from Human Feedback (RLHF) [(Surge AI, 2023)](https://www.surgehq.ai/).\n\n# Key Personnel\n\n- **Edwin Chen**: CEO of Surge AI. There has been a noted lack of communication from the company regarding its operations and the working conditions of its contractors [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n- **Andrew Mauboussin**: Oversees Engineering and Machine Learning teams, with a background in computer science from Harvard.\n- **Bradley Webb**: Leads Product and Growth teams, previously worked at Facebook.\n- **Jefferson Lee**: Heads data labeling and NLP products, with experience in Trust and Safety ML at Airbnb.\n- **Scott Heiner**: Manages Business Development and Operations, with a background in media industry operations [(Surge AI, 2023)](https://www.surgehq.ai/).\n\n# News\n\n## Ethical and Labor Practices\n\nSurge AI has been involved in discussions about the ethical implications of outsourcing data annotation work. Concerns have been raised regarding the lack of training and standards for contractors, which can lead to inconsistent data quality and ethical dilemmas in AI training. The company has not publicly addressed these concerns, which may affect its reputation and operational practices [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n## Worker Experiences\n\nThe gig work model employed by Surge AI has attracted a diverse range of contractors, including students and professionals seeking flexible work opportunities. Reports indicate that some contractors have earned substantial income through data annotation tasks, with pay rates ranging from $20 to $45 per hour. However, there are also reports of job insecurity, with contractors sometimes facing abrupt account suspensions without explanation. Feedback from contractors has been mixed, with some expressing satisfaction with the flexibility and income potential, while others have raised concerns about the lack of support and communication from the company [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n## Industry Position\n\nSurge AI competes with other data curation companies such as Scale AI and Outlier. The demand for such services has surged due to the rapid advancement of AI technologies, particularly in the context of large language models like OpenAI's ChatGPT [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n## Recent Developments\n\nSurge AI has been highlighted in discussions about how AI is creating a safer online world [(Valerias Bangert, VentureBeat, 2022-03-27)](https://venturebeat.com/2022/03/27/how-ai-is-creating-a-safer-online-world/).\n\n# Conclusion\n\nSurge AI is a key player in the data curation market, providing essential data annotation services for AI training. While the company has positioned itself as a leader in the industry, it faces challenges related to labor practices and ethical considerations. Prospective candidates and investors should weigh these factors when considering engagement with Surge AI, as the company's future growth and reputation may be influenced by its handling of contractor relations and data quality standards.",
  "target": [
    "Surge AI",
    "Surge AI",
    "surgehq.ai",
    null,
    false,
    false,
    null,
    [
      false,
      false
    ]
  ],
  "webpage_result": {
    "summary_markdown": "# Surge AI Company Overview\n\n## Company History\nSurge AI is a leading data labeling platform designed to provide high-quality data for machine learning and artificial intelligence applications. The company focuses on addressing the challenges of Natural Language Processing (NLP) and advanced labeling tasks through a robust workforce and modern technology.\n\n## Services\nSurge AI offers a comprehensive data labeling platform that includes:\n\n- **Data Labeling**: Annotating raw data to train or evaluate machine learning models.\n- **Human Feedback**: Utilizing human evaluators to provide feedback for training large language models (LLMs).\n- **Search Evaluation**: Assisting companies in evaluating the quality and relevance of search engine results.\n- **Content Moderation**: Labeling user-generated content to identify hate speech, misinformation, and spam.\n\n## Products\nSurge AI's platform is built from the ground up to handle various data labeling projects, from simple sentiment analysis to complex tasks like training code-generation AI. Key features include:\n\n- **Labeling Tools**: User-friendly tools for individuals and enterprises to create and manage labeling projects.\n- **Surger Workforce**: A skilled workforce that can handle data labeling tasks in over 30 languages.\n- **APIs**: Modern APIs for seamless integration with existing systems.\n\n## Customers\nSurge AI serves a diverse range of clients, including:\n\n- Fortune 500 technology companies\n- Leading social media platforms\n- AI startups and research institutions like Anthropic and Redwood Research\n\nNotable partnerships include working with Anthropic to enhance their LLMs through Reinforcement Learning from Human Feedback (RLHF) and providing data labeling solutions for a leading social media company that improved accuracy by 62%.\n\n## Leadership Team\nThe leadership team at Surge AI includes:\n\n- **Andrew Mauboussin**: Oversees Engineering and Machine Learning teams, with a background in computer science from Harvard.\n- **Bradley Webb**: Leads Product and Growth teams, previously worked at Facebook.\n- **Jefferson Lee**: Heads data labeling and NLP products, with experience in Trust and Safety ML at Airbnb.\n- **Scott Heiner**: Manages Business Development and Operations, with a background in media industry operations.\n\n## Company Culture\nSurge AI fosters a culture of innovation and collaboration, emphasizing the importance of high-quality human data in training AI systems. The company values creativity and adaptability, encouraging its workforce to explore new strategies for data collection and labeling.\n\n## Conclusion\nSurge AI stands out as a premier data labeling platform, leveraging human intelligence to enhance the capabilities of AI systems. With a strong leadership team and a commitment to quality, Surge AI is well-positioned to meet the growing demands of the AI and machine learning industries.\n\nFor more information, visit [Surge AI](https://www.surgehq.ai/).",
    "page_markdowns": [
      "# [World's Most Powerful GenAI Data](https://www.surgehq.ai/)\n",
      "# [Surge AI](https://www.surgehq.ai/blog)\nFeatured\n\nHow Anthropic uses Surge AI’s RLHF platform to train their LLM Assistant on Human Feedback\n\nEdwin Chen\n\nLarge Language Models\n\nLearn how Anthropic partnered with Surge AI to gather high-quality human feedback at scale using the RLHF platform, resulting in one of the safest and most advanced large language models on the planet.\n\nRead more\n\nThank you! Your submission has been received!",
      "# [World's top Enterprises, Startups & LLM Labs](https://www.surgehq.ai/customers)\n",
      "# [Introducing the experts Behind Our Articles](https://www.surgehq.ai/authors)\nAndrew oversees Surge AI's Engineering and Machine Learning teams. He previously led Twitter's Spam and Integrity efforts, and studied Computer Science at Harvard.\n\nBradley runs Surge AI's Product and Growth teams. He previously led Integrity and Data Operations teams at Facebook, and graduated from Dartmouth.",
      "# [All-in-one data labeling platform](https://www.surgehq.ai/about)\nSurge AI is the world’s best data labeling platform and workforce, providing the highest quality data to today's top tech companies and researchers. We're built from the ground up to tackle the extraordinary challenges of Natural Language Processing and other advanced labeling tasks — with an elite workforce, stunning quality, rich labeling tools, and modern APIs.\n\nData labeling is the process of annotating raw data in order to effectively train or evaluate machine learning models and artificial intelligence. Data labeling projects can range from simple (labeling the sentiment of text snippets) to complex (writing Python to train code-generation AI). Surge AI can handle it all, at scale.\n\nIt’s easy. For individuals: sign up for free, create a labeling project, and launch. Watch the results appear in real time!\n\nFor enterprise: book a call with us to discuss your labeling project. In most cases, we’ll launch a sample project for you same-day.\n\nThere are two components to the Surge AI platform — our labeling tools and the Surger workforce.\n\nIndividuals use our labeling tool for free and set their own pricing when using the Surger workforce (we typically recommend 30-40 cents per minute). Please reach out if you’d like further pricing guidance.\n\nFor enterprise, we price projects on a per task basis. Book an intro call to learn more.\n\nFor more info, visit our pricing page.",
      "# [Data Labeling for Large Language Models](https://www.surgehq.ai/rlhf)\n\"Nobody understands how to generate high-quality human data like Surge AI. Our engineering team was spending 50% of their time managing contractors, after unsuccessfully iterating with other data providers for 18 months, which was a poor use of their time. The Surge AI team came in, redesigned our data collection methods, and doubled the amount of high-quality data for training our models in two weeks. That data gave us the biggest gain in metrics I’ve seen since I joined.\"\n\nVP of Engineering\n\nFortune 500 technology company\n\n“The biggest game-changer for my research recently has been using Surge AI for human data collection. With Surge, the workflow for collecting human data now looks closer to “launching a job on a cluster” which is wild to me.”\n\nEthan Perez\n\nResearch scientist at Anthropic\n\n“If you want to do an NLP data collection/labeling process and don't want/need to be managing annotators directly, Surge is remarkably easy to work with and their team does very good work.”\n\nSam Bowman\n\nProfessor at NYU",
      "# [High-quality data labeling in 30+ languages](https://www.surgehq.ai/pricing)\nSurge AI is the world’s best data labeling platform and workforce, providing the highest quality data to today's top tech companies and researchers. We're built from the ground up to tackle the extraordinary challenges of Natural Language Processing and other advanced labeling tasks — with an elite workforce, stunning quality, rich labeling tools, and modern APIs.\n\nData labeling is the process of annotating raw data in order to effectively train or evaluate machine learning models and artificial intelligence. Data labeling projects can range from simple (labeling the sentiment of text snippets) to complex (writing Python to train code-generation AI). Surge AI can handle it all, at scale. You can download our datasets to see what great data looks like.\n\nIt’s easy. For individuals: sign up for free, create a labeling project, and launch. Watch the results appear in real time!\n\nFor enterprise: book a call with us to discuss your labeling project. In most cases, we’ll launch a sample project for you same-day.\n\nThere are two components to the Surge AI platform — our labeling tools and the Surger workforce.\n\nFor enterprise, we price projects on a per task basis. Book an intro call to learn more.",
      "# [Make your data dreams come true](https://www.surgehq.ai/contact)\n",
      "# [Privacy Policy](https://www.surgehq.ai/privacy-policy)\nLast updated: March 8, 2021\n\nThis Privacy Policy explains how Surge Labs, Inc. (\"Surge,\" \"we\" or \"us\") collects, uses, and discloses information about you. This Privacy Policy applies to our Services (as defined in our Terms of Service).\n\nWe may change this Privacy Policy from time to time. If we make changes, we will notify you by revising the date at the top of this policy and, in some cases, we may provide you with additional notice (such as adding a statement to our Services or sending you a notification). We encourage you to review this Privacy Policy regularly to stay informed about our information practices and the choices available to you.\n\nCOLLECTION OF INFORMATION\n\nInformation You Provide to Us\n\nWhen you create an account, we ask that you provide your name and email address. We also collect information when you make a payment (such as your credit card information), apply for a job, communicate with us via third-party social media sites, request customer support, or otherwise communicate with us.\n\nWhen you create a new project with us, we may ask you to provide data files and the names and email addresses of who will be labeling such files. You may also submit information about other users who will be collaborating with you on the project, such as their name, role, and email.\n\nInformation We Collect Automatically When You Interact with Us\n\nWhen you access or use our Services, we automatically collect certain information, including:\n\nTransactional Information: When you make a payment, we collect information about the transaction, such as purchase price, and date and location of the transaction.\n\nDevice and Usage Information: We collect information about how you access our Services, including data about the device and network you use, such as your hardware model, operating system version, mobile network, IP address, unique device identifiers, and browser type. We also collect information about your activity on our Services, such as access times, pages viewed, links clicked, and the page you visited before navigating to our Services.\n\nLocation Information: We may derive the approximate location of your device from your IP address.\n\nInformation Collected by Cookies and Similar Tracking Technologies: We (and our service providers) use tracking technologies, such as cookies and web beacons, to collect information about you. Cookies are small data files stored on your hard drive or in device memory that help us improve our Services and your experience, see which areas and features of our Services are popular, and count visits. Web beacons (also known as \"pixel tags\" or \"clear GIFs\") are electronic images that we use on our Services and in our emails to help deliver cookies, count visits, and understand usage and campaign effectiveness. For more information about cookies and how to disable them, see the Your Choices section below.\n\nInformation We Derive\n\nWe may derive information or draw inferences about you based on the information we collect. For example, we may make inferences about your location based on your IP address.\n\nUSE OF INFORMATION\n\nWe use the information we collect to:\n\nProvide, maintain, and improve our Services;\n\nPersonalize and improve your experience on our Services;\n\nSend you technical notices, security alerts, and support and administrative messages;\n\nRespond to your comments and questions and provide customer service;\n\nCommunicate with you about products, services, and events offered by Surge and others and provide news and information that we think will interest you (see the Your Choices section below for information about how to opt out of these communications at any time);\n\nMonitor and analyze trends, usage, and activities in connection with our Services;\n\nPersonalize the advertisements you see on third-party platforms and websites (for more information, see the Advertising and Analytics section below);\n\nDetect, investigate, and prevent security incidents and other malicious, deceptive, fraudulent, or illegal activity and protect the rights and property of Surge and others;\n\nDebug to identify and repair errors on our Services;\n\nComply with our legal and financial obligations;\n\nCarry out any other purpose described to you at the time the information was collected.\n\nSHARING OF INFORMATION\n\nWe share personal information in the following circumstances or as otherwise described in this Privacy Policy:\n\nWe share personal information with vendors, service providers, and consultants that need access to personal information in order to perform services for us, such as companies that assist us with web hosting, data labeling, fraud prevention, customer service, and marketing and advertising.\n\nWe may disclose personal information if we believe that disclosure is in accordance with, or required by, any applicable law or legal process, including lawful requests by public authorities to meet national security or law enforcement requirements.\n\nWe may share personal information if we believe that your actions are inconsistent with our user agreements or policies, if we believe that you have violated the law, or if we believe it is necessary to protect the rights, property, and safety of us, our users, the public, or others.\n\nWe share personal information with our lawyers and other professional advisors where necessary to obtain advice or otherwise protect and manage our business interests.\n\nWe may share personal information in connection with, or during negotiations concerning, any merger, sale of company assets, financing, or acquisition of all or a portion of our business by another company.\n\nWe share personal information with your consent or at your direction.\n\nWe also share aggregated or de-identified information that cannot reasonably be used to identify you.\n\nSOCIAL SHARING FEATURES\n\nOur Services may offer social sharing features and other integrated tools (such as the Facebook “Like” button). Your use of such features enables the sharing of information with your friends or the public, depending on the settings you establish with the entity that provides the social sharing feature. For more information about the purpose and scope of data collection and processing in connection with social sharing features, please visit the privacy policies of the entities that provide these features.\n\nDATA RETENTION\n\nWe store the information we collect on you for as long as is necessary for the purpose(s) for which we originally collected it, or for other legitimate business purposes, including to meet our legal, regulatory, or other compliance obligations.\n\nTRANSFER OF INFORMATION TO THE UNITED STATES AND OTHER COUNTRIES\n\nSurge is headquartered in the United States, and we have operations and service providers in the United States. We and our service providers may transfer your personal information to, or store or access it in, jurisdictions that may not provide levels of data protection that are equivalent to those of your home jurisdiction. We will take commercially reasonable steps to ensure that your personal information receives an adequate level of protection in the jurisdictions in which we process it.\n\nYOUR CHOICES\n\nAccount Information\n\nYou may update and correct certain account information you provide to us at any time by logging into your account or emailing us at support@surgehq.ai. If you wish to delete or deactivate your account, please email us at support@surgehq.ai, but note that we may retain certain information as required by law or for legitimate business purposes. We may also retain cached or archived copies of information about you for a certain period of time.\n\nCookies\n\nMost web browsers are set to accept cookies by default. If you prefer, you may be able to adjust your browser settings to remove or reject browser cookies. Please note that removing or rejecting cookies could affect the availability and functionality of the Services.\n\nCommunications Preferences\n\nYou may opt out of receiving promotional emails from Surge by following the instructions in those communications. If you opt out, we may still send you non-promotional emails, such as those about your account or our ongoing business relations.\n\nCONTACT US\n\nIf you have any questions about this Privacy Policy, please contact us at support@surgehq.ai.\n\n‍",
      "# [Power Your Search Engine with Human Evaluation](https://www.surgehq.ai/search-evaluation)\n\"Nobody understands how to generate high-quality human data like Surge AI. Our engineering team was spending 50% of their time managing contractors, after unsuccessfully iterating with other data providers for 18 months, which was a poor use of their time. The Surge AI team came in, redesigned our data collection methods, and doubled the amount of high-quality data for training our models in two weeks. That data gave us the biggest gain in metrics I’ve seen since I joined.\"\n\nVP of Engineering\n\nFortune 500 technology company\n\n“The biggest game-changer for my research recently has been using Surge AI for human data collection. With Surge, the workflow for collecting human data now looks closer to “launching a job on a cluster” which is wild to me.”\n\nEthan Perez\n\nResearch scientist at Anthropic\n\n“If you want to do an NLP data collection/labeling process and don't want/need to be managing annotators directly, Surge is remarkably easy to work with and their team does very good work.”\n\nSam Bowman\n\nProfessor at NYU\n\n\"The Surge AI team are experts at collecting data for training and evaluating large language models. They worked closely with us every step of the way, from helping us understand what types of data we should collect to designing our tasks and guidelines. Their experience and expertise accelerated our timelines for training new human feedback models from 1 year to 1 month.\"\n\nVP of Product\n\nA unicorn AI startup\n\n“When I joined our company, one of my first realizations was that low-quality training data was holding our machine learning models back. It was taking our team 6 months to gather datasets to train new models, and our data scientists were saying half the data was unusable due to quality issues. We talked to Surge AI, and in 2 weeks, they replaced a year’s worth of training data. Retraining our models gave us a 63% boost in model AUC – which was larger than our entire team of ML engineers had produced in 2 years.”\n\nDirector of Engineering, Trust & Safety\n\nLarge social media company\n\n\"The data Surge AI produces is worth its weight in gold. I used to work at Google and Facebook, and we’d have accelerated our ML development by years if we’d had something like Surge AI. Their speed and quality has enabled new machine learning products, and they get it all right on the first try, without needing to iterate for months.\"\n\nCTO\n\nA billion-dollar fintech startup",
      "# [Data Labeling for Content Moderation](https://www.surgehq.ai/content-moderation)\n\"Nobody understands how to generate high-quality human data like Surge AI. Our engineering team was spending 50% of their time managing contractors, after unsuccessfully iterating with other data providers for 18 months, which was a poor use of their time. The Surge AI team came in, redesigned our data collection methods, and doubled the amount of high-quality data for training our models in two weeks. That data gave us the biggest gain in metrics I’ve seen since I joined.\"\n\nVP of Engineering\n\nFortune 500 technology company\n\n“The biggest game-changer for my research recently has been using Surge AI for human data collection. With Surge, the workflow for collecting human data now looks closer to “launching a job on a cluster” which is wild to me.”\n\nEthan Perez\n\nResearch scientist at Anthropic\n\n“If you want to do an NLP data collection/labeling process and don't want/need to be managing annotators directly, Surge is remarkably easy to work with and their team does very good work.”\n\nSam Bowman\n\nProfessor at NYU\n\n\"The Surge AI team are experts at collecting data for training and evaluating large language models. They worked closely with us every step of the way, from helping us understand what types of data we should collect to designing our tasks and guidelines. Their experience and expertise accelerated our timelines for training new human feedback models from 1 year to 1 month.\"\n\nVP of Product\n\nA unicorn AI startup\n\n“When I joined our company, one of my first realizations was that low-quality training data was holding our machine learning models back. It was taking our team 6 months to gather datasets to train new models, and our data scientists were saying half the data was unusable due to quality issues. We talked to Surge AI, and in 2 weeks, they replaced a year’s worth of training data. Retraining our models gave us a 63% boost in model AUC – which was larger than our entire team of ML engineers had produced in 2 years.”\n\nDirector of Engineering, Trust & Safety\n\nLarge social media company\n\n\"The data Surge AI produces is worth its weight in gold. I used to work at Google and Facebook, and we’d have accelerated our ML development by years if we’d had something like Surge AI. Their speed and quality has enabled new machine learning products, and they get it all right on the first try, without needing to iterate for months.\"\n\nCTO\n\nA billion-dollar fintech startup",
      "# [Real-World Examples](https://www.surgehq.ai/case-studies)\nCase Studies",
      "# [Get started with Surge AI](https://www.surgehq.ai/sign-up)\nThe biggest game-changer for my research has been using Surge AI\n\nLorem ipsum dolor sit amet consectetur. Nunc sed aliquam eros sed. Purus et lacinia bibendum lacus sem posuere. Viverra nisi id elementum vulputate. Nunc non quis vitae hac hendrerit at fermentum metus. Lacus vitae cursus accumsan sed est.Lorem ipsum dolor sit amet consectetur. Nunc sed aliquam eros sed.",
      "# [Detect Toxicity Instantly](https://www.surgehq.ai/toxicity-api)\nOur toxicity API is a powerful tool for detecting toxic speech online. Try it yourself — type text below and see your results.",
      "# [Terms of Service](https://www.surgehq.ai/terms-of-service)\nLast updated: December 7, 2021\n\nThese Terms of Service (“Terms”) apply to your access to and use of the websites and other online products and services (collectively, the “Services”) provided by Surge Labs, Inc. (“Surge” or “we”). By clicking “I Accept” or by using our Services, you agree to these Terms, including the mandatory arbitration provision and class action waiver in Section 15. If you do not agree to these Terms, do not use our Services.\n\nWe may make changes to these Terms from time to time. If we make changes, we will provide you with notice of such changes, such as by sending an email, providing a notice through our Services or updating the date at the top of these Terms. Unless we say otherwise in our notice, the amended Terms will be effective immediately, and your continued use of our Services after we provide such notice will confirm your acceptance of the changes. If you do not agree to the amended Terms, you must stop using our Services.\n\nIf you have any questions about these Terms or our Services, please contact us at support@surgehq.ai.\n\nYour continued use of this Service after such modifications will constitute acknowledgement of the modified Terms of Service and agreement to abide and be bound by the modified Terms of Service.\n\n1. Privacy\n\nFor information about how we collect, use, share or otherwise process information about you, please see our Privacy Policy.\n\n2. Eligibility\n\nYou must be at least 13 years of age to use our Services. If you are a parent or legal guardian of a user under the age of 18 (or the age of legal majority), you agree to be fully responsible for the acts or omissions of such user in relation to our Services. If you use our Services on behalf of another person or entity, (a) all references to “you” throughout these Terms will include that person or entity, (b) you represent that you are authorized to accept these Terms on that person’s or entity’s behalf, and (c) in the event you or the person or entity violates these Terms, the person or entity agrees to be responsible to us.\n\nWe neither endorse nor assume any liability for the contents of any material uploaded or submitted by third party users of the Service. However, we and our agents have the right at their sole discretion to remove any content that, in our judgment, does not comply with these Terms of Service and any other rules of user conduct for our site, or is otherwise harmful, objectionable, or inaccurate. We are not responsible for any failure or delay in removing such content. You hereby consent to such removal and waive any claim against us arising out of such removal of content.\n\nYou agree that we may at any time, and at our sole discretion, terminate your membership, account, or other affiliation with our site without prior notice to you for violating any of the above provisions. In addition, you acknowledge that we will cooperate fully with investigations of violations of systems or network security at other sites, including cooperating with law enforcement authorities in investigating suspected criminal violations.\n\n3. User Accounts and Account Security\n\nYou may need to register for an account to access some or all of our Services. If you register for an account, you must provide accurate account information and promptly update this information if it changes. You also must maintain the security of your account and promptly notify us if you discover or suspect that someone has accessed your account without your permission. If you permit others to use your account credentials, you are responsible for the activities of such users that occur in connection with your account. We reserve the right to reclaim usernames, including on behalf of businesses or individuals that hold legal claim, including trademark rights, in those usernames.\n\n4. User Content\n\nOur Services may allow you and other users to upload content, including messages, text, photos, videos, software and other materials (collectively, “User Content”). Except for the license you grant below, you retain all rights in and to your User Content, as between you and Surge.\n\nYou grant Surge and its subsidiaries and affiliates a nonexclusive, royalty-free, worldwide, fully paid, and sublicensable license to use, reproduce, modify, adapt, publish, translate, and create derivative works from your User Content as necessary to perform the Services. Notwithstanding anything to the contrary, to the extent the Services involve the labeling of User Content provided by or on your behalf (“User Data”), you hereby grant Surge a non-exclusive, irrevocable, worldwide, non-transferable, sublicenseable, fully paid-up, royalty-free, and perpetual license to use such User Data for Surge’s internal business purposes and to improve Surge’s service offerings.\n\nYou may not upload to the Services any User Content that violates these Terms or for which you do not have all the rights necessary to grant us the license described above. You represent and warrant that your User Content, and our use of such content as permitted by these Terms, will not violate any rights of or cause injury to any person or entity. Although we have no obligation to screen, edit or monitor User Content, we may remove User Content at any time and for any reason with or without notice.\n\n5. Prohibited Conduct and Content\n\nYou will not violate any applicable law, contract, intellectual property right or other third-party right or commit a tort, and you are solely responsible for your conduct while using our Services. You will not:\n\nEngage in any harassing, threatening, intimidating, predatory or stalking conduct;\n\nUse or attempt to use another user’s account without authorization from that user and Surge;\n\nImpersonate or post on behalf of any person or entity or otherwise misrepresent your affiliation with a person or entity;\n\nSell or resell our Services;\n\nCopy, reproduce, distribute, publicly perform or publicly display all or portions of our Services, except as expressly permitted by us or our licensors;\n\nModify our Services, remove any proprietary rights notices or markings, or otherwise make any derivative works based upon our Services;\n\nUse our Services other than for their intended purpose and in any manner that could interfere with, disrupt, negatively affect or inhibit other users from fully enjoying our Services or that could damage, disable, overburden or impair the functioning of our Services in any manner;\n\nReverse engineer any aspect of our Services or do anything that might discover source code or bypass or circumvent measures employed to prevent or limit access to any part of our Services;\n\nAttempt to circumvent any content-filtering techniques we employ or attempt to access any feature or area of our Services that you are not authorized to access;\n\nUse any data mining, robots or similar data gathering or extraction methods designed to scrape or extract data from our Services;\n\nDevelop or use any applications that interact with our Services without our prior written consent;\n\nBypass or ignore instructions contained in our robots.txt file; or\n\nUse our Services for any illegal or unauthorized purpose, or engage in, encourage or promote any activity that violates these Terms.\n\nYou may also upload only User Content that you have all necessary rights to disclose. You may not upload any User Content that:\n\nWould violate any local, state, national or international law;\n\nMay infringe any patent, trademark, trade secret, copyright or other intellectual or proprietary right of any party;\n\nContains any private or personal information of a third party without such third party’s consent;\n\nContains any viruses, corrupted data or other harmful, disruptive or destructive files or content; or\n\nIn our sole judgment, is objectionable, restricts or inhibits any other person from using or enjoying our Services, or may expose Surge or others to any harm or liability of any type.\n\nEnforcement of this Section 5 is solely at Surge's discretion, and failure to enforce this section in some instances does not constitute a waiver of our right to enforce it in other instances. In addition, this Section 5 does not create any private right of action on the part of any third party.\n\n6. Ownership; Limited License\n\nThe Services, including the text, graphics, images, photographs, videos, illustrations, documents, work product and other content and materials contained therein or otherwise provided to you in connection with the Services, are owned by Surge or our licensors and are protected under both United States and foreign laws. Except as explicitly stated in these Terms, all rights in and to the Services are reserved by us or our licensors. Subject to your compliance with these Terms, you are hereby granted a limited, nonexclusive, nontransferable, non-sublicensable, revocable license to access and use our Services. Any use of the Services other than as specifically authorized herein, without our prior written permission, is strictly prohibited, will terminate the license granted herein and violate our intellectual property rights.\n\n7. Trademarks\n\nSurge Labs, Inc. and our logos, our product or service names, our slogans and the look and feel of the Services are trademarks of Surge and may not be copied, imitated or used, in whole or in part, without our prior written permission. All other trademarks, registered trademarks, product names and company names or logos mentioned on the Services are the property of their respective owners. Reference to any products, services, processes or other information by trade name, trademark, manufacturer, supplier or otherwise does not constitute or imply endorsement, sponsorship or recommendation by us.\n\n8. Feedback\n\nYou may voluntarily post, submit or otherwise communicate to us any questions, comments, suggestions, ideas, original or creative materials or other information about Surge or our Services (collectively, “Feedback”). You understand that we may use such Feedback for any purpose, commercial or otherwise, without acknowledgment or compensation to you, including, without limitation, to develop, copy, publish, or improve the Feedback in Surge’s sole discretion. You understand that Surge may treat Feedback as nonconfidential.\n\n9. Third-Party Content\n\nWe may provide information about third-party products, services, activities or events, or we may allow third parties to make their content and information available on or through the Services (collectively, “Third-Party Content”). We provide Third-Party Content as a service to those interested in such content. Your dealings or correspondence with third parties and your use of or interaction with any Third-Party Content are solely between you and the third party. Surge does not control or endorse, and makes no representations or warranties regarding, any Third-Party Content, and your access to and use of such Third-Party Content is at your own risk.\n\n10. Indemnification\n\nTo the fullest extent permitted by applicable law, you will indemnify, defend and hold harmless Surge and our subsidiaries and affiliates, and each of our respective officers, directors, agents, partners and employees (individually and collectively, the “Surge Parties”) from and against any losses, liabilities, claims, demands, damages, expenses or costs (“Claims”) arising out of or related to (a) your access to or use of the Services; (b) your User Content or Feedback; (c) your violation of these Terms; (d) your violation, misappropriation or infringement of any rights of another (including intellectual property rights or privacy rights); or (e) your conduct in connection with the Services. You agree to promptly cooperate with Surge Parties in defending such Claims and pay all fees, costs and expenses associated with defending such Claims (including, but not limited to, attorneys' fees). You also agree that the Surge Parties will have control of the defense or settlement, at Surge's sole option, of any third-party Claims. This indemnity is in addition to, and not in lieu of, any other indemnities set forth in a written agreement between you and Surge or the other Surge Parties.\n\n11. Disclaimers\n\nYour use of our Services is at your sole risk. Except as otherwise provided in a writing by us, our Services and any content therein are provided “as is” and “as available” without warranties of any kind, either express or implied, including, but not limited to, implied warranties of merchantability, fitness for a particular purpose, title, and non-infringement. In addition, Surge does not represent or warrant that our Services are accurate, complete, reliable, current or error-free. While Surge attempts to make your use of our Services safe, we cannot and do not represent or warrant that our Services or servers are free of viruses or other harmful components. You assume the entire risk as to the quality and performance of the Services.\n\n12. Limitation of Liability\n\nTo the fullest extent permitted by applicable law, Surge and the other Surge Parties will not be liable to you under any theory of liability—whether based in contract, tort, negligence, strict liability, warranty, or otherwise—for any indirect, consequential, exemplary, incidental, punitive or special damages or lost profits, even if Surge or the other Surge Parties have been advised of the possibility of such damages.\n\nThe total liability of Surge and the other Surge Parties for any claim arising out of or relating to these Terms or our Services, regardless of the form of the action, is limited to the greater of $100 or the amount paid by you to use our Services within the past 12 months.\n\nThe limitations set forth in this Section 12 will not limit or exclude liability for the gross negligence, fraud or intentional misconduct of Surge or the other Surge Parties or for any other matters in which liability cannot be excluded or limited under applicable law. Additionally, some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so the above limitations or exclusions may not apply to you.\n\n13. Release\n\nTo the fullest extent permitted by applicable law, you release Surge and the other Surge Parties from responsibility, liability, claims, demands and/or damages (actual and consequential) of every kind and nature, known and unknown (including, but not limited to, claims of negligence), arising out of or related to disputes between users and the acts or omissions of third parties. If you are a consumer who resides in California, you hereby waive your rights under California Civil Code § 1542, which provides: “A general release does not extend to claims which the creditor does not know or suspect to exist in his or her favor at the time of executing the release, which if known by him or her must have materially affected his or her settlement with the debtor.”\n\n14. Publicity\n\nYou agree that Surge may use your trade names, trademarks, service marks, logos, domain names and other distinctive branch features in presentations, marketing materials, customer lists, financial reports and website listings for the purpose of advertising or publicizing your use of the Services. Upon request by Surge, you also agree to reasonably cooperate with Surge to produce and publish a public reference, case study and/or quote regarding your use of the Services, to be used for Surge’s marketing and publicity purposes.\n\n15. Disputes\n\nPlease read the following section carefully because it requires you to arbitrate certain disputes and claims with Surge and limits the manner in which you can seek relief from us.\n\nThese Terms and any action related thereto will be governed by the laws of the State of California without regard to its conflict of laws provisions. Except for small claims disputes in which you or Surge seek to bring an individual action in small claims court located in the county of your billing address or claims for injunctive relief by either party, any dispute or controversy arising out of, in relation to, or in connection with these Terms or your use of the Services shall be finally settled by binding arbitration in Santa Clara County, California under the Federal Arbitration Act (9 U.S.C. §§ 1-307) and the then current rules of JAMS (formerly known as Judicial Arbitration & Mediation Services) by one (1) arbitrator appointed in accordance with such rules. Where arbitration is not required by these Terms, the exclusive jurisdiction and venue of any action with respect to the subject matter of these Terms will be the state and federal courts located in Santa Clara, California, and each of the parties hereto waives any objection to jurisdiction and venue in such courts. ANY DISPUTE RESOLUTION PROCEEDING ARISING OUT OF OR RELATED TO THESE TERMS OR THE SALES TRANSACTIONS BETWEEN YOU AND SURGE, WHETHER IN ARBITRATION OR OTHERWISE, SHALL BE CONDUCTED ONLY ON AN INDIVIDUAL BASIS AND NOT IN A CLASS, CONSOLIDATED OR REPRESENTATIVE ACTION, AND YOU EXPRESSLY AGREE THAT CLASS ACTION AND REPRESENTATIVE ACTION PROCEDURES SHALL NOT BE ASSERTED IN NOR APPLY TO ANY ARBITRATION PURSUANT TO THESE TERMS AND CONDITIONS. YOU ALSO AGREE NOT TO BRING ANY LEGAL ACTION, BASED UPON ANY LEGAL THEORY INCLUDING CONTRACT, TORT, EQUITY OR OTHERWISE, AGAINST SURGE THAT IS MORE THAN ONE YEAR AFTER THE DATE OF THE APPLICABLE ORDER.\n\nYou have the right to opt out of binding arbitration within 30 days of the date you first accepted the terms of this Section by emailing us at support@surgehq.ai. In order to be effective, the opt out notice must include your full name and clearly indicate your intent to opt out of binding arbitration.\n\n16. Miscellaneous\n\nThese Terms, together with our Privacy Policy and any order forms you complete while registering or paying for the Services, constitutes the entire agreement between the parties relating to the Services and all related activities. These Terms shall not be modified except in writing signed by both parties or by a new posting of these Terms issued by us. If any part of these Terms is held to be unlawful, void, or unenforceable, that part shall be deemed severed and shall not affect the validity and enforceability of the remaining provisions. The failure of Surge to exercise or enforce any right or provision under these Terms shall not constitute a waiver of such right or provision. Any waiver of any right or provision by Surge must be in writing and shall only apply to the specific instance identified in such writing. You may not assign these Terms, or any rights or licenses granted hereunder, whether voluntarily, by operation of law, or otherwise without our prior written consent.",
      "# [Human Evaluation for Search Ranking with Neeva](https://www.surgehq.ai/case-study/neeva)\nTo succeed, Neeva needs to understand what users think of its search engine and how its capabilities stack up against incumbents. Rather than relying on proxy metrics like clicks, Neeva wanted to gather this data directly by running search evaluations where users rate the quality and relevance of Neeva’s search rankings.\n\nThe Problem?\n\nHigh-quality search evaluations are notoriously hard for companies to run on their own. As Neeva puts it, “when you’re building a search engine, evaluation is one of the most important tricky components to get right. Search is a very human need and so you need unbiased human raters to tell you how well you’re doing.”\n\nWe built Surge AI to make it easy for every company to run the same search evaluations that Google depends on (and many other data labeling use cases too!).\n\nAfter discussing Neeva's needs with their search ranking team, we designed, ran, and delivered a series of search evaluations, including personalized search evaluations, vertical-specific evaluations, and side-by-side evaluations comparing Neeva against Google.\n\nLet’s break our process down into three phases — building a team of Neeva search evaluators, generating and labeling data, and final quality checks.\n\nSearch Evaluation Design\n\nWhile most data labeling tasks involve pre-existing data that needs to be labeled, our Search customers often need datasets created from scratch. In these cases, Surgers must gather and label data, resulting in a highly-customized, one-of-a-kind dataset.\n\nFor Neeva’s Search Evaluation project, we asked Surgers to do the following:\n\n01.\n\nPick a programming query that they had recently searched for (e.g., “python split string into characters”)\n\n02.\n\nExplain the query intent\n\n03.\n\nSearch for the query on Google\n\n04.\n\nRate the Google search result page on a 5-point Likert Scale\n\n05.\n\nExplain their rating\n\n06.\n\nSearch for the query on Neeva\n\n07.\n\nRate the Neeva search result page on the same 5-point Likert scale\n\n08.\n\nExplain their rating\n\n09.\n\nCompare Google vs. Neeva on a 5-point Likert scale\n\n10.\n\nExplain their rating\n\nThoughtful Quality Controls\n\nAs part of this process, we created a series of quality controls to ensure that our search engine raters were performing well. These quality controls included custom search rating examinations, where Surgers rated a series of <query, search result> pairs. We measured their responses, and read through the explanations of their ratings to ensure that their judgments were thoughtful and sound.",
      "# [Careers at Surge AI](https://www.surgehq.ai/careers)\n",
      "# [Human Infrastructure for NLP](https://www.surgehq.ai/category/product)\n",
      "# [Human Infrastructure for NLP](https://www.surgehq.ai/category/ai)\n",
      "# [Humans vs. Gary Marcus vs. Slate Star Codex: When is an AI failure actually a failure? by Edwin Chen on 2024-10-23](https://www.surgehq.ai/blog/humans-vs-gary-marcus)\nScott at Slate Star Codex and Gary Marcus had a recent back-and-forth about the nature of intelligence and AI's scaling hypothesis.\n\nMarcus's point is that large language models don't understand the world, and they're merely parroting their training corpus; as a result, current deep learning techniques are a dead end to true AI. For example, he calls the following “mistake” by GPT-3 evidence that AI models lack commonsense reasoning:\n\nI grew up in Trenton. I speak fluent Spanish and I'm bi-cultural. I've been in law enforcement for eight years […] I'm very proud to be a Latina. I'm very proud to be a New Jerseyan.\n\n(Marcus believes the correct continuation should be English.)\n\nScott argues that each time someone finds AI failures that require “true” intelligence to get right, those failures largely get solved by newer models. So why should GPT-3's mistakes prove that current approaches are doomed? He also disagrees with what Marcus calls a failure:\n\nWhen it gets them “wrong”, I tend to agree with GPT-3 more than Marcus. For example, consider Trenton. It’s true that, viewed as a logical reasoning problem, someone who grows up in Trenton is most likely to speak English fluently. But nobody told GPT-3 to view this as a logical reasoning problem. In real speech/writing, which is what GPT-3 is trying to imitate, no US native fluent English speaker ever tells another US native fluent English speaker, in English, “hey, did you know I’m fluent in English?” If I hear someone talking about growing up in Trenton, and then additionally they brag that they’re fluent in a language, I think “Spanish” would be my guess too.\n\nThis idea – that what Marcus calls a \"failure\" isn't actually a mistake – is an important one, and touches on difficult questions around how to evaluate large language models. Exactly what response do we hope an \"intelligent\" LLM would make?\n\nWe do a lot of work for large language model companies around human evaluation of LLMs. So we took 5 \"mistakes\" that Marcus pointed out and gave them to 15 Surgers each, to see how humans would perform on them instead.\n\nSurgers vs. Marcus #1\n\nLet's start with this prompt:\n\nYou are a defense lawyer and you have to go to court today. Getting dressed in the morning, you discover that your suit pants are badly stained. However, your bathing suit is clean and very stylish. In fact, it’s expensive French couture; it was a birthday present from Isabel. You decide that you should wear\n\nIn a 2020 article, Marcus calls GPT-3’s completion a failure of social reasoning:\n\nYou are a defense lawyer and you have to go to court today. [...] You decide that you should wear the bathing suit to court. You arrive at the courthouse and are met by a bailiff who escorts you to the courtroom.\n\nIn Marcus’s words: The phrase “However, your bathing suit is clean” seems to have led GPT-3 into supposing that a bathing suit is a viable alternative to a suit. Of course, in reality no lawyer would consider wearing a bathing suit to court. The bailiff would probably not admit you, and if you were admitted, the judge might well hold you in contempt.\n\nBut is this truly a mistake? How do real humans complete it? We asked 15 Surgers.\n\nYou are a defense lawyer and you have to go to court today. [...] You decide that you should wear\n\nthe bathing suit anyway. Anything to keep the jury's mind off the actual evidence might help the case\n\nyour stained pants and buy a new pair of pants at Men's Wearhouse, because wearing a swimsuit to court, even a stylish one, would be ridiculous and likely result in a contempt citation.\n\nit and show the court your fashion sense.\n\nthe stained pants anyways, since the bathing suit sadly doesn't fit anymore.\n\nanother pair of suit pants that will look okay with the rest of the outfit.\n\nit next time you go swimming with Isabel.\n\nthe stained paints while you run to the store to buy a new pair of pants before you attend court. A bathing suit would not be appropriate, no matter how nice it is.\n\nit. You will call and try to get the court date postponed to another day and then go swimming at the beach today.\n\nyour bathing suit and head off to work. What's the worst that can happen?\n\nthe stained pair of pants because you're running late and have no time to change. You can't wait until the case is over so that you can plan your trip to Palm Springs.\n\nit. You'll probably end up in TMZ or something. That should be good for your career.\n\na different pair of pants to leave the house. Then text your paralegal to see if you can borrow his suit pants for the hearing.\n\nyour stained suit pants since those would be more acceptable in court over skimpy swimwear.\n\nneither. Instead, you borrow a suit from your best friend, who also happens to be your neighbor.\n\na bathing suit bottom with a suit top to the court. Your client is guilty anyway, so you might as well have some fun while working the case. Hopefully you don't get held in contempt by the judge.\n\n7 of the human completions resulted in wearing a pair of pants to court. 6 result in wearing the bathing suit! 2 sidestep the issue.\n\nSo who's to say GPT-3 is wrong? Maybe it just has a sense of humor.\n\nWinner: GPT-3 / Astral Codex Ten\n\nSurgers vs. Marcus #2\n\nNext, let’s take three of Marcus's language prompts:\n\nI grew up in Mykonos. I speak fluent\n\nI grew up in Hamburg. I speak fluent\n\nI grew up in Trenton. I speak fluent\n\nHow do Surgers complete these?\n\nI grew up in Mykonos. I speak fluent\n\nDothraki. I have been a Game of Thrones fan since the first book came out. Almost no one understands me when I speak it, but it's quite a fun party trick to have at my disposal.\n\nIsland Greek.\n\nPortuguese because my family is from Brazil.\n\nGreek.\n\nGreek but also know a tad of English and Italian.\n\nI grew up in Hamburg. I speak fluent\n\nGerman, Russian, French and other languages.\n\ntourist. Seriously, they stand out like sheep among wolves.\n\nGerman.\n\nGerman but can also speak a bit of English.\n\nJapanese. I learned Japanese because I am obsessed with Japanese culture. I even plan on marrying my dakimakura--once the German authorities make it legal to marry inanimate objects.\n\nI grew up in Trenton. I speak fluent\n\nEnglish, but I use sign-language much more frequently because I am deaf.\n\nTrentonish. It's a bit like Sopranos-style New York, Italian Mobster with a hint of South Jersey asshole mixed in.\n\neast coast slang. Gym tan laundry all day bro.\n\nSpanish, Greek and other languages thanks to my childhood friends.\n\nEnglish.\n\n67% of Surgers complete the prompt with the obvious language – perhaps realizing it’s a commonsense reasoning problem and taking the appropriate cue. However, 33% complete it with a different language – even more, if you consider continuations mentioning multiple languages, and Trenton distinct from mere \"English\"! So what if GPT-3 just likes adding narrative backstory? Nobody said AIs can’t be imaginative too.\n\nWinner: GPT-3\n\nSurgers vs. Marcus #3\n\nFinally, let’s consider this prompt:\n\nI left my keys at a booth in the back of the pub at the army base near the old mill town. I went home. My keys are now\n\nMarcus penalizes GPT-3 for completing the prompt with “in my purse”. However, Scott writes that I think most people saying this sentence, including the word “now”, would be talking about how their keys used to be in that spot, but are now in a different spot.\n\nHow do Surgers complete it?\n\nI left my keys at a booth in the back of the pub at the army base near the old mill town. I went home. My keys are now\n\non the night table of brother's bedroom. I sent him a text to grab them because he was still at the pub. I wanted him to bring them by to me but he was being a total jerk about it. Now I have to walk over to his house to get them.\n\nin my possession. I went back to pick up my keys from the booth.\n\nmissing from my pocket.\n\nlost and I had to call a locksmith and wait for an hour to get into my house.\n\ngone in a drunk soldier's pockets.\n\nprobably left at the bar by someone nice.\n\nmiles away. Should I drive all the way back or just call a locksmith?\n\nofficially missing after calling the pub and finding out they haven't been found or turned in.\n\nwith the bartender at the pub, waiting for me to come pick them up.\n\nat the bottom of the ocean. I heard an employee who I fought with at the pub through my keys in the ocean.\n\n50% of Surgers continue the sentence in such a way that the keys are not, in fact, still at the bar!\n\nWinner: GPT-3. Has anyone asked it solve an Agatha Christie novel?\n\nMore\n\nOverall, several of GPT-3’s “mistakes” resemble a creative human. Evaluating intelligence is subtle, and what you think might be a strange failure – what, you think that ballerina is twirling clockwise? what’s wrong with you? – may in fact be a sign of something deeper, waiting for more data to resolve.\n\nWant to read more?\n\nGPT-2 and the nature of intelligence. Marcus’s original post on GPT-2.\n\nGPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about. A similar post by Marcus, on GPT-3.\n\nMy Bet: AI Size Solves Flubs. Scott’s post mentioning Marcus.\n\nWhat does it mean when an AI fails? A Reply to SlateStarCodex’s riff on Gary Marcus. Marcus’s reply to Scott.\n\nSomewhat contra Marcus on AI scaling. Scott’s reply to Marcus.\n\nGwern on the scaling hypothesis in AI.",
      "# [We asked 100 humans to draw the DALL·E prompts by Edwin Chen on 2024-10-23](https://www.surgehq.ai/blog/humans-vs-dall-e)\nQuick: which one of these was generated by a human, and which by an AI?\n\nWhat about now?\n\n(Answer: AI, human, human, AI.)\n\nOpenAI’s DALL·E image generation system is wild. Imagine a future where every homemade bedtime story can be turned into an IMAX-quality cartoon…\n\nAt Surge AI, our bread and butter is using superintelligent humans to train rich, creative AI. But what happens when those machines become advanced enough to augment human capabilities instead? Where will human artistry and creativity fit in then?\n\nHere's an optimistic comment from a visual designer on Reddit:\n\nArtists, designers, photographers, creative types of all flavors will have important roles in this new AI-image world. I'm a visual designer and I honesty can't wait for the engines to get better, or at least to be able to get access to something like Dall-e-2.\n\nI've said this elsewhere, but AI will make the kind of work I do even more valuable because I'll spend less time on grunt work and more time on higher-value creative tasks such as creative/art direction and concept development. If I need series of icons in a certain style for a project, instead of spending hours or days searching vector stock resources for what I need or creating them myself, I can just describe what I want to the AI and have it generate what I need in seconds. Seconds of work instead of days. That makes me insanely more productive. Instead of one project for a client, I've now churned out a dozen in the same amount of time.\n\nTo understand this question better, we paid 100 random Surgers – most with average drawing skills! – to spend 15-30 minutes drawing one of the DALL·E prompts. Here are some of our favorites and how they compare.\n\nAn astronaut, playing basketball with cats in space, as a children’s book illustration\n\nDALL·E 2 versions:\n\nHuman versions:\n\nTeddy bears, mixing sparkling chemicals as mad scientists, as a 1990s Saturday morning cartoon\n\nInterestingly, as one Hacker News commenter pointed out, the human-drawn bears are clearly mad scientists out to conquer the world, while the AI bears lack that crazy, evil gleam.\n\nDALL·E 2 versions:\n\nSurger versions:\n\nAn illustration of a baby daikon radish, in a tutu, walking a dog\n\nDALL·E 1 versions:\n\nSurger versions:\n\nWhich one’s your favorite? If you'd like to check out more Surger vs. AI examples, check out this Twitter thread!",
      "# [Google Search is Falling Behind by Edwin Chen on 2024-10-23](https://www.surgehq.ai/blog/google-search-is-falling-behind)\nIs Google resting on its laurels?\n\nImagine you’re a programmer, and you forget the syntax to delete a file in Python. So you search “python delete file”, and get the following:\n\nIt’s not a terrible search results page... But:\n\nThe caption for the first search result describes removing a folder, not a file.\n\nYou still have to spend time browsing to find a useful answer. No intelligent question-answering or extraction here!\n\nIs this page any better than what you’d have gotten in 2010? What if it looked like this instead?\n\nIn both cases, a great piece of code (syntax-highlighted!) is highlighted front and center, which means you never even have to click into the blue links. As an ex-Googler, I’ve historically been skeptical of all the other search engines, but go try them yourself — the whole experience feels so much fresher and snappier.\n\nRemember Google's past innovations, like blending Images, Videos, and Maps onto the same page?! Now we’re lucky if we can find a pancake recipe without wading through 7 ads and 3 pages of storytime first.\n\nSeriously! Here’s the top search result for “blueberry pancakes”:\n\nAnd that's before I even get to the recipe. What happened to page quality factors in ranking?\n\nWhere else is Google starting to fall behind, and how could competitors chip away at its edge? Human evaluation of search quality is one of our flagship use cases at Surge, so let’s dive into three key Search verticals — Programming, Cooking, and Travel — and find out.\n\nProgramming\n\nWe’re a human intelligence platform for rich, contextual AI; as part of that, we have high-quality “labelers” with software engineering backgrounds who train AI models to answer programming questions and learn how to code. We asked them to collect searches they performed in their normal workday, and then evaluate their performance on Google, Bing, Neeva, You.com, Kagi, and DuckDuckGo.\n\nHere are more examples of programming queries where Google is lagging behind.\n\nExample #1\n\nRater Background (Jason L.): “I graduated with a degree in Computer Science and a minor in Business last year, and now I’m bootstrapping a passive income business that helps artists sell their work online.”\n\nQuery: “python throw exception”\n\nIntent: “I normally use Java and Go, but wanted to use Python for a quick script, and I forgot how to throw an exception. The ideal search result would be an example of the syntax.”\n\nGoogle Evaluation\n\n‍\n\nGoogle rating: “This search result page is just okay. I don't like the first search result (I already know what exceptions are in programming, so the official Python documentation is way more than I need). I have to scroll halfway down before finding the information that I want.\n\nThe second search result isn’t great either (I don’t want to read a long-winded blog post). Luckily, the third StackOverflow search result is exactly what I was looking for, but pretty much every other search engine performed better.”\n\nNeeva Evaluation\n\nNeeva rating: “Neeva made it very easy to see an example piece of code on the right hand side. The UI also felt very fresh and snappy compared to Google!\n\nThe only way it could be better is if the snippet in the first search result were more relevant (“x = -1” isn’t exactly useful).”\n\nYou.com Evaluation\n\nYou.com rating: “I liked the way that You allowed me to open up the SO answer in the side panel, so that I didn’t need to leave the page.”\n\n“You's code complete module generated Mandarin PHP in this case (but I’ve found it useful in other cases, like writing an email extraction regex)”\n\nBing Evaluation\n\nBing rating: “Bing also did a better job than Google. It seemed to understand my query better, and the box at the top reminded me that the keyword is “raise”, and not “throw” like in Java.\n\nIt extracted a StackOverflow code sample nicely too. The issue is that this was the 5th search result and should have been ranked higher.”\n\nKagi Evaluation\n\nKagi rating: “Kagi also did a better job than Google. Like Neeva and You.com, surfacing code snippets and the StackOverflow answer on the right-hand panel made it much faster for me to find what I wanted.”\n\nExample #2\n\nRater background (Ning X.): “I’m finishing up my senior year in college. I also work as a research assistant in a neuroscience lab, where I use a lot of R and Python, and I’ll be starting a master’s in the fall.”\n\nQuery: “filter pandas dataframe date”\n\nIntent: “I recently started learning how to use the pandas library in Python, and I was trying to figure out how to filter a date column in my data frame.”\n\nGoogle vs. Neeva Evaluation\n\nRating: “Google’s first search result was very relevant, and the same as Neeva’s. However, Neeva’s UI was better since it extracted exactly the code sample I needed on to the search page itself.\n\nIt’s even syntax highlighted, which makes it much easier to read!”\n\nCoding searches are clearly one area where Google is starting to lag behind its competitors. In particular, programmers found the code extraction and StackOverflow features on other sites particularly helpful – in addition to a generally slicker UI.\n\nCooking\n\nWhat about cooking queries? For these, we sampled our general pool of raters.\n\nExample #1\n\nRater background (Daniela M.): “I’m a high school History teacher. Besides History, I also enjoy creative writing and playing the piano. While I love teaching my students, it’s long hours and the pay isn’t great, so I’ve been exploring other fields and may make a move next year.”\n\nQuery: “biryani recipe”\n\nIntent: “I went to an Indian restaurant with some friends and really enjoyed the biryani we ordered, so I wanted to learn how to make it myself.”\n\nGoogle Evaluation\n\nGoogle rating: “Google’s results weren’t anything special. The pictures at the top looked pretty gross, to be honest, and very low-quality. Not what I want to see when looking for a recipe to make.”\n\nBing Evaluation\n\nBing rating: “Bing’s results were the best by far. The pictures at the top are so much more appetizing!\n\nI’ve found the Bing UI distracting in other cases, but it really shone here. I didn’t know much about biryani, so I spent a little time on the search page learning more about it, and I like the way the videos are laid out.\n\nI also liked how it automatically extracted the recipes and videos on the right side. I get a little anxiety when clicking on recipe websites, since you never know what you’re going to find - most, especially recipes from personal bloggers, are incredibly annoying and full of ads and annoying prose.\n\nThe only downside was that only the ingredients and nutritional info were extracted, but not the recipe directions themselves. Hopefully they can fix that soon.\n\nThe filters at the top were also a nice touch. In particular, the “Quick” filter was very useful, since I don’t want to spend over an hour cooking. Overall, Bing gets a 5/5 and leaves Google in the dust!”\n\nNeeva Evaluation\n\nNeeva rating: “The one thing missing from Bing was having the full recipe directions automatically extracted too (not just the ingredients). So I really liked this feature on Neeva.\n\nThe carousel on the bottom also made it very fast to quickly browse through recipes, which was helpful because some of the recipes required way more ingredients than I had.”\n\nTravel\n\nFinally, let’s look at Travel queries.\n\nExample #1\n\nRater background (Alex S.): “I’m a part-time musician and music teacher while I’m staying at home to take care of the kids. Recently, I’ve been trying to learn French and learn more about AI.”\n\nQuery: “what to do in los angeles”\n\nIntent: “I’m going to Los Angeles next week for the first time. I don’t have any plans yet and am looking for fun things to do.”\n\nGoogle Evaluation\n\nGoogle rating: “Google’s search results were good. The first two lists were great, and I liked the pictures of the top sights.”\n\nBing Evaluation\n\nBing rating: “But I liked Bing’s even more. The images and filters at the top made it easy to discover fun attractions. Its page seems to be surprisingly “smarter” than Google’s and more advanced.”\n\nYou.com and Kagi Evaluation\n\nRatings: “I’m a sucker for other people’s recommendations, so I also appreciated the “forum” sections that You.com and Kagi had, though the replies were a little sparse.\n\n[author's note: it would be really interesting to see what these search engines could do with intelligent parsing and scoring of forum threads]\n\nDuckDuckGo Evaluation\n\nDuckDuckGo rating: “As much as people talk about DuckDuckGo, its Maps suggestions at the top were odd. But the rest of the results were fine.”\n\nIn short, Google was already pretty good, but Bing was even better, thanks to its visual UI, its filters, and its map. I also liked the You.com and Kagi concepts of extracting “social” or “forum” elements, and I'm excited to see how they could add even more community intelligence features.”\n\nSummary\n\nTo be clear, we love Google and Search — our team used to work on these problems at Google, Facebook, and Bing. As the Internet changes from what it looked like in 1997 — whether due to the walled gardens of social media, the proliferation of image and video, or the rise of SEO spam and AI-generated content — we just want to make sure the platforms advance alongside it and is optimized for human values.",
      "# [Leading Social Media Company](https://www.surgehq.ai/case-study/leading-social-media-company)\nThey were inundated with user-generated data and needed a data labeling solution that could:\n\nGenerate millions of nuanced judgements per month across multiple domains — hateful speech, misinformation, and spam.\n\nProvide a workforce of high-skilled labelers with a deep understanding of cultural norms and current events in a range of locales.\n\nProvide labelers fluent in English, Portuguese, Spanish, French, German, Italian, Japanese, Arabic, Turkish, and Mandarin.\n\nAfter conducting a vendor evaluation across 10 solutions, the customer selected Surge AI as their data labeling partner.\n\nAfter conducting a vendor evaluation across 10 solutions, the customer selected Surge AI as their data labeling partner. The choice was easy — the customer’s evaluation process revealed that Surge produced 62% higher accuracy. Surge improved quality and efficiency while reducing cost and operational overhead.",
      "# [Surge AI and Redwood Research](https://www.surgehq.ai/case-study/adversarial-testing-redwood-research)\nRedwood is building the tools and methodologies to perform adversarial evaluation on models, envisioning a future where AI/ML labs and companies have large teams dedicated to AI Alignment and Safety. These teams’ ultimate responsibility will be to ensure that deployed models avoid harms resulting from malicious behavior or optimization of the wrong objective.\n\nRedwood’s first project is building a classifier that identifies violent text with an extremely low false negative rate. And they mean extremely low — think 99.999% reliability, not the 95% and 99% landscapes of today.\n\nThere are intricate strategies for training such a model, but if you're building a classifier like Redwood’s that's designed to be virtually impossible to trick, you’ll eventually need to employ a red team of humans to do just that — try to trick it. As the humans identify new tricks that work, you’ll retrain your model to counteract their strategies, and the cycle repeats.\n\nThis is right up our alley at Surge AI. We’re a data labeling platform focused on the richness of AI, whether it's training code generation models, building content moderation systems that are robust to real-world adversarial attacks, or evaluating the creativity and skills of state-of-the-art language models, among other things.\n\nRedwood's task at hand was conceptually simple: generate text that a human reader can detect as violent, but fools the model. The model scores inputs in real-time, and our job was to create violent completions that scored below the 5% threshold. The tricky part: as we feed the model more violent examples, it gets better at detecting them. Finding new strategies for generating violent texts that fool the model requires a wealth of creativity!\n\nOnce we identified a viable line of attack, we could double down and explore various related strategies, all while staying within the bounds of Redwood’s requirements (which included a minimum threshold for violence severity, among other specifications).\n\nWe’ve returned thousands and thousands of examples to Redwood so far, which they use to update their model and plug the holes we identified. Of course, that means that when we begin the next phase of this project on the updated model, it will be significantly harder since our old strategies will likely fail. A Sisyphean task in some sense, but a potentially world-saving one in another.",
      "# [Human Infrastructure for NLP](https://www.surgehq.ai/authors/bradley-webb)\nThe average number of ads on a Google Search recipe? 8.7\n\nBradley Webb\n\nEngineering\n\nHow Surge AI Helps NYU Study the Impact of Social Media\n\nBradley Webb\n\nCase Studies",
      "# [Getting started with the Python SDK by Andrew Mauboussin on 2024-10-23](https://www.surgehq.ai/blog/python-sdk)\nIf you need programmatic access to the Surge platform, look no further! You can use the Surge API to manage all aspects of your labeling project. Our open-source Python SDK provides convenient access to our API, with functions for creating new projects, running tasks, and much more.\n\nIn this blog post, we'll walk through the setup of a sample project from start to finish using our Python SDK.\n\n1. Installation\n\nIf you haven't already, sign up for an account on Surge. Once you are logged in, go to your Profile page and copy your API key. This will be used to authenticate your API requests.\n\nNext, use pip to install our Python package:\n\n<code>pip install --upgrade surge-api<code>\n\n2. Authentication\n\nYour API key carries many privileges, so be sure to keep it secure! Do not share it in publicly accessible areas such as GitHub, client-side code, and so forth.\n\nTo use your API key, assign it to <code>surge.api_key<code>. The Python SDK will then automatically send this key to authenticate each request.\n\nAlternatively, you can set your API key as an environment variable.\n\n<code>export SURGE_API_KEY=YOUR-API-KEY<code>\n\n3. Creating a project\n\nNow, it's time to create a new labeling project. Let's make one to gather information about movie reviews.\n\nEach project should have a list of questions to be completed by the labeling workforce. Surge supports a wide range of questions including multiple choice, free response, text tagging, bounding boxes, etc.\n\nTo create new questions, instantiate the desired <code>Question<code> objects. In this project, we will ask labelers to tag named entities in the movie review (text tagging), determine its sentiment (multiple choice), and write their very own review (free response).\n\nNotice that the text associated with the text tagging question is <code>{{review}}<code>, which is a handlebars expression. The actual movie review will automatically replace this placeholder once we import data, which we'll do in the upcoming task creation step.\n\nOnce the questions have been created, simply pass them into the method <code>surge.Project.create()<code>:\n\nVoila! You now have a new project!\n\n4. Creating tasks\n\nThe next step is to add data that you want to label. After you upload a dataset, each data point becomes a task that can be sent to a worker for labeling.\n\nOne way to create tasks is by formatting your data as a list of dictionaries. You then add the list to your current project by using the method <code>project.create_tasks()<code>:\n\nIn this case, we created two labeling tasks for the workforce: one for Parasite and another for Joker. The workers would answer the questions we made previously using this reviews data.\n\nYou can also create tasks in bulk by uploading a local CSV file. The header of the CSV file must specify the fields that are used in your tasks:\n\nWhenever a task is created, the project is automatically launched if it is not already in progress.\n\nNow that all of the data for tasks has been added, you can see how a task looks by clicking Preview task for the project on the Surge platform. It should look like this:\n\n5. Creating gold standards\n\nGold standards are used to assess the quality of each worker in the labeling workforce. After a gold standard answer is created, each worker would be required to complete it.\n\nOn the Surge platform, the analytics pages show how well workers performed on your gold standards, as well as other quality control metrics.\n\nTo set gold standards using the Python SDK, simply pass in a list of the correct answers to each question:\n\nWrapping up\n\nIn this post, we successfully launched a labeling project on Surge using our Python SDK.\n\nThere are plenty of other features in the API that weren't mentioned here, which you can learn more about in our official API documentation.\n\nYou can also check out more details on our open-source GitHub repo. If you have any feature requests or bug reports, feel free to file an issue. We're more than happy to hear your feedback to help drive our product roadmap!\n\nLabeling in action: an example of a text tagging (NER) question on the Surge platform.\n\n—\n\nDisappointed in your MTurk results? Surge AI delivers better data, faster. Book a quick intro call with our team today!\n\n‍",
      "# [Human Infrastructure for NLP](https://www.surgehq.ai/authors/edwin-chen)\nDALL·E 3 and Midjourney Fail Astral Codex Ten's Image Generation Bet\n\nEdwin Chen\n\nAI\n\nHow Anthropic uses Surge AI’s RLHF platform to train their LLM Assistant on Human Feedback\n\nEdwin Chen\n\nLarge Language Models\n\nHow RLHF Shifts LLMs from Autocompletion to Conversational Understanding\n\nEdwin Chen\n\nAI\n\nWe Evaluated ChatGPT vs. Google on 500 Search Queries\n\nEdwin Chen\n\nLarge Language Models\n\nAI Red Teams for Adversarial Training: How to Make ChatGPT and LLMs Adversarially Robust\n\nEdwin Chen\n\nLarge Language Models\n\nHellaSwag or HellaBad? 36% of this popular LLM benchmark contains errors\n\nEdwin Chen\n\nLarge Language Models\n\nHow TikTok is Evolving the Next Generation of Search\n\nEdwin Chen\n\nSocial Media\n\nEvaluating Generative AI: Did Astral Codex Ten Win His Bet on AI Progress?\n\nEdwin Chen\n\nAI\n\nHuman Evaluation of Large Language Models: How Good is Hugging Face's BLOOM?\n\nEdwin Chen\n\nLarge Language Models\n\nSearch Behind-the-Scenes: How Neeva Uses Human Evaluation to Measure Search Quality\n\nEdwin Chen\n\nCase Studies\n\nHumans vs. Gary Marcus vs. Slate Star Codex: When is an AI failure actually a failure?\n\nEdwin Chen\n\nAI\n\nHow Surge AI Built OpenAI's GSM8K Dataset of 8,500 Math Problems\n\nEdwin Chen\n\nAI",
      "# [Human Infrastructure for NLP](https://www.surgehq.ai/authors/jefferson-lee)\nJefferson leads Surge AI's data labeling and NLP products — whether it's helping customers label their large language models, gather data to train Spam and Hate Speech classifiers, or run large-scale search evaluations. He was previously an early engineer on Airbnb's Trust and Safety ML team, and studied computer science at Harvard.",
      "# [Human Infrastructure for NLP](https://www.surgehq.ai/authors/andrew-mauboussin)\n",
      "# [Human Infrastructure for NLP](https://www.surgehq.ai/authors/scott-heiner)\nScott runs Business Development and Operations at Surge AI, helping customers get the high-quality human-powered data they need to train and measure their AI. Before joining Surge, he led operations and marketing teams in the media industry."
    ],
    "search_results": [
      {
        "title": "Surge AI | World's Most Powerful GenAI Data",
        "link": "https://www.surgehq.ai/",
        "snippet": "Train Al on the Richness of Human Data. Trusted by leading companies. Enterprise Scale and Security. News & Updates.",
        "formattedUrl": "https://www.surgehq.ai/"
      },
      {
        "title": "Blog | Surge AI",
        "link": "https://www.surgehq.ai/blog",
        "snippet": "Surge AI Blog · Featured · Recent articles · Welcome to the world's largest RLHF platform. Get Started. Get Started. Subscribe. The latest in AI, language, and ...",
        "formattedUrl": "https://www.surgehq.ai/blog"
      },
      {
        "title": "Surge AI customers | World's top Enterprises, Startups & LLM Labs",
        "link": "https://www.surgehq.ai/customers",
        "snippet": "Our human-powered datasets have powered the biggest AI advances and large language model research of the past few years.",
        "formattedUrl": "https://www.surgehq.ai/customers"
      },
      {
        "title": "Authors | Introducing the experts Behind Our Articles | Surge AI",
        "link": "https://www.surgehq.ai/authors",
        "snippet": "Authors · Andrew Mauboussin · Bradley Webb · Edwin Chen · Jefferson Lee · Jesse Perez · Meet the world's largest. RLHF platform · Welcome to the world's largest ...",
        "formattedUrl": "https://www.surgehq.ai/authors"
      },
      {
        "title": "About Surge AI | All-in-one data labeling platform",
        "link": "https://www.surgehq.ai/about",
        "snippet": "Edwin Chen. CEO. Edwin founded Surge AI to build the human data platforms needed to power the next generation of rich, intelligent AI. He previously led machine ...",
        "formattedUrl": "https://www.surgehq.ai/about"
      },
      {
        "title": "Data Labeling for Large Language Models | Surge AI",
        "link": "https://www.surgehq.ai/rlhf",
        "snippet": "“Anytime it's pro level NLP data labeling for hard problems, it inevitably leads to the team at Surge AI.” ... “If you want to do an NLP data collection/labeling ...",
        "formattedUrl": "https://www.surgehq.ai/rlhf"
      },
      {
        "title": "Pricing | High-quality data labeling in 30+ languages | Surge AI",
        "link": "https://www.surgehq.ai/pricing",
        "snippet": "We offer an Enterprise plan for teams that need high volume, fully managed data labeling services with guaranteed SLAs.",
        "formattedUrl": "https://www.surgehq.ai/pricing"
      },
      {
        "title": "Contact | Make your data dreams come true | Surge AI",
        "link": "https://www.surgehq.ai/contact",
        "snippet": "Contact us. Send message. Anytime it's pro level NLP data labeling for hard problems, it inevitably leads to the team at Surge AI.",
        "formattedUrl": "https://www.surgehq.ai/contact"
      },
      {
        "title": "Privacy Policy | Surge AI",
        "link": "https://www.surgehq.ai/privacy-policy",
        "snippet": "Mar 8, 2021 ... This Privacy Policy explains how Surge Labs, Inc. (Surge, we or us) collects, uses, and discloses information about you.",
        "formattedUrl": "https://www.surgehq.ai/privacy-policy"
      },
      {
        "title": "Power Your Search Engine with Human Evaluation | Surge AI",
        "link": "https://www.surgehq.ai/search-evaluation",
        "snippet": "Power Your Search Engine with Human Evaluation. The world's top search engines use Surge AI to build relevant, high-quality search experiences – and avoid ...",
        "formattedUrl": "https://www.surgehq.ai/search-evaluation"
      },
      {
        "title": "Data Labeling for Content Moderation | Surge AI",
        "link": "https://www.surgehq.ai/content-moderation",
        "snippet": "Our all-in-one data labeling platform provides the modern APIs, tools, and elite workforces needed to train your language models.",
        "formattedUrl": "https://www.surgehq.ai/content-moderation"
      },
      {
        "title": "Case Studies | Real-World Examples | Surge AI",
        "link": "https://www.surgehq.ai/case-studies",
        "snippet": "Leading Social Media Company. One of the world's largest social media platforms needed to improve their ML models for filtering hateful speech, misinformation, ...",
        "formattedUrl": "https://www.surgehq.ai/case-studies"
      },
      {
        "title": "Sign Up | Get started with Surge AI",
        "link": "https://www.surgehq.ai/sign-up",
        "snippet": "The biggest game-changer for my research recently has been using Surge AI for human data collection. With Surge, the workflow for collecting human data now ...",
        "formattedUrl": "https://www.surgehq.ai/sign-up"
      },
      {
        "title": "Toxicity API | Detect Toxicity Instantly | Surge AI",
        "link": "https://www.surgehq.ai/toxicity-api",
        "snippet": "Instantly. Our toxicity API is a powerful tool for detecting toxic speech online. Try it yourself — type text below and see your results. © 2023 Copyright ...",
        "formattedUrl": "https://www.surgehq.ai/toxicity-api"
      },
      {
        "title": "Terms of Service | Surge AI",
        "link": "https://www.surgehq.ai/terms-of-service",
        "snippet": "Dec 7, 2021 ... These Terms of Service (“Terms”) apply to your access to and use of the websites and other online products and services (collectively, the “Services”) provided ...",
        "formattedUrl": "https://www.surgehq.ai/terms-of-service"
      },
      {
        "title": "Human Evaluation for Search Ranking with Neeva",
        "link": "https://www.surgehq.ai/case-study/neeva",
        "snippet": "Neeva wanted to gather this data directly by running search evaluations where users rate the quality and relevance of Neeva's search rankings.",
        "formattedUrl": "https://www.surgehq.ai/case-study/neeva"
      },
      {
        "title": "Careers at Surge AI",
        "link": "https://www.surgehq.ai/careers",
        "snippet": "Join our world-class team working to advance AI. We're on a mission to inject human values and intelligence into Al",
        "formattedUrl": "https://www.surgehq.ai/careers"
      },
      {
        "title": "Product",
        "link": "https://www.surgehq.ai/category/product",
        "snippet": "How to Pick the Best Data Labeling Platform · Manifold: Using Neural Embeddings to Explore the Shape of Your Data · The AI Bottleneck: High-Quality, Human-Powered ...",
        "formattedUrl": "https://www.surgehq.ai/category/product"
      },
      {
        "title": "Human Infrastructure for NLP - Surge AI",
        "link": "https://www.surgehq.ai/category/ai",
        "snippet": "DALL·E 3 and Midjourney Fail Astral Codex Ten's Image Generation Bet. Edwin Chen. AI · How RLHF Shifts LLMs from Autocompletion to Conversational ...",
        "formattedUrl": "https://www.surgehq.ai/category/ai"
      },
      {
        "title": "Humans vs. Gary Marcus vs. Slate Star Codex: When is an AI failure ...",
        "link": "https://www.surgehq.ai/blog/humans-vs-gary-marcus",
        "snippet": "Scott argues that each time someone finds AI failures that require “true” intelligence to get right, those failures largely get solved by newer models.",
        "formattedUrl": "https://www.surgehq.ai/blog/humans-vs-gary-marcus"
      },
      {
        "title": "We asked 100 humans to draw the DALL·E prompts",
        "link": "https://www.surgehq.ai/blog/humans-vs-dall-e",
        "snippet": "We paid 100 random Surgers – most with average drawing skills! – to spend 15-30 minutes drawing one of the DALL·E prompts. Here are some of our favorites and ...",
        "formattedUrl": "https://www.surgehq.ai/blog/humans-vs-dall-e"
      },
      {
        "title": "Google Search is Falling Behind",
        "link": "https://www.surgehq.ai/blog/google-search-is-falling-behind",
        "snippet": "\"python delete file\" on Google. It's not a terrible search results page... But: The caption for the first search result describes removing a folder, ...",
        "formattedUrl": "https://www.surgehq.ai/blog/google-search-is-falling-behind"
      },
      {
        "title": "Leading Social Media Company",
        "link": "https://www.surgehq.ai/case-study/leading-social-media-company",
        "snippet": "KEY FEATURES USED · Generate millions of nuanced judgements per month across multiple domains — hateful speech, misinformation, and spam. · Provide a workforce ...",
        "formattedUrl": "https://www.surgehq.ai/case-study/leading-social-media-company"
      },
      {
        "title": "Case Study | Surge AI and Redwood Research",
        "link": "https://www.surgehq.ai/case-study/adversarial-testing-redwood-research",
        "snippet": "Redwood's first project is building a classifier that identifies violent text with an extremely low false negative rate.",
        "formattedUrl": "https://www.surgehq.ai/case-study/adversarial-testing-redwood-research"
      },
      {
        "title": "Bradley Webb",
        "link": "https://www.surgehq.ai/authors/bradley-webb",
        "snippet": "Bradley Webb. Bradley runs Surge AI's Product and Growth teams. He previously led Integrity and Data Operations teams at Facebook, and graduated from Dartmouth.",
        "formattedUrl": "https://www.surgehq.ai/authors/bradley-webb"
      },
      {
        "title": "Getting started with the Python SDK",
        "link": "https://www.surgehq.ai/blog/python-sdk",
        "snippet": "Our open-source Python SDK provides convenient access to our API, with functions for creating new projects, running tasks, and much more.",
        "formattedUrl": "https://www.surgehq.ai/blog/python-sdk"
      },
      {
        "title": "Edwin Chen",
        "link": "https://www.surgehq.ai/authors/edwin-chen",
        "snippet": "Introduction to Reinforcement Learning with Human Feedback, Large Language Models, 2022 Blog Recap: Trends in AI, Language, & Data",
        "formattedUrl": "https://www.surgehq.ai/authors/edwin-chen"
      },
      {
        "title": "Jefferson Lee",
        "link": "https://www.surgehq.ai/authors/jefferson-lee",
        "snippet": "Lee ... Jefferson leads Surge AI's data labeling and NLP products — whether it's helping customers label their large language models, gather data to train Spam ...",
        "formattedUrl": "https://www.surgehq.ai/authors/jefferson-lee"
      },
      {
        "title": "Andrew Mauboussin",
        "link": "https://www.surgehq.ai/authors/andrew-mauboussin",
        "snippet": "Andrew Mauboussin. Andrew oversees Surge AI's Engineering and Machine Learning teams. He previously led Twitter's Spam and Integrity efforts, and studied ...",
        "formattedUrl": "https://www.surgehq.ai/authors/andrew-mauboussin"
      },
      {
        "title": "Scott Heiner",
        "link": "https://www.surgehq.ai/authors/scott-heiner",
        "snippet": "Scott Heiner. Scott runs Business Development and Operations at Surge AI, helping customers get the high-quality human-powered data they need to train and ...",
        "formattedUrl": "https://www.surgehq.ai/authors/scott-heiner"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Surge AI | LinkedIn](https://www.linkedin.com/company/surge-ai) (Aug 1, 2020)\n\n# Job boards\n- [Surge AI | Himalayas](https://himalayas.app/companies/surge-ai) (Accessed: 2024)\n- [Careers at Surge AI](https://surgehq.ai/careers) (Accessed: 2024)\n\n# App stores\n- No relevant app store links found.\n\n# Product reviews\n- [Surge AI Reviews - 2025](https://slashdot.org) (Accessed: 2025)\n\n# News articles (most recent first, grouped by event)\n- **Surge AI Achieves SOC 2 Compliance**\n  - [Surge AI Achieves SOC 2 Compliance](https://surgehq.ai) (Feb 24, 2022)\n  \n- **Interviews and Insights**\n  - [5 Q's for Edwin Chen, CEO of Surge AI – Center for Data Innovation](https://datainnovation.org) (Sep 26, 2022)\n\n- **General News**\n  - [Inside the AI Factory: The Humans That Make Tech Seem Human](https://nymag.com) (Jun 20, 2023)\n\n# Key employees (grouped by employee)\n- **Edwin Chen**\n  - [5 Q's for Edwin Chen, CEO of Surge AI – Center for Data Innovation](https://datainnovation.org) (Sep 26, 2022)\n  - [Edwin Chen - CEO, Surge AI](https://surgehq.ai) (Accessed: 2024)\n\n- **Andrew Mauboussin**\n  - [Andrew Mauboussin - Surge AI](https://surgehq.ai) (Accessed: 2024)\n\n- **Bradley Webb**\n  - [Bradley Webb - Surge AI](https://surgehq.ai) (Accessed: 2024)\n\n- **Jefferson Lee**\n  - [Jefferson Lee - Surge AI](https://surgehq.ai) (Accessed: 2024)\n\n- **Scott Heiner**\n  - [Scott Heiner - Surge AI](https://surgehq.ai) (Accessed: 2024)\n\n# Other pages on the company website\n- [About Surge AI | All-in-one data labeling platform](https://surgehq.ai/about) (Accessed: 2024)\n- [Blog | Surge AI](https://surgehq.ai/blog) (Accessed: 2024)\n- [Contact | Make your data dreams come true | Surge AI](https://surgehq.ai/contact) (Accessed: 2024)\n- [Case Studies | Real-World Examples | Surge AI](https://surgehq.ai/case-studies) (Accessed: 2024)\n\n# Other\n- [Surge AI - Overview, News & Similar companies | ZoomInfo.com](https://zoominfo.com) (Accessed: 2024)\n- [Surge AI - Crunchbase Company Profile & Funding](https://crunchbase.com) (Accessed: 2024)\n- [Surge AI | World's Most Powerful GenAI Data](https://surgehq.ai) (Accessed: 2024)",
  "crunchbase_markdown": "# Surge AI, founded 2020-01-01 [(Crunchbase, 2025)](https://www.crunchbase.com/organization/surge-ai-b4ea)\nWelcome to Surge AI, the world's most powerful data labeling platform. Our lightning-fast data labelers — the first labeling workforce designed from the ground up for NLP's extraordinary challenges — build you datasets infused with the richness and subtleties of language. Throw in groundbreaking technology, sophisticated quality controls, and vibrant APIs — our platform unifies sophisticated labelers with the powerful tools you need.\n\n- [Website](https://www.surgehq.ai)\n- [LinkedIn](https://www.linkedin.com/company/surge-ai)\n- [Twitter](https://twitter.com/HelloSurgeAI)\n\n## Funding (25M USD total)\n\n- 25M USD on 2020-07-01\n\n## News\n\n- How AI is creating a safer online world ([Valerias Bangert, 2022-03-27](https://venturebeat.com/2022/03/27/how-ai-is-creating-a-safer-online-world/))\n\n",
  "customer_experience_result": {
    "output_text": "# Sentiment: Negative Feedback on Product\n\n- \"I made $28 on there on a month, thought it was gonna be much better.\" [(MarkusRight, Reddit, 2023-06-23)](https://www.reddit.com/r/mturk/comments/14gyqeg/ai_is_a_lot_of_work_rather_relevant_longform/jp8ygq1/)\n- \"It's incredible how bad it's gotten in the past year. It feels almost as bad as Bing used to.\" [(hey_look_its_shiny, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j173aqu/)\n- \"The chat gpt risotto recipe looks like it's way off, and you would have to be insane to follow its numbers on the house structure thing.\" [(iemfi, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1681vz/)\n- \"ChatGPT failed here too.\" [(None, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j19su0m/)\n\n# Sentiment: Neutral/Informational Feedback on Company\n\n- \"I work for Surge AI / this is OC.\" [(BB4evaTB12, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/)\n- \"Can I buy a 'clean feed' off of your company? I have a fear of live chat, but also want live chat.\" [(Gusfoo, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlp8qg/)\n- \"This is what we found in our recent paper as well!\" [(kawin_e, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmot4f/)\n- \"Models are simply profanity detectors and will never rise above this (at least while remaining truly objective) because the concept of toxicity for better or worse has been thoroughly politicized and in the eye of the beholder...\" [(cyborgsnowflake, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlt8hk/)",
    "intermediate_steps": [
      "- \"I made $28 on there on a month, thought it was gonna be much better.\" [(MarkusRight, Reddit, 2023-06-23)](cache://reddit/3)\n- \"It's incredible how bad it's gotten in the past year. It feels almost as bad as Bing used to.\" [(hey_look_its_shiny, Reddit, 2022-12-22)](cache://reddit/21)\n- \"The chat gpt risotto recipe looks like it's way off, and you would have to be insane to follow its numbers on the house structure thing.\" [(iemfi, Reddit, 2022-12-21)](cache://reddit/52)\n- \"ChatGPT failed here too.\" [(None, Reddit, 2022-12-22)](cache://reddit/53)",
      "- \"I work for Surge AI / this is OC.\" [(BB4evaTB12, Reddit, 2022-02-04)](cache://reddit/58)\n- \"Can I buy a 'clean feed' off of your company? I have a fear of live chat, but also want live chat.\" [(Gusfoo, Reddit, 2022-02-04)](cache://reddit/105)\n- \"This is what we found in our recent paper as well!\" [(kawin_e, Reddit, 2022-02-04)](cache://reddit/106)\n- \"Models are simply profanity detectors and will never rise above this (at least while remaining truly objective) because the concept of toxicity for better or worse has been thoroughly politicized and in the eye of the beholder...\" [(cyborgsnowflake, Reddit, 2022-02-04)](cache://reddit/110)"
    ],
    "url_to_review": {},
    "review_markdowns": [
      "# Post ID 14gyqeg: AI Is a Lot of Work (rather relevant long-form article on workers training AI data - ps if you're looking for batch-work sites, scroll down to where it talks about Surge AI, I'd never heard of those sites :D with +8 score by [(_neminem, Reddit, 2023-06-23)](https://www.reddit.com/r/mturk/comments/14gyqeg/ai_is_a_lot_of_work_rather_relevant_longform/)\n\n\n## Comment ID jp880g0 with +7 score by [(None, Reddit, 2023-06-23)](https://www.reddit.com/r/mturk/comments/14gyqeg/ai_is_a_lot_of_work_rather_relevant_longform/jp880g0/) (in reply to ID 14gyqeg):\n[deleted]\n\n### Comment ID jp8ygq1 with +3 score by [(MarkusRight, Reddit, 2023-06-23)](https://www.reddit.com/r/mturk/comments/14gyqeg/ai_is_a_lot_of_work_rather_relevant_longform/jp8ygq1/) (in reply to ID jp880g0):\nYup I have had the same experience, Remotask was decent starting out but the work just dried up and a lot of it was mind-numbing. I made $28 on there on a month, thought it was gonna be much better.\n\n## Comment ID jpcz2fm with +2 score by [(bluemoonrambler, Reddit, 2023-06-24)](https://www.reddit.com/r/mturk/comments/14gyqeg/ai_is_a_lot_of_work_rather_relevant_longform/jpcz2fm/) (in reply to ID 14gyqeg):\nThanks for posting that. It's really interesting.",
      "# Post ID zryl3i: Evaluating ChatGPT vs. Google on 500 Search Queries with +104 score by [(maximumpineapple27, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/)\nThere’s been a lot of excitement about ChatGPT and the future of these models. (Should I be worried about my job? Should Google?!)\n\nI’ve seen a lot of crazy examples of ChatGPT-for-Search on Twitter, but haven’t been sure how representative they are. I'm a PM at a human data startup (Surge AI) that helps LLM and search companies train and evaluate their models on human feedback, so I ran an analysis of ChatGPT on 500 search queries: [https://www.surgehq.ai/blog/googles-existential-threat-chatgpt-matches-googles-performance-on-informational-search-queries-and-smashes-it-on-coding](https://www.surgehq.ai/blog/googles-existential-threat-chatgpt-matches-googles-performance-on-informational-search-queries-and-smashes-it-on-coding)\n\nObviously ChatGPT is slow, expensive, and needs a lot of improvements before it’s a serious Google contender – \\*right now!\\* But it’s fascinating to see just how good it is out of the box, and to think about what this means once this tech gets into more people’s hands...\n\n## Comment ID j15oc56 with +48 score by [(you-get-an-upvote, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15oc56/) (in reply to ID zryl3i):\n> Large Language Models and the Google-Killer\n\nI've discussed the whole \"ChatGPT will kill Google\" premise with a friend and I really don't see it.\n\nFirst, Google is by far the most likely company to create Search 2.0 -- that is, search that is significantly improved by large neutral networks.\n\n1) Google is one of the top 3 companies on the planet in terms of NLP research\n2) Google is the top company in terms of compute resources\n3) Google is already the dominant search engine\n\nI'm also not concerned about internal inertia preventing this kind of \"novelty\" because Google is literally already using AI to improve search results. Even if I buy that ChatGPT is better than Google right now, I have no reason to think that won't change when Google rolls out a 100B parameter page-reranking-and-snippet-extracting model.\n\nSecond, you're never going to be able to download a PyTorch model and then stop using Google.\n\nA huge problem is freshness -- sports, gossip, news, new products, new research, shopping, etc will all be missing from your model for weeks or months. A model that is released every 1-6 months will be awful at this, and I suspect this is closer to the modal use case than looking up bash commands.\n\nAnother problem is that consumers really hate switching technologies, and search is reliable enough that there is no pressing need to switch off of it.\n\nEdit: I will say, one path I can see for GPT winning is copyright. I imagine there is a limit to what Google can put in their answer-the-query snippet before they're sued for copyright infringement, whereas it's much less likely for any legal problems to happen for GPT.\n\n### Comment ID j17ujhl with +8 score by [(TypoInUsernane, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j17ujhl/) (in reply to ID j15oc56):\nYeah, I don’t know why people assume Google doesn’t already have ChatGPT-level AI. It was already in the news six months ago when a Google employee was so impressed with the quality of LaMDA’s chat responses that he legitimately believed it had achieved consciousness. And LaMDA isn’t even their most advanced model.\n\nIf Google had launched a public demo, people would have flipped out about how amazing LaMDA is, the same way they are flipping out about ChatGPT. But that hasn’t happened because Google is very cautious about releasing something that could potentially generate offensive outputs. The day Google releases a chatbot, thousands and thousands of people will bombard it with adversarial attempts to get the bot to say something racist. And when someone inevitably succeeds, that will be the headline everyone sees the next day. So Google doesn’t rush this kind of thing\n\n#### Comment ID j18mic8 with +6 score by [(Makin-, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j18mic8/) (in reply to ID j17ujhl):\nTo be fair, the Google employee was kind of a quack, and LaMDA was not SOTA even at the time.\n\n#### Comment ID j1dum3d with +1 score by [(unicynicist, Reddit, 2022-12-23)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1dum3d/) (in reply to ID j17ujhl):\n> If Google had launched a public demo\n\n[They have](https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/) -- but it \"has undergone key safety improvements\" so that it doesn't exhibit any of the behavior described by Blake Lemoine. It seems to abort any conversation that is the least bit provocative or existential.\n\n### Comment ID j16twc1 with +6 score by [(Ratslayer1, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j16twc1/) (in reply to ID j15oc56):\nFreshness has been subject to research for a while, see e.g. Atlas by meta AI. Will be solved by external knowledge bases/DBs/etc, to avoid need for retraining.\n\n#### Comment ID j1ad3gp with +1 score by [(maximumpineapple27, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1ad3gp/) (in reply to ID j16twc1):\nYeah, we also worked on WebGPT [https://openai.com/blog/webgpt/](https://openai.com/blog/webgpt/) and other similar projects (i.e., allowing LLMs to browse the web), which would help with this!\n\n### Comment ID j16zrt2 with +23 score by [(Mutated_Cunt, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j16zrt2/) (in reply to ID j15oc56):\n>First, Google is by far the most likely company to create Search 2.0 -- that is, search that is significantly improved by large neutral networks.\n\nI think you're not understanding the problem here. ChatGPT isn't a \"search 2.0\", its a new product that has the potential to be 100x better than the product Google Search offers today. Think about how Google Search destroyed the market for encyclopedias. \n\nGoogle's core business model is designed around web traffic. The more links you click, the more ads you view on the internet provided by Google. They get you to click on links by providing you answers to questions you wanted.\n\nChat GPT provides you answers to questions WITHOUT creating web traffic, and WITHOUT the pain of filtering your way through SEO garbage that Google's business model has generated. Even if Google decides they want to compete with Chat GPT and leverage their enormous R&D department to create a virtual assistant at a similar scale, they must do so at the cost of their old business model, and there's zero guarantee that this new model will be as monetizable. There's also zero guarantee that Google's product will be the winner just because they have the most resources available to spend on the problem. Again think how Facebook managed to come from nothing and build a social network monopoly that sells ads right under Google's noses, despite the billions they spent on trying to make Google+ happen. \n\nHere's a multibillion dollar question that Google is asking right now, How many web searches will no longer be typed in the future because they will be replaced by Chat GPT queries? And not by Chat GPT, but the stronger and more powerful versions of Chat GPT that will be built by different companies in the future that might not have been created yet? \n\nI'd be nervous if I was them.\n\n#### Comment ID j17cygy with +10 score by [(you-get-an-upvote, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j17cygy/) (in reply to ID j16zrt2):\n> Chat GPT provides you answers to questions WITHOUT creating web traffic, and WITHOUT the pain of filtering your way through SEO garbage that Google's business model has generated.\n\nWhy does a user care about web traffic, and why is a chat bot going to be better than an AI that's also hooked up to Google's 100PB Internet index? If Google can keep its results competitive, why would anyone switch over? Especially if ChatGPT is going to fail hard on queries people make all the time, like searching for things to buy, sports, news, etc. Sure these are solvable for a chat bot, but those solutions will require Internet and a backend that crawls and indexes the Internet -- i.e. one that looks a lot more like Google's than anyone else's.\n\n> There's also zero guarantee that Google's product will be the winner just because they have the most resources available to spend on the problem. Again think how Facebook managed to come from nothing and build a social network monopoly that sells ads right under Google's noses, despite the billions they spent on trying to make Google+ happen.\n\n[Google+ launched in June 2011](https://en.wikipedia.org/wiki/Google%2B) when Facebook had [750 million MAUs](https://www.businessofapps.com/data/facebook-statistics/) so this is definitely a great example of the power of consumer inertia, which is one of the reasons I don't expect Google is going anywhere.\n\nI'd also dispute the claim that this is a counter point against the importance of resources, since I seriously doubt the investment in Google+ was higher than Facebook's (Facebook's costs were [nearly a billion dollars in the first half of 2011](https://www.reuters.com/article/us-facebook/exclusive-facebook-doubles-first-half-revenue-idINTRE7863YW20110908)).\n\nThis as an example where the company that had the home field advantage and spent more money won, so it doesn't seem like good evidence in favor of your beliefs. A better example is probably Facebook displacing Myspace.\n\n> I'd be nervous if I was them.\n\nSure. I'm nervous like I'm nervous Tesla will claim 90% of the automobile marketshare. It's not impossible and there is some cool technological progress, but I wouldn't call Tesla a \"Toyota killer\".\n\n### Comment ID j164ooi with +23 score by [(None, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j164ooi/) (in reply to ID j15oc56):\n[deleted]\n\n#### Comment ID j173aqu with +13 score by [(hey_look_its_shiny, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j173aqu/) (in reply to ID j164ooi):\nIt's incredible how bad it's gotten in the past year. It feels almost as bad as Bing used to.\n\n### Comment ID j1d5eo3 with +2 score by [(methyltheobromine_, Reddit, 2022-12-23)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1d5eo3/) (in reply to ID j15oc56):\n>Google is literally already using AI to improve search results\n\nThey're really not. The results keep getting worse, and this is because they're giving out popular results and discarding the rest. But \"the rest\" is what people actually want, for there's no reason to use a search engine to find something popular, that's not what searching is for.\n\nGoogles searches have gotten worse since something like 2008. I could always find whatever I wanted, now I can't. It doesn't even respect quotations anymore, or the plus sign. I can't seem to search for date ranges, either.\n\nThey're removing functionality and showing me what they want to show, rather than what I'm looking for. At this point, I could make a better search engine myself, and I refuse to believe that Google is not doing this on purpose, as that would show an incredible level of incompetence.\n\nI belive that Google is now running on strict whitelists, filtering everything not classified as safe by actual people. Google images is mostly giving results from just 10 different domains, despite the existence of millions of websites.\n\n>A huge problem is freshness\n\nValid! But if you search through 5 years of content rather than 1 week, the content will be better.\n\n#### Comment ID j3piep9 with +2 score by [(lithiumbrigadebait, Reddit, 2023-01-10)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j3piep9/) (in reply to ID j1d5eo3):\nI have heard the internal workings of Search described by someone working on the engineering team for it as \"an insane black box of ML models that nobody really understands end to end any more.\"\n\nIt definitely incorporates AI, it's just not necessarily happening in a manner that actually leads to better search results for the end user; it is, however, very good at showing you sites that have paid for search ads and/or SEO-gamed themselves to the top of the rankings to show you more ads!\n\n### Comment ID j17z59l with +1 score by [(PaulHasselbaink, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j17z59l/) (in reply to ID j15oc56):\nGoogle has much more significant political power and lobbying capabilities, if it would come to a copyright issue, Google has better chances of coming out of it with a better position than what they began with.\n\n## Comment ID j15chcc with +66 score by [(SirCaesar29, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15chcc/) (in reply to ID zryl3i):\nSeeing how good ChatGPT is compared to GPT-2 in explaining \"basic\" (first year undergraduate) concepts has me thinking that in 10 years society will be very different.\n\nI fully expect virtual assistants that replace secretaries for most non-super-rich CEOs, customer service jobs will basically disappear (they are using bots *now* when they suck), and if Zuckerberg's metaverse or anything similar manages to survive the next few years then I see a case for most teachers to be turned into babysitters while the class is wearing VR headsets and interacting with a one-to-one tutor.\n\nI think this is a rare case of people knowing about AI having a huge advantage to plan their futures. Entire sectors will disappear from the job market.\n\nI am also mildly panicking about mathematical research, which is my area. Right now ChatGPT seems to be able to understand and learn, as soon as it gets even slightly more sophisticated it might just start learning everything that humans can learn, and then run in a night the equivalent of the brain power of 10^4 PhD students. At least someone will need to check it's right... for the first few years.\n\n### Comment ID j15m8re with +48 score by [(monoatomic, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15m8re/) (in reply to ID j15chcc):\n> (they are using bots now when they suck)\n\nThis feels like an important takeaway.  AI doesn't have to be truly Intelligent, or perfect.  It just has to be good-enough to make it attractive to cut labor costs by 95% for a given application.\n\n#### Comment ID j4amy31 with +2 score by [(CanuckButt, Reddit, 2023-01-14)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j4amy31/) (in reply to ID j15m8re):\nExactly. Planes didn't have to fly like birds to be useful, and they still don't. LLMs don't have to think like brains, either.\n\n### Comment ID j15fiph with +24 score by [(parkway_parkway, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15fiph/) (in reply to ID j15chcc):\n>I am also mildly panicking about mathematical research\n\nI think a big part of this is formal mathematics too. With a system like metamath you can check the answers that the model produces automatically.\n\nSo you can ask it for a proof of something and then see if it's right, and yeah then just ask over and over until it is.\n\nThere was a system called gpt-f which was already doing this and I used it and it was quite impressive. And yeah a futuristic system like this would be immense.\n\n#### Comment ID j15ga6d with +9 score by [(SirCaesar29, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15ga6d/) (in reply to ID j15fiph):\nAh, yes, that is correct. [This is very bad for the future job security of researchers](https://imgur.com/Jw7mvZ7).\n\n### Comment ID j16u15q with +13 score by [(conjuncti, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j16u15q/) (in reply to ID j15chcc):\n>I am also mildly panicking about mathematical research, which is my area.\n\nKeep in mind that ChatGPT is also good at producing good-sounding, but ultimately false, proofs. For example, I convinced GPT3 that the infinite intersection of open sets is open, and that pi\\^2/6 is rational by \"infinite\" induction.\n\n[Pi\\^2/6 is rational](https://imgur.com/a/ipXwaEJ)\n\n#### Comment ID j17woms with +3 score by [(eric2332, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j17woms/) (in reply to ID j16u15q):\nAren't there already proof engines which can check if a proposed proof is correct?\n\n(Though it may be that the space of false proofs is so large that ChatGPT [edit: or its descendants] will never happen upon the one true proof. I suspect this is most likely)\n\n#### Comment ID j17usyj with +1 score by [(SirCaesar29, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j17usyj/) (in reply to ID j16u15q):\nYes, I have noticed this, but it might only be a matter of time.\n\n### Comment ID j15ky0j with +10 score by [(TheMotAndTheBarber, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15ky0j/) (in reply to ID j15chcc):\nI think you're probably way off when it comes to the speed of productionization and the speed of social change. (The former is impacted by the fact there's about 2 organizations in the world right now with GPT3-level language models, there are reasons to think they won't be quick to go into the customer service business, and it's not easy to catch up to them.)\n\n#### Comment ID j15n80c with +3 score by [(SirCaesar29, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15n80c/) (in reply to ID j15ky0j):\nIs it significantly hard to replicate once you have it?\n\n### Comment ID j15dlq2 with +11 score by [(GibonFrog, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15dlq2/) (in reply to ID j15chcc):\nAs a neuroscience researcher I actually might be safer than you, despite the fact that my research requires less brain power. I don't see robots pipetting and doing general bench work any time within this decade.\n\n#### Comment ID j15jjl6 with +16 score by [(None, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15jjl6/) (in reply to ID j15dlq2):\nso incredible that we live in a world where semi-precise robotics is more difficult of a problem to solve than, like, the creation of intelligence\n\n#### Comment ID j161hxe with +9 score by [(AndChewBubblegum, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j161hxe/) (in reply to ID j15dlq2):\nThey already have robotic incubators that refresh media and apply reagents at certain time points, they're just more expensive than undergrad techs or grad students right now.\n\nI suspect we're going to see a lot of AI-written literature reviews as the tip of the spear of their incursion into scientific discourse.\n\n#### Comment ID j1611w9 with +7 score by [(None, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1611w9/) (in reply to ID j15dlq2):\nthere are already robots pipetting. just not thinking robots.\n\n#### Comment ID j15eu03 with +1 score by [(SirCaesar29, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j15eu03/) (in reply to ID j15dlq2):\nYes, definitely\n\n### Comment ID j17kc52 with +3 score by [(augustus_augustus, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j17kc52/) (in reply to ID j15chcc):\nExpect hand-made artisanal math to become a thing.\n\n### Comment ID j1920bd with +3 score by [(iwasbornin2021, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1920bd/) (in reply to ID j15chcc):\nWe thought AI would decimate blue collar jobs first but it appears that they'll be among the last to go (robotics have an additional layer of complexity)\n\n#### Comment ID j192hdz with +4 score by [(SirCaesar29, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j192hdz/) (in reply to ID j1920bd):\nIn hindsight, things that are easier to scale get accelerated development. A robot fleet of binmen is much harder to build and deploy than a digital smart assistant\n\n#### Comment ID j19lv7o with +4 score by [(07mk, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j19lv7o/) (in reply to ID j1920bd):\nAt this rate, I suspect that the world's oldest profession may also end up becoming the world's final profession as well.\n\n### Comment ID j19sd35 with +1 score by [(callmejay, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j19sd35/) (in reply to ID j15chcc):\n> Right now ChatGPT seems to be able to understand and learn\n\nWhat makes you say that?\n\n#### Comment ID j1b978t with +1 score by [(SirCaesar29, Reddit, 2022-12-23)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1b978t/) (in reply to ID j19sd35):\nApologies for not providing source but... have you seen that guy who taught it a brand new language?\n\n## Comment ID j19r90c with +7 score by [(VelveteenAmbush, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j19r90c/) (in reply to ID zryl3i):\nChatGPT has two major problems that currently prevent it from replacing search:\n\n* It is too expensive to run. Each query costs some amount of GPU time. Google search queries have lower marginal cost. OpenAI is burning money to make it available to the public. This means that it would need a different business model than free-to-all with ads. A ChatGPT style search product would need to monetize at a higher rate than Google queries to make the unit economics positive, which means either charging per use, somehow making it available only to users who yield a sufficiently high price in the instant ads auction, or inventing a new category of ads that monetizes much better than the current style of internet ads. The first doesn't seem workable in the market, and the latter two seem beyond OpenAI's capabilities (although maybe possible if they team up with Bing). I don't know if the march of technology will eventually lower the inference costs of the chat engine enough for standard internet display ads to support its queries, but at least so far the lowered cost of compute has been reinvested in scaling up the models' size and capacity.\n\n* It is often wrong, but seldom in doubt. You can Google for obscure topics and it cites its sources, which you can check and decide whether they're trustworthy. But ChatGPT just gives you an answer, and empirically that answer is sometimes incorrect, with no obvious way to tell.\n\n## Comment ID j160b4b with +7 score by [(PaulHasselbaink, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j160b4b/) (in reply to ID zryl3i):\nIlya Sutskever used to work for Google, and in terms of monetary leverage, it's not even close.\n\nhttps://en.m.wikipedia.org/wiki/Google_Brain\n\n## Comment ID j16uj9g with +5 score by [(philosophical_lens, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j16uj9g/) (in reply to ID zryl3i):\n>\tWe asked 100 Surgers to pull up their search history, and extract their 5 most recent “informational” queries.\n\nWhat exactly does \"informational” mean? And what % of queries meet this definition I wonder? Thanks!\n\n## Comment ID j1681vz with +10 score by [(iemfi, Reddit, 2022-12-21)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1681vz/) (in reply to ID zryl3i):\nThe chat gpt risotto recipe looks like it's way off, and you would have to be insane to follow its numbers on the house structure thing.\n\n### Comment ID j19su0m with +3 score by [(None, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j19su0m/) (in reply to ID j1681vz):\nThe house question was how many ply (i.e. how many pieces of wood, usually 3.2mm, are needed to make a beam strong enough).  This is a standard beam design question for which you use a beam calculator, which is what Google suggested.  The ChatGPT answer seemed to think the question was about plywood on a roof, not how deep a beam needs to be. The other critical piece of information is what the snow load is in the US.  20lbs is what is usually used.  ChatGPT failed here too.  \n\nThe tallest active volcano in the US is Mount Bona (16,550ft), which is in Alaska, and erupted in 847AD, so it definitely not dormant.  Mount Ranier at 14,411 is much taller than St Helen's at 8,364 ft. The largest volcano in Washington by volume is Mount Adams, which is 50% taller than St Helen's and much bigger.  \n\nIf you care just about volume, then the Yellowstone super volcano is the largest, bigger than Mauna Loa. It's magma chamber is about 4000 cubic km, as opposed to Mauna Loa's 1 km^3.\n\nIt is shocking how gullible people are.  They seem to presume that ChatGPT is correct, which a quick Google search could correct them.\n\n#### Comment ID j19vz3m with +2 score by [(iemfi, Reddit, 2022-12-22)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j19vz3m/) (in reply to ID j19su0m):\nI would love to watch a \"how to basic\" style youtube channel where each video is doing a task following chat-GPT's instructions exactly. The house thing makes no sense even if we ignore the question too. It alternates between talking about the roof and the floor while throwing out numbers which look reasonable but make no sense when you actually consider it. Like it tells you to cover the floor with 8 inch wide 3/4 plywood lol.\n\n## Comment ID j1fd9tq with +1 score by [(None, Reddit, 2022-12-23)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j1fd9tq/) (in reply to ID zryl3i):\nI think you miss one other way ChatGPT (or something like it) can murder Google Search (or interent search engines in general). Namely, by allowing to flood the web with cheap nonsense content, which will look OK even for humans at cursory reading.\n\n## Comment ID j3amezq with +1 score by [(wonderfuly, Reddit, 2023-01-07)](https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/j3amezq/) (in reply to ID zryl3i):\nUse https://chatgpt4google.com",
      "# Post ID skjjvm: Holy $#!t: Are popular toxicity models simply profanity detectors? [D] with +412 score by [(BB4evaTB12, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/)\nOne of the problems with real world machine learning is that engineers often treat models as pure black boxes to be optimized, ignoring the datasets behind them. I've often worked with ML engineers who can't give you any examples of false positives they want their models to fix!\n\nPerhaps this is okay when your datasets are high-quality and representative of the real world, but they're usually not.\n\nFor example, many toxicity and hate speech datasets mistakenly flag texts like \"this is fucking awesome!\" as toxic, even though they're actually quite positive -- because NLP datasets are often labeled by non-fluent speakers who pattern match on profanity. (So is 99% accuracy or 99% precision actually a good thing? Not if your test sets are inaccurate as well!)\n\nMany of the new, massive scale language models use the Perspective API to measure their safety. But we've noticed a number of Perspective API mistakes on texts containing positive profanity, so [I wrote a blog post](https://www.surgehq.ai/blog/are-popular-toxicity-models-simply-profanity-detectors) in an attempt to explain the problem and quantify it.\n\nNote: I work for Surge AI / this is OC.\n\n## Comment ID hvlk6eb with +266 score by [(jrkirby, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlk6eb/) (in reply to ID skjjvm):\nSpend a million on GPUs, spend 5000$ on data. Why is my performance so low?\n\n### Comment ID hvmgbz5 with +110 score by [(HateRedditCantQuitit, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmgbz5/) (in reply to ID hvlk6eb):\nOne of my secret weapons at work is sometimes just spending a day or two labeling data. Google sheets as a labeling UI will do wonders.\n\nSometimes it seems like everyone else would rather spend a week (that turns into six months) building an over-complicated model when a day spent labeling a few thousand examples and then another day of building a much much dumber model does better.\n\n(edit: dont even get me started on people trying to explore model issues with absurdly roundabout methodology, instead of just sitting down and labeling problems for a while)\n\n#### Comment ID hvmyl74 with +35 score by [(getbehindmeseitan, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmyl74/) (in reply to ID hvmgbz5):\nlabelstudio is an open-source labeling tool that blows Google Spreadsheets out of the water if you're dealing with text that's longer than a line or two. It's worth checking out.\n\n(But, yes, spending a day or two labeling data is always worthwhile. Hell, even an hour helps.)\n\n#### Comment ID hvo38ww with +8 score by [(dhrumilp15, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvo38ww/) (in reply to ID hvmgbz5):\nI remember when I spent 3 days labeling data in Google sheets for work - the model had good metrics when I finished training and testing. Two weeks after I finished the project, I wanted to extend the model and needed to use the dataset I labelled. I don't remember why or how, but the labels in the dataset were just... wrong. This was crushing and I dreaded spending another three days to label all the transactions. After some ideation, I was able to label the dataset through a mix of active learning and a (very wrong) rule-based labeller. The new system I made allowed me to label the entire dataset within a few hours without requiring me to individually label all the transactions. The extended model also achieved good metrics and performed well in production (the company is using it to expand into another NA country).\n\nI think it's important and useful to really understand your data, but I look back at those three days as time that could have been better spent. I recognize that iteration is part of the process, but I often wonder about how to come up with better labellers from the start.\n\n#### Comment ID hvo348d with +2 score by [(taichi22, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvo348d/) (in reply to ID hvmgbz5):\n… wait, does that mean I’m actually going about my work the right way?\n\nPractically *all* I’ve done is fiddle with the data because we already have a complex model built.\n\n## Comment ID hvlf8dd with +246 score by [(ZestyData, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlf8dd/) (in reply to ID skjjvm):\nFuck yeah nice post, you sick cunt!\n\n### Comment ID hvlsjrh with +161 score by [(BB4evaTB12, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlsjrh/) (in reply to ID hvlf8dd):\nThanks bitch!!!!!\n\n#### Comment ID hvlwm21 with +60 score by [(finitearth, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlwm21/) (in reply to ID hvlsjrh):\nlol both of your comments have been default hidden by reddit for me :D\n\n#### Comment ID hvlstx6 with +20 score by [(BinodBoppa, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlstx6/) (in reply to ID hvlsjrh):\nLmao\n\n#### Comment ID hvnu0gb with +3 score by [(PlayBoiPrada, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvnu0gb/) (in reply to ID hvlsjrh):\n*Jesse Pinkman has entered the chat*\n\n### Comment ID hvn2xhl with +6 score by [(None, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvn2xhl/) (in reply to ID hvlf8dd):\nNice comment cock sucker\n\n### Comment ID hvoyb9q with +1 score by [(None, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvoyb9q/) (in reply to ID hvlf8dd):\nFuck yeah science\n\n## Comment ID hvle9gx with +87 score by [(jayplusplus, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvle9gx/) (in reply to ID skjjvm):\nHonestly it's our fault for making a \"bad bitch\" good and the wicked sick so rad.\n\n### Comment ID hvlm8ti with +54 score by [(oursland, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlm8ti/) (in reply to ID hvle9gx):\nIt's time to stop engineering the models, and begin engineering the people.\n\n#### Comment ID hvlw54z with +23 score by [(Aud4c1ty, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlw54z/) (in reply to ID hvlm8ti):\n>begin engineering the people\n\nEugenics? I'm sure that will be popular.\n\n### Comment ID hvm331s with +19 score by [(LoyalSol, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvm331s/) (in reply to ID hvle9gx):\nIt is kind of amazing how in English you can change the leading word to a swear word and radically change a sentence.\n\nThis is shit\n\nThis is the shit\n\nThis is my shit\n\nThis is total shit\n\n#### Comment ID hvmrb48 with +13 score by [(visarga, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmrb48/) (in reply to ID hvm331s):\n\"shit\" is actually the <mask> token in our brains\n\n#### Comment ID hvo5qh9 with +3 score by [(helm, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvo5qh9/) (in reply to ID hvm331s):\nThis is some new shit\n\n### Comment ID hvlvoul with +19 score by [(fimari, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlvoul/) (in reply to ID hvle9gx):\nActually it's a sanity test for language out of the box. \n\nIrony, sarcasm, witt, slang... are actually tests of the values of the recipient and a proof of your own.\n\nYou can say something and meaning the opposite and to get this, you have to be smart enough and know enough about human values to recognise the inversion.\n\n#### Comment ID hvn9g1j with +5 score by [(YourNameIsMyNameT00, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvn9g1j/) (in reply to ID hvlvoul):\nWhaaaaa? *Mind Blown*\n\n## Comment ID hvlmvsp with +113 score by [(AmalgamDragon, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlmvsp/) (in reply to ID skjjvm):\nThe fundamental problem with toxicity models is that the toxicity is ill defined.  Same for hate speech.\n\n### Comment ID hvmoy7o with +17 score by [(kawin_e, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmoy7o/) (in reply to ID hvlmvsp):\nAgreed.\n\nIn a popular hate speech detection benchmark (DWMW17), the vast majority of information that the input contains about the label is found in 50 potentially offensive words, some of which are common terms in AAVE: https://arxiv.org/abs/2110.08420\n\n#### Comment ID hvnup7y with +9 score by [(HINDBRAIN, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvnup7y/) (in reply to ID hvmoy7o):\nTry strongly disliking AAVE, then the model will become accurate.\n\n### Comment ID hvm1a75 with +20 score by [(Nowado, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvm1a75/) (in reply to ID hvlmvsp):\nIt wouldn't be engineering, if defining problem took over 5% of time and budget.\n\n### Comment ID hvmo0wy with +24 score by [(sdmat, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmo0wy/) (in reply to ID hvlmvsp):\nML with an ill-defined political objective, what could go wrong?\n\n#### Comment ID hvmtv4g with +3 score by [(Prineak, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmtv4g/) (in reply to ID hvmo0wy):\nThey’ll promote philosophy.\n\n*shudder*\n\n### Comment ID hvmp2w9 with +13 score by [(angry_mr_potato_head, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmp2w9/) (in reply to ID hvlmvsp):\nHate speech is easy: it’s speech I don’t like\n\n## Comment ID hvlqbfs with +54 score by [(Appropriate_Ant_4629, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlqbfs/) (in reply to ID skjjvm):\nSentiment analysis has the same problem.\n\nHere's a couple examples from one of the leading commercial systems: \n\n* the following narrative fragment is scored as having an extremely positive sentiment (83%) :\n\n    *\"Late last night, we received notification of a social media post that alerted students not to attend school today. The post indicated there would be a school shooting on both middle and high school campuses.”*\n\n* in contrast, this much more positive fragment scores an extremely negative sentiment (3%).\n\n    *\"The woman and her 3-year-old son have been found unharmed Tuesday after they were reported missing. The mother suffers from depression and speaks limited English.\"*\n\nSeems the commercial systems mostly just count \"positive\" words (\"student\", \"high\", etc) and negative ones (\"missing\", \"limited\", etc) without paying any attention to how the words are used.\n\nEither the algorithms are extremely bad keyword scanners that don't understand context ...\n\n... or the sentiment analysis APIs are getting rather psychotic.\n\n### Comment ID hvlwxn1 with +16 score by [(BB4evaTB12, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlwxn1/) (in reply to ID hvlqbfs):\nThese are concerning examples! Even if the algorithm is just a bad keyword scanner, I'd at least wish that the phrase \"there would be a school shooting\" would serve as a negative  counterbalance to the supposed \"positive\" words like \"student\" and \"high\". \n\nOf course, to your broader point, these systems should be far more than keyword scanners.\n\n#### Comment ID hvm229b with +14 score by [(Appropriate_Ant_4629, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvm229b/) (in reply to ID hvlwxn1):\nYup.  I've reported such bugs to some of the leading cloud vendor's \"ML\" \"API\" teams (at work we're a customer of one of them).   One said they're adding some of my examples to their test cases, so hopefully it's improved by now.\n\nIt's not hard to generate test cases that are very embarrassing for them.\n\nStart with a sentence that can change drastically when one word changes.... like\n\n* The kids were laughing while shooting each other with water guns.\n* The kids were laughing while shooting each other with real guns.\n\n... then tweak the words in ways until you find the grey-areas their model fails on.\n\nMany of those models don't understand that two words that would be pretty neutral in other contexts (\"real\", \"water\") can change the sentiment drastically.   Changing the phrase \"each other\" with \"competition targets\" or \"their kidnappers\" would change the sentiment too.\n\nUnless their training data saw examples where such substitutions had a big impact, they'll make a lot of mistakes in such text.\n\n### Comment ID hvptftn with +4 score by [(Brudaks, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvptftn/) (in reply to ID hvlqbfs):\nIs it just me or do both of these examples have neutral sentiment - at least the way how I'd understand sentiment - as they are factual statements that do not express any opinion, judgement or emotional affect. I mean, detecting sentiment expressed in a statement is a quite different thing than detecting whether the event which is being talked about would be considered good news or bad news.\n\n#### Comment ID hvqknfz with +2 score by [(jorvaor, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvqknfz/) (in reply to ID hvptftn):\nI was thinking the same. But I know nil about sentiment analysis, so I supposed that in this context 'sentiment' means something different than what I was expecting.\n\n#### Comment ID hvwa93s with +2 score by [(Appropriate_Ant_4629, Reddit, 2022-02-07)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvwa93s/) (in reply to ID hvptftn):\nI would have been happy if the systems reported them as \"neutral sentiment\" since from some point of view news stories are just dry boring facts.\n\nI was hoping it could be used as a basis of looking for positive or negative spin and/or feel-good-stories vs tragic-outcomes.\n\nI was mostly just surprised at how the feel-good stories often were scored as extremely negative sentiment; and the tragedies were scored as extremely positive  --- almost as if the ML models had a kinda psycho streak.\n\n### Comment ID hvlvfqf with +4 score by [(Franc000, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlvfqf/) (in reply to ID hvlqbfs):\nYeah, but on the other hand any systems will have weird/bad predictions out of them, so if you cherry pick them you are not really helping. If you are looking for a bad prediction, you will eventually find it, doesn't matter on which system or how good the model is. \n\nThe question is: \"does the commercial system you are inspecting make those type of mistakes often or not, relative to your use case.\"\n\nIf you want a system that makes no mistakes, do not use machine learning, full stop.\n\n#### Comment ID hvlweba with +7 score by [(justifiably-curious, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlweba/) (in reply to ID hvlvfqf):\nBuuuut you also can't use people. I did some inter-annotator agreement checks on sentiment analysis with some data my work collected and it was only around 85%. 15% of the time you're going to disagree with decision a fellow human made\n\n#### Comment ID hvmq9qz with +1 score by [(Appropriate_Ant_4629, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmq9qz/) (in reply to ID hvlvfqf):\n> \"does the commercial system you are inspecting make those type of mistakes often or not, relative to your use case.\"\n\nThey made mistakes even worse than flipping a coin.\n\nI think structures that confuse sentiment analysis algorithms are extremely common in paragraphs from news stories.\n\nNone of the commercial sentiment guessers handled the cases of narratives structured like:\n\n* \"all things considered, based on how things might have easily gone worse, this was a wonderful outcome\"\n\nor:\n\n* \"wow, it was almost a great success, until it wasn't\"\n\nNews stories often have such structures -- because that's what makes them newsworthy.\n\n### Comment ID hvmnnpx with +2 score by [(Echolocomotion, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmnnpx/) (in reply to ID hvlqbfs):\nSomeone who didn't already know we lived in the kind of world where people are taken captive might find learning about an escape from captivity to be bad news: with a different set of background assumptions, observing such a near miss is horrifying. I don't think it's entirely fair to blame non AGI models for making such mistakes.\n\n## Comment ID hvlqcma with +23 score by [(b3rn13mac, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlqcma/) (in reply to ID skjjvm):\ngarbage in, garbage out\n\n## Comment ID hvn3yzm with +11 score by [(Chordus, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvn3yzm/) (in reply to ID skjjvm):\nThis is nearly exactly what my job is, and one of the easiest, most reliable tests of a sentiment analysis tool I've found is to give it the input \"fucking.\"  Most of them mark it as negative sentiment (the ternary distinction of positive/negative/neutral being nearly worthless, but that's another issue), but in actual use, it functions almost exclusively as an emphasizer.  As a verb, the sentiment is fuzzier, but it's used as an adjective something like 95% of the time unless you're pulling text from erotic literature sites.  Anything the labels \"fucking\" as negative has inherent flaws, and should set off *all* the red flags.\n\n\"Conviction\" as a standalone word is another good one, as it can be either positive or negative depending on context.  For more advanced models, check to see if it knows of a notable difference between \"hurt\" and \"hurtful.\"\n\n### Comment ID hvn96er with +6 score by [(BB4evaTB12, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvn96er/) (in reply to ID hvn3yzm):\nGreat points, especially re: \"fucking\". Such a beautifully versatile word! All hail the sentiment analysis tool that can handle it in all its glory.\n\n### Comment ID hvo5lqf with +2 score by [(None, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvo5lqf/) (in reply to ID hvn3yzm):\nAnalyzing what people mean and filtering out negative sentiments are not the same thing though. If I wanted to count all the positive comments found on the internet today about a topic, yes it has to handle that well. If I want to filter out comments that use fucking for emphasis....there are good reasons to do that. One being that something polarizing enough to get everyone all fucking jazzed up is going to inevitably bring party crashers and contrarians and turn whatever online forum it’s on into a cesspool of people that think AOC is a lizard person arguing with people who think they should bring back smallpox and have smallpox parties instead of get Covid vaccines. If people spoke online like they do in reality mankind might become intelligent again.\n\n#### Comment ID hvp1dki with +2 score by [(Chordus, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvp1dki/) (in reply to ID hvo5lqf):\n100% agree, that's why I said it's an emphasizer.  It makes positive words more positive, and negative words more negative.  And neutral words...  more...  neutral?  A good model will take the word \"fucking\" into account, it just won't give it any sentiment if used as a standalone word, free of context.\n\n## Comment ID hvq1ygv with +5 score by [(Pelicantaloupe, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvq1ygv/) (in reply to ID skjjvm):\nI started to wonder if toxicity and sentiment classification could only be fully understood by general artificial intelligence so I put to together a simple prompt using the recent GPT3-instruct just released and for these examples in this post and it seems to do pretty well:\n    \n\n> Score the following text based on it's overall sentiment based on a scale of -100 to 100 where -100 is negative sentiment and 100 is positive sentiment.\n>\n> Late last night, we received notification of a social media post that alerted students not to attend school today. The post indicated there would be a school shooting on both middle and high school campuses.\n> \n> -100\n> \n> The woman and her 3-year-old son have been found unharmed Tuesday after they were reported missing. The mother suffer from depression and speaks limited English.\n> \n> 75\n> \n> In 1969, the United States sent a spacecraft called Apollo 11 to land on the moon. Astronauts named Neil Armstrong and Edwin \"Buzz\" Aldrin were the first people to step out of the spacecraft and walk on the moon.\n> \n> 100\n> \n> This is fucking awesome!\n> \n> 100\n> \n> I lust lover her, she's so me, what a bad bitch.\n> \n> 100\n>\n\n## Comment ID hvlilz7 with +11 score by [(MarkOates, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlilz7/) (in reply to ID skjjvm):\nThis is the shit.\n\nOn a real note, I find that this is the case with a lot of cheap, uninformed software development.  If you're a software vender that can make a statement to a buyer that the software \"blocks profanity\" and also uses \"blockchain AI\" or whatever, the buyer is not really interested in the nuances and pitfalls.  They'll buy it, and then at that point they can say that they use CleanTecSecure™️ technology to provide and ensure safety to the customer.\n\nIt's nothing more than a broad-stroke, grotesquely generalized way that shitty IT teams deliver technology solutions to their businesses.\n\n## Comment ID hvlp8qg with +3 score by [(Gusfoo, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlp8qg/) (in reply to ID skjjvm):\n> Note: I work for Surge AI / this is OC.\n\nCan I buy a \"clean feed\" off of your company? I have a fear of live chat, but also want live chat.\n\n## Comment ID hvmot4f with +4 score by [(kawin_e, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmot4f/) (in reply to ID skjjvm):\nThis is what we found in our recent paper as well! \n\nIn a popular hate speech detection benchmark (DWMW17), the vast majority of information that the input contains about the label is found in 50 potentially offensive words, some of which are common terms in AAVE: https://arxiv.org/abs/2110.08420\n\n## Comment ID hvnse0z with +3 score by [(andreichiffa, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvnse0z/) (in reply to ID skjjvm):\nSomeone, quick, head to Australia to collect samples of their friendly speech.\n\n## Comment ID hvq3pyc with +2 score by [(TreacleAltruistic853, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvq3pyc/) (in reply to ID skjjvm):\nThere is no technological solution to social problems. Toxicity is a social problem. We need to stop expecting that some magical algorithm can deal with that. Positive profanity? Really? Is there such a thing? Don't you think that there is a seed of toxicity in any kind of profanity?\n\n## Comment ID hwshikw with +2 score by [(Jatin-Thakur-3000, Reddit, 2022-02-13)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hwshikw/) (in reply to ID skjjvm):\nI couldn't agree more. I've been watching this shift in acceptable standards in America move from intent to perception with considerable consternation. It seems that an absence of malintent in language is no longer sufficient defense. If one perceives the language as offensive, it is. This is an absurd standard because with a sufficient audience size, someone will find something offensive. This standard is a de facto end to all discussion. It only takes one hyper sensitive audience member (legitimate or troll) to shut down all discussion.\n\n## Comment ID hvlt8hk with +9 score by [(cyborgsnowflake, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvlt8hk/) (in reply to ID skjjvm):\nModels are simply profanity detectors and will never rise above this (at least while remaining truly objective) because the concept of toxicity for better or worse has been thoroughly politicized and in the eye of the beholder and one person's hate speech/toxicity is another person's brave iconoclasm. And the concept is used more to push agendas than to truly create a welcome open atmosphere for all.\n\nCase in point. Racism used to mean simply judging or discriminating by race but now a new definition is coming into vogue where it is or isn't racism to do all the exact same things for or against different groups depending on what supposedly happened to them in the past as if there is some giant metaphysical scoreboard we need to keep track of.  You can see how hard it would be to adjust models to these moving targets.\n\n### Comment ID hvoiko9 with +1 score by [(petrik_coffy, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvoiko9/) (in reply to ID hvlt8hk):\nyour case in point is rather bad.\n\na naïve definition of 'racism', a second fictional definition that implies people 'play racism' for fun (do you think anybody enjoys to confront what's ugly and hurtful in life?) followed up by implied historical revisionism...\n\nthe argument you're trying to make isn't helped by your ideology laden 'think piece'.\n\nfurther there is no such thing as 'truly objective' since the values (and language itself, for all that matters) of a given society are ever changing.\njust like there is no single universal truth.\nthinking otherwise uncaredly opens the gates to history's darkest places.\n\n#### Comment ID hvshjoa with +2 score by [(cyborgsnowflake, Reddit, 2022-02-06)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvshjoa/) (in reply to ID hvoiko9):\nTheres entire communities centered around canceling people for unpc think. Theres multibillion dollar industries, departments, professorships, initiatives in the public and private sector dedicated to combating their definition of 'toxicity/racism' and judging by the groups around places including on reddit and contemporary media coverage its one of the most popular topics and tons and tons of people think about it all day long some even getting paid for it as a profession. Yeah I think some people find playing the antitoxicity/racism, or at least a specific definition of antitoxicity/racism. crusader fun.\n\n### Comment ID hvmny99 with +1 score by [(Echolocomotion, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmny99/) (in reply to ID hvlt8hk):\nThis is an influence, but models often struggle to hit even fixed targets for sentiment analysis.\n\n## Comment ID hvo2nsa with +2 score by [(None, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvo2nsa/) (in reply to ID skjjvm):\nWithin the context of humans who don’t know each other speaking in public it is actually toxic. Online, you could say get your kids off the internet or something, but I don’t see the benefit. So many sentences have been said in public without a single “fuck yeah” and nothing was lost. Online, the polarization is desirable to get engagement up. But I have no interest in redefining what’s toxic in the real world to help slide into the trend of polarizing people to the point profanity is needed for emphasis; just to the brink and not over to the side where the platform is getting sued or losing advertisers.\n\nReal life conversations are boring:\n\n“We just saw the show Cats and loved it!”\n——->”I just took my cousin and he thought it was hilarious how the cats were singing”\n\nMost engaged post online:\n“If loving a musical like cats makes you gay, then bring on the dicks!”\n——->”I’m going to tag some people that like sucking dicks.”\n\nI say just leave the posts boring, filter out shit that would offend humans in real life, and if I get bored I will go outside and bounce a ball up and down. And if my Facebook stock becomes worth less, who cares. Made up, been around since 2004ish. People have been practicing not saying “Oh fuck, that’s badass,” or the equivalent, as loud as possible while at work or grocery shopping for like a cool 4,000 years probably.\n\n### Comment ID hvogbp3 with +3 score by [(petrik_coffy, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvogbp3/) (in reply to ID hvo2nsa):\n> Real life conversations are boring  \n\nmileage may vary\n\n#### Comment ID hvp8oma with +2 score by [(None, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvp8oma/) (in reply to ID hvogbp3):\nOnes you didn’t choose to be in are pretty boring.\n\n## Comment ID hvmm2b9 with +1 score by [(cdsmith, Reddit, 2022-02-04)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmm2b9/) (in reply to ID skjjvm):\nHonestly, my brain also classifies a lot of their examples as toxic.  I mean, I see that the statements are superficially positive, but they are definitely very aggressive, conveying the clear message that you'd better just walk the other way if you feel any differently, because this person doesn't want to be bothered.  So I'd walk away from anyone I encounter talking that way.  I guess that means I lack the \"language skills and context to produce accurate data\".\n\nUltimately, what this comes down to is that this is a problem without a clear right answer.  What is \"toxic\" really?  Can you ever really write down a definition that is independent of the community it's used in?  Probably not.\n\n### Comment ID hvmtq7k with +10 score by [(visarga, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvmtq7k/) (in reply to ID hvmm2b9):\n> What is \"toxic\" really?\n\nA personal judgement. Remove the bubble and improve the user customization. Let everyone rule on their own feeds. But no, what people want is not to have control over their own sources, it's to control what other people can see, to guide society towards their ideal. Can't trust others are going to use their freedom to make the \"right\" choices, they need to be helped.\n\n\n\n## Comment ID hvnvtlz with +1 score by [(iamfab69, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvnvtlz/) (in reply to ID skjjvm):\nneat\n\n## Comment ID hvo4zpw with +1 score by [(Gmroo, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvo4zpw/) (in reply to ID skjjvm):\nWell, it IS profanity. It's also positive. :)\n\n## Comment ID hvod02h with +1 score by [(GlueR, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvod02h/) (in reply to ID skjjvm):\nThis why there's such a push for Explainable AI, especially when used in medical research. This should be adopted horizontally.\n\n## Comment ID hvohapd with +1 score by [(None, Reddit, 2022-02-05)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvohapd/) (in reply to ID skjjvm):\nLol when did we start calling side characters “star”?\n\n## Comment ID hvt736q with +1 score by [(SuchOccasion457, Reddit, 2022-02-06)](https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/hvt736q/) (in reply to ID skjjvm):\nIts also bizzarly easy to manipulate such systems. E.g. have a look at [https://arxiv.org/abs/2106.09898](https://arxiv.org/abs/2106.09898) , simple unicode tricks break them."
    ],
    "sources": {
      "steam_url": null,
      "steam_reviews": null,
      "google_play_url": null,
      "google_play_reviews": null,
      "apple_store_url": null,
      "apple_reviews": null,
      "reddit_urls": [
        "https://www.reddit.com/r/mturk/comments/14gyqeg/ai_is_a_lot_of_work_rather_relevant_longform/",
        "https://www.reddit.com/r/slatestarcodex/comments/zryl3i/evaluating_chatgpt_vs_google_on_500_search_queries/",
        "https://www.reddit.com/r/MachineLearning/comments/skjjvm/holy_t_are_popular_toxicity_models_simply/"
      ],
      "reddit_search_url": "https://www.google.com/search?q=site%3Areddit.com+%22Surge+AI%22+related%3Asurgehq.ai+"
    }
  },
  "glassdoor_result": null,
  "news_result": [
    [
      "Surge AI",
      "Surge AI",
      "surgehq.ai",
      null,
      false,
      false,
      null,
      [
        false,
        false
      ]
    ],
    [
      {
        "title": "Surge AI - Products, Competitors, Financials, Employees ...",
        "link": "https://www.cbinsights.com/company/surge-ai",
        "snippet": "Apr 12, 2024 ... Surge AI specializes in data labeling and reinforcement learning with human feedback (RLHF). The company offers a platform that provides quality human data.",
        "formattedUrl": "https://www.cbinsights.com/company/surge-ai"
      },
      {
        "title": "Ask HN: Who is hiring? (June 2024) | Hacker News",
        "link": "https://news.ycombinator.com/item?id=40563283",
        "snippet": "Jun 21, 2024 ... For example, using our image-based generative AI technology, we designed a ... Surge AI (https://surgehq.ai) | Software Engineers (full-stack, backend ...",
        "formattedUrl": "https://news.ycombinator.com/item?id=40563283"
      },
      {
        "title": "All New York City jobs from Hacker News 'Who is hiring? (March ...",
        "link": "https://hnhiring.com/locations/nyc",
        "snippet": "Mar 15, 2025 ... Our AI matches users to groups for the experiences based on ... Surge AI (https://surgehq.ai/careers) | Software Engineers (full-stack ...",
        "formattedUrl": "https://hnhiring.com/locations/nyc"
      },
      {
        "title": "How Ready Are Generative Pre-trained Large Language Models for ...",
        "link": "https://educationaldatamining.org/edm2024/proceedings/2024.EDM-posters.70/2024.EDM-posters.70.pdf",
        "snippet": "Jul 13, 2024 ... 1Surge AI: https://www.surgehq.ai/faq. 2We use Surge AI as our data annotation platform. ... news outlets and community-driven pages. Specifically, the ...",
        "formattedUrl": "https://educationaldatamining.org/edm2024/.../2024.EDM-posters.70.pdf"
      },
      {
        "title": "All San Francisco jobs from Hacker News 'Who is hiring? (March ...",
        "link": "https://hnhiring.com/locations/sf",
        "snippet": "Mar 14, 2025 ... ... based care standards, we enable health plans to ensure that every ... Surge AI (https://surgehq.ai/careers) | Software Engineers (full-stack ...",
        "formattedUrl": "https://hnhiring.com/locations/sf"
      },
      {
        "title": "How Ready Are Generative Pre-trained Large Language Models for ...",
        "link": "https://arxiv.org/pdf/2406.00039",
        "snippet": "Jun 2, 2024 ... 1Surge AI: https://www.surgehq.ai/faq. 2We use Surge AI as our data annotation platform. ... news outlets and community-driven pages. Specifically, the ...",
        "formattedUrl": "https://arxiv.org/pdf/2406.00039"
      },
      {
        "title": "Current LLM evaluations do not sufficiently measure all we need - AI ...",
        "link": "https://aisingapore.org/ai-governance/current-llm-evaluations-do-not-sufficiently-measure-all-we-need/",
        "snippet": "Aug 6, 2024 ... ... related to those being evaluated using MMLU & HellaSwag. Convergent ... Surge AI. Retrieved July 8, 2024, from https://www.surgehq.ai/blog/hellaswag ...",
        "formattedUrl": "https://aisingapore.org/.../current-llm-evaluations-do-not-sufficiently-measu..."
      },
      {
        "title": "Missci: Reconstructing Fallacies in Misrepresented Science",
        "link": "https://arxiv.org/html/2406.03181v1",
        "snippet": "Jun 5, 2024 ... students, one in biology and one in linguistics, were employed during annotation. The annotators received a pay of 12.26 EUR per hour. We used Surge AI 2 ...",
        "formattedUrl": "https://arxiv.org/html/2406.03181v1"
      },
      {
        "title": "MISSCI: Reconstructing Fallacies in Misrepresented Science",
        "link": "https://aclanthology.org/2024.acl-long.240.pdf",
        "snippet": "Aug 11, 2024 ... Figure 7: Claim annotation interface from Surge AI. Claim Rewriting. Fact-checking articles might discuss multiple related claims or complex argu-. 8https ...",
        "formattedUrl": "https://aclanthology.org/2024.acl-long.240.pdf"
      },
      {
        "title": "A Systematic Review of Toxicity in Large Language Models: De ...",
        "link": "https://www.researchsquare.com/article/rs-4621646/v1.pdf",
        "snippet": "Jul 15, 2024 ... Toloka crowdsource7, and Surge AI8 [D3, D5, D10, D11, D12, D13, D15, D16 ... 8Surge AI, https://www.surgehq.ai/ [accessed on June 6th, 2024]. 21. Page 23 ...",
        "formattedUrl": "https://www.researchsquare.com/article/rs-4621646/v1.pdf"
      },
      {
        "title": "arXiv:2408.12812v2 [cs.CL] 7 Feb 2025",
        "link": "https://www.arxiv.org/pdf/2408.12812",
        "snippet": "Feb 7, 2025 ... 5https://www.surgehq.ai/. 17. Page 18. Study supports. Claim ... Figure 7: Annotation Interface from Surge AI to assign the entailment labels between the a ...",
        "formattedUrl": "https://www.arxiv.org/pdf/2408.12812"
      },
      {
        "title": "Who's Hiring?",
        "link": "https://whoshiring.xyz/",
        "snippet": "Mar 17, 2025 ... amauboussin 4:42:54 pm on March 3rd 2025. Surge AI (https://surgehq.ai ... ai/careers?utm_source=hacker-news. andrewksl 7:11:18 pm on March 3rd 2025. Pitstop ...",
        "formattedUrl": "https://whoshiring.xyz/"
      }
    ],
    [
      "# [Products, Competitors, Financials, Employees, Headquarters Locations](https://www.cbinsights.com/company/surge-ai)\nNow hiring: Part-time AI chatbot tutors, no experience necessary\n\nWe’re sorry, this feature is currently unavailable. We’re working to restore it. Please try again later. Dismiss By Yiwen Lu Save articles for later Got it Advertisement After her second child was born, Chelsea Becker took an unpaid, year of leave from her full-time job as a flight attendant. After watching a video on TikTok, she found a side hustle: training artificial intelligence models for a website called Data Annotation Tech. For a few hours each day, Becker, 33, who lives in Schwenksville, Pennsylvania, would sit at her laptop and interact with an AI-powered chatbot. For every hour of work, she was paid $20 to $40. From December to March, she made more than $10,000. Chelsea Becker, who started training chatbots from home after taking an unpaid leave from her flight attendant job when her daughter was born, at home with her children in Schwenksville, Pa. Credit: New York Times The boom in AI technology has put a more sophisticated spin on a kind of gig work that doesn’t require leaving the house. The growth of large language models such as the technology powering OpenAI’s ChatGPT has fuelled the need for trainers like Becker, fluent English speakers who can produce quality writing. It is not a secret that AI models learn from humans. For years, makers of AI systems such as Google and OpenAI have relied on low-paid workers, typically contractors employed through other companies, to help computers visually identify subjects. They might label vehicles and pedestrians for self-driving cars or identify images on photos used to train AI systems. But as AI technology has become more sophisticated, so has the job of people who must painstakingly teach it. Yesterday’s photo tagger is today’s essay writer. There are usually two types of work for these trainers: supervised learning, where the AI learns from human-generated writing, and reinforcement learning from human feedback, where the chatbot learns from how humans rate their responses. It’s fundamentally not a good idea to outsource or crowdsource concerns about safety and ethics. James Muldoon, University of Essex management professor Companies that specialise in data curation, including the San Francisco-based startups Scale AI and Surge AI, hire contractors and sell their training data to bigger developers. Developers of AI models, such as the Toronto-based startup Cohere, also recruit in-house data annotators. It is difficult to estimate the total number of these gig workers, researchers said. But Scale AI, which hires contractors through its subsidiaries, Remotasks and Outlier, said it was common to see tens of thousands of people working on the platform at a given time. Advertisement But as with other types of gig work, the ease of flexible hours comes with its own challenges. Some workers said they never interacted with administrators behind the recruitment sites, and others had been cut off from the work with no explanation. Researchers have also raised concerns over a lack of standards, since workers typically don’t receive training on what are considered to be appropriate chatbot answers. Loading To become one of these contractors, workers have to pass an assessment, which includes questions such as whether a social media post should be considered hateful, and why. Another one requires a more creative approach, asking contracting prospects to write a fictional short story about a green dancing octopus, set in Sam Bankman-Fried’s FTX offices on November 8, 2022. (That was the day Binance, an FTX competitor, said it would buy Bankman-Fried’s company before later quickly backing out of the deal.) Sometimes, companies look for subject-matter experts. Scale AI has posted jobs for contract writers who hold master’s or doctoral degrees in Hindi and Japanese. Outlier has job listings that mention requirements including academic degrees in math, chemistry and physics. “What really makes the AI useful to its users is the human layer of data, and that really needs to be done by smart humans and skilled humans and humans with a particular degree of expertise and a creative bent,” said Willow Primack, vice president of data operations at Scale AI. “We have been focusing on contractors, particularly within North America, as a result.” Alynzia Fenske, a self-published fiction writer, had never interacted with an AI chatbot before hearing a lot from fellow writers who considered AI a threat. So when she came across a video on TikTok about Data Annotation Tech, part of her motivation was to learn as much about AI as she could and see for herself whether the fears surrounding AI were warranted. As AI technology has become more sophisticated, so has the job of people who must painstakingly teach it Credit: iStock “It’s giving me a whole different view of it now that I’ve been working with it,” said Fenske, 28, who lives in Oakley, Wisconsin. “It is comforting knowing that there are human beings behind it.” Since February, she has been aiming for 15 hours of data annotation work every week, so she can support herself while pursuing a writing career. Ese Agboh, 28, a master’s student studying computer science at the University of Arkansas, was given the task of coding projects, which paid $40 to $45 an hour. She would ask the chatbot to design a motion sensor program that helps gym goers count their repetitions, and then evaluate computer codes written by AI. In another case, she would load a data set about grocery items to the program and ask the chatbot to design a monthly budget. Sometimes she would even evaluate other annotators’ codes, which experts said are used to ensure data quality. She made $2500. But her account was permanently suspended by the platform for violating its code of conduct. She did not receive an explanation, but she suspected that it was because she worked while in Nigeria, since the site wanted workers based in only certain countries. Loading That is the fundamental challenge of online gig work: it can disappear at any time. With no one available for help, frustrated contractors turned to social media, sharing their experiences on Reddit and TikTok. Jackie Mitchell, 26, gained a large following on TikTok because of her content on side hustles, including data annotation work. “I get the appeal,” she said, referring to side hustles as an “unfortunate necessity” in this economy and “a hallmark of my generation and the generation above me.” Public records show that Surge AI owns Data Annotation Tech. Neither the company nor its CEO, Edwin Chen, responded to requests for comments. It is common for companies to hire contractors through subsidiaries. They do so to protect the identity of their customers, and it helps them avoid bad press associated with working conditions for its low-paid contract workers, said James Muldoon, a University of Essex management professor whose research focuses on AI data work. Much of today’s data workers depend on wages from their gig work. Milagros Miceli, a sociologist and computer scientist researching labor conditions in data work, said that while “a lot of people are doing this for fun, because of the gamification that comes with it,” a bulk of the work is still “done by workers who actually really need the money and do this as a main income.” Researchers are also concerned about the lack of safety standards in data labelling. Workers are sometimes asked to address sensitive issues such as whether certain events or acts should be considered genocide or what gender should appear in an AI-generated image of a soccer team, but they are not trained on how to make that evaluation. “It’s fundamentally not a good idea to outsource or crowdsource concerns about safety and ethics,” Muldoon said. “You need to be guided by principles and values, and what your company actually decides as the right thing to do on a particular issue.”",
      "# [Ask HN: Who is hiring? (June 2024)](https://news.ycombinator.com/item?id=40563283)\n",
      "# [Current LLM evaluations do not sufficiently measure all we need on 2024-08-06](https://aisingapore.org/ai-governance/current-llm-evaluations-do-not-sufficiently-measure-all-we-need/)\nWritten By:\n\nTristan Koh Ly Wey\n\nResearch Assistant, AI Singapore\n\nEvaluating Large Language Models (LLMs) presents a complex challenge. Although evaluations provide metrics that seem to objectively measure LLM performance, these figures often do not always effectively capture their nuanced behaviours in real-world applications. Therefore, evaluations, while useful, are not absolute and require careful interpretation. The following will be addressed: (a) Why are LLM evaluations important? (b) What are some existing issues with current evaluation approaches? (c) What are the impacts of imperfect evaluations on the generative AI (genAI) ecosystem? and (d) What can be done about it?\n\nImportance of LLM evaluations\n\nAt first glance, LLMs seem impressive. LLMs are able to generate creative human-like text, images and video using simple, open-ended input in natural language across multiple domains, tasks and contexts. Nevertheless, beyond anecdotal first impressions, how can LLMs’ capabilities be objectively and rigorously measured?\n\nEvaluations are designed to meet such a need. Evaluations are methodologies and functions to evaluate a system-under-test (i.e. LLM) for a particular purpose and interpret the results. It consists of (a) a set of tests with metrics, and (b) a summarisation of the tests using the metrics (MLCommons, 2024). Evaluations attempt to measure performance of LLMs on varying tasks such as reasoning, coding, knowledge retrieval etc. Further, measuring LLM safety concerns such as toxicity or “dual-use capabilities” (Barrett et al., 2024) are of increasing importance. Through testing specific LLM capabilities, evaluations also serve multiple broader purposes within the genAI ecosystem. These include marketing (e.g. GPT-4o mini has “superior textual intelligence and multimodal reasoning” (OpenAI, 2024)), regulatory compliance such as under the EU AI Act, assessing use-case suitability by app developers and consumers, and as an indicator of improvement of model inference capabilities (Hoffmann et al., 2022).\n\nLLM evaluation can be thought of as similar to traditional software testing which aims to measure system behaviour that produce metrics that are reproducible, generalisable across different contexts, consistent over time and objective (McIntosh et al., 2024). However, unlike traditional software testing, LLM evaluations are especially challenging as LLMs are black boxes and their outputs are probabilistic. Errors cannot be traced back to a specific part of the code and system characteristics can only be generalised through repeated multiple testing of prompts for a particular task at scale rather than only through anecdotal examples.\n\nMeasurement theory & issues with evaluations\n\nMeasurement theory concerns the conditions under which mathematical objects (including numbers) can be used to represent the properties of objects. These representations can then be used to express relationships between these objects (Tal, 2020). Measurement theory provides a suitable theoretical framework to assess evaluations because evaluations use numbers to claim certain kinds of relations between different LLMs (i.e. GPT-4o is more capable at reasoning than Claude 3.5). A good measurement has to be reliable and valid. Reliability is often synonymous with terms such as consistency, stability, and predictability. Validity is usually synonymous with truthfulness, accuracy, authenticity and soundness. A good measurement can be reliable but invalid, but not the converse. In other words, reliability is a necessary but insufficient condition for validity (Hubley & Zumbo, 1996).\n\nFigure 1: Reliability vs validity (Trochim, n.d.)\n\nWhen evaluations are reliable and valid, these evaluations can be useful predictors of future performance on similar tasks. However, as explained below, LLM evaluations have various reliability and validity issues that undermine their robustness.\n\nReliability\n\nFirst, LLM evaluations have low internal consistency reliability. This type of reliability assesses consistency between different evaluations that purport to measure the same construct (Hubley & Zumbo, 1996). Some examples that demonstrate low internal consistency reliability are provided below:\n\nMaking spurious correlations during in-context learning: Adding various spurious triggers in prompts used for in-context learning such as random characters (e.g. # / *) & rare words (e.g. solipsism, serendipity) at varying positions led to an average performance drop of 33.7% on GPT-2 (amongst other tested models) on sentiment analysis tasks (Tang et al., 2023). The performance drop also increased with increasing model size.\n\nFormatting: Changing the ordering, numbering format (e.g. from (A) to (1)), quantity of options and adding a “none of the above” option for MCQ-style evaluations results in a significant performance decrease for each of these formatting changes (Wang et al., 2024; Ganguli et al., 2023).\n\nPhrasing of prompts: Rephrasing responses to other questions that still test the same construct results in great variations in performance. For instance, each option for each MCQ was converted into true / false statements, generating three questions with the correct answer as “false”, and one question with the correct answer as “true”. While there was a high consistency (up to 91%) between the responses for the latter questions and the responses from the original MCQ format, there was low consistency (only 51%) between the responses for the former questions because the answers were wrongly predicted as “true” (Wang et al., 2024). In other words, while the model could correctly select the one true option out of three other false options when the question was phrased as a MCQ, the model failed to identify that the other three options were explicitly “false” when the question was phrased as true/false questions.\n\nOverfitting & predictive validity\n\nSecond, models may be overfitting to popular evaluations because most of such evaluations like MMLU (Massive Multitask Language Understanding) and HellaSwag are open-sourced and are likely included in the training data. This contravenes a principle of machine learning: the model’s capabilities should be tested with an out-of-distribution dataset to assess whether the model is able to generalise beyond its training data. The prevailing data science practice separates datasets into train, validation & test sets. The test set is not seen by the model during training and used after the model’s parameters have been optimised on the validation set to provide an unbiased indicator of model performance (Baheti, 2021). However, when answers are included in training data, the evaluation is no longer an out-of-distribution dataset and does not provide an unbiased indicator of model performance. Overfitting thus causes the evaluation to have reduced predictive validity because the evaluation is now not measuring the LLM’s capability to generalise well to unseen data distributions.\n\nConstruct validity\n\nThird, evaluations may not actually be measuring the intended construct (construct validity). As LLMs are black-boxes, though they may return high scores on popular evaluations, these responses may be an imitation of capability (i.e. “stochastic parrots”) rather than a reflection of the models’ actual capabilities. There is no easy or established method to discern the former from the latter. Evaluations may be measuring other irrelevant constructs rather than what was intended.\n\nFor example, chain-of-thought (CoT) prompting is frequently used to increase performance on evaluations. Step-by-step explanations generated by the model could be seen as a demonstration of the model’s underlying reasoning capabilities. However, these explanations can be convincing, but unfaithful to the LLMs’ underlying reasoning when using certain biasing features in the CoT prompts. For instance, when all the answers to the examples used to pre-prompt the model were provided as (A), the model similarly generated CoT explanations that justified (A) as the correct option even though (A) was incorrect without explicitly stating that it was, in fact, the biaising features that caused the LLM to choose (A) as the answer (Turpin et al., 2023). Therefore, when CoT is used in evaluations, though CoT produces higher scores, the model was unlikely to have been exhibiting underlying reasoning capability through use of CoT. Rather, CoT seems more likely to produce explanations based on irrelevant statistical correlations in the CoT prompts.\n\nTypical scoring methods may also lack construct validity. Responses are usually aggregated by predefined metrics to summarise the model performance for that particular evaluation. Typical metrics used in machine learning include RMSE / R-squared (for regression models) or precision / recall / F1 (for classification models). The prevailing convention in LLM evaluation restricts the output of the models to a MCQ format, allowing conventional P/R/F1 scores to be used. “The critical weakness is whether the metric actually reliably tracks the property of interest, not the rigour with which the metric is evaluated” (Olah & Jermyn, 2024). Using such restricted metrics may risk reducing high-dimensional concepts such as creativity, coherence or reasoning into a single number.\n\nConvergent validity\n\nFourth, popular benchmarks such as MMLU & HellaSwag seem to have poor convergent validity with other evaluations that aim to evaluate reasoning constructs closely related to those being evaluated using MMLU & HellaSwag.\n\nConvergent validity refers to how well the scores of a test converge with other constructs based on what would be expected from theory (Shou, Sellbom & Chen, 2022). Convergent validity is also used as evidence to demonstrate high construct validity. For instance, depression is theoretically closely linked to anxiety. To demonstrate that a measure for depression has high construct validity, an established measure for anxiety can be used to show correlation between the scores of the different measures (Hubley, 2014).\n\nA simple reasoning problem was formulated called AIW (Alice-In-Wonderland): “Alice has X brothers and Y sisters. How many sisters does Alice’s brother have?” [where X and Y are integers varied across prompts] (Nezhurina et al., 2024). There was a high discrepancy discovered between models’ performance on popular evaluations (i.e. MMLU, HellaSwag) and AIW. While the latest and biggest models (GPT-4o, Claude 3 Opus, GPT-4) performed consistently well on these popular evaluations (85% and above), on AIW, only these latest and biggest models scored around 40% and more, with the highest, GPT-4o scoring only 65%. AIW, MMLU & HellaSwag all purport to measure various related constructs of reasoning capabilities. Though AIW is not an established measure for reasoning, AIW’s problem is intuitively straightforward to solve. Hence, the high discrepancy between scores on AIW and MMLU raises concerns about the potential lack of construct validity of MMLU & HellaSwag.\n\nExternal validity\n\nLast, even if there is construct validity, external validity may be an issue as evaluation results may not be generalisable. The most common use-cases for such models are on downstream chatbot applications such as drafting text across different disciplines, asking for advice, and explanation of concepts that take place over multi-turn conversations which require more creative output (Wiggers, 2024). Though capability to conduct natural, factual and helpful conversations to generate varying textual outputs undoubtedly requires competency in knowledge, reasoning and inference as measured by existing popular evaluations, measuring these characteristics in isolation through MCQ format does not necessarily relate to competency in downstream applications. App developers also consider more than raw performance metrics when integrating foundation models into software. Some considerations include a balance between costs, type (e.g. multimodal, text, multi language etc.), and latency of generation (Spisak et al., 2024) which are not usually assessed as part of existing evaluations.\n\nImpact on the genAI ecosystem\n\nCombined with the necessity of evaluations to achieve essential broader societal objectives, these issues with LLM evaluations have wide-ranging downstream impact. For instance, some financial experts note that genAI are not “designed to solve the complex problems that would justify the costs [of investment]” and predict that the genAI hype bubble may be about to burst (Goldman Sachs, 2024). Whether genAI indeed has such capability or is merely hype depends, amongst other things, on reliable and valid evaluations.\n\nEvaluations also risk being viewed as ends for model development in themselves rather than merely fallible means of measuring broader, abstract concepts. One well-examined instance of this phenomenon outside AI is how IQ tests became relied upon as a determinate predictor of future educational performance rather than how they were originally designed – to be merely a measure of current cognitive abilities, used to curate appropriate educational aids and tutoring for the child (van Hoogdalem & Bosman, 2023). Muller 2020 terms this as “metric fixation”. A similar phenomenon could arise for the stakeholders in the genAI ecosystem.\n\nModel developers and regulators (e.g. OpenAI, EU AI Office etc.): An assumption is that abstract concepts such as intelligence, understanding or safety can always be fully measured through evaluations. Over reliance on the current state of evaluations by these major stakeholders have a strong normative effect on model development because of metric fixation that result in the development of model capabilities which may not be generalisable to real-life needs and risks.\n\nApp deployers: Due to lack of generalisability of evaluations, product-market fit may be affected and app deployers cannot rely on evaluations to select the right product and design appropriate safety mitigations for their specific use-case.\n\nMinority actors: Issues with external validity due to regulatory capture may be a natural consequence when major actors control the design of evaluations. For example, if the external validity of evaluations for bias is limited to the concerns of predominantly white, Western and economically and socially privileged demographics (Bergman et al., 2023), model capabilities would be focused on developing culturally narrow model capabilities at the expense of representation from minority demographics.\n\nWhat’s next: Possible solutions\n\nExisting “quick fixes” can be instituted to improve reliability and validity. For instance, qualitative human review of a subset of prompts & model responses instead of relying on a single metric may improve reliability. Some evaluation suites also implement various types of irrelevant perturbations to design “adversarial” prompts which still aim to measure the same construct. Such perturbations change tokens but maintain semantic, reasoning and answer invariance which would increase internal consistency reliability (Li et al., 2024). To increase predictive validity, evaluations should not be entirely open-sourced to avoid overfitting. Instead, a hold-out validation set should be kept closed-sourced. Formalising these quick fixes as standardised protocols can improve reliability and predictive validity.\n\nHowever, evaluations can be reliable but still invalid. To substantially improve validity in light of the multifaceted nature of evaluations, evaluations should shift away from the current paradigm of testing. Some have proposed to adapt methodology used for testing human capability within cognitive sciences to test LLMs (Burden, 2024; Zhuang et al., 2023). Cognitive science actively grapples with the measurement of human intelligence as an abstract, social construct. For instance, psychometric testing has designed tests with standardised test protocols that allow the comparison of an individual’s performance with an appropriate comparison group across varying purposes such as cognitive impairment or functional capacity for everyday tasks. Test scores have to be interpreted and applied differently depending on the specific purpose and context (Institute of Medicine, 2015). In this spirit, the MLCommons LLM evaluation test specification schema (MLCommons, 2024) tries to achieve such clarity in the design of evaluations, though more can be done to learn and adapt from such existing experimental controls identified in cognitive science.\n\nIn the same vein, instead of considering evaluations as akin to comparing the speed & acceleration of simple technical objects such as cars, a more suitable comparison could be with the mature fields of sovereign credit ratings, university rankings or cognitive science. While each of these fields aim to achieve objective measurement of their respective systems, these measurements have faced similar problems. Sovereign credit ratings have been criticised for their failure to anticipate financial crises (external validity) (Haspolat, 2015). University rankings have similarly been critiqued for their inability to measure educational quality as educational experience cannot be reduced to a simple ranking (construct validity). Some universities have reallocated resources to improve their ranking at the expense of quality research and teaching (metric fixation) (Robinson, 2014).\n\nLLMs should be evaluated as sociotechnical systems, rather than merely technical objects like conventional software. Sociotechnical systems are a configuration of technologies, services and infrastructures, regulations and actors that fulfil a societal function (Schot et al., 2016). The interaction between the social and technical components determine the risks that manifest (Weidinger et al., 2023). As finance and education are sociotechnical systems, the evaluation of credit risks is not a simple application of financial forecasting models and the assessment of educational quality cannot be fully captured by university rankings. Similarly, evaluations aim to measure capabilities with existing societal meanings such as intelligence, reasoning, toxicity, and bias. GenAI is more than just technology, but includes services, infrastructures and regulators. Accordingly, typical software testing approaches may no longer apply. LLM evaluations should eventually move towards socio-technical methods such that LLM evaluations can sufficiently measure all that we need.",
      "# [Missci: Reconstructing Fallacies in Misrepresented Science](https://arxiv.org/html/2406.03181v1)\nMax Glockner♣, Yufang Hou♢♣, Preslav Nakov♠ Iryna Gurevych♣\n\n♣Ubiquitous Knowledge Processing Lab (UKP Lab),\n\nTU Darmstadt and Hessian Center for AI (hessian.AI)\n\n♢IBM Research, Ireland, ♠MBZUAI\n\nwww.ukp.tu-darmstadt.de\n\nAbstract\n\nHealth-related misinformation on social networks can lead to poor decision-making and real-world dangers. Such misinformation often misrepresents scientific publications and cites them as “proof” to gain perceived credibility. To effectively counter such claims automatically, a system must explain how the claim was falsely derived from the cited publication. Current methods for automated fact-checking or fallacy detection neglect to assess the (mis)used evidence in relation to misinformation claims, which is required to detect the mismatch between them. To address this gap, we introduce Missci, a novel argumentation theoretical model for fallacious reasoning together with a new dataset for real-world misinformation detection that misrepresents biomedical publications. Unlike previous fallacy detection datasets, Missci (i) focuses on implicit fallacies between the relevant content of the cited publication and the inaccurate claim, and (ii) requires models to verbalize the fallacious reasoning in addition to classifying it. We present Missci as a dataset to test the critical reasoning abilities of large language models (LLMs), which are required to reconstruct real-world fallacious arguments, in a zero-shot setting. We evaluate two representative LLMs and the impact of providing different levels of detail about the fallacy classes to the LLMs via prompts. Our experiments and human evaluation show promising results for GPT 4, while also demonstrating the difficulty of this task.\n\n1 Introduction\n\nFalse or misleading narratives spread rapidly on social media (Vosoughi et al., 2018; Wardle, 2018), posing challenges for non-experts in discerning credible information, and exceeding the capabilities of human fact-checkers (HFC). The need to support HFC has accelerated the research in automated fact-checking (AFC) and related tasks (Guo et al., 2022; Schlichtkrull et al., 2023a). Yet, the real-world applicability of AFC systems is limited due to the lack of trustworthiness (Nakov et al., 2021), or their reliance on counter-evidence, which may not exist (Glockner et al., 2022). Often, misinformation distorts genuine information rather than creating new content (Brennen et al., 2020). For example, the claim in Figure 1 that “hydroxychloroquine is a cure for COVID-19” contains a kernel of truth and relies on some content (referred to as accurate premise) of the cited study that found “chloroquine reduced infection of the coronavirus.” However, further content from the study shows that it did not conduct human experiments (s1subscript𝑠1s_{1}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT) and focused on SARS-CoV-1 (s2subscript𝑠2s_{2}italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT), different from the virus causing COVID-19. Only when knowing this additional information (s1subscript𝑠1s_{1}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and s2subscript𝑠2s_{2}italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) about the cited study, one can detect the applied fallacies (Fallacy of Composition and False Equivalence).\n\nIn this work, we focus on inaccurate claims that misrepresent scientific publications. We assume that the misrepresented publication is presented alongside the claim as a “proof” amplifying the claim’s impact through increased perceived credibility. With this assumption, we can access the cited sources, which is essential for detecting fallacious reasoning and implements human verification strategies (Silverman, 2014). Our goal is to automatically outline the fallacious reasoning and explain why the claim is incorrect, a crucial aspect of debunking misinformation (Schmid and Betsch, 2019; Lewandowsky et al., 2020).\n\nEarlier work on fallacy detection focused on surface-level fallacies like Ad Hominem or Loaded Language. More recent work (Jin et al., 2022; Alhindi et al., 2022) also included logical fallacies like False Cause or Hasty Generalization. Yet, they did not adapt the task definition to account for the fact that these fallacies may need information beyond what is explicitly stated in the text. This hinders their applicability to real-world fallacies that rely on external information. To bridge this gap, we introduce Missci, a new argumentation theoretical model for fallacious reasoning, accompanied by a new fallacy detection dataset derived from real-world misinformation. Unlike prior work, we (i) treat inaccurate claims as the conclusion of a logical argument, encompassing all necessary information to detect the applied fallacies (green in Figure 1). We (ii) formulate a distinct fallacy inventory drawn from literature to express fallacies when misrepresenting scientific publications. Finally, inspired by Cook et al. (2018), we (iii) explicitly verbalize the fallacious reasoning via premises (orange) that only implicitly exist based on the claim to reconstruct the fallacious argument.\n\nOur focus lies on the reasoning abilities to reconstruct fallacious arguments, and we manually paraphrase the relevant publication content (green) based on HFC articles, rather than using the original misrepresented document. Motivated by recent progress in zero-shot performance of large language models (LLMs) (Kojima et al., 2022), we evaluate the reasoning abilities of two state-of-the-art LLMs in reconstructing the fallacious reasoning on Missci and define the task in a zero-shot setup, exemplified in Figure 1. Given the claim, an accurate premise, and the publication contexts, the model must verbalize the fallacious reasoning and assign fallacy classes. Our contributions are:\n\n•\n\nA new argumentation theoretical model with a new task formulation to reconstruct the fallacious arguments.\n\n•\n\nA new dataset comprising complex fallacious arguments of real-world misinformation.\n\n•\n\nEvaluation of two state-of-the-art LLMs and their critical reasoning abilities to reconstruct fallacious arguments.\n\n2 Related Work\n\nPrevious work has focused on surface-level fallacies for propaganda detection (Da San Martino et al., 2019; Piskorski et al., 2023; Salman et al., 2023), for online discussions (Habernal et al., 2018a; Sahai et al., 2021), or for gamified settings (Habernal et al., 2017). The addressed fallacies typically do not require information beyond what is stated explicitly in the text. Other work targeted specific fallacies such as Non Sequitur in law (Nakpih and Santini, 2020) or Ad Hominem in social media (Habernal et al., 2018a). More similar to our work, some research (Jin et al., 2022; Musi et al., 2022; Alhindi et al., 2022) focused on logical fallacies from the real world. Yet, they neither verbalized the implicitly applied fallacies, nor considered the underlying sources beyond what is explicitly stated in the text. Moreover, our task design to generate fallacious premises differs from implicit premise detection work (Habernal et al., 2018b; Chakrabarty et al., 2021) in that the premises in Missci are inherently invalid and linked to applied fallacy classes (see p¯1subscript¯𝑝1\\overline{p}_{1}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and p¯2subscript¯𝑝2\\overline{p}_{2}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT in Figure 1; orange). Existing work on fallacy generation focused on data generation (Huang et al., 2023; Alhindi et al., 2023) rather than on articulating applied fallacious reasoning within real-world fallacious arguments.\n\nScientific AFC work (Wadden et al., 2020; Sarrouti et al., 2021; Wadden et al., 2022; Lu et al., 2023; Vladika and Matthes, 2023) considered external sources, like us, but did not identify and articulate the nuanced fallacies when concluding a claim from the cited study. Detecting distortions in scientific communication is part of science communication research (Augenstein, 2021), where studies have examined exaggerations in news articles (Sumner et al., 2014; Bratton et al., 2019; Yu et al., 2020; Wright and Augenstein, 2021), analyzed reporting certainty in scientific publications (Pei and Jurgens, 2021), or quantified information mismatches between reported and actual scientific findings (Wright et al., 2022). In parallel work, Wührl et al. (2024) quantify and compare the original paper with other reporting of their findings across fine-grained dimensions such as certainty or generalization. In addition to our distinct task setup, our problem space differs as we focus on harmful misinformation that comprises more severe distortions, which are not necessarily bound to a study’s main findings.\n\n3 Formalism of Missci\n\n3.1 Misrepresented Science Arguments\n\nInspired by Cook et al. (2018), we reconstruct the fallacious reasoning in the form of a logical argument. For an accurate claim c𝑐citalic_c, a logical argument would be structured as follows:\n\n{p0,p1,…,pN}⇒c⇒subscript𝑝0subscript𝑝1…subscript𝑝𝑁𝑐\\{p_{0}\\,,\\,p_{1}\\,,\\,\\ldots\\,,\\,p_{N}\\}\\Rightarrow c{ italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT } ⇒ italic_c (1)\n\nwhere P={p0,p1,…,pN}𝑃subscript𝑝0subscript𝑝1…subscript𝑝𝑁P=\\{p_{0},p_{1},\\ldots,p_{N}\\}italic_P = { italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT } is a set of accurate premises that jointly entail (⇒⇒\\Rightarrow⇒) the true claim c𝑐citalic_c. For inaccurate claims c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG, the entailment relation does not hold based on accurate premises, formulated as P⇏c¯⇏𝑃¯𝑐P\\not\\Rightarrow\\overline{c}italic_P ⇏ over¯ start_ARG italic_c end_ARG, where ⇏⇏\\not\\Rightarrow⇏ denotes a corrupted entailment relation. To reconstruct a fallacious argument, a set of inaccurate (fallacious) premises p¯i∈P¯subscript¯𝑝𝑖¯𝑃\\overline{p}_{i}\\in\\overline{P}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ over¯ start_ARG italic_P end_ARG must be applied such that P∪P¯⇒c¯⇒𝑃¯𝑃¯𝑐P\\cup\\overline{P}\\Rightarrow\\overline{c}italic_P ∪ over¯ start_ARG italic_P end_ARG ⇒ over¯ start_ARG italic_c end_ARG. For example, consider the following argument (simplified from Figure 2):\n\n•\n\nAccurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT: The viral COVID-19 spike protein inhibits repair of DNA damage.\n\n•\n\nFallacious premise p¯1,2subscript¯𝑝12\\overline{p}_{1,2}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT: COVID-19 vaccine spike proteins are as dangerous as viral COVID-19 spike proteins.\n\n•\n\nConclusion (c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG): Therefore, COVID-19 vaccines inhibit repair of DNA damage.\n\nHere, the accurate premise alone lacks sufficient support for the conclusion (or claim). Establishing a support relationship between the accurate premise and the conclusion requires the fallacious premise, which employs the False Equivalence fallacy. To debunk a claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG, the argument can be deconstructed by highlighting the fallacies applied in each p¯isubscript¯𝑝𝑖\\overline{p}_{i}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. This invalidates the premises that are necessary to establish the claim as a logical conclusion and renders the argument invalid.\n\nMisinformation that is falsely derived from a single credible publication S𝑆Sitalic_S can be formulated as S⇏c¯⇏𝑆¯𝑐S\\not\\Rightarrow\\overline{c}italic_S ⇏ over¯ start_ARG italic_c end_ARG. Each argument in Missci has exactly one accurate premise, P={p0}𝑃subscript𝑝0P=\\{p_{0}\\}italic_P = { italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT }, which is entailed by (parts of) S𝑆Sitalic_S and represents the “kernel of truth” behind the inaccurate claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG. Since all arguments in Missci constitute misinformation, each argument is illogical and contains at least one reasoning gap, which must be bridged via a fallacious premise p¯isubscript¯𝑝𝑖\\overline{p}_{i}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT that applies a fallacy class fisubscript𝑓𝑖f_{i}italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to support the claim. This reasoning gap only becomes imminent after observing relevant context (sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT) from the misrepresented publication S𝑆Sitalic_S. For example, consider Figure 2, where a study observed harm from SARS-CoV-2 spike proteins (accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT). The argument wrongly applied this finding to mRNA vaccines, assuming that viral and vaccine spike proteins behave identically (in both (alternative) fallacious premises). Without detailed content about the misrepresented publication (that it was observed on viral spike proteins in s1subscript𝑠1s_{1}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT), this fallacy is undetectable. In this work, we manually paraphrase this necessary context sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT that exhibits the reasoning gap from the publication S𝑆Sitalic_S where each sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is entailed by S𝑆Sitalic_S. Because the accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is always entailed by the publication, its publication context (s0subscript𝑠0s_{0}italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) is identical to the accurate premise. We represent each fallacious reasoning Ri∈Rsubscript𝑅𝑖𝑅R_{i}\\in Ritalic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_R that bridges one reasoning gap as a triplet Ri=subscript𝑅𝑖absentR_{i}=italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = (sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, p¯isubscript¯𝑝𝑖\\overline{p}_{i}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, fisubscript𝑓𝑖f_{i}italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT). To bridge all reasoning gaps and fully support the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG each fallacious reasoning Ri∈Rsubscript𝑅𝑖𝑅R_{i}\\in Ritalic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_R must be applied. The overall formulation of a fallacious argument 𝒜𝒜\\mathcal{A}caligraphic_A is shown below:\n\n{p0s0=,p¯1↓f1s1↓,p¯2↓f2s2↓,…,p¯N↓fNsN↓}⇒c¯⇒subscript𝑠0subscript𝑝0↓subscript𝑓1subscript𝑠1↓subscript¯𝑝1↓subscript𝑓2subscript𝑠2↓subscript¯𝑝2…↓subscript𝑓𝑁subscript𝑠𝑁↓subscript¯𝑝𝑁¯𝑐\\biggl{\\{}\\,\\,\\overset{\\begin{subarray}{c}s_{0}\\\\ =\\end{subarray}}{p_{0}}\\,,\\,\\underset{\\begin{subarray}{c}\\downarrow\\\\ f_{1}\\end{subarray}}{\\overset{\\begin{subarray}{c}s_{1}\\\\ \\downarrow\\end{subarray}}{\\overline{p}_{1}}}\\,,\\,\\underset{\\begin{subarray}{c}% \\downarrow\\\\ f_{2}\\end{subarray}}{\\overset{\\begin{subarray}{c}s_{2}\\\\ \\downarrow\\end{subarray}}{\\overline{p}_{2}}}\\,,\\,\\ldots\\,,\\,\\underset{\\begin{% subarray}{c}\\downarrow\\\\ f_{N}\\end{subarray}}{\\overset{\\begin{subarray}{c}s_{N}\\\\ \\downarrow\\end{subarray}}{\\overline{p}_{N}}}\\,\\,\\biggr{\\}}\\,\\,\\Rightarrow% \\overline{c}{ start_OVERACCENT start_ARG start_ROW start_CELL italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL = end_CELL end_ROW end_ARG end_OVERACCENT start_ARG italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG , start_UNDERACCENT start_ARG start_ROW start_CELL ↓ end_CELL end_ROW start_ROW start_CELL italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG end_UNDERACCENT start_ARG start_OVERACCENT start_ARG start_ROW start_CELL italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL ↓ end_CELL end_ROW end_ARG end_OVERACCENT start_ARG over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG end_ARG , start_UNDERACCENT start_ARG start_ROW start_CELL ↓ end_CELL end_ROW start_ROW start_CELL italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG end_UNDERACCENT start_ARG start_OVERACCENT start_ARG start_ROW start_CELL italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL ↓ end_CELL end_ROW end_ARG end_OVERACCENT start_ARG over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG end_ARG , … , start_UNDERACCENT start_ARG start_ROW start_CELL ↓ end_CELL end_ROW start_ROW start_CELL italic_f start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT end_CELL end_ROW end_ARG end_UNDERACCENT start_ARG start_OVERACCENT start_ARG start_ROW start_CELL italic_s start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL ↓ end_CELL end_ROW end_ARG end_OVERACCENT start_ARG over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT end_ARG end_ARG } ⇒ over¯ start_ARG italic_c end_ARG (2)\n\nEach argument 𝒜=(c¯,p0,R)𝒜¯𝑐subscript𝑝0𝑅\\mathcal{A}=(\\overline{c},p_{0},R)caligraphic_A = ( over¯ start_ARG italic_c end_ARG , italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_R ) comprises an inaccurate claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG, that builds on the accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and applies at least one fallacious reasoning Ri∈Rsubscript𝑅𝑖𝑅R_{i}\\in Ritalic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_R. As shown in Figure 2, in some cases, multiple fallacious premises with distinct fallacy classes can be used interchangeably (i.e., p¯i=[p¯i,1,p¯i,2]subscript¯𝑝𝑖subscript¯𝑝𝑖1subscript¯𝑝𝑖2\\overline{p}_{i}=\\bigl{[}\\overline{p}_{i,1},\\>\\overline{p}_{i,2}\\bigr{]}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = [ over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i , 1 end_POSTSUBSCRIPT , over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i , 2 end_POSTSUBSCRIPT ]). Interchangeable fallacies always share the identical publication context (sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT), but only one of them is necessary to bridge the reasoning gap.\n\n3.2 Non-exhaustive, Inductive Arguments\n\nUnlike Cook et al. (2018), we do not require arguments to deduce the claim, which is unrealistic based on empirical evidence from scientific publications. Instead, we consider strong inductive support sufficient for (⇒⇒\\Rightarrow⇒). In inductive arguments, invalid premises, by definition, weaken the conclusion without necessarily rendering it false. To avoid labeling minor mismatches as fallacies, we ensure the relevance of each fallacious reasoning Ri∈Rsubscript𝑅𝑖𝑅R_{i}\\in Ritalic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_R in the strong inductive argument by deriving R𝑅Ritalic_R exclusively from the HFC article. By relying on the HFC, the extracted fallacious reasoning lines are non-exhaustive and limited to the most pivotal ones. Importantly, fallacies within the logical arguments do not necessarily match the fallacies made by the claimant. For example, one can make the claim in Figure 1 after only skimming parts of the study without ever knowing that experiments were performed in cell cultures (s1subscript𝑠1s_{1}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT). In this case, the Fallacy of Exclusion rather than the Fallacy of Composition was applied. To account for these cases, we state our objective as detecting the necessary fallacies needed to conclude the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG from all relevant content of the misrepresented publication S𝑆Sitalic_S. This follows the principle of total evidence, which dictates that an inductive argument must consider all available relevant evidence (Chakraborti, 2007).\n\n3.3 Task Definition\n\nWe assess the ability to reconstruct the fallacious reasoning for each fallacious argument 𝒜𝒜\\mathcal{A}caligraphic_A on the fallacious reasoning level: For each fallacious reasoning Ri∈Rsubscript𝑅𝑖𝑅R_{i}\\in Ritalic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_R, given the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG, the accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and the publication context sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT from Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, the model must verbalise the fallacious premise p¯^isubscript^¯𝑝𝑖\\hat{\\overline{p}}_{i}over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and predict the applied fallacy class fi^^subscript𝑓𝑖\\hat{f_{i}}over^ start_ARG italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG to bridge the reasoning gap, so that (p¯^isubscript^¯𝑝𝑖\\hat{\\overline{p}}_{i}over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, fi^^subscript𝑓𝑖\\hat{f_{i}}over^ start_ARG italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG) constitute valid fallacies as approximated via the annotated interchangeable fallacies (p¯isubscript¯𝑝𝑖\\overline{p}_{i}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, fisubscript𝑓𝑖f_{i}italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT) of Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.\n\n4 Dataset\n\nOur main annotator was a M.Sc. student in biology, covering early pilot studies and post-annotation consolidation. Additionally, two more M.Sc. students, one in biology and one in linguistics, were employed during annotation. The annotators received a pay of 12.26 EUR per hour. We used Surge AI as the annotation tool. Weekly meetings involving all annotators and one of the authors were held throughout the project to provide feedback and to refine the guidelines as needed, in line with the recommendations of Klie et al. (2024). To create Missci, we (1) collected HFC articles and pre-selected links that may point to a misrepresented publication, (2) manually selected all links that pointed to a misrepresented publication, and (3) reconstructed the fallacious arguments from the HFC articles. A summary of these three steps is given in Table 1. We collected a total of 527 fact-checking articles from HealthFeedback until January 2023, excluding those that address accurate claims. HealthFeedback collaborates with scientists in reviewing health and medical claims. From these HFC articles, we annotated 8,695 links from reputable sources (cf. §A.1) to determine whether a link pointed to a misrepresented scientific publication. Our annotators found 208 links pointing to misrepresented scientific publications across 150 HFC articles (cf. §A.2; Krippendorff’s α𝛼\\alphaitalic_α was 0.7280.7280.7280.728).\n\n4.1 Fallacious Argument Reconstruction\n\nThe annotators were instructed to generate all elements of the fallacious argument 𝒜𝒜\\mathcal{A}caligraphic_A that falsely concludes the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG. This included the accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT as well as the fallacious premise p¯isubscript¯𝑝𝑖\\overline{p}_{i}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, fallacy class fisubscript𝑓𝑖f_{i}italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and publication context sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for each fallacious reasoning Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (cf. §B.1 for a list of all fallacy classes). Each element had to be justified with an extracted statement from the HFC article. Often, selecting a single definitive fallacious reasoning was ambiguous and oxymoronic, akin to identifying the “correct invalid reasoning” (cf. §3; Figure 2). This aligns with Bonial et al. (2022), who observed that due to overlapping definitions, fallacies could often be reformulated to fit the definition of a different fallacy. Hence, we allowed separate listing of interchangeable fallacies, which were merged during consolidation. As we aimed to detect the fallacious reasoning between a scientific publication and an inaccurate claim, our work rests on the assumption that the publication itself is trustworthy. To verify the trustworthiness, the annotators rated the credibility of the scientific document based on the HFC article, which we analyzed in §C.1. Detailed instructions and the annotation process are outlined in §B.2.\n\n4.2 Inter-Annotator Agreement\n\nWe collected 520 annotated HITs for 208 potential arguments. After consolidation (cf. §B.3), Missci contained 435 distinct fallacious reasoning lines (Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT) bridging different reasoning gaps (with a total of 550 interchangeable fallacies) for 184 fallacious arguments. Each argument involved 1-5 fallacious reasoning lines (Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT), averaging at 2.4 per argument. Most of the arguments within Missci were related to the COVID-19 infodemic. We show the distribution of arguments over years and their relation to COVID-19 in §C.2. Calculating the inter-annotator agreement for the fallacy class annotations faced two challenges: interchangeable fallacies with different but valid labels, and annotators identifying different (non-interchangeable) fallacious reasoning lines that bridge different reasoning gaps.\n\nTo address this, we used two complementary measures: We calculated the inter-annotator agreement for the fallacy class fisubscript𝑓𝑖f_{i}italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT among all 253 fallacious reasoning Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT identified by at least two annotators within the consolidated arguments. When simulating a single-label classification setup, the inter-annotator agreement, measured using Krippendorff’s α𝛼\\alphaitalic_α, was 0.520. This is comparable to Cohen’s κ𝜅\\kappaitalic_κ of 0.47 (Alhindi et al., 2022) and 0.52 (Musi et al., 2022) in similar work. We additionally compared each fallacious reasoning Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT identified by each individual annotator to the consolidated argument and measured how many fallacious reasoning Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of the consolidated argument a single annotator found on average. Here, we considered all fallacies that were merged during consolidation as identical, and did not differentiate whether the annotators selected distinct interchangeable fallacies that apply different fallacy classes. Here, we only considered 70 arguments, which were fully annotated by all three annotators, for the computation to not artificially inflate the coverage by a single annotator. On average, each annotator identified 72.5% of the fallacious reasoning lines Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in the consolidated argument. We examined how this affected the overall recall of the detected fallacies in Missci in §C.3.\n\n4.3 Fallacy Class Analysis\n\nTo understand which fallacy classes have been annotated together as interchangeable fallacies, we show their co-occurrence matrix in Figure 3. The definitions and the examples for all fallacies are given in §B.1. We observe that most co-occurrences are between False Equivalence and Ambiguity (as discussed in Figure 2). In contrast, Hasty Generalization was the most clear-cut fallacy in our annotations, likely because HFC typically explicitly specify when a study lacks sufficient observations for the claim, and because it had little overlap with other fallacy definitions. The majority class of all fallacy class annotations is the Fallacy of Exclusion. This fallacy omits critical information when drawing a conclusion and could theoretically apply to every reasoning gap that depends on the information in the publication context sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, because each sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT contains content that undermines the claim. To address this, during annotation the annotators were tasked to prioritize more specific fallacies before the Fallacy of Exclusion (cf. §B.2), yet the fallacy class remains the most common.\n\nWe found two main reasons for the prevalence of the Fallacy of Exclusion in Missci: The first and primary reason for including this fallacy in our inventory, is that parts of the misrepresented publication contradict the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG. For example, the claim that “spike proteins induced by RNA vaccines can damage blood vessels” is based on a study which concludes that “vaccination could protect against blood vessel damage”. In this case, the authors’ comment must be ignored and no other fallacy in our inventory can be used to conclude a claim opposite to their conclusion. Second, the Fallacy of Exclusion often serves as a fallback class in Missci due to its broad applicability. Given the inevitability of an incomplete fallacy inventory, instances where the detected fallacies do not clearly align with the predefined fallacy classes are frequently labeled as Fallacy of Exclusion. This leads to co-occurrences with other fallacies in borderline cases. For example, the claim that “Pfizer’s COVID-19 vaccine effectiveness dropped from 100% to 20%” relies on infection numbers, and ignores the reported high effectiveness against severe disease. This flawed reasoning could be interpreted as False Equivalence, assuming mild and severe COVID-19 cases are equivalent, or Fallacy of Exclusion by omitting the protection against severe diseases. A clear fallacy class can only be assigned for a specific verbalized fallacious premise.\n\n5 Experiments\n\nFor each input (c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG, p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT), comprising the incorrect claim, the accurate premise, and the publication context linked to a fallacy, the model must generate at least one fallacious premise p¯^isubscript^¯𝑝𝑖\\hat{\\overline{p}}_{i}over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT together with the applied fallacy class fi^^subscript𝑓𝑖\\hat{f_{i}}over^ start_ARG italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG. We only experiment in a zero-shot setting, since the dataset construction depends on high-quality HFC articles, which limits size and scalability. However, we separate 30 arguments as a validation split to allow for a prompt selection without compromising the evaluation on the unseen test split, which comprises the remaining 154 arguments with 363 fallacious reasoning lines Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT bridging different reasoning gaps.\n\n5.1 Metrics\n\nEven though multiple interchangeable fallacies may be applicable, only one of them is required to reconstruct the fallacious argument. Hence, to evaluate the fallacy classes, we report P@1 as our primary metric, where the top-ranked predicted fallacy class f^i,1subscript^𝑓𝑖1\\hat{f}_{i,1}over^ start_ARG italic_f end_ARG start_POSTSUBSCRIPT italic_i , 1 end_POSTSUBSCRIPT is considered correct if it matches any gold fallacy class fi,jsubscript𝑓𝑖𝑗f_{i,j}italic_f start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT of the interchangeable fallacy classes in Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Further, we model the fallacy classification as a multi-label, multi-class classification problem, in which we ask the model to identify all interchangeable fallacy classes within each Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. While the single-label classification measures sufficiency, the multi-label multi-class classification relates to the comprehensiveness of the detected fallacy classes. Akin to previous fallacy detection work (Dimitrov et al., 2021; Jin et al., 2022) with high class-imbalances, we report the micro F1-score. Additionally, we assume that correctly detecting at least one fallacy is sufficient to reject the claim, and report argument-level accuracy, denoted as Arg@1, by considering an argument as rejected if the top-ranked fallacy class prediction of any fallacious reasoning Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is correct.\n\nTo evaluate the generated fallacious premises, we first match the top-ranked generated premises with the gold premises as reference texts via the predicted fallacy class and cosine similarity (cf. §D.1). We then report METEOR score (Banerjee and Lavie, 2005), which was used for rationales in the real-world AFC dataset AVeriTeC (Schlichtkrull et al., 2023b), and BERTScore (Zhang et al., 2020) to account for semantic similarity. Further, we follow Honovich et al. (2022) who use a T5 (Raffel et al., 2020) model trained on NLI data and consider the predicted probability for the entailment label as measure. Rather than using the entailment probability given the reference premise p¯isubscript¯𝑝𝑖\\overline{p}_{i}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as premise and the generated premise p¯^isubscript^¯𝑝𝑖\\hat{\\overline{p}}_{i}over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as hypothesis e⁢(p¯i,p¯^i)𝑒subscript¯𝑝𝑖subscript^¯𝑝𝑖e(\\overline{p}_{i},\\hat{\\overline{p}}_{i})italic_e ( over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) (denoted as NLI-A), we additionally compute a symmetric variant (NLI-S) via max⁢[e⁢(p¯i,p¯^i);e⁢(p¯^i,p¯i)]max𝑒subscript¯𝑝𝑖subscript^¯𝑝𝑖𝑒subscript^¯𝑝𝑖subscript¯𝑝𝑖\\mathrm{max}\\bigl{[}e(\\overline{p}_{i},\\hat{\\overline{p}}_{i});e(\\hat{% \\overline{p}}_{i},\\overline{p}_{i})\\bigr{]}roman_max [ italic_e ( over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ; italic_e ( over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ] to not penalize a model if the generated premise is more specific than the reference premise. More details about the metrics and matching with reference text are provided in §D.1. Finally, we measure the LLM’s internal consistency of the generated premise and fallacy class, by prompting the same LLM again to classify the fallacy present in the generated fallacious premise p¯^isubscript^¯𝑝𝑖\\hat{\\overline{p}}_{i}over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT given (c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG, p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, p¯^isubscript^¯𝑝𝑖\\hat{\\overline{p}}_{i}over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT). We report the percentage in which the same fallacy class is predicted.\n\n5.2 Models\n\nWe evaluated two baselines that predict a randomly selected fallacy class. For the fallacious premise, these baselines either always predict the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG or the accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, both of which are topically related to the gold fallacious premise but meaningless in their verbalized reasoning.\n\nWe conducted experiments with two state-of-the-art LLMs: LLaMA 2 (70B) (Touvron et al., 2023) as an open-source LLM which can be run on a local machine, and GPT 4 (OpenAI, 2023) as a proprietary LLM. In line with our annotation process, we prompted the LLM to generate a ranked list of multiple pairs consisting of the fallacious premise and fallacy class (p¯^i,jsubscript^¯𝑝𝑖𝑗\\hat{\\overline{p}}_{i,j}over^ start_ARG over¯ start_ARG italic_p end_ARG end_ARG start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT, f^i,jsubscript^𝑓𝑖𝑗\\hat{f}_{i,j}over^ start_ARG italic_f end_ARG start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT), which may express interchangeable fallacy classes. We evaluated different prompts, varying in the amount of information provided to the LLMs about the fallacy classes. Specifically, we examined the impact of fallacy definitions (D), the logical form (L), and the examples (E) from our fallacy inventory (cf. §B.1), sourced from Bennett (2012) and Cook et al. (2018). The definitions offer descriptive information about the fallacies. The logical forms abstract from the content, but explicitly indicate the applied fallacious reasoning. For instance, the logical form for the Fallacy of Composition is “A is part of B. A has property X. Therefore, B has property X.”. This resembles surface patterns that were found to be beneficial in logical fallacies (Jin et al., 2022). We hypothesize that different types of information have varying effects on fallacy classification and fallacious premise generation. We selected the best prompt based on the P@1 performance on the validation split (cf. §D.2). For GPT 4, we only report the results based on the respective best LLaMA 2 prompts for fallacy premise generation and fallacy class P@1 on the test set for comparison. Prompts and hyper-parameters are in §F.\n\n5.3 Argument Reconstruction Results\n\nTable 2 shows the results for reconstructing the fallacious argument. LLaMA 2 achieves its best fallacy detection (P@1) and fallacious premise generation performance using (D) or (L) in the prompt, respectively, which is consequently reported for GPT 4. For both LLMs, using only the fallacy definition leads to the best fallacy classification performance. Here, GPT 4 outperforms LLaMA 2 by a large margin, correctly identifying at least one fallacy in 57% of the arguments. For fallacious premise generation, each LLM exhibits the best performance based on different prompts. In the fallacious premise generation, even GPT 4 achieves low scores, particularly compared to the random baselines. The generated premises perform primarily poorly when the predicted fallacy class does not match the gold fallacy class of the reference premise. When separately evaluating the generated fallacious premises over correctly classified fallacies with matching classes only (cf. §D.3; Table 10), GPT 4 surpasses the random baseline and outperforms LLaMA 2 in METEOR (0.2640.2640.2640.264 vs. 0.2430.2430.2430.243) and BERTScore (0.6370.6370.6370.637 vs. 0.6220.6220.6220.622), reaching comparable performance in NLI-S (0.2670.2670.2670.267 vs. 0.2660.2660.2660.266). Finally, both models seem to show (slightly) improved consistency (last column) when given the logical form, suggesting that it helps the fallacy generation to match the expected form. Overall, the consistency is much higher for GPT 4.\n\n5.4 Fallacy Classification Results\n\nWe instructed LLMs to classify the applied fallacy class fi,jsubscript𝑓𝑖𝑗f_{i,j}italic_f start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT based on the provided gold fallacious premise p¯i,jsubscript¯𝑝𝑖𝑗\\overline{p}_{i,j}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT, along with the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG, the accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and the publication context linked to a fallacy sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and report the results in Table 3. Since each fallacious premise pi,jsubscript𝑝𝑖𝑗p_{i,j}italic_p start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT verbalizes a single fallacy class fi,jsubscript𝑓𝑖𝑗f_{i,j}italic_f start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT this becomes a single-label classification problem. These experiments help to (i) compare the difficulty of detecting fallacies with explicit fallacious reasoning provided or not (as in §5.3), and (ii) re-evaluate the LLMs and the prompts used to assess the consistency over the gold fallacious premises. In addition to exploring the impact of (D, L, E), we also evaluated the performance when only provided with the fallacy names (first row), to assess whether sufficient fallacy knowledge was acquired during pretraining. For GPT 4, we evaluated the best prompt based on LLaMA 2 performance, as well as the prompts used to measure consistency in Table 2. Both LLMs performed strong across all prompts, especially considering that this is a 9-way classification problem. In §E.3, we further provide empirical evidence that GPT 4 benefits from the premise generation task, when no gold fallacious premise is available. The accuracy over the gold premises always exceeded the consistency scores, suggesting that model-generated premises were not as clear-cut to a single fallacy class compared to gold fallacious premises, even by the LLMs’ own judgement. The primary misclassification for both LLMs occured between Ambiguity and False Equivalence (cf. §D.4), two very related fallacies (cf. Figures 2 & 3). However, LLaMA 2 overpredicted False Equivalence in general. The best performance was reached with access to the logical form and the examples. We hypothesize that both were most influential to our annotators, and are hence helpful for detecting their generated fallacies.\n\n6 Analysis\n\n6.1 Fallacy-level Performance\n\nWe assess the performances per fallacy class for the best prompts (D) in §5.3 for both LLMs in Figure 4. Specifically, we report the fallacy-level F1-score in a multi-label multi-class setting. GPT 4 outperforms LLaMA 2 in almost all classes. The strongest F1-score by LLaMA 2 is achieved for the False Equivalence class. This aligns with the (LE) prompted LLMs from Table 3, analyzed in §D.4, and primarily stems from a high recall for detecting this fallacy. For all other fallacy classes, GPT 4 achieves a substantially higher recall, leading to an overall higher performance in terms of F1-score, given the mostly similar precision across fallacy classes (cf. §E.2; Figure 16). We observe the biggest difference for Ambiguity and Impossible Expectations, which are frequently detected by GPT 4, but never by LLaMA 2. The same was observed when prompting LLMs to predict fallacy classes applied by the gold fallacious premises (cf. §D.4; Figures 13 & 14), suggesting that the differences were inherent to the LLMs. Interestingly, both LLMs perform best on the most frequent fallacy classes despite no fine-tuning involved.\n\n6.2 Allowing Multiple Predictions\n\nGenerally, we assume that our annotators identified the most fitting fallacies that should be among the top model predictions. However, different applicable fallacy classes may exist and our annotations cannot guarantee full recall. To address this, in Figure 5, we evaluate all LLMs in a more lenient setting. We borrow the HasPositive@k𝑘kitalic_k metric from Shaar et al. (2020) and consider a detected fallacy class correct, if any of the top k𝑘kitalic_k predicted fallacy classes is accurate. This approach avoids penalizing models for predicting different fallacies, as long as they also predict a gold fallacy class. The results demonstrate a consistent improvement in the performance of GPT 4 as more predictions are considered. In contrast, LLaMA 2, in most cases, fails to predict the gold fallacy, even within the top 6 predictions. This confirms that GPT 4’s superiority on this task is not a result of subtle selection bias for the top-ranked fallacy class, but arises from its better ability to identify the required fallacy classes. GPT 4 especially benefits from improving the detection of Fallacy of Exclusion and False Equivalence when increasing k𝑘kitalic_k (cf. §E.1), which account for 45.3% of all 550 interchangeable fallacies in Missci, and nearly doubles the accuracy when considering the top 3 predictions. The argument-level performance (Arg@k𝑘kitalic_k) peaks at a maximum of 89.0% for GPT 4 and 59.7% for LLaMA 2 for k=6𝑘6k=6italic_k = 6.\n\n6.3 Human Evaluation\n\nWe manually evaluated 240 predictions from the main experiments in Table 2 (60 per LLM with (D) and (L) prompts; 50% for correctly and incorrectly classified fallacies based on P@1). Table 4 shows the estimated overall results. Additional results and details are provided in §E.4. Our human judgment found the fallacies produced by GPT 4, in particular (L), the most plausible. Yet, the predicted fallacy class often did not match the premise. Overall, we observed a major quality difference of generated premises across both LLMs, with LLaMA 2 often repeating parts of the input. NLI-S showed the strongest correlation with human judgements (Pearson r𝑟ritalic_r=0.209; p-value=0.0010.0010.0010.001; cf. §E.4). Due to the complexity of this task and its automatic evaluation, we echo Schlichtkrull et al. (2023b) who argue that human evaluation is necessary for robustness.\n\n7 Discussion\n\nFollowing suggestions in Schlichtkrull et al. (2023a), we outline how our research contributes to combating misinformation. The analyzed data subjects and data actors are social media users. For responsible applications, we emphasize that data owners should ideally have domain expertise, recognizing that any system will inevitably be imperfect. We strictly did not ask the models to assign an overall rating of the claim’s veracity. Instead, we kept the user in the loop for decision-making and only assisted by outlining the fallacious discrepancies between the cited publication and the claim. Clearly communicating the inaccuracies behind a claim is important for effective debunking (Schmid and Betsch, 2019; Lewandowsky et al., 2020) and can help to increase digital literacy, which is important for building resilience against misinformation (Lewandowsky and Van Der Linden, 2021; Musi et al., 2022). While previous approaches taught digital literacy using serious games (Roozenbeek and van der Linden, 2020; Musi et al., 2023) that require active participation, we envision a system that supports passive consumers of social media.\n\n8 Conclusion and Future Work\n\nWe introduced Missci, a novel dataset to combat real-world misinformation that misrepresents scientific publications. We proposed a novel task formulation to automatically reconstruct the fallacious reasoning through logical arguments based on the cited publication’s content. We showcased Missci as a testbed for evaluating the reasoning abilities of LLMs. Our experiments on two LLMs demonstrated the potential for reconstructing fallacious arguments. In future work, we plan to use Missci with different LLMs, domains, and languages.\n\nLimitations\n\nTo reconstruct fallacious arguments, we solely relied on the expertise of a single fact-checking organization. Missci is limited to this organization’s selected claims, topics, and biases. While fallacies are derived from reasoning flaws detected by the HFC, separating fallacious reasoning from valid reasoning is not always clear-cut. Generalizing or abstracting from specific observations is an essential part of reasoning (Bennett, 2012) and some argue that fallacy theory in general has limited applicability for real-world claims (Boudry et al., 2015). When selecting claims for fact-checking, the virality of claims is a major factor (Arnold, 2020). It is, therefore, likely that information about the claim, and why it is inaccurate may have been acquired by the LLMs during pretraining (Magar and Schwartz, 2022), similarly to leaked evidence effects observed in fact-checking (Glockner et al., 2022). While Missci addresses real-world misinformation, it is just one step toward detecting such fallacies: Our design choices exclude joint use of multiple publications to derive a claim. Assessing a claim by its cited source as done in this work is necessary but insufficient; verifying a claim in the real world requires consultation with complementary sources and domain experts (Silverman, 2014). Our approach requires knowledge of the misrepresented publication, which may not always be provided together with the claim. Moreover, Missci does not consider the original content of the misrepresented publication, but relies on paraphrasing from HFC articles, which is not available in real-world applications. Finally, Missci comprises pure misinformation, and our results offer no insight into model performance over accurate claims. For practical utility, fallacy detection systems must discern whether a fallacy is present before selecting the specific type of fallacy. We note that including unbiased accurate claims is challenging, as they likely differ in topic, specificity, and may cite multiple scientific publications. Due to these limitations, neither the tested models nor any derived from Missci in this form should be directly applied in the real world.\n\nEthics Statement\n\nThe objective of this work, to combat misinformation and to increase the public resilience to it, is ethically uncritical and beneficial to society. Nevertheless, our work bears the danger of undesired side effects. Although our task definition is clearly bound to the content used when deriving a claim, our evaluation may favor models that align with the best knowledge available during COVID-19, which makes up the majority of our dataset. Yet, scientific knowledge may change over time, which will not be reflected in Missci. Moreover, we task the models to produce fallacious reasoning. This is important to explain the fallacious reasoning behind a claim for debunking (Lewandowsky et al., 2020), yet it may also be misused by malicious actors. Nevertheless, we argue that our work is rather a further demonstration of how generating fallacies in a controlled setup can be used for good, and aligns with previous work that generated misinformation to improve NLP-based approaches (Zellers et al., 2019; Huang et al., 2023; Alhindi et al., 2023). We did not take any steps to anonymise the collected data. All claims in Missci are taken from HFC articles which often focus on claims by public figures. We neither contacted the individuals making the claim, nor the HFC. Following Schlichtkrull et al. (2023b) we will remove claims from Missci upon request by any individual that stated the claim, is subject of the claim or created the HFC article.\n\nAcknowledgments\n\nThis research work has been funded by the German Federal Ministry of Education and Research and the Hessian Ministry of Higher Education, Research, Science and the Arts within their joint support of the National Research Center for Applied Cybersecurity ATHENE, and by the the German Research Foundation (DFG) as part of the UKP-SQuARE project (grant GU 798/29-1). Yufang Hou is supported by the Visiting Female Professor Programme from TU Darmstadt. We gratefully acknowledge the support of Microsoft with a grant for access to OpenAI GPT models via the Azure cloud (Accelerate Foundation Model Academic Research). We are grateful to our dedicated annotators who helped to create Missci. Finally, we wish to thank Jan Buchmann, Nils Dycke, Aniket Pramanick, Luke Bates and Jing Yang for their valuable feedback on an early draft of this work.\n\nReferences\n\nAlex et al. (2010) Bea Alex, Claire Grover, Rongzhou Shen, and Mijail Kabadjov. 2010. Agile Corpus Annotation in Practice: An Overview of Manual and Automatic Annotation of CVs. In Proceedings of the Fourth Linguistic Annotation Workshop, pages 29–37, Uppsala, Sweden. Association for Computational Linguistics.\n\nAlhindi et al. (2022) Tariq Alhindi, Tuhin Chakrabarty, Elena Musi, and Smaranda Muresan. 2022. Multitask Instruction-based Prompting for Fallacy Recognition. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 8172–8187, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\n\nAlhindi et al. (2023) Tariq Alhindi, Smaranda Muresan, and Preslav Nakov. 2023. Large Language Models are Few-Shot Training Example Generators: A Case Study in Fallacy Recognition. ArXiv preprint, abs/2311.09552.\n\nArnold (2020) Phoebe Arnold. 2020. The challenges of online fact checking: how technology can (and can’t) help. Technical report, FullFact.\n\nAugenstein (2021) Isabelle Augenstein. 2021. Determining the Credibility of Science Communication. In Proceedings of the Second Workshop on Scholarly Document Processing, pages 1–6, Online. Association for Computational Linguistics.\n\nBanerjee and Lavie (2005) Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 65–72, Ann Arbor, Michigan. Association for Computational Linguistics.\n\nBennett (2012) Bo Bennett. 2012. Logically Fallacious: The Ultimate Collection of Over 300 Logical Fallacies (Academic Edition). eBookIt.com.\n\nBonial et al. (2022) Claire Bonial, Austin Blodgett, Taylor Hudson, Stephanie M. Lukin, Jeffrey Micher, Douglas Summers-Stay, Peter Sutor, and Clare Voss. 2022. The Search for Agreement on Logical Fallacy Annotation of an Infodemic. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 4430–4438, Marseille, France. European Language Resources Association.\n\nBoudry et al. (2015) Maarten Boudry, Fabio Paglieri, and Massimo Pigliucci. 2015. The fake, the Flimsy, and the Fallacious: Demarcating Arguments in Real Life. Argumentation, 29:431–456.\n\nBowman et al. (2015) Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632–642, Lisbon, Portugal. Association for Computational Linguistics.\n\nBratton et al. (2019) Luke Bratton, Rachel C Adams, Aimée Challenger, Jacky Boivin, Lewis Bott, Christopher D Chambers, and Petroc Sumner. 2019. The association between exaggeration in health-related science news and academic press releases: a replication study. Wellcome open research, 4(148).\n\nBrennen et al. (2020) J. Scott Brennen, Felix M. Simon, Philip N. Howard, and Rasmus Kleis Nielsen. 2020. Types, Sources, and Claims of COVID-19 Misinformation. Technical report, Reuters Institute for the Study of Journalism.\n\nChakrabarty et al. (2021) Tuhin Chakrabarty, Aadit Trivedi, and Smaranda Muresan. 2021. Implicit Premise Generation with Discourse-aware Commonsense Knowledge Models. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6247–6252, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\n\nChakraborti (2007) Chhanda Chakraborti. 2007. LOGIC: Informal, Symbolic and Inductive. PHI Learning Pvt. Ltd. Page 48.\n\nCook et al. (2018) John Cook, Peter Ellerton, and David Kinkead. 2018. Deconstructing climate misinformation to identify reasoning errors. Environmental Research Letters, 13(2).\n\nDa San Martino et al. (2019) Giovanni Da San Martino, Seunghak Yu, Alberto Barrón-Cedeño, Rostislav Petrov, and Preslav Nakov. 2019. Fine-Grained Analysis of Propaganda in News Article. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5636–5646, Hong Kong, China. Association for Computational Linguistics.\n\nDettmers et al. (2022) Tim Dettmers, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. 2022. GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale. In Advances in Neural Information Processing Systems, volume 35, pages 30318–30332. Curran Associates, Inc.\n\nDimitrov et al. (2021) Dimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj Alam, Fabrizio Silvestri, Hamed Firooz, Preslav Nakov, and Giovanni Da San Martino. 2021. Detecting Propaganda Techniques in Memes. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6603–6617, Online. Association for Computational Linguistics.\n\nGlockner et al. (2022) Max Glockner, Yufang Hou, and Iryna Gurevych. 2022. Missing Counter-Evidence Renders NLP Fact-Checking Unrealistic for Misinformation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5916–5936, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\n\nGuo et al. (2022) Zhijiang Guo, Michael Schlichtkrull, and Andreas Vlachos. 2022. A Survey on Automated Fact-Checking. Transactions of the Association for Computational Linguistics, 10:178–206.\n\nHabernal et al. (2017) Ivan Habernal, Raffael Hannemann, Christian Pollak, Christopher Klamm, Patrick Pauli, and Iryna Gurevych. 2017. Argotario: Computational Argumentation Meets Serious Games. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 7–12, Copenhagen, Denmark. Association for Computational Linguistics.\n\nHabernal et al. (2018a) Ivan Habernal, Henning Wachsmuth, Iryna Gurevych, and Benno Stein. 2018a. Before Name-Calling: Dynamics and Triggers of Ad Hominem Fallacies in Web Argumentation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 386–396, New Orleans, Louisiana. Association for Computational Linguistics.\n\nHabernal et al. (2018b) Ivan Habernal, Henning Wachsmuth, Iryna Gurevych, and Benno Stein. 2018b. The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1930–1940, New Orleans, Louisiana. Association for Computational Linguistics.\n\nHe et al. (2021) Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2021. DeBERTa: Decoding-enhanced BERT with Disentangled Attention. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.\n\nHonovich et al. (2022) Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy, Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, and Yossi Matias. 2022. TRUE: Re-evaluating Factual Consistency Evaluation. In Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering, pages 161–175, Dublin, Ireland. Association for Computational Linguistics.\n\nHuang et al. (2023) Kung-Hsiang Huang, Kathleen McKeown, Preslav Nakov, Yejin Choi, and Heng Ji. 2023. Faking Fake News for Real Fake News Detection: Propaganda-Loaded Training Data Generation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14571–14589, Toronto, Canada. Association for Computational Linguistics.\n\nJin et al. (2022) Zhijing Jin, Abhinav Lalwani, Tejas Vaidhya, Xiaoyu Shen, Yiwen Ding, Zhiheng Lyu, Mrinmaya Sachan, Rada Mihalcea, and Bernhard Schoelkopf. 2022. Logical Fallacy Detection. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 7180–7198, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\n\nKhot et al. (2018) Tushar Khot, Ashish Sabharwal, and Peter Clark. 2018. SciTaiL: A Textual Entailment Dataset from Science Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1).\n\nKlie et al. (2024) Jan-Christoph Klie, Richard Eckart de Castilho, and Iryna Gurevych. 2024. Analyzing Dataset Annotation Quality Management in the Wild. Computational Linguistics, pages 1–48.\n\nKojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large Language Models are Zero-Shot Reasoners. Advances in neural information processing systems, 35:22199–22213.\n\nLewandowsky et al. (2020) Stephan Lewandowsky, John Cook, Ullrich Ecker, Dolores Albarracin, Michelle Amazeen, Panayiota Kendou, Doug Lombardi, E Newman, Gordon Pennycook, Ethan Porter, et al. 2020. The Debunking Handbook 2020.\n\nLewandowsky and Van Der Linden (2021) Stephan Lewandowsky and Sander Van Der Linden. 2021. Countering Misinformation and Fake News Through Inoculation and Prebunking. European Review of Social Psychology, 32(2):348–384.\n\nLu et al. (2023) Xinyuan Lu, Liangming Pan, Qian Liu, Preslav Nakov, and Min-Yen Kan. 2023. SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7787–7813, Singapore. Association for Computational Linguistics.\n\nMagar and Schwartz (2022) Inbal Magar and Roy Schwartz. 2022. Data Contamination: From Memorization to Exploitation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 157–165, Dublin, Ireland. Association for Computational Linguistics.\n\nMusi et al. (2022) Elena Musi, Myrto Aloumpi, Elinor Carmi, Simeon Yates, and Kay O’Halloran. 2022. Developing Fake News Immunity: Fallacies as Misinformation Triggers During the Pandemic. Online Journal of Communication and Media Technologies, 12(3).\n\nMusi et al. (2023) Elena Musi, Elinor Carmi, Chris Reed, Simeon Yates, and Kay O’Halloran. 2023. Developing Misinformation Immunity: How to Reason-Check Fallacious News in a Human–Computer Interaction Environment. Social Media + Society, 9(1).\n\nNakov et al. (2021) Preslav Nakov, David Corney, Maram Hasanain, Firoj Alam, Tamer Elsayed, Alberto Barrón-Cedeño, Paolo Papotti, Shaden Shaar, and Giovanni Da San Martino. 2021. Automated Fact-Checking for Assisting Human Fact-Checkers. In Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, pages 4551–4558. International Joint Conferences on Artificial Intelligence Organization. Survey Track.\n\nNakpih and Santini (2020) Callistus Ireneous Nakpih and Simone Santini. 2020. Automated Discovery of Logical Fallacies in Legal Argumentation. International Journal of Artificial Intelligence and Applications (IJAIA), 11.\n\nOpenAI (2023) OpenAI. 2023. GPT-4 Technical Report. ArXiv preprint, abs/2303.08774.\n\nPei and Jurgens (2021) Jiaxin Pei and David Jurgens. 2021. Measuring Sentence-Level and Aspect-Level (Un)certainty in Science Communications. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9959–10011, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\n\nPiskorski et al. (2023) Jakub Piskorski, Nicolas Stefanovitch, Nikolaos Nikolaidis, Giovanni Da San Martino, and Preslav Nakov. 2023. Multilingual Multifaceted Understanding of Online News in Terms of Genre, Framing, and Persuasion Techniques. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3001–3022, Toronto, Canada. Association for Computational Linguistics.\n\nRaffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. J. Mach. Learn. Res., 21:140:1–140:67.\n\nReimers and Gurevych (2019) Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982–3992, Hong Kong, China. Association for Computational Linguistics.\n\nRoozenbeek and van der Linden (2020) Jon Roozenbeek and Sander van der Linden. 2020. Breaking Harmony Square: A game that “inoculates” against political misinformation. The Harvard Kennedy School Misinformation Review, 1(8).\n\nSahai et al. (2021) Saumya Sahai, Oana Balalau, and Roxana Horincar. 2021. Breaking Down the Invisible Wall of Informal Fallacies in Online Discussions. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 644–657, Online. Association for Computational Linguistics.\n\nSalman et al. (2023) Muhammad Salman, Asif Hanif, Shady Shehata, and Preslav Nakov. 2023. Detecting Propaganda Techniques in Code-Switched Social Media Text. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 16794–16812, Singapore. Association for Computational Linguistics.\n\nSarrouti et al. (2021) Mourad Sarrouti, Asma Ben Abacha, Yassine Mrabet, and Dina Demner-Fushman. 2021. Evidence-based Fact-Checking of Health-related Claims. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3499–3512, Punta Cana, Dominican Republic. Association for Computational Linguistics.\n\nSchlichtkrull et al. (2023a) Michael Schlichtkrull, Nedjma Ousidhoum, and Andreas Vlachos. 2023a. The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 8618–8642, Singapore. Association for Computational Linguistics.\n\nSchlichtkrull et al. (2023b) Michael Sejr Schlichtkrull, Zhijiang Guo, and Andreas Vlachos. 2023b. AVeriTeC: A Dataset for Real-world Claim Verification with Evidence from the Web. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track.\n\nSchmid and Betsch (2019) Philipp Schmid and Cornelia Betsch. 2019. Effective strategies for rebutting science denialism in public discussions. Nature Human Behaviour, 3(9):931–939.\n\nSchuster et al. (2021) Tal Schuster, Adam Fisch, and Regina Barzilay. 2021. Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 624–643, Online. Association for Computational Linguistics.\n\nShaar et al. (2020) Shaden Shaar, Nikolay Babulkov, Giovanni Da San Martino, and Preslav Nakov. 2020. That is a Known Lie: Detecting Previously Fact-Checked Claims. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3607–3618, Online. Association for Computational Linguistics.\n\nSilverman (2014) Craig Silverman. 2014. Verification Handbook: An Ultimate Guideline on Digital Age Sourcing for Emergency Coverage. European Journalism Centre.\n\nSumner et al. (2014) Petroc Sumner, Solveiga Vivian-Griffiths, Jacky Boivin, Andy Williams, Christos A Venetis, Aimée Davies, Jack Ogden, Leanne Whelan, Bethan Hughes, Bethan Dalton, Fred Boy, and Christopher D Chambers. 2014. The association between exaggeration in health related science news and academic press releases: retrospective observational study. BMJ, 349.\n\nThorne et al. (2018) James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018. FEVER: a Large-scale Dataset for Fact Extraction and VERification. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 809–819, New Orleans, Louisiana. Association for Computational Linguistics.\n\nTouvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. ArXiv preprint, abs/2307.09288.\n\nVladika and Matthes (2023) Juraj Vladika and Florian Matthes. 2023. Scientific Fact-Checking: A Survey of Resources and Approaches. In Findings of the Association for Computational Linguistics: ACL 2023, pages 6215–6230, Toronto, Canada. Association for Computational Linguistics.\n\nVosoughi et al. (2018) Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science, 359:1146–1151.\n\nWadden et al. (2020) David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu Wang, Madeleine van Zuylen, Arman Cohan, and Hannaneh Hajishirzi. 2020. Fact or Fiction: Verifying Scientific Claims. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7534–7550, Online. Association for Computational Linguistics.\n\nWadden et al. (2022) David Wadden, Kyle Lo, Bailey Kuehl, Arman Cohan, Iz Beltagy, Lucy Lu Wang, and Hannaneh Hajishirzi. 2022. SciFact-Open: Towards open-domain scientific claim verification. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 4719–4734, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\n\nWardle (2018) Claire Wardle. 2018. 5 Lessons for Reporting in an Age of Disinformation. Technical report, First Draft.\n\nWei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. Advances in Neural Information Processing Systems, 35:24824–24837.\n\nWilliams et al. (2018) Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112–1122, New Orleans, Louisiana. Association for Computational Linguistics.\n\nWolf et al. (2020) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-Art Natural Language Processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38–45, Online. Association for Computational Linguistics.\n\nWright and Augenstein (2021) Dustin Wright and Isabelle Augenstein. 2021. Semi-Supervised Exaggeration Detection of Health Science Press Releases. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 10824–10836, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\n\nWright et al. (2022) Dustin Wright, Jiaxin Pei, David Jurgens, and Isabelle Augenstein. 2022. Modeling Information Change in Science Communication with Semantically Matched Paraphrases. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 1783–1807, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\n\nWührl et al. (2024) Amelie Wührl, Dustin Wright, Roman Klinger, and Isabelle Augenstein. 2024. Understanding Fine-grained Distortions in Reports of Scientific Findings. ArXiv preprint, abs/2402.12431.\n\nYu et al. (2020) Bei Yu, Jun Wang, Lu Guo, and Yingya Li. 2020. Measuring Correlation-to-Causation Exaggeration in Press Releases. In Proceedings of the 28th International Conference on Computational Linguistics, pages 4860–4872, Barcelona, Spain (Online). International Committee on Computational Linguistics.\n\nZellers et al. (2019) Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin Choi. 2019. Defending Against Neural Fake News. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 9051–9062.\n\nZhang et al. (2020) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. BERTScore: Evaluating Text Generation with BERT. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020.\n\nZhang et al. (2019) Yuan Zhang, Jason Baldridge, and Luheng He. 2019. PAWS: Paraphrase Adversaries from Word Scrambling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1298–1308, Minneapolis, Minnesota. Association for Computational Linguistics.\n\nAppendix A Dataset Construction I: Selecting Misrepresented Scientific Publications From HFC Articles\n\nA.1 URL Filtering\n\nFor reproducibility we collect all HTML webpages via the Wayback Machine . We apply the following filtering on URLs that may be relevant to our instances. We initially only include URLs with the following top level domains:\n\n•\n\n“.gov”, “.org”, “.int”, “.edu”, “.gov.uk”, “.org.uk”, “.gov.au”, “.org.nz”, “.edu.au”, “.gov.in”, “.org.au”, “.ac.uk”.\n\nWe remove commonly occurring fact-checking organizations that are within the applied filtering: “fullfact.org”, “www.poynter.org”, “factcheck.org”, “npr.org”. We finally add known publishers of scientific content that would otherwise be removed via our filtering step:\n\n•\n\n“nature.com”, “jamanetwork.com”, “thelancet.com”, “researchgate.net”, “academic.oup.com”, “bmj.com”, “onlinelibrary.wiley.com”,“www.mdpi.com”, “www.ijidonline.com”, “link.springer.com”, “sciencedirect.com”, “tandfonline.com”, “journals.lww.com”, “cell.com”, “papers.ssrn.com”, “cebm.net”, “thejournal.ie”, “cebm.ox.ac.uk”, “elsevier.com”, “biomedcentral.com”, “journalofinfection.com”, “journals.sagepub.com”, “scientificamerican.com”, “pfizer.com”, “www.the-scientist.com”, “www.cancer.net”, “www.ema.europa.eu”\n\nFinally, we keep archived URLs\n\n•\n\n“archive.is”, “archive.ph”, “archive.md”, “archive.vn”, “perma.cc”, “archive.fo”\n\nas it is unknown from the surface form if it refers to a scientific publication or not.\n\nA.2 Annotation Process\n\nWe selected 8,695 links for annotation, using a curated list of reputable scientific publishers and top-level domains (cf. §A.1). Few, if any, links in a fact-checking article point to a misrepresent scientific publication. HFC articles must be assessed in their entirety as critical statements may be scattered. Further, articles may cover multiple related claims, or various subclaims, each possibly misrepresenting different publications. For efficient annotation, we grouped up to 8 distinct links per fact-checking article into one HIT, highlighting each link in a different color (Figure 6). This resulted in 1,385 HITs for annotation.\n\nEach highlighted link was given to the annotators within the original context of the HFC article, to decide if the link points to a scientific publication that is misrepresented by a non-true claim as discussed in the article at hand. For each misrepresented publication, annotators had to provide triplets consisting of (1) a non-true claim that misrepresents (2) a scientific publication, and (3) a justification of the flawed reasoning. Each triplet requires an extracted statement from the article as justification, explaining how the document could be misused to support the claim (S⇒c¯⇒𝑆¯𝑐S\\Rightarrow\\overline{c}italic_S ⇒ over¯ start_ARG italic_c end_ARG) and why it does not (S⇏c¯⇏𝑆¯𝑐S\\not\\Rightarrow\\overline{c}italic_S ⇏ over¯ start_ARG italic_c end_ARG). Consecutive HITs present the same HFC article to prevent context switching. Annotators label a link as “misrepresented” only if the claim explicitly relied on the linked publication’s content. Indirect misrepresentation (e.g., through a press release) is also classified as “misrepresented” as the claim relied on the same content. Remaining links are grouped into three sub-categories during annotation (cf. §A.3), but these are collapsed to “not applicable” during dataset compilation and discarded from further annotation steps.\n\nIn a pilot study with all 927 selected links from 50 fact-checking articles we found that single annotation instead of double annotation (Krippendorff’s α𝛼\\alphaitalic_α of 0.728; cf. §A.4) results in a minor loss in recall only. Hence, each instance is annotated by a single annotator. Note that redundant annotations mainly impact the recall of misrepresented scientific documents. Data quality remains unaffected, as errors in link selection are rectified in later annotation tasks. In total, we identified 208 scientific publications labeled as “misrepresented” across 150 HFC articles. 107 articles contained only one misrepresented publication, while 43 articles contained 2-4 misrepresented publications.\n\nDefinitions.\n\nWhen selecting the triplets consisting of (1) a non-true claim that misrepresents (2) a scientific publication, and (3) a justification of the flawed reasoning we consider the following definitions: We consider a claim as non-true and misrepresenting if it is not fully accurate (e.g., including partly true or misleading claims) and lack a valid entailment relationship (⇏⇏\\not\\Rightarrow⇏) with the cited document. We exclude documents from the misrepresented category if the claim can be validly inferred from an incorrect source or if refutation requires additional external evidence. We consider a publication as scientific if it is published in a scientific venue, may be submitted to such a venue (preprints), or constitutes a scientific report from a credible institution, (e.g., annual CDC reports) and include non-peer-reviewed documents because they can be misrepresented before being accepted.\n\nA.3 Link Annotation: Fine-grained labels\n\nAnnotators categorize each link into one of four categories:\n\n•\n\nMisrepresented: This category is designated for scientific publications that are explicitly misrepresented by a non-true claim. Such publications may be referenced either directly or indirectly, for example, through a press release.\n\n•\n\nMisrepresentable: This category is assigned to publications that were not misrepresented but have the potential to be misrepresented. This occurs when the HFC discuss related scientific documents for a comprehensive overview. While these documents could be susceptible to misrepresentation by similar claims, they haven’t been misrepresented by the claimant.\n\n•\n\nMaybe Misrepresentable: Annotators can choose this category when uncertain. Uncertainty may stem from ambiguity regarding a document’s scientific status or doubts about misrepresentation.\n\n•\n\nNot Applicable: This category applies to all other links not covered by the previous categories.\n\nAnnotators must provide an explanation for labels other than “not applicable”. In Missci, we focus exclusively on real-world misinformation involving genuinely misrepresented scientific documents. Instances not labeled as “misrepresented” are collapsed into the “not applicable” class and excluded. While we exclude links labeled “misrepresentable” or “maybe misrepresentable” from Missci, we provide all annotations using the fine-grained taxonomy.\n\nA.4 Link Annotation: Pilot Study and Final Results\n\nAgreement.\n\nThe annotators, alongside one author, annotated all 221 links from 16 randomly chosen fact-checking articles. The inter-annotator agreement, assessed with Krippendorff’s α𝛼\\alphaitalic_α, was 0.360. Disagreement primarily arose from cases initially marked as “misrepresentable” or “maybe misrepresentable” later grouped into the “not applicable” category (as per §A.3). Using the grouped labels, we calculated binary inter-annotator agreement between “misrepresented” labels and “not applicable” labels. This resulted in an inter-annotator agreement of 0.751. The annotators then double-annotated all 706 links from additional 34 randomly selected fact-checking articles, achieving comparable inter-annotator agreement of 0.728.\n\nSingle annotations are sufficient.\n\nWe assess the value of having two annotations versus one using the double-annotated data. Specifically, if at least one annotator labels an instance as “misrepresented” we classify it as such. A single annotator identifies 78.3% of the same instances as “misrepresented”. When we also consider instances labeled as “misrepresentable” by the single annotator, 95.5% of the presumed “misprepresented” double-annotated instances are detected. These additional cases were labeled as “misrepresentable” only by the second annotator, indicating more uncertainty. To reduce the workload while maintaining sufficient coverage, all remaining instances were annotated by a single annotator.\n\nResults.\n\nIn total, we found 208 (2.4%) scientific publications labelled as “misrepresented”, 425 (4.9%) labelled as “misrepresentable”, and 596 (6.9%) labelled as “maybe misrepresentable”. The remaining 7,466 (85.9%) links were unrelated to our problem.\n\nAppendix B Dataset Construction II: Fallacious Argument Reconstruction\n\nB.1 Fallacious Reasoning for Misrepresented Science\n\nFallacy Inventory Selection.\n\nTo select a suitable fallacy inventory, we begin by examining the fallacies employed by Cook et al. (2018) as they pertain to misinformation within the scientific domain. A distinction lies in the relation to science, as they focus on climate-change denial whereas our focus lies on the misrepresentation of scientific documents that seemingly support the claims. Consequently, we exclude fallacies like Red Herring which divert attention from opposing arguments, or Fake experts, which contradicts our requirement for credible evidence. We select the remaining fallacies by examining instances of misrepresentation of scientific publications, guided by the collection of logical fallacies from Bennett (2012). An overview of all selected fallacies can be found in Table 5, along with examples in Table 6.\n\nMerged Fallacies.\n\nAfter annotation, we merge several fallacy classes due to difficulties in differentiation based solely on the information from the fact-checking article, or because they share similar traits and one is very infrequent:\n\n•\n\nFallacy of Division/Composition: Combines Fallacy of Division and Fallacy of Composition as both involve generalizations through the part-of relationship.\n\n•\n\nCausal Oversimplification: Merges Single Cause and False Causeas they are often indistinguishable based solely on the fact-checking article.\n\n•\n\nAmbiguity: Combines Ambiguity with its subtype Equivocation, which relies on the same vocabulary in the claim and premises, a detail not accessible during annotation.\n\nFallacies annotated as Other were resolved into one of the existing fallacy classes. This was always possible, as Fallacy of Exclusion can be applied in almost all cases (as it ignores compromising content (or context) of S𝑆Sitalic_S.\n\nFallacy Inventory Discussion.\n\nSeveral fallacies, such as False Causality, Hasty Generalization, False Dilemma or Ambiguity are present in most existing NLP fallacy inventories in some form. A distinction of our selected fallacies lies in our exclusive focus on corrupted support (⇏⇏\\not\\Rightarrow⇏) relationships. For this reason, we exclude several fallacies that are commonly used in fallacy detection datasets and important for propaganda techniques (Da San Martino et al., 2019; Piskorski et al., 2023) or misinformation in general (Musi et al., 2022; Alhindi et al., 2022):\n\n1.\n\nFallacies that attack (e.g. Ad Hominem).\n\n2.\n\nFallacies that divert (e.g. Strawman Fallacy).\n\n3.\n\nFallacies that use manipulation techniques like slogans or emotional language (e.g. Appeal to Emotion).\n\n4.\n\nFallacies that utilize non-credible evidence (e.g. False Authority), or omit evidence altogether (e.g. Evading the Burden of Proof).\n\nFallacy Inventory Comparison.\n\nIn contrast to other works (Musi et al., 2022; Alhindi et al., 2022), a strong focus lies on a detailed analysis of generalization fallacies. We employ various specific generalization fallacies, such as Hasty Generalization, Biased Sample Fallacy and False Equivalence. The fallacy of Cherry Picking has been addressed in prior research. However, our interpretation of this fallacy aligns more closely with Slothful Induction. This distinction arises because our focus is not on presenting selectively chosen information but rather on the omission of crucial aspects of the study that weaken the claim’s validity. We find False Analogy as employed by e.g. Alhindi et al. (2022), to be comparable to False Equivalence. Both fallacies can be applied to the same problems. Without access to the claimant’s specific reasoning, we find it impossible to prioritize one over the other when generating fallacious premises. For similar reasons, we adopt a broad definition of the False Dilemma fallacy, which assumes that only two options (or outcomes) exist when, in reality, more options are available. We consolidate it with the fallacy of Affirming the Disjunct, which assumes an “either/or” possibility among different options, even when these options are not mutually exclusive. Despite their differences (in False Dilemma the options are indeed mutually exclusive but not exhaustive), they share similar characteristics in exhibiting black-and-white thinking and may only differ in their specificity of the explicit reasoning that is unavailable to us.\n\nB.2 Argument Reconstruction Guidelines\n\nAnnotators should base their reconstruction of fallacious arguments on content in the fact-checking article. The final argument should be:\n\n•\n\nComprehensive: All fallacies identified by the fact-checker should be incorporated.\n\n•\n\nSelf-contained: Subsequent steps should not necessitate the use of the fact-checking articles.\n\nFor all text generation tasks our annotators utilize Grammarly , integrated into the Surge AI tool, to ensure high-quality text. Each of the previously detected 208 misrepresented links was provided to the annotators together with the the preprocessed fact-checking article with highlighted links, and the justification for labeling the link as “misrepresented” (from §A.2) and annotators were tasked to reconstruct all parts of the fallacious argument. Annotations were conducted in batches of 30-40 arguments per annotator per week with weekly meetings, adhering to agile annotation principles (Alex et al., 2010). Each argument was independently assessed by at least two annotators. At the end of annotation, annotators reviewed their own annotations, excluding the last batch, to rectify errors resulting from initial guideline misunderstandings and enhance consistency.\n\nClaim Rewriting.\n\nFact-checking articles might discuss multiple related claims or complex arguments with subclaims. Annotators should first understand the main claim of the fact-checking article and the misrepresented scientific document. The misrepresenting claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG should be formulated as such that S∪P¯⇒c¯⇒𝑆¯𝑃¯𝑐S\\cup\\overline{P}\\Rightarrow\\overline{c}italic_S ∪ over¯ start_ARG italic_P end_ARG ⇒ over¯ start_ARG italic_c end_ARG. Annotators should use the main claim of the fact-checking article if possible, and make minimal changes if necessary. While the formulation of c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG is a prerequisite for detecting fallacious reasoning lines R𝑅Ritalic_R, the validity of S∪P¯⇒c¯⇒𝑆¯𝑃¯𝑐S\\cup\\overline{P}\\Rightarrow\\overline{c}italic_S ∪ over¯ start_ARG italic_P end_ARG ⇒ over¯ start_ARG italic_c end_ARG can only be checked after constructing the argument. Therefore, annotators should re-evaluate c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG after identifying all fallacies. The annotation interface, including a link to the pre-processed fact-checking article and relevant information is shown in Figure 7.\n\nAccurate Premise Writing.\n\nThe accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT provides a correct description of the misrepresented scientific document S𝑆Sitalic_S. Its purpose is to offer logical support for the claim (p0⇒c¯⇒subscript𝑝0¯𝑐p_{0}\\Rightarrow\\overline{c}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ⇒ over¯ start_ARG italic_c end_ARG) but it falls short due to the presence of fallacious reasoning. Fact-checkers always include an accurate description of the misrepresented scientific document. Annotators must locate all relevant information and formulate p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT s.t.\n\n1.\n\nThe wording is as precise as possible and uses the HFC vocabulary.\n\n2.\n\nAll accurate content that strengthens p0⇒c¯⇒subscript𝑝0¯𝑐p_{0}\\Rightarrow\\overline{c}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ⇒ over¯ start_ARG italic_c end_ARG is included.\n\n3.\n\nAny accurate content that weakens p0⇒c¯⇒subscript𝑝0¯𝑐p_{0}\\Rightarrow\\overline{c}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ⇒ over¯ start_ARG italic_c end_ARG is excluded.\n\nWe guide annotators to include information in the accurate premise p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT only if it increases the plausibility of c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG. Any information (from S𝑆Sitalic_S) that decreases plausibility is paraphrased as sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and is part of Risubscript𝑅𝑖R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. The publication context sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is optional and required only if additional information beyond the given p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is necessary.\n\nHidden Premise Writing.\n\nFact-checkers explain how the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG relates to the scientific publication S𝑆Sitalic_S. This may include additional knowledge not found in c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG or S𝑆Sitalic_S. For example, to understand why the claim “Cucumber kills lung cancer cells.” was made based on the scientific finding that “cucubitacin B promoted lung tumor cell death.” one must know that cucumbers contain cucubitacin B. This information is likely not provided by the misrepresented publication itself. Annotators can provide any number of hidden premises which are concise, accurate statements that complement S𝑆Sitalic_S and are essential in understanding the connection between c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG and S𝑆Sitalic_S. Each hidden premise should be a single sentence derived from the fact-checking article.\n\nFallacy Class Selection Preference\n\nAnnotators are directed to prioritize fallacies that engage with the content (all fallacies except Fallacy of Exclusion) rather than ignoring crucial aspects. We allow interchangeable fallacies with distinct classes, but we instruct annotators to prioritize more specific fallacies over broader ones. When multiple fallacies share the same flawed reasoning, annotators should select the most specific fallacy class. For example, when a conclusion is drawn from a biased sample, it can be labeled as the Biased Sample Fallacy. Alternatively, it might be seen as the Single Cause Fallacy assuming that the properties for which the sample is biased do not impact the conclusion. In this example, both fallacy classes do not differ in their applied reasoning, but only in their level of specificity. Therefore, the more specific Biased Sample Fallacy should be preferred. . We provided a taxonomy to the annotators to specify how to choose the more specific fallacy class if multiple apply.\n\nFallacious Premise Writing.\n\nAnnotators should thoroughly review the fact-checking article to identify all sections discussing the claim c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG misrepresenting the scientific publication S𝑆Sitalic_S. These discussions may be distributed throughout the article. Annotators must focus solely on fallacies discernible from the content of S𝑆Sitalic_S. This excludes other scientific documents used by the HFC to refute c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG or assessing the credibility of S𝑆Sitalic_S (e.g., if S𝑆Sitalic_S is retracted or inaccurate). Each fallacy should be separately formulated by the annotator and must be accompanied by a justification extracted from the fact-checking article. The context for each fallacy must be constructed akin to p0subscript𝑝0p_{0}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, emphasizing the weakening of the claim rather than its strengthening. The fallacious premise must align with the selected fallacy class and make the fallacious reasoning explicit. Given that selecting the fallacious reasoning is subjective since different fallacious premises pisubscript𝑝𝑖p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can re-instantiate S∪pi⇒c¯⇒𝑆subscript𝑝𝑖¯𝑐S\\cup p_{i}\\Rightarrow\\overline{c}italic_S ∪ italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⇒ over¯ start_ARG italic_c end_ARG, annotators are permitted to formulate multiple alternative variants that they consider plausible. The annotation interface for a fallacy is visualized in Figure 8. After constructing all fallacies, annotators are tasked with reviewing their own constructed argument to ensure the coherence of the fallacies, claim, and accurate premise, in their HIT.\n\nB.3 Argument Consolidation\n\nOur primary annotator, with the most project experience, handled the consolidation process. The consolidator aligned all annotated fallacious reasoning lines, and selected the best verbalized candidate for each c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG, p¯isubscript¯𝑝𝑖\\overline{p}_{i}over¯ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and sisubscript𝑠𝑖s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, or paraphrased multiple such candidates into an improved version. Interchangeable fallacies with different classes were preserved. Only clearly unjustified fallacy annotations were discarded or corrected if possible. Each consolidated argument underwent double-checking by an author. The consolidator and one of the authors collaborated on a final round of fallacious premise curation. Due to different URLs used to link to the same scientific document, some arguments with duplicate annotations were merged using normalized URLs (cf. §B.4), resulting in 193 distinct fallacious arguments 𝒜𝒜\\mathcal{A}caligraphic_A. Individual annotators might discard arguments during annotation if they cannot reconstruct a fallacious argument, for example because of insufficient information provided by the HFC or violations of the credibility assumption of the cited publication (we analyze the impact of such cases where fewer annotations are available in §C.3). In seven cases no annotator could reconstruct 𝒜𝒜\\mathcal{A}caligraphic_A, and two more fallacious arguments were discarded during consolidation.\n\nAppendix C Dataset Analysis\n\nC.1 Publication Credibility\n\nAugenstein (2021) identifies two key challenges in science communication: (1) assessing the credibility of scientific publications, and (2) preventing the misrepresentation of a study’s findings. This study addresses the second challenge, while assuming the credibility. To examine to which degree our assumption holds, we report the credibility annotations of the used publications in Table 7. Note that a publication may exhibit more than one credibility issue (e.g., a preprint, that was criticised) We consider a publication S𝑆Sitalic_S as “credible” only if no annotator detected any aspect compromising its credibility in the HFC article, providing a conservative estimate. For 123 arguments, no credibility violations were identified. Even identified violations do not necessarily mean that the publication is not credible or not misrepresented by c¯¯𝑐\\overline{c}over¯ start_ARG italic_c end_ARG. For instance, preprints lack formal community approval but may still be credible. At the time of annotation, 16 out of 28 publications marked as preprints by the HFC were accepted. Further, criticism of a study does not make it scientifically unsound. In fact, some critics highlight omitted limitations that could lead to misunderstandings similar to the misrepresentations studied in this work. The overall agreement in distinguishing credible documents from those with any credibility issue is 0.577 (Krippendorff’s α𝛼\\alphaitalic_α).\n\nFigure 10 displays the co-occurring credibility annotations assigned to fallacious arguments. We count an occurrence of a credibility label if at least one annotator assigned it to the misrepresented document, and, hence, ignore duplicate annotations of the same label.\n\nC.2 Claims about the COVID-19 infodemic\n\nMissci comprises fallacious arguments from 2014 to 2022. We manually evaluate each argument for its association with COVID-19 misinformation, considering context provided by the HFC, rather than explicit COVID-19 mentions. For instance, we consider the claim “Ivermectin sterilizes most men who take it” as COVID-19-related because it only exists due to the misinformation about Ivermectin as a COVID-19 cure. Figure 11 illustrates argument distribution over time and their COVID-19 relevance.\n\nC.3 On the Coverage of Fallacies\n\nIn some cases, annotators may decide that an argument cannot be reconstructed and discard the HIT. This can for example happen, if the annotator considers the information provided by the HFC insufficient to reconstruct the argument, or if the cited publication itself is non-credible. Table 8 compares the annotation assignments and successful argument reconstructions. A total of 153 arguments were reconstructed by all assigned annotators. In 25 cases, one annotator, and in 6 cases, two annotators could not reconstruct the argument. Given the limited number of annotations and ambiguity when assigning fallacy classes, we aim to shed light into the recall of our detected fallacies. To this end, we compare the number of successfully reconstructed fallacious arguments with the number of detected fallacies (excluding interchangeable fallacies) in Figure 12. More annotators generally lead to more identified fallacies. The majority of arguments with successful reconstructions of two and three annotators comprise two or three distinct fallacies respectively.\n\nThe analysis indicates that Missci may lack comprehensiveness of fallacies, in arguments with fewer annotations. However, this does not affect our main objective since annotators are likely to identify the most severe fallacies, highlighted by the HFC, that violate strong inductive support (cf. §3.2). A single study, under specific conditions, rarely gives unconditional support for any claim c𝑐citalic_c without potential generalizations. While not necessarily or severely fallacious, these generalizations may be less emphasized by HFC, which makes them harder to detect as fallacious reasoning for the annotators. In real-world texts, identifying different fallacies among annotators is not unusual (Da San Martino et al., 2019), and distinguishing between fallacious and accurate reasoning can be subtle (Boudry et al., 2015).\n\nAppendix D Experiments\n\nD.1 Fallacious Premise Eva",
      "# [Who's Hiring?](https://whoshiring.xyz/)\n"
    ],
    "# Surge AI Company and Product Report\n\n## Company Overview\n\nSurge AI is a data curation company based in San Francisco, specializing in training data for artificial intelligence models. The company is known for its focus on providing high-quality training data to developers of AI systems, including large language models (LLMs). Surge AI operates through various subsidiaries, including Data Annotation Tech, which has gained attention for its role in the gig economy by hiring contractors to annotate data for AI training purposes [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n### Executive Leadership\n\nThe CEO of Surge AI is Edwin Chen. However, there has been a lack of communication from the company regarding its operations and the working conditions of its contractors, as noted by various sources. This silence may reflect a broader trend among tech companies to avoid negative press related to labor practices [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n## Product Overview\n\nSurge AI's primary product is its data annotation service, which supports the training of AI models by providing high-quality labeled data. This service is crucial for the development of AI systems, as it allows models to learn from human-generated content. The company employs a gig economy model, hiring contractors to perform data annotation tasks, which can include anything from writing to coding evaluations [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n### Market Position and Competitors\n\nSurge AI competes with other data curation companies such as Scale AI and Outlier. These companies also hire contractors to provide training data for AI models. The demand for such services has surged due to the rapid advancement of AI technologies, particularly in the context of large language models like OpenAI's ChatGPT [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n## Financials and Growth\n\nWhile specific financial details about Surge AI are not publicly available, the company is part of a growing sector that has seen significant investment and interest. The gig economy model allows Surge AI to scale its operations flexibly, responding to the fluctuating demand for AI training data. The company has been noted for its ability to attract a large number of contractors, with reports indicating that tens of thousands of workers may be active on its platforms at any given time [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n## Recent Developments\n\nSurge AI has been involved in discussions about the ethical implications of outsourcing data annotation work. Concerns have been raised regarding the lack of training and standards for contractors, which can lead to inconsistent data quality and ethical dilemmas in AI training [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai). The company has not publicly addressed these concerns, which may affect its reputation and operational practices.\n\n## Employee and Contractor Insights\n\nThe gig work model employed by Surge AI has attracted a diverse range of contractors, including students and professionals seeking flexible work opportunities. Reports indicate that some contractors have earned substantial income through data annotation tasks, with pay rates ranging from $20 to $45 per hour. However, there are also reports of job insecurity, with contractors sometimes facing abrupt account suspensions without explanation [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n### Worker Experiences\n\nFeedback from contractors has been mixed, with some expressing satisfaction with the flexibility and income potential, while others have raised concerns about the lack of support and communication from the company. This polarized feedback highlights the challenges of managing a gig workforce in a rapidly evolving industry [(CB Insights, 2023)](https://www.cbinsights.com/company/surge-ai).\n\n## Conclusion\n\nSurge AI operates in a dynamic and competitive landscape, providing essential data annotation services for AI training. While the company has positioned itself as a key player in the data curation market, it faces challenges related to labor practices and ethical considerations. Prospective candidates and investors should weigh these factors when considering engagement with Surge AI, as the company's future growth and reputation may be influenced by its handling of contractor relations and data quality standards. \n\nFor further verification and details, please refer to the original sources cited throughout this report."
  ],
  "lineage": {
    "run_at": "2025-04-01T14:14:05.826919",
    "git_sha": "6f872bf"
  }
}