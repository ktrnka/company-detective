{
  "summary_markdown": "# About Gable\n\nGable is a Seattle-based startup founded in 2019 by Chad (CEO), Adrian (CTO), and Daniel (Founding Engineer). The company was established after the founders experienced significant data quality and governance challenges at Convoy, a freight tech startup. Gable aims to revolutionize the data industry by fostering a data culture of collaboration, accountability, quality, and governance through its innovative data communication, change management, and collaboration platform [(Gable Company Overview, Gable.ai, Date Unknown)](https://www.gable.ai/blog/data-lineage-tools).\n\nGable specializes in data contracts, which are formal agreements that define the structure, format, and criteria for data sharing between producers and consumers. These contracts help ensure data quality, compliance, and governance throughout the data lifecycle. The company's key offerings include:\n\n- **Data Contracts**: Establish clear definitions and ownership of data, ensuring quality and compliance.\n- **Data Governance Solutions**: Tools and frameworks to manage data effectively and securely.\n- **Data Quality Management**: Strategies to maintain high data quality across various systems and processes.\n- **Data Lineage and Provenance**: Tracking the flow and transformation of data to ensure integrity and compliance [(Gable Company Overview, Gable.ai, Date Unknown)](https://www.gable.ai/blog/data-lineage-tools).\n\nGable serves a diverse range of clients, including organizations in finance, healthcare, retail, and technology sectors. Their solutions are designed to meet the needs of data teams, data engineers, analysts, and business leaders who require reliable and high-quality data for decision-making [(Gable Company Overview, Gable.ai, Date Unknown)](https://www.gable.ai/blog/data-lineage-tools).\n\nThe company operates on a B2B model, offering a platform for collaboration to write and execute data contracts, supporting communication between data providers and consumers [(Crunchbase, 2024)](https://www.crunchbase.com/organization/gable-f237). Gable has raised a total of $24 million in funding, with $17 million raised on July 26, 2024, and $7 million on September 12, 2023 [(Crunchbase, 2024)](https://www.crunchbase.com/organization/gable-f237).\n\n# Key Personnel\n\n- **Chad**: CEO, responsible for overall strategy and vision.\n- **Adrian**: CTO, oversees technology development and product innovation.\n- **Daniel**: Founding Engineer, focuses on engineering and product implementation [(Gable Company Overview, Gable.ai, Date Unknown)](https://www.gable.ai/blog/data-lineage-tools).\n\n# News\n\n## Financial Performance\n\nGable's financial performance has shown promising growth. In 2023, the company achieved an operating income of Baht 5,338 million, a 13% increase from the previous year. The gross profit margin remained stable at around 21%, with a net profit of Baht 253 million. The company’s backlog reached an all-time high of over Baht 4.5 billion, indicating strong future income potential [(GABLE delivers all-time high income, G-Able Public Company Limited, Date Unknown)](https://www.g-able.com/insights/g-able-enable-the-future).\n\n## Market Position and Growth Potential\n\nThe global data catalog market is projected to grow significantly, from $878.8 million in 2023 to $4,680.9 million by 2032, with a compound annual growth rate (CAGR) of 17.7%. Gable's unique positioning as a data contracts platform allows it to tap into this growing market by offering a proactive approach to data quality management, which is increasingly recognized as essential for modern organizations [(Top 5 Data Lineage Tools, Gable.ai, Date Unknown)](https://www.gable.ai/blog/data-lineage-tools).\n\n## Competitive Landscape\n\nGable competes with several established players in the workspace management and data lineage markets. Its primary competitors include Envoy, Robin, SpaceIQ, and OfficeSpace. Gable differentiates itself through its user-friendly interface, extensive integration capabilities, and flexible pricing model, which starts at $3 per seat per month for its HQ product [(Top Envoy Alternatives: Why Gable Is the Best Choice for Hybrid Workspaces, Gable, Date Unknown)](https://www.gable.to/blog/post/envoy-alternatives).\n\n## User Feedback and Market Sentiment\n\nUser feedback on Gable has been largely positive, with many praising its intuitive interface and responsive customer support. One user noted, “The employee experience has improved dramatically with Gable. It’s far superior to our previous systems” [(Top Envoy Alternatives: Why Gable Is the Best Choice for Hybrid Workspaces, Gable, Date Unknown)](https://www.gable.to/blog/post/envoy-alternatives).\n\n# Conclusion\n\nGable is well-positioned to capitalize on the growing demand for data management and workspace optimization solutions. With its innovative approach to data contracts and a comprehensive suite of products tailored for hybrid work environments, Gable is poised for significant growth. The company's strong financial performance, backed by a capable leadership team and positive user feedback, makes it an attractive option for prospective candidates and investors looking to engage with a forward-thinking organization in the data industry. For more information, interested parties can explore Gable's website or sign up for their product waitlist.",
  "target": [
    "Gable",
    "Gable",
    "gable.ai",
    [
      "data"
    ]
  ],
  "webpage_result": {
    "summary_markdown": "# Gable Company Overview\n\n## Company History\nGable was founded in 2019 by Chad (CEO), Adrian (CTO), and Daniel (Founding Engineer) after they experienced significant data quality and governance challenges while working at Convoy, a freight tech startup. They recognized that the data industry was lagging behind software engineering practices, particularly in managing data at the source. This realization led to the creation of Gable, aimed at fostering a data culture of collaboration, accountability, quality, and governance.\n\n## Services and Products\nGable specializes in data contracts, which are formal agreements that define the structure, format, and criteria for data sharing between producers and consumers. These contracts help ensure data quality, compliance, and governance throughout the data lifecycle. Key offerings include:\n\n- **Data Contracts**: Establish clear definitions and ownership of data, ensuring quality and compliance.\n- **Data Governance Solutions**: Tools and frameworks to manage data effectively and securely.\n- **Data Quality Management**: Strategies to maintain high data quality across various systems and processes.\n- **Data Lineage and Provenance**: Tracking the flow and transformation of data to ensure integrity and compliance.\n\n## Customers\nGable serves a diverse range of clients, including organizations in finance, healthcare, retail, and technology sectors. Their solutions are designed to meet the needs of data teams, data engineers, analysts, and business leaders who require reliable and high-quality data for decision-making.\n\n## Leadership Team\n- **Chad**: CEO, responsible for overall strategy and vision.\n- **Adrian**: CTO, oversees technology development and product innovation.\n- **Daniel**: Founding Engineer, focuses on engineering and product implementation.\n\n## Company Culture\nGable promotes a culture of collaboration and continuous learning. Employees express satisfaction with their growth and the opportunity to work on impactful products. The company values flexibility, adaptability, and a proactive approach to problem-solving, fostering an environment where team members can thrive and innovate.\n\n## Data Governance and Compliance\nGable emphasizes the importance of data governance and compliance, especially in light of evolving regulations like GDPR and the American Privacy Rights Act (APRA). They provide insights and strategies for organizations to navigate these challenges effectively, ensuring that data practices are ethical, transparent, and secure.\n\n## Conclusion\nGable is at the forefront of transforming data management practices through innovative solutions like data contracts. By addressing the critical issues of data quality, governance, and compliance, Gable empowers organizations to leverage their data effectively and responsibly.\n\nFor more information, visit [Gable's website](https://www.gable.ai/).",
    "page_markdowns": [
      "# [Data Contracts Platform](https://www.gable.ai/)\nData governance\n\nFederated Data: Advantages for Data Leaders\n\nTo date, centralized data systems have served an important purpose. Learn why federated data is proving to be the best way forward.\n\nData governance\n\nData Compliance: What You Need to Know in 2025\n\nData compliance often revolves around the \"now.\" But data leaders should look ahead to 2025 trends to ensure that they stay ahead of the curve.",
      "# [Gable Blog](https://www.gable.ai/blog)\nData governance\n\nFederated Data: Advantages for Data Leaders\n\nTo date, centralized data systems have served an important purpose. Learn why federated data is proving to be the best way forward.\n\nData governance\n\nData Compliance: What You Need to Know in 2025\n\nData compliance often revolves around the \"now.\" But data leaders should look ahead to 2025 trends to ensure that they stay ahead of the curve.\n\nData Quality\n\nFinancial Data Quality: Modern Problems and Possibilities\n\nMoney talks. But it's data that's walking the walk for modern banks and financial institutions. Learn why this all hinges on financial data quality.\n\nData products\n\nTop 5 Data Lineage Tools (+ How to Choose)\n\nThe need for high-quality data is surging. This means the ability for data teams to choose and use the right data lineage tools is paramount. Learn how.\n\nData Quality\n\nSemi-Structured Data: Examples and How to Manage\n\nMany things in data engineering are this or that. And that is good. But we do deal with some less-than-obvious concepts, like semi-structured data.\n\nData governance\n\nData Governance as Code: Modernize Data Governance\n\nData governance as code and RoboCop have lots in common. Both are cool. Both automate enforcement. And both should be taken seriously on their respective beats.\n\nData governance\n\nData Maturity Models: Measuring What Makes the Difference\n\nTime spent managing data does not an exceptionally data-driven organization make. And data maturity models are key for helping decision-makers understand why.\n\nData Quality\n\n7 Common Data Quality Issues (and How to Solve Them)\n\nCommon data quality issues aren't to be ignored, especially since each compounds under the pressures of big data. But data teams can beat them to the punch.\n\nData Quality\n\nData Quality Management: 6 Key Ingredients\n\nServing as the \"back of the house\" in the restaurant that is the data-driven organization, data quality management (DQM) is the secret to serving up success.\n\nData governance\n\nVetting Federated vs. Centralized Data Governance\n\nLearn why data leaders are weighing the benefits of federated vs. centralized data governance, in addition to one way of ensuring either can excel in practice.\n\nData governance\n\nAutomated Data Lineage: Why Do, How To, And Types Of Tools To Use\n\nIn theory, tracked data lineage is better than none at all. But in practice, automated data lineage processes are proving essential for modern organizations.",
      "# [Career](https://www.gable.ai/career)\n\"I’ve leveled up...\"\n\n\"Gable is my favorite company I've worked at so far in my entire career! In the year that I've been here, I feel like I've leveled up so much as an engineer. Also, I'm building a product that would have been a game-changer in my past teams which is immensely satisfying.\"\n\nSuzanne\n\nSoftware Engineer\n\n\"We quickly adapt...\"\n\n“I enjoy working at Gable because of the scrappiness and flexibility of the team. We are a small group which means we're able to quickly adapt if needed. I've also genuinely learned more from this job than any other job I've had in the past!”\n\nGeoffrey\n\nSoftware Engineer",
      "# [Legal](https://www.gable.ai/terms)\nGeneral Terms\n\nBy accessing or using the site, you agree that you have read and understood, and, as a condition to your use of the site, you agree to be bound by these terms and our privacy policy available at https://gable.ai/privacy. If you do not agree to the terms, then you do not have our permission to use the site. Your use of the site, and our provision of the site to you, constitutes an agreement by company and by you to be bound by these terms.\n\nEligibility\n\nYou must be at least 18 years old to use the Site. By agreeing to these Terms, you represent and warrant to us that: (a) you are at least 18 years old; (b) you have not previously been suspended or removed from the Site; and (c) your use of the Site is in compliance with any and all applicable laws and regulations.\n\nUse of the site\n\nSubject to your complete and ongoing compliance with these Terms, Company hereby permits you to use the Site for your personal non-commercial use only, provided that you comply with these Terms in connection with all such use. If any software, content or other materials owned or controlled by us are distributed to you as part of your use of the Site, we hereby grant you, a personal, non-assignable, non-sublicensable, non-transferrable, and non-exclusive right and license to access and display such software, content and materials provided to you as part of the Site. Your access and use of the Site may be interrupted from time to time for any of several reasons, including, without limitation, the malfunction of equipment, periodic updating, maintenance or repair of the Service or other actions that Company, in its sole discretion, may elect to take.\n\nRestrictions on your use of the site\n\nExcept and solely to the extent such a restriction is impermissible under applicable law, you may not: (a) reproduce, distribute, publicly display, or publicly perform the Site; (b) make modifications to the Site or any Materials; (c) use, reproduce or remove any copyright, trademark, service mark, trade name, slogan, logo, image, or other proprietary notation displayed through the Site; or (e) interfere with or circumvent any feature of the Site, including any security or access control mechanism. If you are prohibited under applicable law from using the Site, you may not use them.\n\nAccount information\n\nTo use the Site, you may need to create an account or link another account, such as your Apple, Facebook or Google account (“Account”). You agree to provide us with accurate, complete and updated information for your Account. You are solely responsible for any activity on your Account and for maintaining the confidentiality and security of your password. We are not liable for any acts or omissions by you in connection with your Account.\n\nYou must immediately notify us at security@gable.ai if you know or have any reason to suspect that your Account or password have been stolen, misappropriated or otherwise compromised, or in case of any actual or suspected unauthorized use of your Account. You agree not to create any Account if we have previously removed your, or we previously banned you from any of the Site, unless we provide written consent otherwise.\n\nInformation you submit\n\nDo not submit any information or other materials that you consider confidential or proprietary through the Site. If you choose to provide input and suggestions regarding us, our products or services, or problems with or proposed modifications or improvements to the Site (“Feedback”), then you do so on a non-confidential basis (regardless of any designation or indication to the contrary in the submitted information or any accompanying correspondence) and you hereby grant Company an unrestricted, perpetual, irrevocable, non-exclusive, fully-paid, royalty-free, transferable, sublicensable right to exploit the Feedback in any manner and for any purpose, including to improve the Site and create other products and services.\n\nOwnership; proprietary rights\n\nThe Site is owned and operated by Company. The “look and feel”, proprietary content, visual interfaces, graphics, design, compilation, information, data, computer code, and all other elements of the Site (“Materials”) provided by Company are protected by intellectual property and other laws. As between us, all Materials included in the Site are the property of Company or its third party licensors. Except as expressly authorized by Company, you may not make use of the Materials. Company reserves all rights to the Materials not granted expressly in these Terms. The Company’s name, logo and all related names, logos, product and service names, designs and slogans are trademarks of the Company or its affiliates or licensors. Other names, logos, product and service names, designs and slogans that appear on the Services are the property of their respective owners, who may or may not be affiliated with, connected to, or sponsored by us.\n\nThird party sites\n\nThe Site may contain links to third party websites. Linked websites are not under Company’s control, and Company is not responsible for their content.\n\nProhibited conduct. BY USING THE SITE YOU AGREE NOT TO:\n\nuse the Site for any illegal purpose or in violation of any local, state, national, or international law;\n\nviolate, or encourage others to violate, any right of a third party, including by infringing or misappropriating any third party intellectual property right;\n\ninterfere with security-related features of the Site, including by: (i) disabling or circumventing features that prevent or limit use or copying of any content; or (ii) reverse engineering or otherwise discovering the source code of any portion of the Site except to the extent that the activity is expressly permitted by applicable law;\n\nuse automation software (bots), hacks, modifications (mods) or any other unauthorized third-party software designed to modify the Site;\n\ninterfere with the operation of the Site or any user’s enjoyment of the Site, including by interfering with or disrupting any network, equipment, or server connected to or used to provide the Site;\n\nexploit the Site for any commercial purpose, including without limitation communicating or facilitating any commercial advertisement or solicitation; or\n\naccess or use the Site in any way not expressly permitted by these Terms.\n\nUpdating these terms\n\nWe may modify these Terms from time to time in which case we will update the “Last Revised” date at the top of these Terms. If we make changes that are material, we will use reasonable efforts to attempt to notify you, such as by e-mail and/or by placing a prominent notice on the first page of the Site. However, it is your sole responsibility to review these Terms from time to time to view any such changes. The updated Terms will be effective as of the time of posting, or such later date as may be specified in the updated Terms. Your continued access or use of the Site after the modifications have become effective will be deemed your acceptance of the modified Terms.\n\nIndemnity\n\nTo the fullest extent permitted by law, you are responsible for your use of the Site, and you will defend and indemnify Company and its officers, directors, employees, consultants, affiliates, subsidiaries and agents (together, the “Company Entities”) from and against every claim brought by a third party, and any related liability, damage, loss, and expense, including reasonable attorneys’ fees and costs, arising out of or connected with: (a) your unauthorized use of, or misuse of, the Site; (b) your violation of any portion of these Terms, any representation, warranty, or agreement referenced in these Terms, or any applicable law or regulation; (c) your violation of any third party right, including any intellectual property right or publicity, confidentiality, other property, or privacy right; or (d) any dispute or issue between you and any third party.\n\nWe reserve the right, at our own expense, to assume the exclusive defense and control of any matter otherwise subject to indemnification by you (without limiting your indemnification obligations with respect to that matter), and in that case, you agree to cooperate with our defense of those claims.\n\nDisclaimers; no warranties\n\nThe site and all materials and content available through the site are provided \"as is\" and on an \"as available\" basis. Company disclaims all warranties of any kind, whether express or implied, relating to the site and all materials and content available through the site, including: (a) any implied warranty of merchantability, fitness for a particular purpose, title, quiet enjoyment, or non-infringement; and (b) any warranty arising out of course of dealing, usage, or trade. Company does not warrant that the site or any portion of the site, or any materials or content offered through the site, will be accurate, uninterrupted, secure, or free of errors, viruses, or other harmful components, and company does not warrant that any of those issues will be corrected.\n\nNo advice or information, whether oral or written, obtained by you from the site or company entities or any materials or content available through the site will create any warranty regarding any of the company entities or the site that is not expressly stated in these terms. you understand and agree that you use any portion of the site at your own discretion and risk, and that we are not responsible for any damage to your property (including your computer system or mobile device used in connection with the site) or any loss of data.\n\nThe limitations, exclusions and disclaimers in this section apply to the fullest extent permitted by law. Company does not disclaim any warranty or other right that company is prohibited from disclaiming under applicable law.\n\nLimitation of liability\n\nTo the fullest extent permitted by law, in no event will the company entities be liable to you for any indirect, incidental, special, consequential or punitive damages (including damages for loss of profits, goodwill, or any other intangible loss) arising out of or relating to your access to or use of, or your inability to access or use, the site or any materials or content on the site, whether based on warranty, contract, tort (including negligence), statute, or any other legal theory, and whether or not any company entity has been informed of the possibility of damage. To the fullest extent permitted by law, the aggregate liability of the company entities to you for all claims arising out of or relating to the use of or inability to use the site or otherwise under these terms, whether in contract, tort, or otherwise, is limited to $10.\n\nEach provision of these terms that provides for a limitation of liability, disclaimer of warranties, or exclusion of damages is intended to and does allocate the risks between the parties under these terms. This allocation is an essential element of the basis of the bargain between the parties. each of these provisions is severable and independent of all other provisions of these terms. The limitations in this section will apply even if any limited remedy fails of its essential purpose.\n\nMiscellaneous",
      "# [Privacy Notice](https://www.gable.ai/privacy-notice)\nGeneral Terms\n\nThis Privacy Policy for Manifest Data Labs, Inc. d/b/a Gable (“Company”, “we”, “us” “our”) describes how we collect, use and disclose information about users of the Company’s website, www.gable.ai, applications, services, tools and features (collectively, the “Services”). For the purposes of this Privacy Policy, “you” and “your” means you as the user of the Services. Please note that the Services are designed for users in the United States only and are not intended for users located outside the United States.\n\nPlease read this Privacy Policy carefully. By using, accessing, or downloading any of the services, you agree to the collection, use, and disclosure of your information as described in this Privacy Policy. If you do not agree to this Privacy Policy, please do not use, access or download any of the services.\n\nUpdating this privacy policy\n\nWe may modify this Privacy Policy from time to time in which case we will update the “Last Revised” date at the top of this Privacy Policy. If we make material changes to the way in which we use information we collect, we will use reasonable efforts to notify you (such as by emailing you at the last email address you provided us, by posting notice of such changes on the Services, or by other means consistent with applicable law) and will take additional steps as required by applicable law. If you do not agree to any updates to this Privacy Policy please do not access or continue to use the services.\n\nCompany’s collection and use of information\n\nWhen you access or use the Services, we may collect certain categories of information about you from a variety of sources.\n\nSome features of the Services may require you to directly enter certain information about yourself. You may elect not to provide this information, but doing so may prevent you from using or accessing these features. Information that you directly submit through our Services may include:\n\nContact information, such as, name, email, job title, and employer. We collect contact information to communicate with you, provide you with the Services, and market to you.\n\nAccount information, such as username, password, and photo. We collect account information to maintain and secure your account with us. If you choose to use the Services and register an account, you are responsible for keeping your account credentials safe. We highly recommend that you do not share your username, password, or other access details with anyone else. If you believe your account has been compromised, please contact us immediately.\n\nAny other information you choose to include in communications with us, for example, when you email us.\n\nWe also automatically collect certain information about your interaction with the Services (“Usage Data”). To do this, we may use cookies. Usage Data may include:\n\nUnique device identifier\n\nDevice type, such as your phone, computer, or tablet\n\nIP address\n\nBrowser type\n\nDate and time stamps, such as the date and time you first accessed the Services\n\nOperating system\n\nLog data\n\nGeolocation\n\nWe useinformation we collect automatically to tailor features and content to you and run analytics and better understand user interaction with the Services.\n\nWe use the information we collect automatically to tailor features and content to you and run analytics and better understand user interaction with the Services.\n\nYour employer, we may receive your contact and account details from your employer if they register an account on your behalf.\n\nCareer websites, such as LinkedIn, which is used to obtain business leads for the Services, and to populate your contact information, such as, your employer and job title.\n\nMarketing databases or other data enrichment companies, which are used to better customize advertising, marketing to you, provide us with business leads for the Services.\n\nThird party platforms we use to communicate with you, for example, the Company’s Slack community, where you can communicate with us and send us information.\n\nAny information we receive from outside sources will be treated in accordance with this Privacy Policy. We are not responsible or liable for the accuracy of the information provided to us by third parties and are not responsible for any third party’s policies or practices. See Section 5 below for more information. In addition to the foregoing, we may use any of the above information to comply with any applicable legal obligations, to enforce any applicable terms of service, and to protect or defend the Services, our rights, and the rights of our users or others.\n\nHow the company shares your information\n\nIn certain circumstances, the Company may share your information with third parties for legitimate purposes subject to this Privacy Policy. Such circumstances include:\n\nWith vendors or other service providers, such as, identity identification companies, cloud storage providers, security vendors, and email providers.\n\nWith our affiliates or otherwise within our corporate group.\n\nTo comply with applicable law or any obligations thereunder, including cooperation with law enforcement, judicial orders, and regulatory inquiries.\n\nIn connection with an asset sale, merger, bankruptcy, or other business transaction.\n\nTo enforce any applicable terms of service.\n\nTo ensure the safety and security of the Company and/or its users.\n\nWhen you request us to share certain information with third parties, such as through your use of social media widgets or login integrations.\n\nWith professional advisors, such as auditors, law firms, or accounting firms.\n\nCookies and other tracking technologies\n\nDo Not Track Signals : Your browser settings may allow you to transmit a “Do Not Track” signal when you visit various websites. Like many websites, our website is not designed to respond to “Do Not Track” signals received from browsers. To learn more about “Do Not Track” signals, you can visit http://www.allaboutdnt.com/.\n\nCookies and other tracking technologies : Most browsers accept cookies automatically, but you may be able to control the way in which your devices permit the use of cookies. If you so choose, you may block or delete our cookies from your browser; however, blocking or deleting cookies may cause some of the Services, including any portal features and general functionality, to work incorrectly. If you have questions regarding the specific information about you that we process or retain, as well as your choices regarding our collection and use practices, please contact us using the information listed below.\n\nThird party websites and links\n\nWe may provide links to websites or other online platforms operated by third parties. If you follow links to sites not affiliated or controlled by us, you should review their privacy and security policies and other terms and conditions. We do not guarantee and are not responsible for the privacy or security of these sites, including the accuracy, completeness, or reliability of information found on these sites.\n\nInformation you provide on public or semi-public venues, including information you share on third-party social networking platforms (such as Slack) may also be viewable by other users of the Services and/or users of those third-party online platforms without limitation as to its use by us or by a third party. Our inclusion of such links does not, by itself, imply any endorsement of the content on such platforms or of their owners or operators, except as disclosed on the Services.\n\nData security\n\nPlease be aware that, despite our reasonable efforts to protect your information, no security measures are perfect or impenetrable, and we cannot guarantee “perfect security.” Please further note that any information you send to us electronically, while using the Services or otherwise interacting with us, may not be secure while in transit. We recommend that you do not use unsecure channels to communicate sensitive or confidential information to us.\n\nHow to contact us",
      "# [What is DataOps? What Leaders Need to Know](https://www.gable.ai/blog/dataops)\nSomething interesting is taking place in the world of DataOps right now. A big something. But what’s really interesting is what’s at play behind the scenes.\n\nAccording to our friends at Global Market Insights (GMI), the calculated annual growth rate (CAGR) of the DataOps platform marketplace is projected to grow 22% from 2023 to 2032 (i.e., less than one decade). By comparison, this is potentially 1% more than the much-buzzed-about low-code application marketplace is projected to grow during the same time.\n\nHowever, the factors driving DataOps aren’t quite as clear compared to low-code.\n\nData orchestration capabilities need to keep pace with the growing volume and complexity of Big Data, and this is part of the reason for this exceptional amount of growth. Improving customer service and experience, increasing operational efficiency, and maintaining competitive advantages are ongoing priorities for businesses.\n\nHowever, this near-exponential investment in DataOps may be due to a reckoning between two other causal trends—the increasing business need for real-time data insights and the growing impact of data governance and compliance globally.\n\nTo better understand why, let’s start by breaking down DataOps, covering its core principles, best practices, and implementation challenges within modern organizations.\n\nA basic definition of DataOps\n\nFor those who work in leadership or data-adjacent teams, DataOps is a lot like shifted paradigms—no doubt you’ve heard it mentioned while doing business. However, lacking any direct experience, what exactly DataOps is may be less than clear. Let’s correct this now.\n\nDataOps is short for Data Operations. It is a process-oriented methodology that shares and builds on many characteristics of Agile methodologies, DevOps, and lean manufacturing. Simply, the goal of DataOps is to reduce the cycle time of data analytics. In practice, it does so by streamlining collection from data sources to consumption by data consumers.\n\nBroadly speaking, the DataOps process is driven through an organized emphasis on automation, collaboration, and communication. For good reason, this means DataOps and DevOps cross streams quite often in practice. Both are instrumental in keeping Big Data and business value from being at odds.\n\nWe’ve done our best to compare and contrast both processes elsewhere. But know that exploring the core pillars of DataOps helps clarify the distinct role it plays.\n\nCore principles of modern DataOps\n\nAndy Palmer coined the term \"DataOps\" in 2015, describing it as the intersection of data engineering, data quality, and data integration with a focus on various data professionals in a given organization communicating and collaborating to increase the velocity, reliability, and quality of data analytics.\n\nWhile the concept and practice of DataOps has evolved and expanded beyond Palmer’s definition the core principles that enable professionals to put DataOps into practice remain largely the same:\n\n1. Automation and Continuous Integration and Deployment (CI/CD)\n\nThe beating heart of DataOps is automation, which aims to reduce manual efforts related to data validation, integration, and deployment processes.\n\nThis often includes automating data ingestion, testing, monitoring, and deployment within a build/deployment pipeline to ensure both consistency and reliability.\n\n2. Agile and lean methodologies\n\nPractitioners work to streamline data management processes by incorporating agile and lean methodologies.\n\nAgile’s focus on flexibility, continuous improvement, and the delivery of high-quality products in short cycles enables data teams to accelerate experimentation and adaptation based on feedback. Lean methodologies, in turn, guide teams to streamline data pipelines, minimize inefficiencies, and ensure that data delivery remains firmly coupled to business needs.\n\n3. Collaboration and alignment\n\nEffective DataOps encourages a culture of collaboration and alignment among cross-functional teams, which typically includes data engineers, scientists, and business stakeholders.\n\nFostering collaboration in this fashion ensures data products align with business needs and that data analysts can deliver all insights efficiently.\n\n4. Cloud-first and scalable infrastructure\n\nModern DataOps ecosystems should prioritize cloud-based solutions for optimal scalability and flexibility.\n\nThis principle specifically supports distributed data processing and storage, enabling organizations to scale data operations as needed.\n\n5. Highly automated and continuous processes\n\nDataOps ecosystems should feature high levels of automation to manage the scale and scope of enterprise data efficiently and effectively.\n\nIn practice, this often includes automating the cataloging, movement, and organization of data, in addition to testing and releasing processes.\n\n6. Openness and interoperability\n\nAn ecosystem in which DevOps practitioners leverage best-in-class, open-source, and potentially free tools is essential for innovation. The inverse also holds true—DataOps practitioners should avoid reliance on single, proprietary platforms (as opposed to a variety of tools that are easy to integrate and replace).\n\nThis ease of integration should also apply to a broad spectrum of potential data sources (e.g., data lakes, data warehouses) to improve data quality and governance.\n\n7. Data quality and governance\n\nImplementing robust data governance guidelines and practices is essential to ensure high data quality.\n\nAt a minimum, governance should involve data validation, cleaning, and reconciliation processes which can ensure accuracy and reliability throughout the data lifecycle.\n\n8. Ephemeral environments and code reuse\n\nEphemeral environments are temporary by nature, so using them for testing further enhances flexibility and accelerates development. As such, they reduce the risk of conflicts between environments while promoting resource efficiency.\n\nCode reuse helps practitioners maintain consistency, reduce errors, and save time by avoiding duplications of effort. Additionally, containerization encapsulates applications and their dependencies into containers that can run reliably in different computing environments.\n\n9. Monitoring, observability, and customer centricity\n\nDataOps practitioners should prioritize continuous monitoring and observability of data pipelines, ensuring data availability, performance, and security. This is vital for identifying, addressing, and resolving issues as quickly as possible.\n\nWhile DataOps practitioners focus on reducing cycle times for data delivery, enabling faster insights, and improving data-driven decision-making, ultimately everything done must remain rooted in delivering value to the organization’s end-users and customers.\n\nBeing such an elemental aspect of any data practice, it’s also beneficial to explore how other data leaders articulate their core principles of DataOps. For an excellent perspective to which we can compare and contrast the above, we recommend looking at DataKitchen’s seminal DataOps Cookbook (that is, after finishing our own article, here, of course).\n\nDataOps best practices\n\nIf core principles are one side of the DataOps coin, best practices are the other. Without them, no amount of core principles would allow organizations to actively streamline their data management processes, accelerate their insight generation, and (perhaps most fundamentally) improve data quality.\n\nBecause of this, DataOps best practices naturally intertwine with the principles outlined above. But the key best practices are still worth detailing, as they are applicable across industries and organizations:\n\nFoster a collaborative culture\n\nThe existence of departmental silos within organizations is understandable. But they aren’t acceptable. This is why DataOps best practices begin by breaking down obstacles and fostering communication and collaboration between teams—data engineers, data scientists, business users, stakeholders, and operations.\n\nDataOps makes data quality and accessibility a shared responsibility across an organization, which, in turn, sets the stage for all best practices that follow.\n\nAdopt a customer-centric approach\n\nToo often, adopting a customer-centric approach emerges as an afterthought in the practice of DataOps. This borders on being a tragic irony, as the benefits of DataOps itself—enhanced value delivery, promoting agility and responsiveness, driving innovation, fueling trust and loyalty, etc.—can only be fully realized by engaging with end-users to understand their needs, challenges, and desires.\n\nImplement agile methodologies\n\nLook to agile practices like sprints and scrums to manage data projects, allowing for rapid iteration and responses to change. Practitioners can also use Agile approaches to prioritize work based on business needs and value.\n\nHowever, it bears noting that when practitioners seek to leverage Agile as a DataOps best practice, they must ensure its impact is balanced and holistic within the organization. When employed dogmatically, these Agile methodologies can muddle the practice of proper documentation, over-complicate data management, erode data quality for the sake of responsiveness, and potentially introduce security and compliance risks.\n\nFor these reasons, make sure that Agile within your organization is used as part of the overall DataOps solution, not a solution unto itself.\n\nAutomate data pipelines\n\nActively implement CI/CD pipelines in order to automate data integration, testing, deployment, and monitoring processes. In addition to this best practice of reducing manual efforts and errors, CI/CD pipelines help ensure seamless, automated updates and deployments.\n\nEmbrace continuous testing\n\nLeverage automation to test data quality, data integration, and performance throughout the organization’s data lifecycle.\n\nFurthermore, test-driven development (TDD) approaches should be adopted for data-related code and pipelines. TDD encourages earlier issue identification and potential integration issues while contributing to overall data quality.\n\nMake version control ubiquitous\n\nTrack changes and facilitate collaboration by utilizing version control for all data assets—code, configurations, and data modeling, to name a few.\n\nAdditionally, data versioning strategies should be considered to manage changes in datasets. Doing so enables reproducibility and replicability, supports the experimentation and iteration that DataOps champions, and allows organizations to demonstrate the lineage and provenance of their data.\n\nObsessively monitor data quality and performance\n\nThe ability to identify and solution for issues quickly requires the continuous monitoring of pipeline performance and data quality.\n\nEstablishing key performance indicators (KPIs) and metrics related to quality is itself key for operationalizing effective monitoring capabilities.\n\nEnsure data security and compliance\n\nData security, privacy, and compliance checks should be embedded through data pipelines to protect sensitive information while helping the organization comply with all relevant regulations (e.g., GDPR, CCPA).\n\nThese compliance checks also require regular reviews, and security practices must be updated to keep pace with ever-evolving threats and regulations.\n\nInvest in scalable and flexible infrastructure\n\nUtilize cloud services and technologies that bolster operational pillars of effective DataOps, scalability, optimal data processing, and organizational flexibility.\n\nIn doing so, data teams should consider adopting data virtualization and containerization capabilities to improve agility and resource efficiency.\n\nLeverage metadata management while planning for growth\n\nWork to implement robust metadata management practices to improve data discoverability, understanding, and governance.\n\nAs part of planning for future (perhaps inevitable) growth, design data architectures and systems to allow for easy adaption and scaling. Use metadata to automate data lineage, data cataloging, and impact analysis.\n\nEmbrace ongoing learning\n\nAs part of laying the foundations for future growth, DataOps initiatives should encourage team members to continually seek out, evaluate, and adopt emerging technologies and practices that will benefit the organization over time.\n\nDataOps is a journey, not a destination. As such, opportunities and areas of improvement should always be identified as part of a culture of testing, learning, and growing.\n\nCommon roadblocks to DataOps implementation (and how data contracts help)\n\nWhether an organization is just getting off the ground or has already experienced some measure of success, DataOps practices may be poorly defined or functionality non-existent. This is also common and commonly attributed to one or a combination of many of the challenges that follow. Fortunately, drafting and implementing a robust data contract can help in all cases.\n\nChange-averse cultures\n\nIt’s not uncommon for progressive thinkers to face resistance from within when trying to inspire a shift towards more collaborative, agile approaches to data management. Reluctance to adopt new processes (even those that are clearly beneficial) in addition to existing departmental silos can hinder DataOps initiatives before they can even begin.\n\nIn these situations, the data contract drafting process can act as a cultural balm, as it necessitates a clear definition of expectations, responsibilities, and roles of all parties involved in data management and usage (not just those directly involved in data analytics). The drafting process also mitigates resistance to new workflows by setting and/or codifying standardized processes all stakeholders must agree upon.\n\nSkill or knowledge deficits\n\nEven a modest implementation of DataOps requires a healthy mix of skills that span data engineering, data science, software development, and operations. Depending on their size or maturity, an organization may lack the diverse skill set and experience needed to integrate these distinct disciplines effectively.\n\nNo data contract is capable of directly addressing gaps in skills and experience. The implementation of data contracts does, however, clarify standards and requirements for data security, access, and quality. As such, they can indirectly guide employee training and development.\n\nInadequate data governance\n\nAs mentioned, effective DataOps relies on the foundation of solid data governance. Therefore, organizations may struggle to implement governance frameworks that are both robust and agile enough to support modern DataOps practices.\n\nData contracts directly support governance within an organization by establishing clear guidelines for data usage, sharing, and management. The framework for compliance and data quality standards established as they’re drafted makes governance more actionable and aligned with ensuing DataOps goals.\n\nComplexities regarding data integration\n\nThe ability to integrate data from a variety of sources presents significant technical challenges, especially in complex or legacy IT environments. This complexity can stall the progress of DataOps implementation by making data pipelines hard to manage or brittle.\n\nConversely, data contracts simplify integration efforts by specifying data interfaces, standards, and formats. This ensures that raw data from any number of sources will be compatible with the organization’s data infrastructure and can be processed and analyzed with optimal efficiency.\n\nPervasive data quality issues\n\nPoor data quality is (unfortunately) a common challenge in the business world, undermining analytics and eroding trust in data-driven decision-making. This can be an open secret too, with employees painfully aware of the issues substandard data is causing while struggling to quantify what exactly is to blame.\n\nThe metrics, validation processes, and remediation steps for non-compliance that data contracts define can make this a non-issue within organizations. This proactive approach (which is always ideal, especially in enterprise data environments) quickly becomes instrumental in maintaining high data quality across the organization.\n\nDifficulties in scaling data operations\n\nFinally, as organizations grow, it’s increasingly challenging to scale data operations efficiently while maintaining data quality. DataOps aims to address scalability issues but, ironically, a lack of foresight and flexibility regarding processes and infrastructure can prevent this from happening.\n\nData contracts circumvent these issues through the guidelines and expectations for data infrastructure, processing capabilities, and performance metrics they crystalize. This ensures that as the volume of data an organization must subsist on grows, systems and processes adapt and scale accordingly.\n\nDrafting an optimal DataOps process\n\nIt’s clear that DataOps functions best at the genetic level of data-driven organizations. It’s also clear that, given such high stakes in the market, business leaders should be doing everything in their power to get their own DataOps right.\n\nAs covered in the last section, data contracts serve as an excellent solution to ensure this happens. That said, the benefits these contracts bring to a data-centric organization extend far beyond DataOps.\n\nFor a quick, digestible, informative primer on data contracts, give Why Data Leaders Opt for Ounces Over Pounds a read.\n\nThis article is part of our blog at Gable.ai — where our goal is to create a shared data culture of collaboration, accountability, quality, and governance.\n\nCurrently, our industry-first approach to drafting and implementing data contracts is in private Beta.",
      "# [About Gable](https://www.gable.ai/about-gable)\nIn 2019, the Gable co-founders: Chad (CEO), Adrian (CTO), and Daniel (Founding Engineer) worked together on the Data Platform team at a late-stage freight tech startup called Convoy. Data was incredibly valuable at Convoy. It drove everything from a central pricing model to dashboards that powered day-to-day business operations. Despite this, data scientists, analysts, and data engineers were constantly dealing with data quality, data governance, and change management issues stemming from issues with upstream source data.\n\nAfter spending time talking to dozens of data teams, the trio realized that the data industry’s approach to managing data at the source was 15 years behind software engineering. Data contracts, integration testing, unit testing, diffs, and monitoring were all sorely lacking outside the Data Warehouse. This caused data quality issues to cascade from upstream sources into the analytical environment spurring an overflow of failed tests and randomly changing data - a problem that made data products fundamentally unscalable. Shortly after, Gable was born, with the mission of creating a data culture of collaboration, accountability, quality, and governance.",
      "# [4 Best Data Producer Practices to Improve Your Data Quality](https://www.gable.ai/blog/data-producers)\nData engineering teams and data producers can find it hard to collaborate within an organization for a number of reasons.\n\nPoor data quality is one of them.\n\nFor example, a customer’s address may be recorded incorrectly, which can affect their delivery. Sometimes, there are inconsistent data formats (e.g., inconsistency between two datasets). These issues can make data integration tricky and hamper data analytics. As a consequence, you risk dealing with outages and lose a lot of time that goes into fixing things.\n\nThat’s precisely why you need to gain a thorough understanding of data producers, assess their relationship with data consumers, and follow best practices for data producers to minimize data quality issues and improve your data management.\n\nWho and what are data producers?\n\nA data producer is anything that collects, processes, generates, and stores data that’s relevant to your organization and makes it available for data consumers. This can be a user interface, service, device, system—or human.\n\nData producers serve a key role in data lifecycle as the main source of truth. This information is fed into analysis and decision-making processes. Since data producers often generate unstructured data or raw data, it needs to undergo further processing in order to derive meaningful insights from it.\n\nFor example, a point-of-sale (PoS) system is a data producer for a retail company. It generates raw data in the form of sales transaction records, including customer information, product ID, and purchase details. You can perform processing and analysis on this data via customer segmentation or sales trend analysis to understand consumer buying behavior.\n\nSoftware engineers, on the other hand, are also data producers because they develop and maintain systems and applications that generate large amounts of data. They create transactional databases, message queues like Kafka topics, and other tools that produce data.\n\nData producers vs. data consumers\n\nWhile data producers generate data, a data consumer is an entity that uses it. Data consumers copy this data, perform data transformations on it, or send it to other systems. Some examples of data consumers include marketing automation platforms, BI platforms, data analysts, and data scientists. In the case of data analysts, Python, SQL, and other tools can analyze, transform, or visualize data.\n\nTechnical overview of data producers\n\nConsider an ecommerce website that uses a database to store product information, customer profiles, and transaction records. The website's API serves as the intermediary, enabling seamless communication between the database and the front-end interface. The website provides users with a user-friendly interface to browse products, add items to their cart, and complete purchases.\n\nWhen it comes to data producers, your data follows a unidirectional path. In other words, data only flows upstream or downstream at any given time. In this example, the data follows a unidirectional flow, starting from the database, where product information and customer details are stored. The API then processes this data and delivers it to the front-end interface, allowing users to view product listings, add items to their cart, and make purchases. User interactions with the front-end interface, such as selecting products and completing payments, are returned to the API and then stored in the database.\n\nWhat you should keep in mind is that a data producer can function as a data consumer in a different context. The database functions as the data producer when it generates and stores data for the website. The API is the data consumer when it retrieves the data from the database.\n\nHowever, the API becomes the data producer when the front-end interface (acting as a data consumer) calls it to retrieve data. Similarly, the front-end interface can become a data producer for the customer who is now the data consumer that goes through the information provided on the website.\n\nData producer examples\n\nData producers can consist of any of the following:\n\nSoftware engineers act as data producers when they develop applications or systems that generate data during user interactions.\n\nSales associates contribute as data producers when they record customer interactions and sales transactions into company systems. The data they generate helps to improve customer relationship management and boost sales.\n\nCustomers become data producers by interacting with the company’s platforms via online purchases and social media engagement. Their activities generate valuable data on user preferences, behaviors, and feedback. This data helps to analyze and improve customer experience in the future.\n\nBest practices for data producers\n\nStruggling to maintain standardized data formats and failing to streamline data integration can leave your organization behind the curve and impact your decision-making processes. Data engineering managers should consider the following best practices for data producers to improve data management within their organization.\n\n1. Understand your data sources\n\nYou need to understand your data sources when it comes to data producers. When you assess how the data was created and its context, you can identify potential inaccuracies, biases, or limitations.\n\nFor instance, an automated employee attendance tracking system is a data producer. The system serves as the data producer by generating and recording employee attendance data. Understanding the data source—in this case, a biometric attendance system—allows the office management to identify any potential inaccuracies or limitations. They might recognize that the system may not be able to capture nuanced attendance details, such as the reasons for late arrivals. By reviewing these limitations, office management can implement relevant initiatives such as periodic manual checks to provide more accurate information for data producers.\n\n2. Introduce metadata management\n\nMetadata management provides context and information about the data. It helps data producers understand the structure, meaning, and relationships within a dataset. For instance, data producers, such as customer service agents, need to know how the customer data is organized with the CRM system.\n\nMetadata management includes documenting and categorizing different data types within the CRM system via a data catalog. This can help agents understand whether the data is numerical, textual, or categorical. They can also learn about relationships between different data entities. For example, it can uncover how customer data is linked to past purchases or interactions.\n\n3. Implement data quality assurance\n\nData quality assurance is an ongoing process to ensure data is accurate, reliable, consistent, and relevant. It includes using a wide range of techniques and practices to maintain and improve the quality of data that producers generate. This process involves validating data at the point of entry, identifying and resolving errors within it, and ensuring it remains consistent across different systems throughout the organization.\n\nConsider a financial firm where a transaction monitoring system serves as a data producer. The system generates data on customer transactions, account activities, and financial operations. Implementing data quality assurance in this context includes validating how accurate the transaction data is, ensuring data is standardized and consistent across different accounts, and detecting any potential fraudulent activities. This can be done through real-time transaction monitoring, anomaly detection algorithms, and anti-money laundering (AML) compliance checks.\n\n4. Use a data collaboration management platform\n\nGartner analysts predict that by next year, 50% of businesses will embrace a modern data quality solution.\n\nAfter GitHub was launched in 2008, it quickly became a must-have tool for software development teams throughout the world for companies of all scales. GitHub helped teams to manage and track code effectively in a collaborative environment.\n\nSimilar to how GitHub was highly needed for software teams, there’s a need for a collaboration management tool for data teams. Fortunately, Gable.ai fills this vacuum. Gable.ai can bridge the gap between data producers and data consumers. By introducing data contracts and a data collaboration system, the platform can help to improve data quality, consistency, and communication.\n\nFor example, if you have an order processing system as a data producer and an inventory management system as a data consumer, Gable.ai can create data contracts for them. These contracts define specific data parameters that are required by the inventory system and ensure that the order processing system produces data according to its needs.\n\nRevolutionize the way you communicate data between your data producers and consumers",
      "# [Data Debt: What Is it and How to Avoid It](https://www.gable.ai/blog/data-debt)\nAccruing data debt might be the cost of doing business in today's digital economy. But, just like its financial cousin, data debt can cost a business dearly if left unmanaged.\n\nAnd, while the monetary analogy makes for a helpful onramp, it's crucial to appreciate the unique and specific impacts data debt has on organizations. While gaining this appreciation, it's also essential to differentiate data debt from technical debt—an analog that occurs in data engineering and software departments.\n\nData debt, to begin with, refers to shortcuts and compromises made within an organization related to data quality, data architecture, and data management in an effort to accelerate access to data. As opposed to creating immediate issues, data debt accumulates over time and can create significant, long-term challenges that, ironically, \"seem to come out of nowhere.\" And, while a majority of modern business models are susceptible to these effects, data debt is particularly troublesome within organizations for whom accessible, reliable, high-quality data is mission-critical.\n\nAlternatively, for technical debt, the causal decisions often involve hardware and software-related factors. While the \"costs\" associated with correcting technical debt can impact an entire organization, the damage inherent in data debt can be far more insidious.\n\nData is increasingly—if not overwhelmingly—fueling the engines of modern business. Poor data quality, compounded by an accumulation of data debt, compromises data-driven decision-making.\n\nWhat's more, left unchecked, data issues can also lead to operational inefficiencies, hamper scalability, harm customer trust, increase security and compliance risks, and more.\n\nFor these reasons, proactively handling data debt should be considered mission-critical. And the ability to do so hinges on helping stakeholders appreciate the multitude of ways data debt can damage an organization.\n\n13 symptoms that may mean data debt is sinking the ship\n\nIntegration issues: When a company moves to adopt new tools or systems, data debt begins to complicate the integration process, leading to delays, complexity, and errors. This same situation can occur when two companies merge and are forced to reconcile two drastically different data systems.\n\nProject delays: Projects in highly data-dependent departments (e.g., IT and product development) may be the first to slow down, be put on hold, or begin going over budget as teams increasingly deal with inconsistencies or proper data hygiene.\n\nSystem degradation: Data debt can begin to compound data integrity, creating malfunctions, service errors and outages, or even complete system failures.\n\nPoor decision-making: It’s admirable when an organization’s leadership tries to use data to make better decisions. But data debt can begin empowering sub-optimal strategies and actions that cause more harm than good. In this sense, no data truly is better than bad data.\n\nMissed opportunities: As data grows untrustworthy or begins to lag behind real time, leadership will also struggle to capitalize on market trends, competitive intel, or the evolving needs of their own customers.\n\nReduced productivity: Employees who end up (re)cleaning, transforming, and validating data are spending less time on their own tasks. As data debt snowballs, inefficiencies and lessening throughput do as well.\n\nIncreasing operational costs: The constant rework needed to counteract an organization’s growing debt begins increasing direct costs like bringing in more resources to help, and indirect costs related to lost time and effort.\n\nSecurity vulnerabilities: Data debt can begin to erode overall security, leading to lax user access management, inadequate encryption, or outdated data storage protocols that begin exposing the organization to unacceptable amounts of risk.\n\nRegulatory and legal issues: Common debt contributors make it exceptionally difficult to handle user data with the same level of integrity and transparency once limited to a few specific industries, like finance and health care. But, while the scope of who needs to clear regulatory bars has changed, the consequences of failing to do so haven’t, often resulting in severe penalties and/or fines.\n\nDecreasing employee morale: We’ve touched on impacts ranging from projects and processes to workflows and costs. Unfortunately, data debt can also announce itself through the toll it takes on employee wellbeing. Frustration builds as day-to-day employees continually deal with data-related fire drills, leading to low morale and updated LinkedIn accounts.\n\nDissatisfied customers: Ongoing data issues eventually leech out through the walls of the organization as billing mishaps, ineffective customer support, misleading product recommendations, and poor customer experience begin frustrating customers.\n\nBrand reputation damage: The same data quality issues that begin to eat away at customer satisfaction can also harm an organization’s reputation within its industry. This, in turn, puts the screws to customer acquisition and retention.\n\nDulling competitive edge: Companies that manage data effectively generate insights faster, utilize them better, respond to market changes quicker, and not only innovate but do so more rapidly. For organizations drowning in data debt, the exact opposite holds true. And it’s these organizations that, sooner or later, find themselves losing step with competitors.\n\nBest practices for managing data debt\n\nFortunately, despite all the factors that can contribute to data debt within an organization, there is an array of best practices that business leaders can champion to counteract debt’s ability to accrue. Broadly, these best practices can be lumped into three categories: procedural, technological, and cultural. Or, as it’s commonly known in reference to digital transformation, “people, processes, and technologies.”\n\nProcedural best practices\n\nThese best practices begin and end with instituting and supporting a robust data governance framework. To counteract data debt, this framework needs to clearly outline all methodologies, use cases, procedures, and policies related to the data lifecycle.\n\nThe governance framework should be employee-accessible, ensuring individuals at all levels of the organization understand data standards and how they can avoid contributing to poor-quality data. These efforts should also include training and workshops, so the entire organization gets on (and stays on) the same page regarding data management best practices.\n\nAs you develop your governance framework, put a system in place for documenting how data is collected, processed, and stored. Plan to use this system as a foundation for clear data lineage procedures in order to benefit from the ability to trace and map data’s unique journey throughout your organization.\n\nProcedures also need to account for data retention policies, outlining where data should be retained, for how long, and whether it should eventually be archived or deleted entirely. Audit processes should then be put in place so that data is regularly reviewed for consistency, accuracy, and relevance.\n\nTechnological best practices\n\nNext, turn your attention to tools and technology that actively work against data debt. Ideally, this begins by modernizing your data infrastructure. Data should be migrated carefully from any legacy systems to more agile, efficient, and scalable systems. And cloud-based solutions continue to make this increasingly easy to implement.\n\nConsider introducing data integration platforms to keep the merging, cleaning, and integration of data from different sources streamlined over time. Metadata management systems make it easier to manage, store, and access valuable context about data as it flows into, and through, your organization. Use data quality tools and automated data validation so that new data is validated against a specific set of standards, and corrected automatically when those standards aren’t met.\n\nAnd while access to data documentation and context should be widely available, access to the data itself shouldn’t be. By implementing access control tools you can dial in user permissions, ensuring only specified individuals can access and modify data.\n\nCultural best practices\n\nWith proper processes and technologies in place, you must absolutely address the human element inherent in an organization’s data debt.\n\nStart with buy-in from leadership because data quality is everyone’s responsibility. Without executives and stakeholders making this clear, data quality within an organization will rot from the roots up—diligent, day-to-day processes ultimately keep organizational data aligned with the truth. It’s important, then, to ensure top management commits and is ready to take accountability for their organization’s data debt. Leadership will also need to ensure best practices are funded and adopted.\n\nWith leadership behind these efforts, a culture of data ownership can actually be fostered. As employees begin to benefit from data debt mitigation, it will be easier for peers to hold each other accountable for good data management and contributing to data quality.\n\nAs this sense of ownership takes hold, encourage a collaborative environment where departments work together on data projects, as this requires unified standards, promotes data literacy, and breaks down silos.\n\nKeep communication channels open so that your increasingly empowered employees can easily suggest improvements and report data issues as they arise. Comparing and contrasting feedback from different departments can uncover valuable insights. And, finally, actively reward data hygiene.\n\nA natural by-product of these best practices is that the idea of data quality and data debt will become much more tangible. Reinforce this tangibility by recognizing and rewarding teams and individuals who maintain the highest standards of data quality and management.\n\nData contracts: 10 ways better data agreements and specifications are paving a data debt-free future\n\nData contracts can play a pivotal role in minimizing or mitigating data debt. At its core, a data contract is a formal agreement or specification that outlines the format, structure, and semantics of data. They are particularly important when different systems or services interact with one another, ensuring a standardized and expected format of data exchange. Here's how they can help:\n\nStandardization: Data contracts ensure a consistent structure, which means that data from different sources or teams adheres to a unified format. This reduces discrepancies and inconsistencies, a common form of data debt.\n\nValidation: Data contracts can be used as a validation mechanism, ensuring that incoming or outgoing data meets specific criteria or standards before processing. This can prevent inaccurate or corrupt data from entering the system.\n\nDocumentation: A well-defined data contract serves as a form of documentation that’s version controlled, clarifying how data should be structured, what each attribute means, and any constraints on the data. This reduces the chances of misunderstandings or misinterpretations.\n\nInteroperability: As organizations grow, they may integrate multiple systems, tools, or external services. Data contracts ensure seamless integration by setting clear expectations about how data should be sent and received between systems.\n\nReduction in ambiguity: With clear data contracts, there's less guesswork or ambiguity involved in how data should be managed or understood, reducing the risk of errors.\n\nEasier troubleshooting: When issues arise, having a data contract in place makes it easier to pinpoint deviations from the expected data format, speeding up troubleshooting and resolution processes. Contracts also ensure that the correct data owners are contacted based on the specific issues at hand.\n\nSupport for evolution: As data needs change, data contracts can be versioned, allowing for organized transitions and updates. This ensures that even as changes occur, there's a clear record of different data formats and structures over time.\n\nEfficiency in collaboration: When different teams or departments collaborate, having clear data contracts reduces friction and misunderstandings. Everyone knows what to expect, ensuring smoother collaboration.\n\nTransparency and trust: For consumers of the data (which might be internal teams or external partners), a clear contract gives confidence in the data's consistency and quality, fostering trust.\n\nEnhanced compliance: For industries with stringent regulatory requirements around data, having clear data contracts can assist in ensuring compliance by setting and following clear data standards.\n\nTo harness these benefits, it's essential to ensure that data contracts are kept up-to-date, widely accessible to relevant stakeholders, and strictly enforced.\n\nAnd that’s the core principle Gable was designed to address. Join our beta waiting list to be one of the first in your field to learn how data contracts are foundational aspects of a strong data strategy, effectively curbing the accrual of data debt.\n\n‍",
      "# [Data Modeling: Definition, Types, and Challenges](https://www.gable.ai/blog/data-modeling)\nServing as a (very real, fully accredited, we swear) 101-level collegiate course, this blog article aims to lay a solid, real-world-based foundation regarding the concept and practice of data modeling.\n\nAs such, the article will include a summary of data modeling’s historical prevalence in data engineering, its more recent dissolution, a definition of the concept, and different methods of use.\n\nWe’ll conclude by exploring why any attempt to discuss the benefits of one type over another consistently equates to booting a hornet’s nest.\n\n‍\n\n‍\n\nThis foundation will serve as a gateway for newer data engineers, function as a juicy target of ridicule for the more seasoned, and will act to foster an appreciation for the role data contracts will play in data modeling’s future.\n\nCourse schedule:\n\nData modeling: An overview\n\nData modeling defined\n\nCommon types of data models\n\nCauses of controversy in the data modeling space\n\nRestoring the model of balance\n\nSuggested next steps\n\n1. Data modeling: An overview\n\nAt one point in the not-too-distant past, data modeling was the cornerstone of any data management strategy. Due to the technical and business practices that were predominant at the end of the 21st century, data modeling at its zenith placed a strong emphasis on structured, well-defined models.\n\nHowever, in the late 2000s, the emergence of major cloud service providers like Google Cloud Platform, Microsoft Azure, and Amazon Web Services (AWS) enabled cloud computing to gain traction within business organizations.\n\nBy the end of that same decade, the benefits of scaleable, on-demand computing resources led to a proper surge within business organizations, which then led to the proliferation of what is now commonly referred to as the modern data stack—a group of cloud-based tools and technologies used for the collection, storage, processing, and analysis of data.\n\nCompared to the at-the-push-of-a-button benefits available on demand, data modeling was then seen by a growing number of practitioners as rigid and inflexible. Data modeling takes time. It can get complicated. The costs and overheads associated with the process reflected this. Perhaps most damaging at the time, it became easy to frame data modeling as a bottleneck—dead weight hampering the speed and flexibility of modern data management.\n\nHowever, this overemphasis on speed and flexibility and the underutilization of data modeling wasn’t sustainable. Though there is no specific “breaking point” to point to, by the mid-2010s, these issues became increasingly attributable to data modeling’s diminution.\n\nWhile far from exhaustive, increasingly common factors helped to precipitate this recalibration in the data space:\n\nData governance challenges: The abundance of cloud-based data storage and processing fueled an explosive increase in the data sources and repositories the average organization had access to. This sudden abundance, in turn, intensified the maintenance of data quality, security, and compliance, irreparably complicating the governance process.\n\nData quality issues: The fevered rate at which cloud-based solutions were adopted resulted in the neglect of data modeling and proper data architecture, resulting in inconsistencies, data quality issues, and difficulties in data integration.\n\nLack of standardization: While cloud environments freed teams to use various tools and platforms, the consistency of data management practices degraded, making it harder to ensure consistency and interoperability across an organization.\n\nScalability and performance issues: Without proper data modeling, it became difficult to optimize systems for performance and scalability. Bottlenecks and reduced system efficiency resulted as data volumes grew.\n\nSecurity and compliance risks: Rapid cloud adoption without adequate attention to data modeling and architecture can expose organizations to security vulnerabilities and compliance risks, especially when dealing with sensitive or regulated data.\n\nDifficulties in extracting value from data: Without a well-thought-out data model, organizations struggle to extract meaningful insights from data. Inevitably, these organizations found that simply having data in the cloud did not guarantee it was inherently usable or valuable for decision-making.\n\n2. Data modeling defined\n\nData modeling is the practice or process of creating a conceptual representation of data objects and the relation between them. Data modeling is comparable to architecture, in that the process blueprints how data is stored, managed, and used within and between systems and databases.\n\nIn essence, there are three key components of data modeling:\n\nEntities: Entities represent the real-world objects or concepts an organization wants to understand better. Examples of data modeling entities include products, employees, and customers.\n\nAttributes: These are the characteristics or properties of the entities being modeled. Attributes provide details that are used to describe and distinguish instances of an entity—product names, prices, customer names, phone numbers, etc.\n\nRelationships: The connections between entities in a data model are called relationships. They can be one-to-one, many-to-many, or one-to-many. Each entity is represented in a relational database in the typical data modeling process. While each entity has a unique identity, it can have multiple instances.\n\nTraditionally, the role of data modeling primarily focused on designing databases for transactional systems and normalizing data to reduce redundancy, improving database performance. The process itself mainly involved working with structured data in relational databases.\n\nModern data modeling is highly varied by comparison. And while its practice and process have evolved beyond some of its inherent qualities viewed negatively in the past, others are now increasingly accepted as trade-offs to be balanced against.\n\nData modeling today caters to a wide range of data storage and processing systems, ranging from traditional relational database management systems (RDBMS) to data lakes and NoSQL databases. Data models now facilitate data integration. They can support advanced analytics, data science initiatives, and predictive modeling. Modern models emphasize agility and scalability to quickly adapt to shifting business requirements.\n\nAs such, data modeling now also supports efforts in the data space to democratize data, helping to make data more understandable and accessible to a wide range of users.\n\n3. Common types of data models\n\nThere are four main types of data models, conceptual, logical, physical, and dimensional. This is true when the goal is to simplify the categorization of data models.\n\nDepending on the business needs of an organization, however, more than these initial four may be considered and utilized. We note the former simply because of the confusion this can sometimes cause within the data space.\n\nConceptual data models\n\nThe purpose of conceptual data models is to establish a macro, business-focused view of an organization’s data structure. Conceptual models are often leveraged in the planning phase of database design or a database management system.\n\nIn these cases, a data architect or modeler may work with business stakeholders and analysts to identify relevant entities, attributes, and relationships using unified modeling language (UML) and entity-relationship diagrams (ERDs).\n\nLogical data modeling\n\nLogical data models work to provide a detailed view of organizational data that is independent of specific technologies and physical considerations. By doing so, logical models are free to focus on capturing business requirements and rules without being biased by technical constraints. As a result, they can provide a clearer understanding of data from a business perspective.\n\nThe ability of less technical stakeholders to more easily understand logical data models also makes them a particularly useful tool for communicating with technical teams.\n\nPhysical data modeling\n\nAlternately, physical data modeling aims to capture and represent the detailed structure and design of a database, taking into account the specific features and constraints of a chosen database management system (DBMS), as well as business requirements for performance, access methods, and storage.\n\nFor this reason, the entities database administrators and developers will focus on include physical aspects of a database—indexes, keys, partitioning, stored procedures and triggers, etc.\n\nDimensional data modeling\n\nFor business intelligence and data warehousing applications, dimensional data modeling is often used. This is because a dimensional model employs an efficient, user-friendly, flexible structure that organizes data into fact tables and dimensions to support fast querying and reporting.\n\nDue to this, dimensional data models can specifically support related applications' complex queries, analysis, and reporting needs.\n\nObject-oriented data modeling\n\nBased on the principles of object-oriented programming, object-oriented data modeling represents data as objects instead of entities. The objects in this type of data modeling encapsulate both data and behavior. This object-oriented approach is key, making object-oriented models highly useful in scenarios where data structures must reflect real-world objects and their relationships.\n\nCommon examples of these scenarios include ecommerce and inventory management systems, banking and financial systems, customer relationship management (CMS) systems, and educational software.\n\nData vault modeling\n\nAs the word “vault” implies, data vault modeling is used in data warehousing, but also in business intelligence. Both data warehousing and BI projects benefit from the historical data preservation, scalability, flexibility, and integration capabilities that data vault models provide.\n\nIn theory, this makes data modeling a potential tool for any organization that needs to integrate data from multiple sources while maintaining data history and lineage (e.g., healthcare organizations, government agencies, and manufacturing companies).\n\nNormalized data modeling\n\nThis type of data modeling focuses on two things—reducing data redundancy and improving data integrity. This can be crucial for transactional systems where data integrity and consistency are of prime importance. Normalized models are easier to maintain and update, while they also prevent data anomalies like inconsistencies and duplication.\n\nDe-normalized data modeling\n\nAlternately, de-normalized data models involve the intentional introduction of redundancies into a dataset in order to improve performance. Through de-normalized modeling, related data can be stored in the same table or document. This reduces the need for computationally expensive join operations, which can slow down query performance.\n\nBecause of how they function, de-normalized data models also harmonize with the principles of NoSQL databases, which prioritize flexibility, scalability, and performance.\n\n4. Causes of controversy in the data modeling space\n\nData scholars agree that discussions around data modeling function similarly to a hornet’s nest in nature—both tend to cause massive amounts of pain when stumbled into. While unfortunate for the stumbler, it helps to understand that, in both cases, damage results in the attempt to defend what one holds dear.\n\nFor hornets, driven to protect the nest’s existing and developing queens, the aggression results from a combination of their innate programming, alarm pheromones, and the instinct to attack in numbers in order to intimidate and dissuade larger foes.\n\nFor data practitioners, however, aggressively defending one’s beliefs about the process and practice of data modeling is usually motivated by one or more of the following factors:\n\nDiverse perspectives: Data modeling is a field that intersects with numerous disciplines, including data science, software engineering, database design, data analytics, and business intelligence. While sharing varying degrees of overlap, these disparate professional backgrounds act as frames through which the views of “effective data modeling” become wildly divergent in the data space.\n\nComplexity and trade-offs: Additionally, data modeling tends to involve near-endless tradeoffs between competing priorities. These tradeoffs include speed vs. governance, normalization vs. performance, and structure vs. flexibility—each with passionate advocates on both sides of the aisle.\n\nOrganizational context: The “right” data model in one organization may not be the same in another, even when operating within the same industry. Differing business rules and goals, data requirements, schema, information systems, and data maturity all but guarantee that there will never be one true data modeling technique or process.\n\nSubjectivity in design: Data modeling itself can be quite subjective. Like many design disciplines, there are often multiple ways to model a given dataset. And data modelers themselves often have legitimate reasons for championing one approach over another. This subjectivity is part of why many find the challenges of data modeling so fulfilling.\n\nEvolving technologies: Despite the order and logic practitioners attempt to bring to the table, the exponentially rapid evolution of data technologies—from traditional relational databases to NoSQL, low and no-code platforms, and big data—necessitates approaches to data modeling to continuously diversify.\n\nFluctuating best practices: Due to the ever-evolving modeling landscape, its related best practices invariably need to change. Techniques once considered sacrosanct can find themselves outdated, furthering debates about what the current best approach may be at any given time.\n\nEmotional Investment: Data practitioners tend to be curious, persistent, analytical thinkers who benefit from a high attention to detail. As such, those who practice data modeling (or cross paths with it) tend to invest a great deal of intellectual and emotional capital in their work. Occasionally, this can create an environment where critiques or suggestions for alternate approaches can either be delivered as a personal attack, or taken as such.\n\n5. Restoring the model of balance\n\nThe good news is that navigating the tension between the impact of data modeling and the convenience of the modern data stack is inevitable. Organizations helping to strike the balance should consider employing the following:\n\nAdopt a hybrid approach: Consider using structured data modeling for core business entities that require consistency and stability above all. In areas that call for more agility and flexibility, employ modern data technologies that enable rapid iteration.\n\nHarmonize flexibility with standardization: Building on a hybrid approach, look to standardize core data elements and processes. At the same time, allow for flexibility in areas where rapid change can be expected. Embrace constant balancing and rebalancing of the strengths of structured data modeling and the modern data stack.\n\nUse iterative data modeling: Instead of insisting on extensive upfront data modeling, try an iterative approach. Start with a basic model, then evolve it as needed. Iteration can produce the best of both worlds, maintaining a structured approach while responding to requirements as they change over time.\n\nLeverage data virtualization: Data visualization provides a helpful layer of abstraction that allows for integrating diverse data sources without extensive modeling. In some organizations, this approach maintains agility while ensuring data is effectively understood and used.\n\nFocus on metadata management: Bridging the gap between structure modeling and agility usually involves a (sometimes renewed) focus on effective metadata management. Robust metadata curation further enables organizational flexibility while clarity regarding data structures and relationships is maintained.\n\nEmphasize data governance: When individuals are empowered to enact consistent data governance, clear policies and standards guiding data quality, usage, and security help ensure a data environment remains as agile as possible.\n\nEnable self-service data access: When implemented with appropriate controls, self-service data access supports agility by allowing users to access data as needed while still operating within the framework of the established data model.\n\nContinuous collaboration: Make sure to foster continuous collaboration between your data architects, engineers, and business users. While the passionate data modeling discussions will still take place from time to time, making cross-disciplinary collaboration an important part of the culture helps keep modeling efforts and business needs aligned.\n\nImplement data contracts: Finally, employ data contracts to provide structured agreements on data formats and interfaces. Their ability to foster communication between data producers and consumers promotes balance just as the other tactics here do—but also allows that balance to scale.\n\n6. Suggested next steps\n\nAs is now abundantly clear, treating data as a product is paramount for any organization looking to succeed in an overwhelmingly data-dependent world. Data contracts are the best way to guarantee the quality of data before it even enters an organization.",
      "# [What Are Data Contracts? What Leaders Need to Know](https://www.gable.ai/blog/data-contracts)\nFounding Father Benjamin Franklin knew a few things about a few things. However, what he couldn’t know is how much one of those things relates to the use of data in our modern age—that it’s far easier to prevent a fire than it is to put one out.\n\nThis insight, the basis of the proverb “An ounce of prevention is worth a pound of cure,” came from Franklin’s work to counsel city leaders in 18th-century Philadelphia, helping them deal with particularly hazardous urban fires.\n\n‍\n\n‍\n\nBut why?\n\nBecause Franklin knew what the stakes were. He’d witnessed firsthand how panic and disorganization prevented any response to a blaze from being efficient, coordinated, and effective. And he realized that, when everything around you is on fire, success at best can only be less of a failure.\n\nSo it goes with data, especially with the sheer impact it has on modern business, society, and well, life in general. But here, in our more modern world, Franklin’s favoring ounces over pounds relates squarely to data contracts and the role they play in preventing our need for high-quality data from erupting into flames.\n\nThat said, as vital a role as they’re already playing, data contracts are a newer concept to many, even unheard of by some. So let this article serve as our proverbial Bucket Brigade, raising awareness of the value of data contracts by defining exactly what they are, how they work, and valuable ways they can be used.\n\nWhat is a data contract?\n\nA data contract is a formal agreement between two or more parties that outlines specific terms and conditions of data sharing. These contracts can exist between organizations, systems, or individuals.\n\nWhere traditional contracts exist as written or spoken agreements, data contracts tend to encompass a combination of documents, tools, and artifacts that provide clear specifications, assurances, and systems to monitor and manage the data exchange between parties.\n\nWe now live in a world where the amount of new data created each day, structured by complex data architecture, rests comfortably in the quintillions of bytes. In this world, where business leaders work to enable digital transformation initiatives and more data-driven decision-making, data contracts are proving to be invaluable.\n\nHow do data contacts work?\n\nIn practice, the formal agreement that data contracts represent will marshal the exchange, handling, storage, and usage of data. Contracting parties agree to ensure that any data outlined in the contract is managed accurately and securely, remaining in compliance with relevant regulations.\n\nThese agreements aren’t hypothetical. A contract only works if it can be enforced. This is why data contracts that involve software should be programmatic.\n\nOperationally, contracts will commonly include the following:\n\nSchema definitions: A data contract should explicitly define the schema, including semantics, so the structure of data is clear. As part of a contract, schema definitions may involve specifying which formats, structures (e.g., Avro or JSON), and data types will be used.\n\nValidation rules: These rules make sure all ensuing data adheres to the defined schema and will meet data quality standards the contracting parties require.\n\nAccess control: Data contracts may specify who approved data producers and data consumers will be for the duration of time specified within the contract.\n\nData flow management: Contracts typically outline how datasets should flow between specific systems like data pipelines and data ingestion processes. They may also determine how data should be managed as it moves between contracting parties, such as data engineers and software engineers.\n\nCommunication protocols: API specifications and communication protocols may also be outlined to standardize the data exchange between systems and platforms.\n\nVersioning: Data contracts implement versioning to manage changes made to the data schema. This management ensures that all changes, including breaking changes, will be handled in a way that won’t disrupt existing systems.\n\nDependency and metadata management: To make sure changes don’t negatively impact dependent systems, dependencies between different data entities may also be managed as part of a data contract. Data contracts may also dictate how metadata will be managed and exchanged between systems, ensuring data will be understandable and usable.\n\nCompliance and auditing: Data contracts will ensure that all data exchange and management adhere to legal and compliance requirements. Mechanisms for auditing and tracking data usage and changes can also be specified.\n\nError handling: Finally, as much as data contracts work to make sure things go right, they should also guide responses when things go wrong. Defining how errors and discrepancies in data will be handled ensures that any issues that arise will be logged, addressed, and communicated properly.\n\nEssential aspects of the contract drafting process\n\nHaving defined what a data contract is and what it should typically entail, we can turn to how they’re implemented.\n\nWhile implementation specifics of a data contract will certainly vary from case to case, the blend of technical, organizational, and governance practices will, more or less, consist of the following nine aspects:\n\n1. Objectives and parameters\n\nEffective data contracts begin with defining the landscape in which they’ll operate. At their most basic, these landscapes should include all relevant stakeholders and use cases to which the contract will pertain.\n\nAs part of the stakeholder identification process, it’s important to understand their needs and challenges. Use cases can contain as much or as little detail deemed necessary, but should at least include the specific data requirements of both data producers and data consumers. With this foundational information, the ideal duration of the data contract can also be outlined.\n\n2. Schema design and management\n\nNext, a clear and comprehensive scheme should be defined using formats like YAML, JSON, or Avro to detail data structure, formats, and types. However, know that the data contract does not need to describe the entire data schema. Comprehensive as it relates to data contracts refers to everything that will be useful and can be well-owned.\n\nDoing so ensures schema changes that occur over the course of the contract will not disrupt existing systems. Further, contract parties should align how metadata will be managed to ensure valuable context about data will be accurate and accessible.\n\n3. Data quality assurance\n\nValidation rules can then be established to ensure optimal data quality and consistency. Take email for instance—are we validating that information entered in an email field is actually a real address? Or are we employing value-based validation, ensuring for example that numbers added to an age field are never less than zero?\n\nData quality metrics should also be identified at this time. Doing so ensures all parties agree on how the data quality will be defined, which metrics will be monitored, and the role the data contract will play in ensuring adherence to these standards.\n\nWhile this step may seem straightforward, it shouldn’t be undervalued—especially considering the humbling costs poor data quality enacts on businesses each year.\n\n4. Technical implementation\n\nBased on the constraint, different enforcements of the contract, such as those involving SQL queries, will be needed depending on the technologies used. This makes sense as, for example, the actualities of protecting against NULLS in a database like MySQL will differ from checking value constraints in Kafka.\n\nAPI design should also be accounted for, as needed. If APIs will be used for data exchange, they should be designed to follow GraphQL or RESTful principles, as per requirements.\n\nA format like JSON or Avro will need to be chosen for appropriate data serialization. Plans to implement robust data ingestion mechanisms and data pipelines that will handle data flow also need to be outlined.\n\n5. SLA, security, and compliance\n\nSpecifics regarding data quality, latency, and availability will be clearly defined and minted in the data contract’s SLA. Any service-level agreement will also require monitoring to ensure adherence by all contracting parties. Monitoring and detection pre-deployment here is also essential for identifying any post-implementation issues proactively.\n\nSecurity factors should involve the use of access control mechanisms that will regulate who can produce and consume data. The contract should clearly establish how data management and data exchange will comply with all relevant legal and regulatory requirements. Working in parallel, outlined data governance policies can further guide data management throughout its lifecycle.\n\n6. Communication, error handling, and resolution\n\nData contracts should be authored to facilitate collaboration between data engineers, other data teams, and data consumers affected by the contract. This collaboration relies on clear lines of communication being established and maintained among stakeholders. Moreover, providing as much context as possible bi-directionally helps teams changing the contract understand why constraints are needed while keeping consumers aware of how and when updates are being made.\n\nCommunication is key for managing expectations and providing the right updates at the right time throughout the course of the contract. That said, a data contract should at least include the basics of how productive lines of communication will be established and maintained—and who is responsible for doing so. Error logging and a defined resolution workflow must be established as part of the drafting process. Contract owners should also be alerted if the contract itself is ever violated.\n\n7. Documentation and changes\n\nWhile the contract is being drafted, the formalities of robust documentation and change management must also be captured. While both are important parts of the data contract process, each is its own distinct element. They support the contract by providing clarity and the framework for managing changes and maintaining records.\n\nDocumentation during the course of the data contract should be a clear and clearly accessible chronicle of operating facets of the data contract, including schemas and workflows.\n\nChanges in the data contract or schema should be recorded separately to ensure they can be communicated to stakeholders as needed.\n\n8. Continuous improvement\n\nAs a data contract actively guides the use of data in a given situation, feedback loops need to be established with data consumers and producers. Feedback provides valuable information that can be used to continuously improve how the data contract functions.\n\nFeedback loops also enable contracting parties to adopt an iteration approach to making these improvements, gradually enhancing and refining the data contract as needs evolve.\n\n9. Technology, tooling, and testing\n\nWith the previous aspects defined, appropriate tools and technologies can be chosen to put the contract to work. Automation should be implemented if and when possible in order to streamline the data management and validation processes.\n\nOnce completed, data contracts require thorough testing to ensure they meet all requirements and handle edge cases effectively. This testing should also validate the performance of data exchange mechanisms under various loads and scenarios.\n\nThree use cases for data contracts\n\nFinally, to stitch the why of data contracts together with their respective what and hows, the following three distinct use cases illustrate their importance and application in practice.\n\nReal-time data streaming in financial services\n\nIt’s increasingly common for financial institutions to rely on real-time data streaming—essential for making instantaneous decisions related to trading, fraud detection, and customer service.\n\nBut, with stakes this high, data must be accurate, timely, and reliable. Data discrepancies or delays can cripple decision-making and lead to financial losses.\n\nIn this use case, data contracts provide the following:\n\nAccuracy: The schema that data contracts define can ensure that data is both available and guaranteed to adhere to expected formats.\n\nSLA management: The data contract will ensure that data latency remains within acceptable parameters and selected data sources will be able to provide and process data as needed.\n\nSecurity: The contract will also make sure that sensitive financial data remains secure while transmitted, and that it can only be authorized to approved entities and individuals.\n\nCollaborative data ecosystems in healthcare\n\nHealthcare ecosystems present their own substantial regulatory and privacy concerns, as stakeholders such as doctors, hospitals, insurance companies, and research institutions need to share sensitive patient data to function at their best.\n\nThe challenges here then involve not just data privacy and consistency, but also extensive interoperability required among diverse systems to ensure compliance with regulations like HIPAA (Health Insurance Portability and Accountability Act).\n\nIn this use case, data contracts provide the following:\n\nData quality: In this case, the data contract will ensure that data shared among entities will be accurate and reliable—essential for both patient care and research.\n\nData privacy and compliance: Data contracts define how sensitive health data can be handled, which then ensures compliance with regulatory and legal requirements.\n\nInteroperability and dependency management: Data contracts ensure not only the consistency and interoperability necessary in healthcare ecosystems but can also manage dependencies between diverse systems and stakeholders.\n\nSupply chain management in retail\n\nRetailers engage with supply chains that can consist of a huge network of logistics providers, manufacturers, and suppliers. Doing so enables retailers to keep products manufactured, transported, and stocked efficiently.\n\nWith 74% of supply chain leaders reporting increasing their investment in technology and innovation in 2023, the need to guarantee traceability, transparency, and efficiency within retail supply chains increasingly hinges on the availability of consistent, high-quality data.\n\nIn this use case, data contracts provide the following:\n\nData integration: With so many players involved in even basic retail supply chains, data contracts can facilitate the integration of data across all relevant entities, ensuring data is both consistent and accessible.\n\nTransparency and traceability: Data contracts are instrumental in defining data related to product movement, timelines, and quantities. This ensures the complicated journey products take from manufacturer to retailer remains traceable and transparent.\n\nAutomation: Contracts also govern a seamless flow of data across the entire supply chain which, in turn, enables automation and real-time decision-making.\n\nWhat goes around comes around\n\nIn the ever-evolving landscape of data management, the age-old wisdom of thought leaders like Benjamin Franklin remains strikingly relevant. If “an ounce of prevention is worth a pound of cure,” the importance of proactive measures in data handling cannot be overstated.\n\nData contracts, as highlighted in this article, serve as that crucial ounce of prevention, safeguarding businesses from potential pitfalls and ensuring seamless data operations. As we move forward in this digital age, the value of such preventive measures only increases.",
      "# [What is Data Provenance? Importance & Challenges](https://www.gable.ai/blog/data-provenance)\nThe amount of data swarming throughout our daily lives increases exponentially. For this reason, data quality is becoming a frequently discussed topic. Bring it on, we say.\n\nBut as data quality (and big data more generally) is discussed more often, it’s imperative that we all understand and employ key terms related to data management and data governance the same way.\n\nData provenance—the term, concept, and practice—should be toward the top of one’s list. For forward-thinking organizations working to improve data quality and use, the provenance of data plays a key role in ensuring the integrity, reliability, and value of all data handled.\n\nWhat is data provenance?\n\nData provenance refers to the information (often metadata) that traces the origin and movement of data throughout the data life cycle. Ideally, this information encompasses the history of specific data—where it came from, the processes and methodologies undergone since origination, and changes of ownership and structure along the way.\n\nThis information is essential for compliance with regulations like the General Data Protection Regulation (GDPR), which requires clear data audit trails. Additionally, this information aids in reproducing scientific research, validating experimental results, and managing the ever-increasing complexity and volume of metadata.\n\nIn this way, data provenance is similar to data lineage because the information is essential for ensuring data authenticity, integrity, and reliability. This makes both data lineage and provenance vitally important across industries and applications, from supporting the service quality and operational efficiency of massive telecommunications companies to case-by-case applications in business analytics.\n\nDespite the similarities between data provenance and lineage, they are distinct concepts. What’s more, applying data provenance as a process further distinguishes it from its contextual cousin. So, let’s use an entertaining analogy to ensure we understand how to give provenance its due.\n\nHow are data provenance and data lineage different?\n\nTo help draw a clearer distinction between data provenance and lineage, consider this basic use case:\n\nA business intelligence (BI) team in a large organization needs to generate some reports to aid in executive decision-making.\n\nOne humble data engineer, our hero, compiles relevant customer data (i.e., customer profiles, demographics, shopper behavior) into a dataset and delivers it to the BI team, as requested.\n\nWith the data in hand, the BI team plugs the dataset into a data visualization tool and begins analyzing it, hunting for trends and insights.\n\nLet’s visualize this use case through a cinematic lens (pun intended). The BI team, scouring that customer data for said trends and insights? That’s a movie (you choose the genre).\n\nThis movie has a prequel. That’s data provenance: all the unique backstory, characters, and formative events that, together, made the dataset what it is today. The data provenance here would include all processes and methodologies the data engineer used to collect, cleanse, and transform customer data from multiple data producers pre-delivery.\n\nChances are good that our main movie will also have a sequel or two. Any and all sequels will be data lineage—chronicling the continued adventures of the dataset as the plot and characters flow on and progress through various systems, data consumers, and subsequent use cases.\n\nSo, as different yet equally valuable facets of data management, provenance and lineage help engineers, analysts, auditors, and administrators answer different types of questions.\n\nData provenance answers these questions:\n\nWho created this data, and when?\n\nHow was this data initially collected/generated?\n\nWhat standards and methodologies were used to collect this data?\n\nWhat is the original data source?\n\nData lineage answers these questions:\n\nWhich processes or systems did this data come from?\n\nWhat transformations has this data undergone?\n\nWhere will it go next?\n\nHow will this data be applied in downstream processes and systems?\n\nHow data professionals put data provenance to work\n\n1. Ensuring data integrity and authenticity\n\nIf data is the new oil, data quality is its sweetness (i.e., “sweet crude,” data’s relative value). Data provenance provides a comprehensive history of data that includes sources of the data, changes that were made to it, and who made the changes. This historical record becomes essential for helping teams verify the authenticity and integrity of organizational data. When data quality can be verified, that data can be trusted—applicable for reporting, analysis, and decision-making.\n\n2. Supporting data quality\n\nTherefore, data provenance is intrinsically linked to data quality—providing the context needed for data teams to assess the accuracy, completeness, and reliability of their data. When the history of data is clear, teams can more easily identify the root causes of data issues if, or when, they arise. This reduces the time needed to implement corrective measures, helping to maintain high data quality over time.\n\n3. Facilitating compliance and auditing\n\nIndustries are increasingly subject to data privacy and security regulations that require fastidious data management and record-keeping practices. Data provenance ensures organizations keep data compliant and secure by providing a verifiable trail of its data origins and transformations.\n\nThis makes provenance a key contributor to audit trails—when data teams need to demonstrate compliance with specific regulations and laws, avoiding penalties and damage to organizational reputation.\n\n4. Enhancing transparency and accountability\n\nThe micro to compliance’s macro, day-to-day use and reliance on data requires ongoing transparency and accountability. The audit trail of a piece of data that provenance enables also fosters trust and accessibility among data users and stakeholders, ensuring all parties are confident in the validity of the data used to do their jobs.\n\n5. Improving data security\n\nData provenance allows data teams to make sure the logs they use to track data maintain access and that changes are immutable. As such, these logs can significantly improve cybersecurity. Potential security issues can be quickly identified and responded to, protecting sensitive information from unauthorized access and breaches.\n\n6. Enhancing decision-making\n\nIt borders on the unavoidable; data is, in one way or another, informing most of the critical decisions made in organizations today. Therefore, data teams must guarantee all data used in the decision-making process is reliable and has not been inadvertently altered or tampered with. This goes a long way toward ensuring data is informing, not misinforming, decisions destined to drive business success.\n\n7. Increasing research reproducibility and validity\n\nFinally, among research, analyst, and scientific communities, data provenance is crucial to ensure the reproducibility and validity of studies. Provenance allows researchers to trace the origin of research data, understand any applied methodologies, and evaluate the integrity of their findings.\n\nThis traceability is essential for building robust, verifiable evidence and facilitating peer review and collaboration.\n\nKey characteristics of a well-defined data provenance system\n\nA well-defined data provenance system will be meticulously designed to track data as it is collected, transformed, and used throughout its data life cycle.\n\nWhat follows is a sense of how such systems work in practice and what sets well-defined data provenance systems apart.\n\nComprehensive data capture: Well-defined data provenance systems should automatically log detailed information about the data’s origin, transformations, and states throughout its life cycle. These details should include metadata, system processes, user inputs, and external interactions. Capturing detailed contextual information is key.\n\nData management tool integration: To avoid potential gaps in data tracking, data provenance systems should seamlessly integrate with existing data management systems (e.g., databases, data lakes, ETL tools). Seamless integration ensures all transformations and movements are logged without manual entry.\n\nGranular data tracking: Provenance systems should track data at a granular level, including individual data elements or records. This provides data teams with precise traceability and allows for detailed data history analysis. This is especially important when organizational data needs to undergo complex analysis or auditing.\n\nAutomated workflows for compliance and auditing: To avoid manual or reactive compliance or auditing, well-defined data provenance systems should include automated workflows to generate reports or alerts for anomalies.\n\nData integrity and security measures: These systems implement robust security measures to protect data and its provenance while helping to ensure its integrity. These measures typically include encryption, access controls, and regular integrity checks.\n\nUser-friendly access and visualization: As with other aspects of data management, information from data provenance systems should not be limited to technical users or rely on formats that are hard for stakeholders throughout the company to understand. User-friendly interfaces and visualization tools allow a wide range of professionals to easily access and interpret provenance data, increasing its value organization-wide.\n\nWhy data provenance and prequels both deserve a better script\n\nWhen the stakes are high, whether for data provenance or a movie prequel, script quality becomes vitally important.\n\nIn addition to establishing important story details, settings, and narrative elements, a prequel script needs to address more practical matters—like introducing key characters, budgetary constraints, and high audience expectations.\n\nA well-drafted data contract serves this purpose when relating to data provenance and data management in general. It handles source details, data handling specifications, quality requirements, and regulatory clauses.",
      "# [Data Collaboration: What Working Better Together Really Entails](https://www.gable.ai/blog/data-collaboration)\nIt only takes a Google search (or a hot minute or two on LinkedIn) to find a long list of modern data trends:\n\nBig data and the mind-bogglingly explosive volume of it all. Competitive pressures across industries as more organizations endeavor to digitally transform. Machine learning and the use of AI becoming the rule, not the exception. The push towards data democratization. Globalization, distributed teams, and increasingly stringent and complex digital privacy governance and regulations.\n\nActing as a force multiplier, data collaboration can dramatically increase the effectiveness of organizational efforts and systems without the need for additional resources, effort, or investment. That said, there exists an exceptional amount of pressure on data engineers to get data collaboration right within their organizations.\n\n‍\n\n‍\n\nAll of this leads to a central truth: It’s imperative that organizations both understand and embrace what data collaboration is, how it functions to benefit an organization, why data engineers should begin their own collaboration initiatives by looking outside their profession, and best practices that can help facilitate success.\n\nWhat is data collaboration?\n\nData collaboration is the process or practice of sharing, managing, and working on data across different teams, departments, or even entire organizations to achieve common goals in a coordinated and strategic manner. These goals can vary but often relate to an organization wanting to increase data integration to make better decisions, improve personalization and customer experiences, or increase operational efficiency.\n\nBased on these goals, data collaboration may be applied on a case-by-case basis or implemented as a fundamental aspect of how an organization functions. But to fully understand (and appreciate) data collaboration, we must go beyond its technical definition and touch on the complicated interplay it relies upon and enables in data-driven ecosystems.\n\nData sharing, one of the main aspects of data collaboration, will often involve combining datasets (i.e., collections of data) from different departments within an organization and external data producers.\n\nPartnerships between departments and external sources will be unique to an organization, as differing business outcomes may require data sharing with a variety of data sources—suppliers, consultants, customers, research institutions, or other businesses. This diversity is important, as this pooling of resources and knowledge enriches data, leading to better, more comprehensive insights.\n\nApplication programming interfaces (APIs) play a vital role in facilitating the connection and communication between all the differing software applications data providers bring to the table. Workflows ensure data sets are collected, processed, analyzed, and utilized accurately and efficiently. And visualization tools like dashboards play a vital role, enabling data collaborators to more easily monitor, report, and make decisions based on their enriched data.\n\nBut the value data collaboration creates can’t come at the expense of data security. Data access—and stakeholders maintaining control of their data throughout the data collaboration process—is essential. So data teams must stringently manage permissions, controlling access at various levels to ensure these newly created datasets remain compliant and abide by all relevant privacy regulations.\n\nWhile the above only scratches the surface of the complexities involved, it sheds light on the interplay required to successfully implement data collaboration to drive insights, innovation, and improved business performance.\n\nThe benefits of data collaboration\n\nAgain, there are as many potential benefits of data collaboration as ways of using data. In general, within an organization, these typically include better organizational knowledge and skill development, more creativity, innovation, and better cross-functional alignment,\n\nHowever, for an organization's more technical practitioners, beneficial use cases may specifically include the following:\n\nEnhanced data change management processes\n\nRobust data collaboration helps ensure any and all changes to data structures, formats, and usage are systematically recorded, reviewed, and implemented with full visibility.\n\nThe resulting transparency and accessibility facilitates clearer communication among data stakeholders. In this way, data collaboration also improves the traceability of changes and better compliance with data governance standards.\n\nImproved dependency alerting\n\nData collaboration also enables dependency alerting to become more accurate and proactive. In turn, the organization can benefit from earlier identification of potential issues, more agility to respond to changes, and minimized impact of said changes on dependent processes or systems.\n\nHighly collaborative teams may also find it easier to automate alerts that notify relevant data consumers in real time about changes in the data they depend on.\n\nChange request centralization\n\nBusiness environments are increasingly dynamic, meaning that change requests can come from anywhere in the organization (and at any time). Data collaboration also benefits here as it can centralize the process of requesting changes to data or data practices. Further, the requests themselves become more structured and efficient.\n\nChange requests submitted through a centralized platform enable teams to log, prioritize, and address each in a timely manner. Overall, this can make an organization’s data management strategy more adaptive.\n\nFaster detection and response to broken data pipelines\n\nIn addition to consistently producing better solutions, collaborative data analysis can help teams identify issues before they become problems (and fix problems before they create issues). As a result, teams (not just individuals) get better at analyzing and interpreting trends, patterns, correlations, and anomalies related to their data pipelines over time.\n\nThis also means that when a pipeline does break down, the collaborative team is better equipped to drill down into an issue faster, decreasing time-to-resolution.\n\nData models evolve more effectively\n\nData models enjoy enhanced flexibility and scalability thanks to robust data collaboration. This fosters an environment where stakeholder feedback, insights, and emerging needs are better integrated into the evolution of data models.\n\nAdditionally, the improved alignment with business goals and increased ability to leverage new data sources often improves the effectiveness of data-driven initiatives.\n\nImproved potency of data contracts\n\nAs a final benefit of note, while drafting data contracts, highly collaborative organizations enjoy more opportunities to reduce misunderstandings or potential conflicts regarding their data use.\n\nData contracts are drafted, agreed on, and maintained with contributions from all relevant parties. As such, they enter service optimally comprehensive, clear, and aligned with the needs of all stakeholders—facilitating smoother data exchanges and integration efforts.\n\nThe valuable (and somewhat counterintuitive) starting point for successful data collaboration initiatives\n\nMelvin Conway is well-known among software developers for Conway’s Law: “Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization's communication structure.” As noted by the author, speaker, and software developer Martin Fowler, this axiom is important enough “to affect every system [he’s] come across, and powerful enough that you're doomed to defeat if you try to fight it.”\n\nThere’s something immutable to this idea—that the things we make are invariably shaped by the ways we make them—which is why Conway’s Law can, and should, serve as a potent starting point for data engineers to champion data collaboration best practices in their own organizations.\n\nHere’s why:\n\nData engineering often requires an extensive focus on technical proficiency and system optimization. Engineers typically work on specific systems or components within larger organizational architectures.\n\nIn these cases, user experience or user-centric design may naturally take a back seat, while the predominant roles and goals of the data engineer may not include a deep understanding of the broader dynamics at play within an organization, especially how these dynamics pertain to data flow and usage. For engineers looking to head up or bolster a data collaboration initiative, these factors can lead to several blindspots.\n\nRephrased for the context at hand, Conway’s Law could instead read as follows: “In organizations where data engineers are tasked with implementing data collaboration initiatives, the structure and effectiveness of these initiatives will mirror the communication patterns and organizational structures within the company.\"\n\nAs such, embracing our take on Conway’s Law grounds the data engineer in a mindset where cross-functional collaboration needs to be championed in addition to the technical aspects of data systems.\n\nDespite the complexity and time invested in existing projects, the engineer must realize that the organizational change inherent in data collaboration necessitates adaptations in data systems, with an emphasis on flexibility and scalability.\n\nAnd, as part of true collaboration, the pursuit of technical solutions can’t overtake the need for clear data governance structures that both support and mirror the overall communication and decision-making processes of the organization.\n\nWith this important keystone of collaboration in place, data engineers can employ best practices knowing that the foundation they’re building on is immutable as the law that informs it.\n\nBest practices for implementing data collaboration\n\nThere exists a healthy bit of overlap for how best to implement a data process or practice. Since data quality is a foundational requirement for all data activities, it should be viewed and treated as a product, not a commodity. Clear governance and policies need to be established to ensure data is shared and used correctly.\n\nThere are, however, a few best practices specific to successful data collaboration:\n\n1. Encourage cross-functional collaboration\n\nActively break down organizational silos (data silos, departmental silos, etc.) in order to foster collaboration across different departments and teams. Whatever their justification, siloing stifles the diverse data and sources that productive collaboration hinges on.\n\n2. Promote transparency and open communication\n\nWhile important in all areas, everyone involved in data collaboration, be it a project or process, needs to be accountable for promoting transparency and open communication. Build on the clear policies and guidelines established through governance. Establish feedback mechanisms. Recognize and reward openness as data collaboration begins to thrive.\n\n3. Invest in people and processes before tools and technologies\n\nIn data engineering, prioritizing tools and technologies is common. But that doesn’t make it correct. Due to the complexity and scale of data collaboration in organizations, even the tech provides diminishing returns without skilled personnel operating within a robust framework of efficient, adaptable processes. It will be the people and processes that begin to cultivate a culture of collaboration, one where technology serves an organization’s goals (as opposed to dictating them).\n\nFrom Conway to contracts: Why collaborative success hinges on better beginnings\n\nFor those seeking to harness the full potential of their data through data collaboration, the implementation of data contracts inevitably emerges as a pivotal tool. These contracts serve as a blueprint ensuring clarity, consistency, and compliance in the collaborative process, much like architectural plans in building design.\n\nAs we navigate the intricate landscape of data collaboration, the value of well-defined data contracts cannot be overstated. They are the cornerstone of effective data management, enabling organizations to unlock the true power of their data assets.",
      "# [Data Compliance: What You Need to Know in 2025](https://www.gable.ai/blog/data-compliance)\nData leaders and stakeholders in data-driven organizations are already well aware of the stakes inherent in data compliance. But as the present reality within data environments becomes more challenging to deal with, it can be hard to keep an eye on what's just over the horizon.\n\nThat said, global and US state-level privacy laws are set to expand. As just one example, fines for non-compliance under the American Privacy Rights Act (APRA) may reach up to 4% of a company's global revenue. This will mirror the stringent penalties under General Data Protection Regulation (GDPR), signaling that non-compliance will carry increasingly heavy financial consequences.\n\nWith all the potential fines and reputation damage at play, the stakes that data leaders face would be intimidating in any casino. Therefore, access to information about tomorrow's key compliance, security, and privacy concerns is crucial to ensuring that no one in their org is rolling the dice regarding data compliance.\n\nAnd this information ideally consists of more than understanding what’s in store regarding data compliance. Through some analysis, data leaders can begin to strategize what to do moving forward.\n\nAwareness: Key data compliance trends for 2025\n\nAs big data continues to make the business world smaller, data leaders face trends of increasing global proportions.\n\nThat said, we now face an inflection point where access to the scale and complexity business owners need to keep their organizations competitive is less of an issue. The quality and ethical implications of data use, however, have never been more important.\n\n1. Stricter data privacy laws for greater global standardization\n\nAs 2025 peeks out at us from just over the horizon, so too do more stringent data privacy laws. These laws are spurring a move toward global standardization.\n\nNew regulations, such as the APRA in the US, will introduce federal standards that align with the European Union’s GDPR (which went into effect back in 2018). Once in effect, these new regulations will require companies to adapt their data compliance programs across regions.\n\nThe ensuing shift will simplify some aspects of compliance for businesses but will increase accountability across third-party vendors and data processors as a result.\n\nOrganizations must build security safeguards and transparent data practices into their compliance frameworks (i.e., fully embracing data governance as code) to remain fully compliant with these increasingly global privacy regulations.\n\n2. Broader data sovereignty and localization mandates\n\nAdditionally, nations around the world are pushing for stronger data sovereignty through localization laws that mandate the storage and processing of personal information within specific geographic boundaries.\n\nFor organizations operating globally, this trend requires revisiting data storage and access strategies to ensure compliance with local laws while avoiding significant penalties.\n\nMoreover, as more regions embrace these localization mandates, data leaders must prioritize regulatory compliance within their organizations. By doing so, they actively safeguard sensitive and proprietary data, keeping it securely stored and managed as part of their data management frameworks according to each jurisdiction's standards.\n\n3. Increasing demands for more ethical and compliant AI data governance\n\nAs AI systems increasingly rely on vast amounts of personal data, rapid integration of AI into business operations is driving the creation of new and unique compliance requirements.\n\nRegulators, in turn, are focusing more intently on AI governance to ensure data is handled ethically, securely, and in accordance with evolving privacy laws.\n\nThe resulting shift will compel data leaders to robustify existing frameworks they use to oversee AI-driven data practices—ensuring compliance with both local and international data protection regulations. Failing to do so will be unacceptable, if it isn’t already, as it will jeopardize the ethical development and deployment of AI technologies.\n\n4. Deeper integrations of data privacy and security in compliance foundations\n\nAs cybersecurity threats grow more sophisticated, data security and functionality like automated data governance are gaining precedence among the other facets responsible for robust data compliance, like data lifecycle management and risk management.\n\nTo adapt, organizations must adopt proactive measures like real-time monitoring, access control, and encryption to safeguard sensitive information from vulnerabilities and unauthorized access, both from data consumers and external bad actors.\n\nIn addition to regulatory requirements, post-pandemic consumer expectations are driving this trend, as consumers demand greater transparency in data handling, and rightly so.\n\nIncreasingly essential components of a strong data compliance program include the following:\n\nSecurity standards and access control: By implementing standards like SOX, PCI DSS, and NIST, data leaders provide individuals with only the customer data they are authorized to use, such as credit card information and other personally identifiable information in relevant industries.\n\nRisk management and assessment: Leaders should also implement a consistent cadence of risk assessments and data audits to pinpoint compliance vulnerabilities and mitigate cyber threats effectively. Proactivity is key here, as data teams who actively keep data aligned with data compliance regulations can also foster more robust information security management programs.\n\nData deletion and data storage protocols: In addition to secure storage, data deletion policies play a critical role in protecting customer privacy. Sometimes overlooked in older, more-is-better approaches to data management, data leaders who champion these policies improve organizational adherence to privacy regulations, making certain their teams securely erase outdated or irrelevant data in compliance with regulatory requirements.\n\nBy embedding these data security practices into a comprehensive compliance program, organizations can reduce the risks associated with data breaches and non-compliance and position themselves as trustworthy custodians of sensitive information.\n\n5. Better safeguards for health information through tighter healthcare compliance standards\n\nExperts predict the emergent direct-to-consumer healthcare industry will gain traction in 2025 as patients increasingly seek expanded access to drugs and medical devices without going through traditional healthcare providers.\n\nHealthcare compliance demands a heightened focus on privacy and security, especially in light of regulations like HIPAA, which governs the handling of health information in the US.\n\nHealthcare providers and service organizations are required to meet strict standards in data collection, storage, and access to protect patient information from data breaches and unauthorized use.\n\nKey factors that influence healthcare compliance in 2025 will include:\n\nPrivacy regulations and data protection laws: HIPAA, along with emerging health-focused privacy laws, ensures that healthcare organizations prioritize the security of health information and patient privacy.\n\nData collection, access, and storage: As the healthcare industry continues to digitize patient data, healthcare providers must adhere to data compliance regulations governing the storage, access, and management of health data. Effective access control, data safeguards, and consistent data audits are essential to protect patient data from vulnerabilities and ensure compliance.\n\nIndustry-specific compliance: Healthcare providers must stay agile and responsive to changing standards around patient data privacy and secure information handling. This requires balancing data access needs with compliance obligations. As compliance frameworks evolve, organizations should conduct regular assessments to continuously meet new regulations and maintain patient trust.\n\nThe healthcare industry’s unique requirements for data privacy and protection underscore the importance of compliance programs that address sector-specific regulations.\n\nHowever, by embedding robust data safeguards and adopting healthcare-compliant data storage and access controls, data leaders in relevant industries ensure that patient data remains protected while their organization maintains optimal compliance.\n\nAnalysis: Increasingly critical data compliance challenges in 2025\n\nBased on these trends, data leaders are in the hot seat—responsible in large part for helping their organizations prepare to navigate these changing tides of data compliance.\n\nDoing so creates specific challenges for anyone in these roles, including the mounting complexities of new regulations (both broad and niche), the persistent need to keep data de-siloed, and consumers who, on average, care more about the information they share online, and who expect far more transparency from those who use it.\n\nKeeping pace with stricter regulations and global standardization\n\nIn addition to APRA, as mentioned in our introduction, 2025 will witness the emergence of new state privacy laws in Delaware, Iowa, and Minnesota. These laws will further complicate the already intricate framework of regulations in the United States.\n\nAs always, evolving data compliance regulations demand continuous monitoring and adaptation to avoid non-compliance penalties, which can include fines, reputational damage, and increased scrutiny from regulatory bodies.\n\nThat said, rising cyber threats and vulnerabilities compound this challenge and force organizations to adopt stronger safeguards and security standards, such as those defined by SOX, PCI DSS, and HIPAA.\n\nBreaking down data silos to enhance accessibility and governance\n\nData silos will continue to be significant barriers to compliance in 2025. Fragmented data spread across systems or departments prevents organizations from implementing consistent security controls, such as access control and authentication, which are critical for ensuring compliance with privacy regulations. These silos also hinder effective governance and make it difficult to meet requirements for data accuracy, accessibility, and storage management.\n\nBreaking down silos enables a more comprehensive view of operations. This, in turn, not only improves efficiency and overall data quality but also facilitates the alignment of data handling practices with compliance frameworks.\n\nFor organizations that are managing sensitive customer or health information, this step is critical for maintaining regulatory compliance, particularly under laws like GDPR and HIPAA.\n\nEmbedding privacy by design into compliance foundations\n\nPrivacy by Design (PbD) is increasingly becoming a regulatory mandate under frameworks like Europe’s GDPR, Brazil’s General Data Protection Law (LGPD), and emerging US privacy laws. This approach requires organizations to proactively embed privacy considerations into the design and development of systems, processes, and products rather than applying them retroactively.\n\nBy 2025, PbD will be integral for managing compliance across industries and will ensure that safeguards for personal data—including data deletion protocols—are in place throughout the data lifecycle. However, implementing PbD can be challenging, as it requires cross-functional data collaboration between legal, IT, and product development teams to ensure they consistently prioritize consumer privacy.\n\nAs technologies like AI create new opportunities and risks, organizations will need to align their AI governance efforts with privacy regulations to address emerging ethical concerns while maintaining compliance. PbD will remain a cornerstone of these efforts, ensuring the design of systems and processes anticipate and mitigate compliance vulnerabilities from the outset.\n\nAction: 3 key strategies for adjusting to 2025’s evolving compliance needs\n\nAs it stands, data leaders should begin rethinking (or at least thoroughly considering) their current approaches to compliance. Despite high stakes, most won't need to scratch their current strategies and processes completely.\n\nThe value here is to reconcile what's worked in the past with what must work in the near future—optimizing solutions to address evolving demands to help their organizations both keep pace and stay competitive.\n\n1. Embrace upstream data contracts\n\nData contracts are agreements between data producers and consumers. They define how data is structured, shared, and maintained. As such, a data contract that is drafted and implemented upstream enforces data quality, schema consistency, and compliance requirements at the data lifecycle’s inception point. This is why data contracts are particularly critical for navigating stricter data privacy laws, such as APRA or GDPR, as well as sector-specific mandates like HIPAA in healthcare.\n\nBy embedding these contracts into CI/CD pipelines, companies can automate the enforcement of data standards, which reduces the risk of non-compliance due to schema-breaking changes or poor-quality data.\n\nThis proactive approach supports governance frameworks and ensures that organizations handle sensitive data, like health information and customer data, in full compliance with regulations.\n\nData contracts also reduce technical debt and align all stakeholders on data handling requirements, which is increasingly important as organizations face global standardization pressures and localization mandates.\n\n2. Automate your data lineage processes and audits\n\nAutomated data lineage tools provide a real-time view of how data moves through an organization, from its origin to its final destination. Transparent data flows are essential for demonstrating compliance with evolving data compliance regulations—such as GDPR or PCI DSS—and meeting industry-specific requirements, including those in the payment card industry or healthcare.\n\nAutomated lineage tools simplify compliance reporting by creating audit trails that regulators can review efficiently. These tools also ensure that data deletion and access protocols align with privacy regulations. As regulations grow more complex in 2025, real-time monitoring and lineage automation will be critical for identifying vulnerabilities, ensuring compliance across data lifecycles, and reducing the manual burden on compliance teams.\n\n3. Invest in staff training and promote optimal awareness\n\nHuman error remains a significant factor in compliance failures and data breaches. Training employees on evolving regulations, cybersecurity best practices, and internal compliance protocols is essential to mitigate this risk. In sectors like healthcare, where compliance with HIPAA and privacy-focused regulations is paramount, staff awareness plays a critical role in protecting health information.\n\nRegular training programs help organizations adapt to regulatory changes and foster a culture of privacy and data integrity. This approach ensures that employees understand their responsibilities in managing sensitive data, from implementing access controls to adhering to secure data storage and deletion standards.\n\nPlanning ahead: Future-proof your organization’s compliance framework by shifting data left\n\nMoving forward into 2025, we can agree that proactive and integrated data compliance will be essential, not optional. VPs of data must lead the way by building scalable, adaptable compliance frameworks that meet regulatory demands and protect organizational trust.\n\nBut for these leaders, it’s of critical importance to understand that high stakes are best managed well before cards ever hit the table. The answers here are upstream, embracing tools and technologies that prevent data compliance from becoming a gamble in the first place.",
      "# [Database Schema: The Need for (and Risks of) Iterative Evolution](https://www.gable.ai/blog/database-schema)\nThe humble, foundational aspects of data environments make it possible for modern tools, solutions, and platforms to scale and adapt to our ever-evolving digital world.\n\nAnd while it’s understandable that an abundance of digital ink will be spilled to cover new frontiers, let’s not forget that said foundational aspects and their need to keep pace are just as important, if not more so.\n\n‍\n\n‍\n\nFor organizations of all sizes, database schema serves as a critical blueprint that dictates the functional structure of data management.\n\nThis is especially true for startups and smaller organizations, where data can be a significant driver of innovation and growth.\n\nDatabase schema, defined\n\nA database schema acts as the blueprint within a relational database management system (DBMS), outlining its logical structure and organization. Schemas are often defined using data definition language (DDL), which provides a clear, consistent way to define how data is stored in tables.\n\nDatabase schemas also define the relationships between these tables, incorporating integrity constraints to establish and maintain optimal data quality. Such organization makes efficient data retrieval, query optimization, and overall performance management possible, playing a crucial role in database design and operation.\n\nTo do so, database schema typically encompasses a wide range of database objects (but certainly not all of them). Schema primarily focuses on the specific database objects needed to define a given database’s structure and organization.\n\nTypically, these objects will include the following:\n\nTables: The core components of a database schema, tables store data in rows and columns, with each table representing a set of related data.\n\nIn the context of data warehouses or multidimensional database models, schemas often include more specialized “fact tables.” These specialized tables are designed to store quantitative data for analysis, known as facts, and often contain keys that link to related dimension tables, which store descriptive attributes.\n\nColumns: Within tables, columns (also known as fields) represent the attributes or properties of the data. Each column in a table is designed to store a specific type of data (e.g., integers, text, dates, etc.).\n\nRows: Individual records in a table are represented as rows, where each row in a table contains unique data for the corresponding columns.\n\nPrimary keys: These are special fields that uniquely identify each record in a table. A primary key ensures that each row in a table is distinct from all others.\n\nForeign keys: Fields in a table that link to primary keys in other tables are called foreign keys. These keys establish relationships between tables and are crucial for maintaining referential integrity within a database.\n\nIndexes: Functioning as an “address book” of sorts, indexes guide databases to the location of needed data more quickly. This functionality speeds up overall data retrieval from the database.\n\nStored procedures and functions: These are sets of SQL statements that perform tasks like calculations and data manipulation that are frequently reused.\n\nViews: A view is a virtual table based on the result-set of an SQL statement. Just like a real table, views contain rows and columns. However, views are created with the data from one or more tables.\n\nConstraints: Constraints are rules that ensure the data in the database remains accurate and reliable.\n\nTriggers: Scripts that are automatically executed in response to certain events are referred to as triggers on a particular table or view in the database.\n\nAll together, these are the components that enable schema to function as the metaphorical blueprint, keeping databases optimally structured as their data is stored, organized, and managed.\n\nA note on schema types: While they often focus on similar data objects, different schemas may vary depending on the nature of the data being used and the requirements of their respective systems. In exploring the types of database schemas, database administrators may use a conceptual or logical schema during the planning phase.\n\nHowever, they may transition to a physical schema for implementation and then a physical database schema to manage the physical aspects of the database when it’s put into use. Data scientists and business analysts, on the other hand, might rely on star schema to enable complex queries or snowflake schema if data integrity and reduction of data redundancy take precedence.\n\nThe need for iterative schema evolution\n\nIterative schema evolution is a critical aspect of successfully implementing and managing a database, particularly in dynamic environments where business requirements and data models are subject to change. Its importance can be understood in relation to other key factors in database management:\n\nAdaptability to changing requirements: One of the most significant challenges in database management is the continuous need to adapt to evolving business needs. Iterative schema evolution allows for gradual, controlled modifications to the database schema, ensuring that it can keep pace with changing requirements without disrupting ongoing operations.\n\nData integrity and consistency: While maintaining data integrity and consistency is vital, overly rigid schema designs can hinder necessary changes. Iterative schema evolution, when done correctly, allows for schema modifications while maintaining data integrity through versioning, migration scripts, and backward compatibility.\n\nPerformance optimization: Over time, it's common for the performance requirements of a given database to change. Iterative schema evolution enables incremental adjustments to optimize performance, such as indexing strategies and partitioning, without the need for a complete overhaul.\n\nScalability: As the volume of data grows, a database schema might need to be adjusted to scale effectively. Iterative evolution allows for scaling-related changes, such as denormalization or sharding, to be implemented as needed.\n\nCompatibility with development practices: Modern development practices, such as Agile and DevOps, emphasize continuous improvement and rapid iteration. Iterative schema evolution aligns well with these methodologies, allowing database schema changes to be integrated into the broader development lifecycle.\n\nRisk management: By enabling small, incremental changes, iterative schema evolution reduces the risk associated with large-scale database modifications. It allows for easier rollback, testing, and validation of changes.\n\nThe risks of iterative schema evolution\n\nAttempting to enable iterative schema evolution without a data contract in place does, unfortunately, present several challenges and risks.\n\nThese risks are amplified in environments where data integrity, consistency, and compliance are crucial:\n\nLack of predictability and standardization: Without support, changes to the data schema can occur in an ad-hoc, inconsistent manner. The unpredictability this introduces can lead to issues in data quality and compatibility, especially when logical constraints are not uniformly applied across multiple teams or systems.\n\nData integrity risks: Sporadic schema changes can lead to data integrity issues. If a field's data type is altered without proper synchronization, for example, it could lead to data loss or corruption.\n\nCompliance violations: In regulated industries or under laws like GDPR or CCPA, organizational data needs to be handled according to specific guidelines. Iterative schema changes can inadvertently lead to non-compliance, resulting in legal and financial repercussions.\n\nIncreased testing and validation overhead: Schema changes require extensive testing and validation to ensure they don’t break existing systems. While important, this process becomes more complex and time-consuming as a database needs to evolve, as there are no predefined rules or expectations to test against.\n\nDependency management issues: In a microservices architecture or in systems with multiple data sources, changes in one part often affect others. Managing these dependencies over time compounds testing complexity while the subsequent risks of system failures or downtime increase.\n\nDifficulty in rollbacks: If a schema change leads to issues, a rollback may be required. However, this operation becomes difficult when no record of the previous schema state is available, or when data may have already been transformed in a way that is not easily reversible.\n\nImpact on data consumers: Applications or services consuming the data may face issues if they are not aware of or prepared for schema changes. This can lead to system errors, application crashes, or incorrect data processing.\n\nScaling challenges: As an organization’s systems scale, managing schema evolution takes an increasing toll on data teams. Moreover, as the volume of organizational data and the number of interconnected services increases, the complexity and risk of making changes without breaking existing functionalities also grows exponentially.\n\nWhy your database blueprints deserve their own blueprint\n\nData leaders in organizations of all sizes need to embrace the reality that their database will need to evolve. Therefore, any means or method that can mitigate the risks of iterative schema evolution should be embraced as well.\n\nEnter data contracts. For database designers and data engineers, these contracts can support the design of a database schema, not just its management.\n\nData contracts: Advantages for schema design\n\n1. Defining data structure and format\n\nEarly specification: Data contracts can provide an early specification of the data structure, including data types, formats, and fields, guiding the normalization process in database design. This helps in designing database tables and relationships that align with these specifications.\n\nConsistency across systems: When a database needs to interact with other systems, a data contract ensures that the schema is designed in a way that is compatible and consistent with these external systems.\n\n2. Setting standards and constraints\n\nData integrity: By defining the rules and constraints for data, contracts help in designing schemas that inherently support data integrity and validity.\n\nStandardization: Data contracts often include standardization rules, which are crucial in designing a schema with consistent syntax and structure.\n\n3. Guiding relationships and dependencies\n\nRelationship mapping: Contracts can outline the relationships between different data entities, providing a clear visual representation through an entity-relationship diagram in the schema design process.\n\nDependency management: Understanding the dependencies between different data elements as specified in a contract helps in designing a schema that efficiently manages these dependencies.\n\n4. Facilitating scalability and evolution\n\nFuture-proofing: Data contracts can include provisions for future changes, which can guide the design of a flexible and scalable schema.\n\nIterative development: As contracts may evolve, designing a schema with the ability to accommodate these changes is crucial. Data contracts provide guidelines on how the schema should adapt, ensuring it remains relevant and functional over time.\n\n5. Ensuring compliance and security\n\nCompliance: Data contracts often outline requirements for compliance with regulations. This can be integrated into the schema design to ensure that data storage and processing meet legal standards.\n\nSecurity protocols: Contracts may specify security protocols or encryption standards, which can be considered in the schema design to ensure data is stored and accessed securely.\n\n6. Data governance\n\nGovernance framework: Data contracts often form part of a broader data governance strategy. Designing a schema with these contracts in mind helps align it with the organization's data governance policies, ensuring the effective organization of data.\n\nRole and access management: Data contracts may define roles and access levels for database users, which can influence the design of the schema in terms of access controls and data segregation.\n\n7. Optimizing performance and efficiency\n\nPerformance requirements: Contracts can specify performance requirements, guiding the design of efficient indexes, optimized query paths, and streamlined data structures.\n\nResource management: Understanding the expected data load and usage patterns from the contract can guide decisions on resource allocation and optimization in the schema design.\n\nReady to support your own database schemas? Here’s how to get started\n\nCompared to larger organizations, smaller organizations and startups often require wearing multiple hats, achieving more with less, and just doing what it takes to get the work done. That’s why it’s simply not worth leaving database schema unsupported, which effectively creates little ticking time bombs tucked away in some of the most vulnerable aspects of your data infrastructure.\n\nFortunately, we’re improving the process required to draft and implement a top-notch data contract, in part because everyone in our data-driven world (not just enterprise organizations) deserves the security and operational support they provide.\n\nReserve your spot now to learn more about Gable and how you can create a preventative strategy with data contracts.\n\n‍",
      "# [How to Think About Data Quality](https://www.gable.ai/blog/data-quality)\nBig data is big enough that, yes, it still warrants the occasional media story or captivating infographic. But, increasingly, our collective attention needs to focus far more on the quality—not quantity—of data.\n\n‍\n\n‍\n\nHowever, good data quality doesn’t manifest itself. Management of specific factors and categories by data governance teams, data stewards, and the like is essential to ensure data from producers consistently reaches consumers in its optimal form.\n\nThis is why any data quality initiative should arguably begin with internal alignment on what those factors and categories entail.\n\nWhat are the 5 characteristics of data quality?\n\nLike many aspects of data engineering and science, the concept of data quality is quite simple until two professionals sit down to discuss it. Professionals of varying specialties and experience will, understandably, emphasize different characteristics concerning data quality they consider more important.\n\nBut at a very foundational level, we can define the quality of a specific dataset by evaluating five key characteristics:\n\nAccuracy: How accurate is the data at hand? Data values should represent the real-world event or instance it exists to depict.\n\nConsistency: High-quality data contains no contradictions across a given dataset or system.\n\nReliability: Referring to the trustworthiness of data sources, the reliability of a source can often be determined through data lineage.\n\nTimeliness: Whenever required, data is both up-to-date and available.\n\nUniqueness and completeness: Quality data is whole, with no missing values or parts.\n\nWhat are the 4 categories of data quality?\n\nTaken together, data quality characteristics allow us to quantify the quality of data flowing from producers to consumers. However, a categorical lens also provides valuable context for data governance when paired with the five factors above. Traditionally, these categories are organized to address specific areas of concern or dimensions.\n\nAs such, the four most common categories are as follows:\n\nAvailability and accessibility issues: Can the data be used when needed? Can it also be accessed by those who need it (and inaccessible to those who don’t)? In addition to permissions structures and security protocols, this category includes issues like system errors and data outages.\n\nAccuracy and integrity issues: Here we focus on whether the data is reliable and correct. Can it be trusted? Addressing this category typically involves correcting for inconsistencies, inaccuracies, and whether or not the relationships between datasets maintain their integrity.\n\nConformity issues: This category covers whether a dataset or system conforms to a predefined standard or set of business rules based on particular formats, standards, or patterns.\n\nRelevancy, completeness, and timeliness issues: This final category of data quality focuses on whether or not the data is current, complete in terms of covering all necessary aspects, and relevant to its intended use.\n\nIt bears repeating that these characteristics and categories are in no way mutually exclusive.\n\nFor instance, the characteristic of data \"completeness” can be seen in both the relevancy/completeness/timeliness and accuracy/integrity categories. While the quality characteristic of “reliability” also naturally slots into the accuracy/integrity category, it also relates to availability/accessibility issues.\n\nThe point is whether they’re characteristics or categories or both, use whichever makes the most sense based on your needs and the needs of your organization.\n\nThe five data quality characteristics might make more sense for metrics and measurement or data profiling. In contrast, the four categories may be more useful for data governance or managing stakeholder expectations.\n\nCharacteristics and categories, leveraged in tandem, can also support a balanced and effective approach to managing data quality in diverse scenarios.\n\nData quality vs. data integrity\n\nIt’s also important to clarify the difference between data quality and data integrity, as the nouns quality (how good or bad something is) and integrity (the quality of being honest and having immutable moral principles) can be used synonymously in some situations. However, regarding data, they are significantly different.\n\nHere's how:\n\nData quality, as we've defined above, refers to the condition or state of data at a given point in time. Being a finite measurement, the level of quality relates to the data's value as it can be used in specific, intended instances—such as in business operations, planning, or decision-making.\n\nData integrity, however, refers to the accuracy and consistency of data across its entire lifecycle. Does quality data from a reliable source fundamentally remain unchanged and unaltered once it's been ingested into an organization? And has it been accidentally or maliciously tampered with or corrupted? These are questions of data integrity.\n\nOther differences between quality and integrity relate to scope, implementation, overall concerns, and security issues related to data. In this sense, data quality and data integrity both relate to the reliability and trustworthiness of data.\n\nTogether, those contributing to data management have a way of referring to the usability of their data (data quality), and their ability to trust its quality will be consistent over time (data integrity).\n\nThe mission-critical impact data quality has on business\n\nAs is obvious now, data quality can have a profound effect on business initiatives and operations—both positive and negative.\n\nBenefits of high data quality\n\nMore efficient operations: High-quality data helps to streamline processes, reduce operational errors, and can lead to cost savings. The potency of data analytics, reporting, and forecasting also hinges on the availability of high-quality data.\n\nImproved decision-making: Timely, accurate, reliable data ensures that data-informed business decisions are grounded in reality, leading to better strategic decisions and outcomes.\n\nBetter customer relations: Accurate customer data enables businesses to tailor their offers, services, and communication to consumers, increasing customer satisfaction and loyalty.\n\nCompliance and mitigated risks: Reliable, high-quality data reduces the risk of penalties and legal consequences by helping businesses comply with various regulations.\n\nIncreased trust: Organizations that prioritize high data consistency and quality data assets are more easily seen as trustworthy and reliable, which can strengthen their brand reputation in-market.\n\nInnovation fuel: Advanced analytics, AI, and machine learning processes live or die based on the reliability of data they have access to. So, too, does their ability to support innovative or completely new data-driven products and solutions.\n\nIncreased revenue: Ultimately, high-quality data can increase revenue as it enables more accurate pricing strategies, better campaign targeting, and the continual improvement of sales processes.\n\nIssues stemming from low data quality\n\nOperational inefficiencies: Stakeholder and business intelligence initiatives based on outdated or inaccurate data can produce poor—if not outright detrimental—business processes and outcomes.\n\nIncreased costs: Low-quality, inconsistent data leads to more mistakes, data discrepancies, and handling issues. And costs due to rework and remediation can get out of hand quickly.\n\nHindered digital initiatives: Poor data can grind digital transformation efforts to a halt, especially in cases where an organization wishes to leverage the benefits of advanced data-reliant technologies like artificial intelligence (AI).\n\nCompliance risks: Bad data can result in regulatory violations. And, in industries where data accuracy is paramount, organizations can face reputational damage and financial penalties.\n\nLoss of trust: Regular errors, issues, and inaccuracies can erode trust in general, both with stakeholders internally and customers externally.\n\nCustomer dissatisfaction: Flawed customer data can lead to miscommunication, bad targeting and personalization efforts, or errors in service delivery. For increasingly digitally savvy consumers, the resulting dissatisfaction can quickly lead to loss of business.\n\nDecreased revenue: A sustained lack of access to high-quality data can ultimately result in ineffective marketing campaigns, decreased sales effectiveness, and missed opportunities.\n\nHow to measure data quality\n\nData quality management, be it more or less formally practiced, should be considered table stakes in any modern business environment, not just in situations where data-driven decisions need to be accurate and effective.\n\nBut that doesn't mean measuring the quality of data is easy to do (especially at scale). After all, the idea of \"quality\" can sometimes be frustratingly subjective. Fortunately, utilizing a data quality assessment is an excellent way to both quantify what quality data means in the context of one's organization and assess it using multiple dimensions of data quality.\n\nPerforming a data quality assessment involves a series of sequential steps, the basics of which we've outlined here:\n\n1. Define your criteria\n\nBefore jumping into measurement, start by outlining clear criteria based on business needs. Based on those needs, outline which aspects of data quality are most relevant (i.e., which characteristics—be they five, or more, or less).\n\n2. Develop key performance indicators (KPIs)\n\nDetermine which KPIs can best be used to measure each aspect of data quality you’ve outlined as part of your criteria. Using our five characteristics to illustrate, these KPIs might be established by the following actions:\n\nComparing a sample of your data against a trusted source or standard, then using the percentage that matches to represent data accuracy.\n\nCalculating the percentage of missing data in a dataset to represent data completeness.\n\nQuantifying any identified discrepancies within a dataset or between datasets to represent data consistency.\n\nTracking the number of times a data source provides incorrect information or suffers outages to represent data reliability.\n\nMeasuring the delay between when data is generated and when it becomes available for use to represent data timeliness.\n\n3. Implement continuous monitoring\n\nAdd continuous monitoring tools to the mix as well, as they will help you constantly check and report on how the quality of your data is—or is not—improving over time based on your specific KPIs. To best do so, we always recommend establishing monitoring as early as possible. Setting up alerts to inform you of any significant deviations is also beneficial.\n\n4. Establish feedback loops\n\nWork needed to keep something from breaking is always preferable to working to fix what’s broken. This is why the time and effort required to establish feedback loops is well spent. Enabling data consumers to report anomalies or issues they encounter is valuable. But the fact that feedback loops keep data producers and consumers in lockstep—more often identifying problems before they become problematic—is invaluable.\n\n5. Implement data profiling tools\n\nData profiling tools analyze data to provide a statistical summary while highlighting inconsistencies or anomalies. The information provided can provide insights regarding outliers, patterns, and potential quality issues. Ultimately, however, profiling tools prove invaluable for helping teams identify and resolve issues as quickly as possible.\n\n6. Score data quality\n\nData quality scorecards can prove invaluable for clearly displaying the result of your ongoing data quality measurements against benchmarks you set. When used correctly, these scorecards also make it easier for stakeholders to understand the current state of the organization's data quality. Ideally, data quality scores should also be tied back to specific data products.\n\n7. Audit regularly\n\nAuditing can be periodic. But they should occur consistently, as the deep dives they require can reveal system issues that tend not to appear in day-to-day checks.\n\n8. Benchmark externally\n\nWhenever possible, compare your data quality metrics with industry standards or benchmarks. Doing so provides valuable context, helping you maintain a sense of where you stand relative to industry peers and best practices.\n\n9. Conduct a business impact analysis\n\nA business impact analysis can help you measure the actual bottom-line-impact data quality issues are having within your organization. In instances where poor data quality led to a flawed business decision, the cost implications of that decision should be made apparent.\n\n10. Review regularly (and continuously adapt)\n\nAs communication is a key aspect of maintaining high-quality data, review your measurement strategies to account for how data sources, tools, stakeholder expectations, and the overall business environment evolve.\n\nIf nothing else, when you keep stakeholders aware of the impact of data quality on business outcomes, they're more likely to support and participate in your quality improvement initiatives.\n\nThe best way to improve data quality\n\nBased on the above, ensuring data quality is less of a singular task and more of a continuous journey. And the process of managing data quality is fundamentally intertwined with the tools and strategies employed in its management, such as data quality tools that scrutinize and enhance accuracy, feedback mechanisms that perpetually refine it, and master data management (MDM) that ensures its consistency and accuracy across the organization.\n\nTruly, the quality of data as it moves downstream to consumers is dependent on its quality when it enters an organization. More specifically, if data from producers is flawed, the resulting analyses, decisions, and strategies it’s used for will be, too.\n\nThis brings us to a pivotal solution: data contracts. These can be seen as the vigilant gatekeepers ensuring that only the finest, most pristine data enters your organization's repositories.\n\nWhy data contracts are quintessential for high-quality data\n\nEnsuring consistency: Data contracts establish a standardized format, ensuring incoming data adhere to predetermined quality and structural benchmarks. With clear data expectations and the assurance of data quality and accuracy, organizations can collaborate more effectively.\n\nMinimizing errors: By defining the acceptable data parameters, data contracts inherently reduce the influx of erroneous data, safeguarding analytical outcomes.\n\nIntegration testing: Contracts enable teams to check upstream in a CI/CD pipeline before any breaking issues occur. This also helps bring data producers and consumers together, improving data collaboration and the general understanding of its use.\n\nEnhancing compliance: Data contracts ensure that data adheres to regulatory and organizational standards, mitigating compliance risks.\n\nOptimizing data management: By ensuring that only quality data enters the system, data management processes are streamlined and optimized.\n\nWith the stakes so high, quality should be contractual\n\nIn modern organizations, there will always be an alarming amount of things we simply can’t control. Often, these things add up to become the proverbial cost of doing business. This is why that which we can control deserves all the more investment—especially when, as data does, it can make all the difference in organizational success or failure.",
      "# [What is Data Lineage? Tools, Techniques, Examples](https://www.gable.ai/blog/data-lineage)\nWhen data becomes more complex, big data analytics also becomes more complex—and, in turn, data compliance and regulations are even more complex.\n\nAnd this all ripples to affect the complexity of data governance.\n\nWhile data-driven decision-making actually becomes easier, maintaining competitive data advantages becomes more difficult. Access to quality data is already vital, but understanding how an organization uses that quality data is now essential.\n\nEnter: Data lineage.\n\nWhat is data lineage?\n\nData lineage refers to how specific data is used and transformed over time. Data professionals employ data lineage practices to record and share this data use and transformation as it occurs.\n\nTime out: How is data lineage different from data provenance and data governance?\n\nOne of the challenges of data management is that you can’t break out aspects of the data lifecycle and affix each to specific periods of time—past, present, or future.\n\nThis is why we sometimes find data, especially in large complex systems, to be a perceptual challenge. We can’t cleanly break it down into easily categorical chunks. For this reason, it can seem like all data (e.g., data flows, data assets, data environments, etc.) can, at times, be proverbially everything, everywhere, all at once.\n\nHowever, with data’s growing role in our lives, it’s important everyone works to understand these fundamental aspects of data management—as our collective ability to ensure data security, compliance, and data-driven decision-making relies on it.\n\nFortunately, we can use our new book on data contracts (now available in early release from our friends at O’Reilly Media) as an illustrated example of how provenance, governance, and lineage all relate.\n\nProvenance: Data Contracts: Developing Production-Grade Pipelines at Scale has two authors and a unique editorial history. The record of this authorship and editorial history over time is like the book’s data provenance.\n\nGovernance: Our publisher, O’Reilly, sets forth specific guidelines and standards—a prescribed framework—determining how the book should be used, secured, and maintained. These guidelines and standards also ensure the level of quality the book must aspire to. As such, this framework acts as the book’s governance.\n\nLineage: Finally, we want the book to find its way into the hands of people who will love it. Our distribution plan to make this happen can be mapped (i.e., tracked)—clearly showing how the book goes on to reach readers, where it is sent (both on and offline), who distributes it, and how it moves through various systems and processes as a distinct body of work. This map is the book’s lineage, and as such, the map becomes essential for troubleshooting, measuring the book’s impact, and analyzing any dependencies related to it.\n\nWhile the above hopefully parses the different roles that provenance, governance, and lineage play in effective data management, our hope is that it also illustrates their interdependencies—how each of the three functionalities improves the other two when orchestrated together.\n\n9 Common types of data lineage\n\nNow that we’ve simplified things, let’s go ahead and complicate them again (just a bit).\n\nIn data management, there are many different kinds of data lineage. There need to be—because different stakeholders and departments within an organization can use the same data in very different ways. And knowing everything about all data all the time isn’t necessary (despite what that one data analyst two cubicles over would have you believe).\n\nDepending on these varying user requirements and perspectives, some aspects, dimensions, and attributes will make more sense to map in one instance, and less (or not at all) in another. To this, other factors determining what should or should not be mentioned include data complexity, regulatory compliance, data governance, and strategy, among others. This leads us to nine common types of data lineage in use across organizations.\n\nBackward lineage: This type of data lineage traces the data flow from a given point back to its point of origin. Doing so can help data teams verify data quality related to different data outputs (e.g., data sets, reports, analytics results, etc.).\n\nForward lineage: By tracing data flow from a given point to its final destination, teams can evaluate the relevance and value of data inputs and measure the impact of changes to data or alterations enacted upon it.\n\nHorizontal lineage: The flow of data across different systems, platforms, and applications is mapped using horizontal data lineage—showing how data moves, integrates, and transforms between its source and its target. Mapping horizontal lineage also includes the tools and processes involved in these data flows.\n\nVertical lineage: Alternately, mapping the verticality of data refers to its flow within a specific system, platform, or application. This information helps data teams understand how data in these locations is structured, stored, and accessed at different layers, including tables, columns, keys, records, fields, and files.\n\nEnd-to-end lineage: Teams may also map the horizontal and vertical aspects of data together, referred to as end-to-end lineage. This is done when stakeholders need a holistic view of data provenance, usage, and quality.\n\nTable-level lineage and column-level lineage: When a much more detailed form of data tracking is required, table-level lineage—mapped at the table level of databases or systems—provides teams with a detailed, macro view of data flow. Viewing the data at the table level can be useful when performing impact analysis, data integrations, migrations, or compliance and auditing.\n\nHowever, data quality management, debugging, or detailed impact analysis can require an even more granular view of data. In these cases, column-level lineage illuminates how data moves between individual columns or fields in a table, shows how that data is altered, and provides a view of its dependencies.\n\nTechnical data lineage: Zooming back out, teams map technical data lineage to broadly track the flow of data as it moves through technical processes and transformations. The details of data’s journey from data producers to its final destination(s) are key for maintaining data efficiency, integrity, and transparency throughout an organization.\n\nOperational data lineage: Additionally, mapping how data is used and accessed in day-to-day business operations provides another way to track how data moves throughout an organization (albeit a slightly broader one). By focusing on operational systems, teams can conduct business impact analysis, compliance, and reporting, and gauge operational efficiency.\n\nBusiness data lineage: Finally, data flowing between business processes can also be mapped. Business data lineage takes less concern with the specifics of what is happening to data. Often utilized by less technical stakeholders, this form of mapping tells the story of how data is impacting the business as a whole.\n\nData lineage best practices: Our 9 recommendations\n\nSettling on the right best practices for data lineage is a lot like settling on the best title for a book on data contracts; both are exercises in limitations and precision. (And another good option always pops to mind the moment you think you’re “done.”)\n\nThat said, we think the following nine best practices, as a whole, accomplish two things:\n\nThey can be used to support the foundational needs for tracking effective data lineage across most organizations.\n\nThey balance these foundational needs with some advanced enhancements.\n\n1. Clarify objectives, tying them to IT and business needs\n\nEstablishing clear objectives before embarking on any initiative, data-related or otherwise, is crucial. In this instance, clarity helps data leaders ensure that all tools, policies, and procedures that make up an organization’s data lineage practices will be efficient, sustainable, and aligned with ongoing business needs.\n\nIt’s worth considering how data contracts help you get the most out of this process, as the value of ongoing and tangible evidence of how data lineage practices positively impact an organization over time can’t be overstated.\n\n2. Leverage automation to maximize lineage fidelity and scalability\n\nPlan to automate data lineage practices as much as possible. Gaining access to accurate and consistent information is the point, after all. Automation, especially automated data discovery, can play a crucial role here, as it reduces the risks of errors inherent in manual processes.\n\nAt the same time, automation promotes scalability—ensuring that data lineage practices (especially those related to metadata capture and management) remain functionally efficient over time.\n\n3. Vet tool and system integrations\n\nFor most of us tasked with implementing data lineage practices, chances are good an established data environment will already be in operation. Audit existing data management tools based on established objectives, ensuring they’ll contribute to maximizing the utility of data lineage information. You can then determine if you’ll need to invest in a dedicated data lineage tool or if some combination of existing tools and systems will provide the needed functionality.\n\nWhile reviewing integration capabilities, you might request demonstrations and trials, assess levels of support from potential vendors, and conduct cost-benefit analyses as needed.\n\n4. Normalize (and standardize) comprehensive documentation\n\nMaintaining detailed and accurate records of data lineage should be the rule, not the exception. This documentation becomes crucial for understanding data flows and ensuring data quality throughout the lifecycle.\n\nDepending on the size of organizations, data teams may also need to be vigilant regarding whether this documentation remains standardized over time. This contributes to robust data governance, guiding consistent understanding and use across departments and teams—reducing confusion while fostering solid communication.\n\n5. Establish robust security and access control\n\nSecurity has always been critical for protecting sensitive lineage information. But it’s increasingly critical to position data security as the responsibility of everyone, not just those in IT. To this, implement secure communications and help your co-workers understand why, at their most basic level, encryption and secure APIs are being used.\n\nEstablish a consistent cadence and maintain detailed access logs to make sure systems and tools are patched and updated regularly. Implement monitoring tools to automatically detect unusual access patterns and ensure the right alerts get sent to the right people at the right times. And, as more of the organization leans in to keep data secure, robust access controls become increasingly important. Consider utilizing security principles like the principle of least privilege as you define and refine which roles and responsibilities get specific data access.\n\n6. Take time to make time for stakeholder buy-in\n\nAt this point, you’re more or less ready to approach stakeholders for their support. Make sure you do, and that a tacit buy-in is what you actually walk away with.\n\nDepending on your stakeholders, it may help to engage with them early and often. Make sure you clearly outline and identify the benefits the organization’s data lineage practices will have. Demonstrate how the lineage practices align with the business and set realistic expectations, the latter of which can often be aided through a strategic series of pilot programs.\n\n7. Visualize lineage and support ongoing training\n\nYou probably visualized parts of your lineage proposal to help sell it. Carry the visualization forward, representing data lineage in ways that make it easy for employees with different experience levels, skill sets, and backgrounds to understand and digest.\n\nAs able, promote training that ensures different users understand how to leverage the tool or tools used to map data lineage. (Note: To promote this training, consider pizza.)\n\n8. Monitor and measure mapping effectiveness\n\nSystematic measurement requires systematic monitoring of how effective data lineage practices are over time. In turn, effectively doing both helps data teams ensure that supporting systems are robust, responsive, and stay aligned with organization governance and management objectives.\n\nIdeally, this monitoring and measurement isn’t limited to lineage alone but functions as part of broader data management efforts.\n\n9. Review and update lineage practices regularly\n\nThe tail of the best-practices snake here consists of regular audits and reviews of the data lineage process as it unravels.\n\nThis is vital, as it allows data teams to adjust the granularity of data lineage mapping, balancing utility across users and uses while optimizing for evolving stakeholder needs.\n\nA data catalog can also be beneficial here. When embedded with data lineage information, these catalogs make it easier for users to get at and understand the data they need, enhancing overall data management.\n\nRemember that in data lineage, “well-begun” is half-done\n\nThe potential impact of a map directly correlates to the quality of information used to create it.\n\nBest practices, in addition to a clear understanding of the concept, certainly make data lineage practices more efficient and effective. But shifting the emphasis and expectation of data quality further left can make them exceptional.\n\nBe among the first to find out the role data contracts can (and increasingly do) play in the lineage of data by signing up for our product waitlist at Gable.ai.\n\n‍",
      "# [Data Governance: What Is It + Best Practices](https://www.gable.ai/blog/data-governance)\nRegarding data, knowing how, who, and what are the most critical questions to govern it efficiently and responsibly. Data governance gives organizations the strategy to manage their information.\n\nIn this article, we’ll define data governance. Then, we’ll dive into why it’s essential, critical pillars of governance, its benefits, and its challenges. By the end, you’ll learn about one of the most innovative ways to govern your data assets: combining the common reactive approach with a more efficient, preventative strategy.\n\nWhat is data governance?\n\nData governance sets clear rules for handling and stewarding customer information throughout its lifecycle. It ensures data is accurate, used correctly, and kept safe.\n\nOne great way to imagine a data governance program is by picturing the following scenario:\n\nSuppose you buy an RV from an estate sale. It works great and looks terrific, but the seller says you get the whole package. Everything inside from the previous owners is yours. There might be something valuable in there, but you won’t know until you look around and sift through the items (and clutter) in the vehicle.\n\nThese objects, like pieces of data, have to be organized into a few categories:\n\nDetection: You discover and identify what’s in the RV. There might be old vinyl records in a cubby, family photographs in the closet, or valuable jewelry left behind. Some things might be useful, others worthless, while different pieces might have significance in the future (for example, maybe you don’t need the power drill you found in an old toolbox, but you might need it when you want to make minor improvements in the future).\n\nClassification: Now, it’s time to classify each item and formalize what you’ve found. Label the value and use of each item. Organize everything so you can easily access it when it’s time to move them to the right place.\n\nProcess: Decide the policy you’ll base decisions on, like how you plan on using the items. What determines a good object or not? Where should it go? Create a strategy to follow.\n\nParameters: Now that you have the process on paper, you can follow specific guidelines to determine what to do with each piece—a set of clear rules.\n\nCommunication: Through documentation with metadata management, you can add the vital information you need to retrieve and understand it. In the context of the RV, it might look like labels, a notebook explaining everything, or another system entirely. This data catalog also articulates to others what they should do with the items—there’s clear data lineage.\n\nLike the RV example, those governing data start with a central location. From there, they must decide what to do with the data, and who it should go to.\n\nFor example, different teams within an organization require different data sets, instructions on how to use them, and permissions for data access. Marketing teams, accounts receivable, customer service teams, and tech/product support would look different in the data governance context—especially as it may include social security numbers and sensitive data.\n\nThe data team can enact the process for governance that would create a way to protect everyone, provide accurate information at the right time, and provide clear guidelines on how to use it.\n\nWhy is it important?\n\nGood data governance has become essential now more than ever. Thanks to innovative technology (like artificial intelligence and machine learning) and customers living more of their lives online, there is a significant amount of information to collect, analyze, and use for decision-making and improving customer experiences.\n\nCustomers also expect you to use data efficiently, with McKinsey & Company reporting that 71% of consumers want personalized interactions and 76% get frustrated when companies fall short of it.\n\nThe importance of data governance initiatives is two-fold:\n\n1. Accurate, responsible, and efficient data for companies\n\nWith an effective data governance strategy, organizations can ensure high-quality data, use it responsibly, and maximize output.\n\nCompanies should ensure they have the right compliance, procedures, and tools to get the most out of data and use it to improve the customer experience.\n\nOne significant challenge is dealing with reactive strategies. While a quick response is ideal when something goes wrong with your data collection and processing, it’s not enough to ensure quality data governance. Companies need a preventative solution.\n\nGable's innovative technology helps organizations improve data quality at scale by fostering communication between data producers and consumers via data contracts. These contracts eliminate the human error component and stop mistakes before they happen.\n\n2. Ensuring customer trust in today’s climate\n\nThe data industry knows the challenges it’s faced with privacy, transparency, and consumer trust—in short, the world is paying attention to how companies handle data.\n\nCompanies should be able to uphold regulations like GDPR and perform above standards to remove themselves from avoidable pitfalls. They can position themselves as one of the industry's safest, most trustworthy businesses.\n\nSince 2019, data privacy search inquiries have doubled, signaling the need for more responsible data management. It’s no longer enough to handle data ethically, but consumers want full transparency and clarity on what’s collected and how it’s used.\n\nSource: Google Trends | Search inquiries for data privacy have doubled in only a few years.\n\nEffective data governance addresses these concerns. Companies can use the tools necessary to handle big data responsibly and enable access to the right individuals. Organizations can also provide clear and transparent policies to customers, communicating data practices and what to expect.\n\nAs mentioned, customers want personalized experiences. This starts with quality data. And if we can combine that with the qualifications expected from us when it comes to building trust—like data protection and transparency—then we can create a productive data strategy.\n\nWhen we fail to govern data\n\nWhen we can no longer trust data, it becomes unreliable. We no longer have a picture of consumers, the world, and where the market is heading. Management is stuck making business decisions no longer based on information but on best guesses.\n\nBut that doesn’t have to be the case. By following foundational principles, we can avoid situations that compromise our data.\n\nData governance in the cloud era\n\nIn recent years, cloud technology has changed the data governance landscape. Depending on the infrastructure you use, data is available anywhere and everywhere. This has brought more concerns about safety, security, and management protocols.\n\nThe changes have led to more federated data governance. Unlike previous systems that centralized data, federated governance addresses the distributed nature of data in the cloud. It enables companies to manage and govern across different teams and platforms, providing flexibility, scalability, and efficiency regarding governance policies.\n\nAnother issue to consider is the involvement of non-technical teams in data governance. Non-technical staff will inevitably influence how data is managed as it becomes more accessible. Without the right system, code vulnerabilities can spark major concern.\n\nThat’s why a user-friendly no-code solution that allows users to manage data can help safeguard and empower non-technical teams to govern effectively. Clear guidelines that help govern data will also accelerate your governance strategy for better and safer results.\n\nThese fast-paced changes in modern cloud data governance require agile and adaptive systems. Unlike traditional governance, which might move slowly, contemporary governance must work quickly to adapt to changing tech and consumer expectations. Companies can adopt automated governance tools, implement continuous monitoring, and have a tighter feedback loop to adjust swiftly and respond to evolving requirements.\n\nThe four pillars of the data governance framework\n\nData governance comprises a few foundational principles, often summarized in four pillars. As a data governance team works towards efficient and secure information, they have the job of ensuring that data is organized and ready for an organization to grow and achieve its top-level priorities.\n\n1. Upholding standards and regulations\n\nTeams must ensure that all practices, regulatory requirements, and compliances are maintained and upheld.\n\nFor example, the GDPR, or the General Data Protection Regulation, is one of the strictest laws globally for data security and privacy. The EU law ensures that consumers are protected and that there is transparency on what data is being collected and what it’s being used for.\n\nWhen companies become GDPR compliant, they meet EU standards and build one of the strongest, safest foundations for their data governance journey.\n\nGDPR and other relevant compliances and regulations are essential to ensuring companies meet legal standards. Afterward, they can continue to create an above-and-beyond approach to create a safer and more transparent system for consumers. As trends and privacy expectations evolve, businesses can lead the way.\n\n2. Data quality\n\nTeams are then expected to supervise data and ensure it is authentic and reliable. Data is only as good as its quality, and companies need it to make the right decisions. Quality can be measured by preciseness, thoroughness, authenticity, timeliness, and consistency.\n\nPreciseness: Is the data correct? Can it be validated and trusted?\n\nThoroughness: Is the data complete, and does it make sense as it is? Can it be used? Is there missing information that prevents the data from telling a complete story? Is the data organized?\n\nAuthenticity: Does each piece of information accurately represent the subject or action?\n\nTimeliness: Is this data relevant to understanding present situations? Does older information add context, or is it misleading? Using this data, can we predict growing trends?\n\nConsistency: Are we gathering enough data through regular intervals, touchpoints, and actions? Are all tools in sync and integrated? Is manual labor getting in the way of collection, metrics, and analytics?\n\n3. Transparency and privacy\n\nData should be ethically managed—every involved party should know what’s collected, as well as how and what it’s used for. Managers should also make sure that these guidelines and promises are upheld.\n\n4. Data management\n\nManagement refers to the overall components of governance—the “governing” portion. While stewardship identifies who is accountable and shapes the program, data management refers to all the moving pieces of making governing possible—like how efficient, secure, and cost-effective the process is. Additionally, it includes what tools are being used and how the data is stored.\n\nData governance key roles\n\nWhile there are many roles and responsibilities within data governance (like strategic level oversight), there are a few hands-on positions.\n\nSteward: The data steward cares for the data to ensure it’s accurate and up to policy standards.\n\nManager: The data manager helps put the strategic plan into action.\n\nUser: Data users involve the team and how they perform daily tasks, interact with the data, and study sets.\n\nWhat are the challenges of maintaining data governance?\n\nEach pillar of data governance faces obstacles.\n\nIs it accurate and timely? Data teams must optimize and review how they collect and analyze data consistently. Additionally, they need parameters to evaluate expired data. If the data is no longer accurate, the team loses trust in the information, leadership makes the wrong decisions, and the organization builds data debt.\n\nIs it going to the right people, and are they using the data as they should? Data teams must decide who has access to the data, how much of it, and what they can use it for. If there are inconsistencies in the policy or if circumstances change and leadership does not follow up, companies risk irresponsible governance and vulnerabilities.\n\nWhat happens when there is an inefficiency? How is it handled? If data tools are not working right, if data isn’t organized, or if something is throwing a wrench into collection and analysis, teams need to quickly identify and solve the issue.\n\nIs the organization communicating its data policy? Teams must ensure that what data they collect and how they use it is communicated to customers, employees, and essential stakeholders. There should be transparency as data policies evolve.\n\n5 best practices to consider when managing data governance\n\n1. Choose the right team\n\nGovernance is about the right people. You need team members who are passionate about quality data and have the never-ending desire to ensure the best and most accurate information possible. Additionally, that information serves the organization and its initiatives.\n\n2. Understand it’s a process\n\nData governance is a lot like gardening. You don’t plant seedlings and then revisit them in a few months. Most of them would die. Instead, you visit, water, and care for them often. When you spot weeds, you pull them out. Data governance is a continuous process that should be treated with care and dedication.\n\n3. Set high standards and communicate expectations\n\nEnsure your team is consistently communicating. They should question how enterprise data is collected, presented, and analyzed. Team members should be able to correct issues quickly and prevent the same ones in the future.\n\n4. Know the vision\n\nThe strategy should be crystal clear. If data teams know what the business goals are, they can manage data so that it’s organized and efficient to use for the needs of the organization. If team members aren’t sure what the vision is, it creates confusion, messy data, and more difficulty in making strategic decisions.\n\n5. Invest in the right technology and data governance tools\n\nIn the data world, inefficient technology and human error can wreak havoc. That’s why choosing the right platforms and tools to help govern your data through contracts, automation, and communication is critical for creating a smooth process, reducing issues, and providing the best, most relevant information possible.\n\nGable: From reactive to preventative solutions\n\nReactive problem-solving is important. We need to be able to identify an issue and fix it to preserve data integrity and security. But it shouldn’t be the only solution.\n\nMany reactive situations can be avoided from the start.\n\nGable’s proprietary technology provides data teams with data contracts to eliminate human error and prevent issues. Instead of waiting to identify a problem once it’s already happening (and causing damage), you can stop it from happening altogether.\n\nGable’s data contracts enable you to establish data owners, set requirements for the data, and codify these nuances as version-controlled code.\n\nWe know reactive data monitoring isn’t enough. Gable ensures that alerts trigger from notifications within the CI/CD workflow. Our bot provides context to developers where they are and tags data consumers after detecting breaking changes.\n\nBy bridging the communication gap between data producers and consumers, our platform creates a more accurate, efficient solution for data.",
      "# [Data Consumers: How to Make a Meal Of Your Data](https://www.gable.ai/blog/data-consumers)\nData consumers don’t bite. Honest.\n\nBut they do play increasingly vital roles in modern businesses. And their ability to deliver on behalf of the organization does depend on you keeping them well-fed—with data, that is.\n\n(Cue record-scratch.)\n\n‍\n\nData consumers are individuals, systems, and applications that access and use data to perform specific tasks or make informed decisions. As data continues to proliferate into more aspects of daily life, this definition becomes increasingly important.\n\nWhile most of us consume data by default, technical data consumers—those working in data analytics, data science, business intelligence, and the like—rely as much on the quality of data as they do its availability. This necessitates treating data as a product, with the entire organization working together to ensure the highest standards of quality are maintained over the course of the data lifecycle.\n\nThis is why it’s imperative for those working in tech-adjacent roles (e.g., managers, executives, decision-makers, and stakeholders) to understand how they can optimize for data consumers within their own organizations. But we’ll circle back to that.\n\nFirst, let’s lay a foundation by making sure we clarify what separates data producers from data consumers (and what doesn’t) in addition to covering who commonly acts as a data consumer in modern businesses.\n\nData producers vs. data consumers: As simple as it seems?\n\nIt does seem obvious. Data producers produce and/or provide data, while data consumers access and use that data. However, there are nuances to this relationship that are worth understanding. Here are some key factors, common within business environments, that can challenge the seemingly clear distinction between data production and consumption.\n\nOverlapping functions\n\nWhile often considered separately, a single entity can function as both a data producer and consumer. For example, sales teams often produce data about customer interactions, which counts as a producer role. However, it’s common for these same teams to handle the analysis of this data in order to refine their sales strategies. More generally, feedback loops within a data-savvy organization have this effect as well.\n\nData transformation\n\nTransformation of data is an instrumental part of data management. In practice, data producers may act as sources of raw data. This data then undergoes a transformation process as it’s ingested into the organization for use downstream. This can blur the line between producers and consumers in practice, as the transformation process necessitates data being consumed from one source before being delivered for use to another.\n\nVariability of data production\n\nData is produced both actively and passively. An example of active production could be the filling out of a basic web form, a deliberate act of data entry, or data generation. This could be related to customer data or personal data when individuals provide information about themselves.\n\nAn example of passive data production is how user interactions are typically logged on a social media platform or a website. These data sources often involve data collection methods that track user behavior. Whether or not data is actively or passively produced can challenge the notion of whether it’s being produced or consumed by a given data system.\n\nData stewardship and ownership\n\nGranted, data producers generate data. However, they may not have stewardship or ownership over the data produced. At the same time, data stewards who may not produce or consume data directly often play a crucial tertiary role in ensuring data quality, privacy, and security.\n\nTiming and evolution\n\nProducers and consumers of data often interact with data at different times. It’s common for data produced in real-time to be consumed in batches, or vice versa. This asynchronicity can also cloud a binary notion of who’s producing and consuming data over time.\n\nAnd, over time, the needs of data evolve as business models evolve. Meaning systems traditionally viewed as data consumers, like home appliances, can become data producers (i.e., the Internet of Things).\n\nThe basic definitions of data producers and consumers are simple enough. But as business leaders, it’s advantageous to appreciate how fluid these definitions can be in practice.\n\nWho (and what) are data consumers?\n\nWith this valuable context in mind, let’s now touch on who—and what—typically functions as a data consumer within an organization. This of course includes individuals and teams, but consumers can also be systems and applications or external entities.\n\nIndividuals and teams\n\nBusiness analysts and data scientists: Those who analyze data to extract insights, identify trends, and recommend business improvements certainly count as data consumers, as do the experts using advanced statistics, machine learning, and sheer compute to cull insights and predictions from data.\n\nSales and marketing teams: The aforementioned sales teams consume data to track sales performance, identify leads, and forecast sales trends. At the same time, marketing teams leverage data to better understand customer behavior, segment markets, measure campaign effectiveness, and, like their counterparts in sales, attempt to forecast trends.\n\nFinance, accounting, and operations teams: Key players on these teams consume data for budgeting, forecasting, financial reporting, and risk assessment analysis.\n\nOperations and supply chain teams: These teams consume data to optimize inventory and streamline operations.\n\nHuman resources (HR): Those working in human resources increasingly consume data related to recruitment trends (i.e., supply and demand), workforce analytics, and employee performance.\n\nCustomer support and service teams: High-performing contact centers rely on a constant stream of data to track service requests, evaluate customer feedback, and improve customer satisfaction.\n\nProduct managers: These roles require all available data to monitor product performance, user engagement, and identify areas of improvement.\n\nDecision makers and stakeholders: In data-driven organizations, senior leaders and managers rely on aggregated data and insights to make more productive, strategic decisions.\n\nSystems and applications\n\nBusiness intelligence tools: BI tools like Tableau, QlikView, and Power BI consume data in order to create visual representations and dashboards that analysts (also data consumers, see above) use in their work.\n\nCustomer relationship management systems: Alternatively, popular CRMs (think Salesforce and Hubspot) also consume data. Some do produce data visualizations as well, but this functionality is secondary to their primary goal of helping manage customer data and interactions.\n\nEnterprise resource planning systems: ERPs are comprehensive software solutions built to consume massive quantities of data in order to integrate various business processes and functions into a single system, one that aids in data management, process automation, reporting, analytics, and more.\n\nAutomated reporting systems: Complexity is not a prerequisite for being a data consumer, as straightforward reporting systems like NinjaOne and Alteryx consume data only as needed to aid in data preparation and report generation.\n\nData warehouses and data lakes: Typically thought of as data sources, centralized data repositories engineered to store structured and unstructured data must, by design, consume data in order to serve their purpose.\n\nMachine learning models: The algorithms driving artificial intelligence (AI) consume troves of data in order to make business-related predictions or automate decision-making processes.\n\nApplication programming interfaces: And, while APIs do not technically consume data to serve their purpose, they do get an honorable mention here since they create the pathways different systems and applications use to communicate, consume, and share data together.\n\nExternal entities\n\nPartners and affiliates: Business partners like suppliers, vendors, marketing agencies, and consulting firms often need to consume organizational data to measure joint campaign performance or align strategies.\n\nRegulatory bodies: In highly regulated industries like finance and healthcare, organizations may need to share data with regulatory authorities to ensure business operations and data management are in compliance.\n\nYour valued customers: Last but not least, digitally sophisticated customers are voracious when it comes to data consumption in the world of B2C. And, in B2B scenarios, customers are also increasingly consuming data reports and analytics as they grow both more available and accessible to less technical audiences.\n\n15 best practices to optimize your org for data consumers\n\nIn business, sadly, not all individuals get to enjoy the luxury of thinking about data management and information technology all day, every day. For those who cannot, all the information we’ve shared at this point was provided to foster an understanding and appreciation for the nuanced and varied roles consumers play in the data lifecycle.\n\nBut, often, these are the same people who have the influence and pull needed to empower a truly data-driven organization. For this reason, the following list of 15 succinct best practices is curated for those stakeholders and decision-makers who want to help set the table, so to speak.\n\nLet’s dig in:\n\n1. Engage with your data consumers\n\nOne of the best things a stakeholder can do is simple: Regularly communicate with data users in the organization. Take the time to understand the distinct requirements and challenges they face in their role.\n\nPro tip: Make constant communication easy by scheduling regular, brief check-ins with those you consider to be key data users. Quick, consistent 15-minute meetings are far more useful than longer meetings set up and attended “once in a while.”\n\n2. Treat your data as a product\n\nRestaurants live and die based on the quality of the ingredients they source. The needs and importance of your data consumers are just one of many reasons to make sure your data is of the highest possible quality, ensuring it is reliable, timely, and consistent.\n\nPro tip: The volume of data flow through even a relatively small organization is often more than can be managed manually. Work with your data leaders to implement automated data quality checks. Also, make sure that any alerts these systems use when they detect anomalies are set up to go to the right people, at the right time.\n\n3. Adopt a strong data governance framework\n\n“Data governance” can sound intense. But at its heart, governance is really just a formalized approach to defining and maintaining clear roles for data ownership and stewardship.\n\nPro tip: Robust governance is a must in today’s data-driven business world. Do your part by making sure the team or data stewards in charge are given the support and bandwidth required to succeed in their role (especially if one of those stewards will be you).\n\n4. Prioritize data security and compliance\n\nIt’s a lot harder to deal with a burglar when they’re already inside your house. Ensure that encryption, access controls, and regular audits are all in place to protect data on behalf of your consumers. It’s important to ensure everyone is up to date with regularly updated data privacy regulations specific to your organization and business model.\n\nPro tip: In partnership with your data leaders, look to leverage cloud-based solutions that include built-in security features. Doing so reduces the burdens of managing security completely in-house.\n\n5. Provide accessible data tools\n\nChampion tools and platforms for your data consumers that have earned a reputation for being highly intuitive to use. Powerful solutions that are also user-friendly encourage wide adoption, enhanced productivity, reduced training costs, and increased data accuracy.\n\nPro tip: Don’t sleep on the power of data visualization in business. BI tools in particular tend to offer dashboard capabilities that allow for quick insights without the deep dives.\n\n6. Educate and train staff\n\nData literacy should no longer be relegated to specific departments. It’s not a chore—it’s a responsibility. The health and quality of data is determined by all of its consumers, both direct and indirect. Promote this mission-critical knowledge through regular training sessions and workshops, in addition to up-to-date, accessible resources.\n\nPro tip: On-demand online training modules can drastically simplify an ongoing data literacy initiative. They serve as a means to centralize information and resources, in addition to minimizing the need for lengthy (read: costly) training sessions.\n\n7. Design for scalability and adaptability\n\nHelp ensure data systems in your organization are built to scale with the needs of your business and your data consumers.\n\nPro tip: Explore how cloud solutions can also support your ability to scale with respect to data. As these solutions grow more ubiquitous, it becomes easier to find one that can grow in sync with your business, without the need for frequent upgrades.\n\n8. Encourage cross-functional collaboration\n\nOne data-related area that firmly falls within the onus of leadership is whether or not collaborative environments are actively fostered within the organization. Optimizing for data consumption requires departments proactively working to share data and insights, and minimize data silos.\n\nPro tip: Think of inter-office communication platforms like Slack or Teams as collaboration platforms. Encourage quick, specific chats as a way of keeping your data consumers out of lengthy meetings.\n\n9. Streamline data collection processes\n\nTo ensure efficiency and reduce redundancy, normalize the ongoing automation and optimization of data collection.\n\nPro tip: Automating everything isn’t the goal. Look at where a little bit of automation will have the biggest impact. Sometimes, something as simple as utilizing APIs to pull data without manual intervention can net significant benefits.\n\n10. Iterate based on feedback\n\nThere should be no set-it-and-forget-it with organizational data management. Data processes need to be continuously refined based on the feedback you get from data consumers. More than just understanding their needs, you can play a vital role in keeping those needs met.\n\nPro tip: Business is complicated, but soliciting valuable feedback doesn’t have to be. Look to use simple feedback tools or surveys. Think about how you can reduce barriers so feedback relating to data usage is easy to give and receive.\n\n11. Stay in the know regarding data innovations\n\nLike data literacy, many people within an organization should be investing time to review emerging data-related trends through the lens of their role, experience, and skill sets. The sparks that lead to early adoption can come from anywhere. And the competitive advantages of early adoption can often prove invaluable.\n\nPro tip: Subscribe to a few industry newsletters and data-related Substacks. Just as regularly reading the trades is a must in Hollywood, use a few moments of your morning to review who’s doing what with data in your industry.\n\n12. Clarify data use cases\n\nUse cases are an excellent way to make sure specific scenarios or objectives your data consumers face align with the business’s overall goals.\n\nPro tip: It never hurts to base consumer use cases on clear business objectives. Keeping a focus on goals enables you to help streamline data processes and reduce unnecessary work.\n\n13. Leverage external data resources\n\nConsider formal partnerships or collaborations with external data sources that can enhance and complement internal data. Market trends, demographic information, and industry benchmarks can often enrich internal sales data. Analyzing data from external sources can lead to new market opportunities, potential risks, and emerging trends. And external data can be used to benchmark organizational performance against industry standards, or the competition.\n\nPro tip: Outsourcing some data needs can save time and improve data quality. But always endeavor to partner with the most reputable and trustworthy data providers.\n\n14. Document your data processes\n\nDocumentation is a critical part of maintaining high data quality. Your organization should maintain an accessible repository of all data guidelines, standards, and workflows, ensuring consistency and clarity in data practices.\n\nPro tip: To keep documentation from becoming daunting, leverage documentation tools with simple yet robust templates. Over time, these templates reduce the effort needed to update and maintain your documentation.\n\n15. Conduct regular data audits\n\nData access, usage, and quality all need to be reviewed periodically. By making data audits consistent, you’ll help identify areas of improvement while ensuring compliance.\n\nPro tip: Don’t expect your peers to party when audit time rolls around. But do work to schedule audits during less busy periods in the business. This consideration, along with keeping up a regular cadence with the audits themselves, can prevent unexpected issues and reduce stress.\n\nOrganizations are brimming with data-hungry professionals—make sure the data you source is always up to code\n\n‍\n\nWe’re still a bit in the Wild West when it comes to managing data at scale, especially with the recent rise of large language models. However, there are valuable third parties that can lend a hand through the use of data contracts. Gable.ai is transforming how data contracts work, and the data consumers in your organization deserve to benefit from what we’re cooking up in our own kitchen.",
      "# [Data Contracts: Developing Production Grade Pipelines at Scale](https://www.gable.ai/data-contracts-book)\nGet the ultimate guide to Data Contracts\n\nPoor data quality threatens data teams, risking revenue and trust. Data contracts solve this by ensuring data quality through clear definitions, ownership, and CI/CD enforcement.\n\nThis guide covers the essentials of data contract architecture, from its significance to real-world applications and implementation strategies, advocating for its adoption in organizations.",
      "# [How to Protect the Data Pipeline Process with Data Contracts](https://www.gable.ai/blog/data-pipeline-process)\nThe most efficient systems may be extremely valuable and essential, but everything goes out the window when there's a vulnerability.\n\n‍\n\nTake, for instance, air travel. It’s the most efficient way to get you from Point A to Point B.\n\n‍\n\nThe passengers of Alaska Airlines would’ve agreed too, when suddenly, on January 5th, 2024, a piece of the aircraft snapped off with a bang.\n\n‍\n\nThankfully, they made it back safely, and the aircrew acted heroically to ensure everyone was safe. But it brings up an important issue.\n\n‍\n\nLike an aircraft, your data pipeline process should be accurate and protected at all times. That’s why ensuring your pipeline is safeguarded from future vulnerabilities, breakages, and interruptions is critical.\n\n‍\n\n‍\n\nFirst, we’ll define a data pipeline. Then, we’ll go over some types you can expect, steps, and benefits for data pipelines.\n\n‍\n\nFinally, we’ll learn how data contracts can help protect your data pipeline process for better accuracy and efficiency.\n\nWhat is a data pipeline?\n\nA data pipeline is how a company defines and executes how raw data moves between systems, gets verified, stored, and maintained.\n\nThe data pipeline process clarifies how we incorporate our data strategy.\n\nWhen the data is processed, it goes to the data sink for use case applications, a data warehouse for analytics, or the data lake for continued data science and machine learning.\n\nWhat types of data pipelines are there?\n\nData pipeline strategies vary based on your industry and needs. But the pipeline can be split into two types.\n\n1. Batch processing pipeline\n\nThe batch method is one of the more traditional options companies choose for enterprise data. It’s when a company processes data through fixed, predefined parameters. Your team can process larger quantities of data at a time.\n\nSince such a big data load can cause latency issues, the information is often processed during odd hours with less user activity, such as at 3 a.m.\n\nBatch processing is effective for processing lots of data that aren’t as time-sensitive. It can include historical data or metadata that could be useful in the future.\n\nBatch pipelines, however, are challenging to maintain, with systems often having to process data even if it hasn’t changed (which is a lot of work for humans and computers). Since you load volumes of data, your system will also have a knowledge gap and contain outdated information.\n\n2. Real-time or streaming processing pipeline\n\nStreaming processing pipelines are a great way to manage your data in the fast-paced world of computers and the internet.\n\nA streaming pipeline is when companies process data as it arrives, giving them low latency and current insights. Data engineers and teams can work with new data and updated datasets through automation.\n\nUnlike batch data, stream processing is constantly changing. It influences your dashboards with metrics, data analytics, and decision-making information.\n\nWhile this pipeline is very effective, it can be risky if you don’t have the right data strategy in place. You want to ensure you have the right tools and management to verify data quality and prevent hiccups as data is gathered and processed.\n\nPipelines can also include focused categories, depending on your type of business and where your data flow is. Some examples include:\n\nCloud data process: The focus on cloud-based services and how data lives, processes, and is integrated within the cloud.\n\nMachine learning process: How data is processed for machine learning (the end-to-end deployment of learning models and data preparation).\n\nData governance process: How data is governed and protected for quality, security, and compliance.\n\nWhat is ELT and ETL?\n\nAs you improve your data pipeline process, you may come across the terms ELT and ETL. They sound the same, and for the most part they are.\n\nBoth of these models focus on the order of steps for pipelines.\n\nThe initials stand for the same but place emphasis on the order:\n\nE = Extract\n\nL = Load\n\nT = Transform\n\nThey cover how data is collected, changed, and stored. These days, different pipelines can have multiple stages where ELT and ETL are involved. Often, the methods are talked about interchangeably and already function within your pipeline.\n\nELT (extract, load, and transform) might be good for a SaaS with strict rules and a critical schema to follow.\n\nOn the other hand, ETL (extract, transform, load) might be a good option to store information in your data warehouse or lake.\n\nWhat is the difference between an ETL/ELT and data pipeline?\n\nETL and ELT fall under the umbrella of your data pipeline and how you process information. While two different things, the ETL and ELT refer to your tactical steps while the pipeline encompasses the process.\n\nWhat are the benefits of a data pipeline process?\n\nData pipelines create a better way to manage your data and save you time. Below are the top advantages of a healthy process:\n\n1. Get better data quality\n\nWhen you implement a data pipeline process, you get cleaner results. The pipeline can refine the information, find and correct redundancies, and provide a usable dataset to work with.\n\n2. Make it a more efficient process\n\nData pipelines, thanks to data contracts, make it possible to automate the process. This saves thousands of hours of data engineering work. Instead, your team can use the saved time to find ways to improve your data approach or analyze the information.\n\n3. Implement a holistic approach to data\n\nThrough automation and the ability to bring your data together, your pipeline can integrate your data sources, transform data, and create a holistic product. It checks values from different sources and finds consistency errors. Additionally, it flags and corrects other common errors.\n\nWhat are the steps of the data pipeline process?\n\nETL and ELT are part of the data pipeline infrastructure. The concepts are also commonly summarized into the following:\n\n1. Data ingestion\n\nThis is when data is extracted from sources and brought to a central location for company access and analyses.\n\nThe data is often found from a source like a CRM (Salesforce, Hubspot, or Zoho). It can also come from other sources that collect data.\n\n2. Data transformation\n\nData is converted and structured to fit your system as a usable format.\n\nTransformation can take many forms. It may be the way you need data recognized, filtered, or segmented. Company pipelines may include data contracts to automatically sort and manipulate the data.\n\n‍3. Data storage\n\nFinally, your data is stored so that the company can access it and use it for business operations.\n\nIt usually arrives at a data warehouse or data lake. From there, your data team can analyze the information or use it.\n\nWhat are the benefits of Apache Kafka?\n\nApache Kafka is a popular solution for data pipeline processing. It is an open-source platform that helps manage and transform your real-time data—which is great for streaming pipelines.\n\nThere are plenty of benefits to using Apache Kafka.\n\nIt’s open-sourced, which means you can build your own solutions or partner with a third party to create a custom fit for your company.\n\nIt’s fast and scalable, so you can process data immediately across many servers.\n\nIt’s durable with Apache Kafka’s ability to provide intra-cluster replication.\n\nIt has high performance, even when dealing with large amounts of data.\n\nHow do data contracts support pipelines?\n\nData is only as good as its accuracy. The minute it’s compromised, you can’t trust it. Your business decisions, customer behavior analytics, and planning are now done in the dark.\n\nThankfully, we now have the technology to prevent data pipeline issues before they happen.\n\nYou no longer have to worry about a problem after that fact, you can rely on data contracts to execute smooth processes and eliminate avoidable mistakes.\n\nData contracts define the structure, format, and criteria for data as it is extracted, transformed, and stored. It eliminates human error and can find issues before they become a problem.\n\nData contracts automate your pipeline for a smoother, more accurate data process and workflow.\n\nData contracts for a better pipeline process\n\nWhen you think of a literal pipeline that moves water, it’s a powerful force. It’s efficient, it moves fast, and it can push the resource to its destination.\n\nWhere pipelines might depend on water pressure, gravity, and energy to function properly, your data pipeline needs its power source too.\n\nData contracts move, transform, and store your information efficiently through automatic processes. Choosing the right solution provides the power source to make it possible.\n\nGable automatically generates contract templates, manages contract versioning, and enforces contracts using a variety of alerting thresholds.\n\nYou can collaborate with data engineers, data scientists, and software engineers to create and modify contracts over time.\n\nWith Gable, you can prevent breaking changes programmatically and alert consumers when contract updates will impact them. You can manage contract versions and evolution simply and easily.\n\nIt’s perfect for your data pipeline process, especially if you want to take control of your data management and use your information to its full potential—so you can grow your company with secure, reliable, and efficient data."
    ],
    "search_results": [
      {
        "title": "Gable | Data Contracts Platform",
        "link": "https://www.gable.ai/",
        "snippet": "Gable is a a shift left data platform that bridges the gap between data producers and data consumers through data contracts.",
        "formattedUrl": "https://www.gable.ai/"
      },
      {
        "title": "Gable Blog",
        "link": "https://www.gable.ai/blog",
        "snippet": "Learn why data leaders are weighing the benefits of federated vs. centralized data governance, in addition to one way of ensuring either can excel in practice.",
        "formattedUrl": "https://www.gable.ai/blog"
      },
      {
        "title": "Career",
        "link": "https://www.gable.ai/career",
        "snippet": "We're looking for passionate, innovative individuals to help us redefine the data industry. Explore our open positions below and find the role that's perfect ...",
        "formattedUrl": "https://www.gable.ai/career"
      },
      {
        "title": "Legal",
        "link": "https://www.gable.ai/terms",
        "snippet": "May 29, 2023 ... Gable is a a shift left data platform that bridges the gap between data producers and data consumers through data contracts.",
        "formattedUrl": "https://www.gable.ai/terms"
      },
      {
        "title": "Privacy Notice",
        "link": "https://www.gable.ai/privacy-notice",
        "snippet": "May 29, 2023 ... Gable is a a shift left data platform that bridges the gap between data producers and data consumers through data contracts.",
        "formattedUrl": "https://www.gable.ai/privacy-notice"
      },
      {
        "title": "Gable Blog - What is DataOps? What Leaders Need to Know",
        "link": "https://www.gable.ai/blog/dataops",
        "snippet": "Apr 4, 2024 ... DataOps is short for Data Operations. It is a process-oriented methodology that shares and builds on many characteristics of Agile methodologies ...",
        "formattedUrl": "https://www.gable.ai/blog/dataops"
      },
      {
        "title": "About Gable",
        "link": "https://www.gable.ai/about-gable",
        "snippet": "Gable is a shift left platform strive to create a shared data culture of collaboration, accountability, quality, and governance through data contract.",
        "formattedUrl": "https://www.gable.ai/about-gable"
      },
      {
        "title": "Gable Blog - 4 Best Data Producer Practices to Improve Your Data ...",
        "link": "https://www.gable.ai/blog/data-producers",
        "snippet": "Dec 12, 2023 ... Follow best practices for data producers to minimize data quality issues and improve your data management.",
        "formattedUrl": "https://www.gable.ai/blog/data-producers"
      },
      {
        "title": "Gable Blog - Data Debt: What Is it and How to Avoid It",
        "link": "https://www.gable.ai/blog/data-debt",
        "snippet": "Nov 17, 2023 ... Standardization: Data contracts ensure a consistent structure, which means that data from different sources or teams adheres to a unified format ...",
        "formattedUrl": "https://www.gable.ai/blog/data-debt"
      },
      {
        "title": "Gable Blog - Data Modeling 101: General Foundations to Specific ...",
        "link": "https://www.gable.ai/blog/data-modeling",
        "snippet": "This blog article aims to lay a solid, real-world-based foundation regarding the concept and practice of data modeling.",
        "formattedUrl": "https://www.gable.ai/blog/data-modeling"
      },
      {
        "title": "Gable Blog - What Are Data Contracts? What Leaders Need to Know",
        "link": "https://www.gable.ai/blog/data-contracts",
        "snippet": "Jan 23, 2024 ... In practice, the formal agreement that data contracts represent will marshal the exchange, handling, storage, and usage of data. Contracting ...",
        "formattedUrl": "https://www.gable.ai/blog/data-contracts"
      },
      {
        "title": "Gable Blog - What is Data Provenance? Importance & Challenges",
        "link": "https://www.gable.ai/blog/data-provenance",
        "snippet": "May 17, 2024 ... Data provenance provides a comprehensive history of data that includes sources of the data, changes that were made to it, and who made the ...",
        "formattedUrl": "https://www.gable.ai/blog/data-provenance"
      },
      {
        "title": "Gable Blog - Data Collaboration: What Working Better Together ...",
        "link": "https://www.gable.ai/blog/data-collaboration",
        "snippet": "Feb 14, 2024 ... Enhanced data change management processes. Robust data collaboration helps ensure any and all changes to data structures, formats, and usage are ...",
        "formattedUrl": "https://www.gable.ai/blog/data-collaboration"
      },
      {
        "title": "Gable Blog - Data Compliance: What You Need to Know in 2025",
        "link": "https://www.gable.ai/blog/data-compliance",
        "snippet": "Data compliance often revolves around the \"now.\" But data leaders should look ahead to 2025 trends to ensure that they stay ahead of the curve.",
        "formattedUrl": "https://www.gable.ai/blog/data-compliance"
      },
      {
        "title": "Gable Blog - Database Schema: The Need for (and Risks of ...",
        "link": "https://www.gable.ai/blog/database-schema",
        "snippet": "Feb 16, 2024 ... Increased testing and validation overhead: Schema changes require extensive testing and validation to ensure they don't break existing systems.",
        "formattedUrl": "https://www.gable.ai/blog/database-schema"
      },
      {
        "title": "Gable Blog - How to Think About Data Quality",
        "link": "https://www.gable.ai/blog/data-quality",
        "snippet": "What are the 5 characteristics of data quality? · Accuracy: How accurate is the data at hand? · Consistency: High-quality data contains no contradictions across ...",
        "formattedUrl": "https://www.gable.ai/blog/data-quality"
      },
      {
        "title": "Gable Blog - What is Data Lineage? Tools, Techniques, Examples",
        "link": "https://www.gable.ai/blog/data-lineage",
        "snippet": "May 21, 2024 ... Horizontal lineage: The flow of data across different systems, platforms, and applications is mapped using horizontal data lineage—showing how ...",
        "formattedUrl": "https://www.gable.ai/blog/data-lineage"
      },
      {
        "title": "Gable Blog - Data Governance: What Is It + Best Practices",
        "link": "https://www.gable.ai/blog/data-governance",
        "snippet": "Dec 13, 2023 ... Data governance sets clear rules for handling and stewarding customer information throughout its lifecycle. It ensures data is accurate, used ...",
        "formattedUrl": "https://www.gable.ai/blog/data-governance"
      },
      {
        "title": "Gable Blog - Data Consumers: How to Make a Meal Of Your Data",
        "link": "https://www.gable.ai/blog/data-consumers",
        "snippet": "Nov 17, 2023 ... Producers and consumers of data often interact with data at different times. It's common for data produced in real-time to be consumed in ...",
        "formattedUrl": "https://www.gable.ai/blog/data-consumers"
      },
      {
        "title": "Data Contracts: Developing Production Grade Pipelines at Scale",
        "link": "https://www.gable.ai/data-contracts-book",
        "snippet": "Download the Data Contracts: Developing Production Grade Pipelines at Scale Book.",
        "formattedUrl": "https://www.gable.ai/data-contracts-book"
      },
      {
        "title": "Gable Blog - How to Protect the Data Pipeline Process with Data ...",
        "link": "https://www.gable.ai/blog/data-pipeline-process",
        "snippet": "Feb 26, 2024 ... We'll learn how data contracts can help protect your data pipeline process for better accuracy and efficiency.",
        "formattedUrl": "https://www.gable.ai/blog/data-pipeline-process"
      },
      {
        "title": "Gable Blog - 3 Data Contract Types and Examples",
        "link": "https://www.gable.ai/blog/data-contract-example",
        "snippet": "Nov 5, 2024 ... In event streaming, data contracts enforce structure and data quality rules when APIs transfer real-time data across systems. By doing so, the ...",
        "formattedUrl": "https://www.gable.ai/blog/data-contract-example"
      },
      {
        "title": "Gable Blog - Semi-Structured Data: Examples and How to Manage",
        "link": "https://www.gable.ai/blog/semi-structured-data",
        "snippet": "Oct 23, 2024 ... Flexibility and scalability: Semi-structured data formats like JSON and XML allow companies to store and process information without a rigid ...",
        "formattedUrl": "https://www.gable.ai/blog/semi-structured-data"
      },
      {
        "title": "Gable Blog - OLTP vs OLAP: What's the Difference?",
        "link": "https://www.gable.ai/blog/oltp-vs-olap",
        "snippet": "Feb 15, 2024 ... OLTP and OLAP are two fundamental concepts that serve different but complementary purposes, both in managing and utilizing data within organizations.",
        "formattedUrl": "https://www.gable.ai/blog/oltp-vs-olap"
      },
      {
        "title": "Gable Blog - Top 5 Data Lineage Tools (+ How to Choose)",
        "link": "https://www.gable.ai/blog/data-lineage-tools",
        "snippet": "We're showcasing five potentially potent tools for data lineage here, noting the pros, cons, and pricing for each.",
        "formattedUrl": "https://www.gable.ai/blog/data-lineage-tools"
      },
      {
        "title": "Gable Blog - Automated Data Governance: The Science of Better ...",
        "link": "https://www.gable.ai/blog/automated-data-governance",
        "snippet": "Aug 1, 2024 ... Automated data governance offers significant advantages, including enhanced compliance, improved efficiency, cost savings, and better support ...",
        "formattedUrl": "https://www.gable.ai/blog/automated-data-governance"
      },
      {
        "title": "Gable Blog - Data Quality Management: 6 Key Ingredients",
        "link": "https://www.gable.ai/blog/data-quality-management",
        "snippet": "Aug 14, 2024 ... Data quality management (DQM) frameworks act as the kitchen where quality data is prepped for use. And the DQM tools, techniques, and processes that live ...",
        "formattedUrl": "https://www.gable.ai/blog/data-quality-management"
      },
      {
        "title": "Gable Blog - Data Supply Chains: Supporting the Smartification of ...",
        "link": "https://www.gable.ai/blog/data-supply-chain",
        "snippet": "May 30, 2024 ... Data supply chains that support real-time data processing functionality are essential for supporting the up-to-the-minute data AI applications ...",
        "formattedUrl": "https://www.gable.ai/blog/data-supply-chain"
      },
      {
        "title": "Gable Blog - The Pragmatist's Guide to Data Management ...",
        "link": "https://www.gable.ai/blog/data-management-framework",
        "snippet": "May 14, 2024 ... A pragmatic approach to formalizing a robust data management framework naturally benefits data stewards, data consumers, and data assets alike.",
        "formattedUrl": "https://www.gable.ai/blog/data-management-framework"
      },
      {
        "title": "Gable Blog - Automated Data Lineage: Why Do, How To, And Types ...",
        "link": "https://www.gable.ai/blog/automated-data-lineage",
        "snippet": "Jul 9, 2024 ... Automated data lineage is a means to an end—an end that often includes improving data quality, compliance, and operational efficiency. 2. Select ...",
        "formattedUrl": "https://www.gable.ai/blog/automated-data-lineage"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Gable.ai LinkedIn](https://www.linkedin.com/company/gable-ai)  \n- [Gable.ai Twitter](https://twitter.com/gable_ai)  \n\n# Job boards\n- [Static Code Analysis Expert - Gable](https://apply.workable.com/gable/j/1A48FFBF3B/)  \n- [Staff Software Engineer - Data - Gable.ai | Built In Seattle](https://www.builtinseattle.com/job/staff-software-engineer-data/93730)  \n- [Static Code Analysis Expert - GeekWork](https://www.geekwire.com/jobs/job/gable-ai-seattle-2-static-code-analysis-expert/)  \n\n# App stores\n- No relevant app store links found.\n\n# Product reviews\n- No detailed product reviews found.\n\n# News articles (most recent first, grouped by event)\n### Gable.ai Developments\n- [Gable.ai Raises $7M in Seed Funding](https://www.finsmes.com/2023/09/gable-ai-raises-7m-in-seed-funding.html) - Sep 12, 2023  \n- [With 'GitHub for data,' Gable.ai wants to connect software engineers ...](https://venturebeat.com/ai/with-github-for-data-gable-ai-wants-to-connect-software-engineers-and-ml-developers/) - Sep 12, 2023  \n- [Seattle startup Gable raising another round to help developers and ...](https://www.geekwire.com/2024/seattle-startup-gable-raising-another-round-to-help-developers-and-data-teams-work-together/) - Jul 31, 2024  \n- [Gable.ai Unveils Data Collaboration Platform Set to Transform ...](https://www.prnewswire.com/news-releases/gableai-unveils-data-collaboration-platform-set-to-transform-analytics-and-ai-workflows-301923978.html) - Sep 12, 2023  \n\n### Other News\n- [Sample Series A pitch deck: Gable's $16M deck | TechCrunch](https://techcrunch.com/2023/03/02/sample-series-a-pitch-deck-gable/) - Mar 2, 2023  \n\n# Key employees (grouped by employee)\n### Chad Sanderson\n- [Chad Sanderson - The Future of Data Products](https://www.propeldata.com/podcasts/chad-sanderson---the-future-of-data-products)  \n- [Master AI-Ready Data Infrastructure by Chad Sanderson on Maven](https://maven.com/chad-sanderson/datainfra)  \n\n### Adrian Kreuziger\n- [Launching Gable, a data collaboration platform | Adrian Kreuziger ...](https://www.linkedin.com/posts/adrian-kreuziger-b737b115b_happy-to-say-that-i-can-finally-share-what-activity-7107413148034363393-dEhB?trk=public_profile_like_view)  \n\n# Other pages on the company website\n- [About Gable](https://www.gable.ai/about-gable)  \n- [Gable Blog](https://www.gable.ai/blog)  \n- [Career](https://www.gable.ai/career)  \n- [Gable | Data Contracts Platform](https://www.gable.ai/)  \n\n# Other\n- [Gable (Business/Productivity Software) Company Profile 2024 ...](https://pitchbook.com/profiles/company/535437-19)  \n- [Gable Blog - Data Collaboration: What Working Better Together ...](https://www.gable.ai/blog/data-consumers)  \n- [Gable Blog - What Are Data Contracts? What Leaders Need to Know](https://www.gable.ai/blog/data-contracts)  \n- [Gable Blog - Data Governance: What Is It + Best Practices](https://www.gable.ai/blog/data-governance)  \n- [Gable Blog - Data Quality Management: 6 Key Ingredients](https://www.gable.ai/blog/data-quality-management)",
  "crunchbase_markdown": "# Gable, founded 2023-01-01 [(Crunchbase, 2024)](https://www.crunchbase.com/organization/gable-f237)\nGable is a B2B data infrastructure SaaS that offers a platform for collaboration to write and execute data contracts. Gable supports communication between data providers and consumers using data contracts, assisting companies to increase data quality at scale.\n\n- [Website](https://www.gable.ai)\n- [LinkedIn](https://www.linkedin.com/company/gable-ai)\n- [Twitter](https://www.twitter.com/GableAI)\n\n## Funding (24M USD total)\n\n- 17M USD on 2024-07-26\n- 7M USD on 2023-09-12\n\n",
  "customer_experience_result": {
    "output_text": "# COMPANY Gable\n\n## Positive Sentiment\n- \"I'm just so happy to see this guy get the kind of opportunities he's getting right now.\" [(Impressive-Potato, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt5xfas/)\n- \"Looks fun.\" [(Sharktoothdecay, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1bhsg/)\n- \"Sign me up for anything starring Ke Huy Quan.\" [(pineapplesailfish, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1o6ir/)\n- \"I am so happy to see Quan get more work, tbh.\" [(JPVsTheEvilDead, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1wwp9/)\n- \"This movie is from the same producers of the John Wick and Nobody movies - so, it's gonna be a banger. So excited.\" [(FLORD1LUNA, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1gaop/)\n- \"After all these years, ~~Short Round~~ Waymond Wang finally takes his place amongst action movie royalty!\" [(KingMario05, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1pbjb/)\n\n## Neutral Sentiment\n- \"For a moment I thought he was Jackie Chan.\" [(Karurosun, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1ddkc/)\n- \"He's definitely channeling Jackie's 'I don't want trouble!' vibe in a good way!\" [(doomrabbit, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1f5jp/)\n\n# PRODUCT Gable\n\n## Negative Sentiment\n- \"MyRISE is broken in one case - for me at least. After completing the side story, 'A Good Inv-EST-ment,' my character was teleported to an area that doesn’t have Molly Holly in it. This doesn’t allow me to continue to the main storyline, which renders my second playthrough incomplete and unplayable.\" [(BrandonIsWhoIAm, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd80hzv/)\n- \"Had to literally wipe a save due to a gamebreaking bug. It wouldn't load the story any further and instead returned to the main menu of the game.\" [(Yoruichi90, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd87qey/)\n- \"The game crashes almost as often as 2k20.\" [(Expert-Singer4926, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8t1ba/)\n\n## Confusion/Frustration\n- \"For the love of God, what do the pin sliders do.\" [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8atb4/)\n- \"I can kinda understand the copyright thing but I don't understand not being able to use their music for menus and stuff.\" [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9ofk5/)\n- \"In Universe mode some of the matches on the match card disappear, when that happens one or 2 matches you play the pins and submissions are automatically turned off and you are unable to exit the ring.\" [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9ofk5/)",
    "intermediate_steps": [
      "- \"I prefer using Loveland Innovations over Hover. You can directly import 3D and measurements into Xactimate. I use their AI for roof damage and it's quick and easy.\" [(Purblebelly87, Reddit, 2024-05-10)](cache://reddit/16)",
      "",
      "```\n```",
      "- \"I'm just so happy to see this guy get the kind of opportunities he's getting right now.\" [(Impressive-Potato, Reddit, 2024-10-22)](cache://reddit/286)\n- \"Looks fun.\" [(Sharktoothdecay, Reddit, 2024-10-21)](cache://reddit/231)\n- \"Sign me up for anything starring Ke Huy Quan.\" [(pineapplesailfish, Reddit, 2024-10-21)](cache://reddit/226)\n- \"I am so happy to see Quan get more work, tbh.\" [(JPVsTheEvilDead, Reddit, 2024-10-21)](cache://reddit/230)\n- \"This movie is from the same producers of the John Wick and Nobody movies - so, it's gonna be a banger. So excited.\" [(FLORD1LUNA, Reddit, 2024-10-21)](cache://reddit/209)\n- \"For a moment I thought he was Jackie Chan.\" [(Karurosun, Reddit, 2024-10-21)](cache://reddit/233)\n- \"He's definitely channeling Jackie's 'I don't want trouble!' vibe in a good way!\" [(doomrabbit, Reddit, 2024-10-21)](cache://reddit/234)\n- \"After all these years, ~~Short Round~~ Waymond Wang finally takes his place amongst action movie royalty!\" [(KingMario05, Reddit, 2024-10-21)](cache://reddit/242)",
      "```\n```",
      "- \"MyRISE is broken in one case - for me at least. After completing the side story, 'A Good Inv-EST-ment,' my character was teleported to an area that doesn’t have Molly Holly in it. This doesn’t allow me to continue to the main storyline, which renders my second playthrough incomplete and unplayable.\" [(BrandonIsWhoIAm, Reddit, 2023-03-22)](cache://reddit/357)\n- \"Had to literally wipe a save due to a gamebreaking bug. It wouldn't load the story any further and instead returned to the main menu of the game.\" [(Yoruichi90, Reddit, 2023-03-22)](cache://reddit/384)\n- \"For the love of God, what do the pin sliders do.\" [(None, Reddit, 2023-03-22)](cache://reddit/372)\n- \"The game crashes almost as often as 2k20.\" [(Expert-Singer4926, Reddit, 2023-03-22)](cache://reddit/410)\n- \"I can kinda understand the copyright thing but I don't understand not being able to use their music for menus and stuff.\" [(None, Reddit, 2023-03-22)](cache://reddit/414)\n- \"In Universe mode some of the matches on the match card disappear, when that happens one or 2 matches you play the pins and submissions are automatically turned off and you are unable to exit the ring.\" [(None, Reddit, 2023-03-22)](cache://reddit/414)"
    ],
    "url_to_review": {},
    "review_markdowns": [
      "# Post ID 1g8uzk5: First Images from 'Love Hurts' - Key Huy Quan stars as Marvin Gable, a real estate agent in the Milwaukee suburbs whose life is upended when he receives a mysterious envelope from his former partner-in-crime he left for dead with +4940 score by [(MarvelsGrantMan136, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/)\n\n\n## Comment ID lt1ba5c with +1078 score by [(Sisiwakanamaru, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1ba5c/) (in reply to ID 1g8uzk5):\nI am excited about Ke Huy Quan being a lead in action movie, especially when 87north is behind this.\n\n### Comment ID lt1oxyi with +277 score by [(funky_grandma, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1oxyi/) (in reply to ID lt1ba5c):\nWe are one step closer to the Short Round series where he travels the world solving mysteries in the 1970s\n\n#### Comment ID lt20j1m with +68 score by [(None, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt20j1m/) (in reply to ID lt1oxyi):\nHe better be! In fact, scene of Indy picking up his whip at the end of his last movie could very well lead to the start of Short Round's series where he's revealed as the whip's next bearer!\n\n#### Comment ID lt2ceyz with +13 score by [(mdavis360, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2ceyz/) (in reply to ID lt1oxyi):\nAs a kid of the 80s this was all I ever wanted.  I loved Short Round-he was my ambassador on the screen and I wanted to see more of him!\n\n#### Comment ID lt2sh6y with +14 score by [(jrgman42, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2sh6y/) (in reply to ID lt1oxyi):\nWhy not a series with Data going around the world solving puzzles, searching for treasure, and setting booty traps.\n\n#### Comment ID lt2makw with +5 score by [(InnocentTailor, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2makw/) (in reply to ID lt1oxyi):\nDo it!  It’s an easy way to continue the Indiana Jones mythos without recasting Ford or trotting him out for more stuff, at least in a main character capacity.\n\n#### Comment ID lt2sqjg with +4 score by [(YallaHammer, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2sqjg/) (in reply to ID lt1oxyi):\nI would subscribe to a streaming service just to watch a Shortround series\n\n#### Comment ID lt3l0by with +3 score by [(ImpressionFeisty8359, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3l0by/) (in reply to ID lt1oxyi):\nWould be cool but he is 54 now unless they de-age him.\n\n#### Comment ID lt6b81c with +2 score by [(MAXMEEKO, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt6b81c/) (in reply to ID lt1oxyi):\nmy head canon when i was young was Short Round and Willie go back to shanghai and take over the club\n\n#### Comment ID lt79pco with +2 score by [(Impressive-Potato, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt79pco/) (in reply to ID lt1oxyi):\nThe Indy franchise had what, 3 movies to bring him back in modern times? \nInstead we had Shia pushed on us.\n\n### Comment ID lt1qk8n with +21 score by [(In_My_Own_Image, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1qk8n/) (in reply to ID lt1ba5c):\nQuan + 87north sounds like a win to me. The Wick movies and Nobody are top tier action movies and with Quan's martial arts skills and charisma it should almost certainly be worth checking out.\n\n## Comment ID lt19kzq with +558 score by [(None, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt19kzq/) (in reply to ID 1g8uzk5):\n[deleted]\n\n### Comment ID lt1azbc with +349 score by [(Sisiwakanamaru, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1azbc/) (in reply to ID lt19kzq):\nI do not mind it though, he was so funny in \"Bottoms\"\n\n#### Comment ID lt1fjws with +520 score by [(Antrikshy, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1fjws/) (in reply to ID lt1azbc):\nFun trivia about Marshawn in Bottoms, from IMDb:\n\n>Marshawn Lynch was initially unsure about accepting the role. He ended up taking it as a way to rewrite his regret of mishandling his younger sister coming out to him in high school.\n\n#### Comment ID lt1g79c with +85 score by [(naetron, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1g79c/) (in reply to ID lt1azbc):\nHe had a great cameo in Brooklyn99, too.\n\n#### Comment ID lt1klcw with +60 score by [(Upbeat_Tension_8077, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1klcw/) (in reply to ID lt1azbc):\nThe way he delivered \"The Holocaust. It happened\" in that killed me\n\n#### Comment ID lt2oo0m with +31 score by [(falafelthe3, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2oo0m/) (in reply to ID lt1azbc):\n>\"Thanks for coming in today.\"\n\n>\"We have to come in, it's class.\"\n\n>\"Try telling Dimitri Walker that. Little motherfucker came in the first week, and I ain't seen him since.\"\n\n>\"...Dimitri Walker committed suicide the first week of school...\"\n\n>\"Suuuuure he did 😏\"\n\n#### Comment ID lt1s9w0 with +17 score by [(martian_maneater, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1s9w0/) (in reply to ID lt1azbc):\n\"I'm not stupid, I just look like this\"\n\n#### Comment ID lt1mbdg with +32 score by [(TheFotty, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1mbdg/) (in reply to ID lt1azbc):\nHe was just there so he wouldn't get fined.\n\n#### Comment ID lt4u75w with +8 score by [(CaliCareBear, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4u75w/) (in reply to ID lt1azbc):\nHe was the funniest episode of that Will Arnett cop improv show on Netflix.\n\n#### Comment ID lt61kq2 with +5 score by [(ballplayer0025, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt61kq2/) (in reply to ID lt1azbc):\nHis episode of Murderville was great too.\n\n### Comment ID lt1kr0l with +76 score by [(Etzell, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1kr0l/) (in reply to ID lt19kzq):\nHe was great in Murderville.\n\n#### Comment ID lt2h5m1 with +21 score by [(ken_NT, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2h5m1/) (in reply to ID lt1kr0l):\nDetective Bagabiche\n\nProbably my second favorite of season 1 (Kumail Nanjiani was my favorite). He played it off so well as someone without a background acting or comedy.\n\n#### Comment ID lt1v2x0 with +30 score by [(stillabitofadikdik, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1v2x0/) (in reply to ID lt1kr0l):\nThe best part of that show! All the other guests were clearly buddies or knew Will Arnett enough that it was just kinda awkward for them playing off him playing a character. Marshawn jumped right in.\n\n### Comment ID lt1c0f3 with +43 score by [(Sign_of_Zeta, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1c0f3/) (in reply to ID lt19kzq):\nIm Just Here So I Dont Get Fined\n\n### Comment ID lt1dzvr with +16 score by [(pembunuhUpahan, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1dzvr/) (in reply to ID lt19kzq):\nSomeone gave him a lot of skittles\n\n### Comment ID lt1n1zp with +6 score by [(BelonyInMyLeftPocket, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1n1zp/) (in reply to ID lt19kzq):\nThanks for asking\n\n### Comment ID lt1xy7d with +3 score by [(btotherad, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1xy7d/) (in reply to ID lt19kzq):\nIt’s a great question but it never hurts to Marshawn make some random appearances. He’s awesome.\n\n### Comment ID lt2j933 with +3 score by [(Guinea-Charm, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2j933/) (in reply to ID lt19kzq):\nMarshawn is the best!!! He’s so funny in Bottoms! Love that dude.\n\n### Comment ID lt4bbxc with +3 score by [(CUNTRY-BLUMPKIN, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4bbxc/) (in reply to ID lt19kzq):\nHe just there so he don’t get fined\n\n### Comment ID lt264pc with +3 score by [(ChannelNeo, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt264pc/) (in reply to ID lt19kzq):\nHe's just there so he won't get fined.\n\n### Comment ID lt217md with +2 score by [(whobroughtmehere, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt217md/) (in reply to ID lt19kzq):\nShowed up drunk but everyone thought he was fun so they let him stay\n\n### Comment ID lt3m6tr with +2 score by [(knildea, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3m6tr/) (in reply to ID lt19kzq):\nhe's everywhere lol\n\n### Comment ID lt2nanp with +2 score by [(Civ96, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2nanp/) (in reply to ID lt19kzq):\nHe is representing the North side of Milwaukee. 😂\n\n### Comment ID lt2unbu with +1 score by [(iChieftain, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2unbu/) (in reply to ID lt19kzq):\nI’m not sure, but I need Key to ask him why they didn’t run the ball\n\n### Comment ID lt4pg02 with +1 score by [(Umpire1468, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4pg02/) (in reply to ID lt19kzq):\nSomeone stole his Skittles\n\n### Comment ID ltao2ec with +1 score by [(Mills_Miles, Reddit, 2024-10-23)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/ltao2ec/) (in reply to ID lt19kzq):\nHe’s just here so he don’t get fined\n\n## Comment ID lt1ljhw with +173 score by [(SigmaKnight, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1ljhw/) (in reply to ID 1g8uzk5):\nThe Quanaissance continues.\n\n### Comment ID lt1s8eb with +27 score by [(M086, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1s8eb/) (in reply to ID lt1ljhw):\nYou love to see it.\n\n### Comment ID lt29oh0 with +25 score by [(Primetime22, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt29oh0/) (in reply to ID lt1ljhw):\nI am so happy EEAAO was not a one time thing for him. He was excellent in Loki.\n\n### Comment ID lt1vviw with +13 score by [(ContinuumGuy, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1vviw/) (in reply to ID lt1ljhw):\nMay it go on forever.\n\n## Comment ID lt1cdna with +269 score by [(artpayne, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1cdna/) (in reply to ID 1g8uzk5):\nSo, is this like the Ke Huy Quan version of *Nobody?*\n\n### Comment ID lt1defo with +146 score by [(ROBtimusPrime1995, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1defo/) (in reply to ID lt1cdna):\nYes but a romantic comedy version from the same studio, so it should be kickass and funny.\n\n### Comment ID lt1hb39 with +35 score by [(Cuminmyshoes69, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1hb39/) (in reply to ID lt1cdna):\nI am so fucking down for that\n\n### Comment ID lt2unhm with +19 score by [(Worthyness, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2unhm/) (in reply to ID lt1cdna):\nBro spent so long as a fight choreographer and now he gets to lead his own potential franchise. I'm so happy for him.\n\n## Comment ID lt1gaop with +317 score by [(FLORD1LUNA, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1gaop/) (in reply to ID 1g8uzk5):\nThis movie is from the same producers of the John Wick and Nobody movies - so, it's gonna be a banger. So excited.\n\n### Comment ID lt1kxy4 with +134 score by [(Upbeat_Tension_8077, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1kxy4/) (in reply to ID lt1gaop):\nNoticed that they were also involved in Bullet Train & The Fall Guy, so if it's closer to that vein, it's perfect for Ke Huy Quan\n\n#### Comment ID lt1olt8 with +45 score by [(ButterSlickness, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1olt8/) (in reply to ID lt1kxy4):\nAtomic Blonde, too.\n\nIt's 87North.\n\n#### Comment ID lt1qr3o with +36 score by [(Hellknightx, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1qr3o/) (in reply to ID lt1kxy4):\nBullet Train was unreasonably good. Perfect casting all around.\n\n#### Comment ID lt2vwdp with +2 score by [(RedditorDeluxe1319, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2vwdp/) (in reply to ID lt1kxy4):\nViolent Night, too.\n\n#### Comment ID lt2u4lm with +1 score by [(None, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2u4lm/) (in reply to ID lt1kxy4):\nOh yeah that tone would be great for him. I like Ke Huy Quan but he's either heavily typecast or can only really play one character.\n\n### Comment ID lt24o50 with +12 score by [(coffeeandhead, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt24o50/) (in reply to ID lt1gaop):\nNobody was so good\n\n#### Comment ID lt256oj with +9 score by [(FLORD1LUNA, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt256oj/) (in reply to ID lt24o50):\nThe second movie will start filming soon apparently, I hope it's as good as the first part, and Bob Odenkirk is always worth seeing in anything he's in.\n\n#### Comment ID lt2ydvh with +1 score by [(fugazzzzi, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2ydvh/) (in reply to ID lt24o50):\nIt still is\n\n#### Comment ID lt9k75c with +1 score by [(station13, Reddit, 2024-10-23)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt9k75c/) (in reply to ID lt24o50):\nFilmed in the same city as Love Hurts.  The beginning of the Winnipegverse.  Get Keannu in town for a John Wick shoot, promise him he  can start in goal for the Jets for a night.\n\n### Comment ID lt3nqjm with +2 score by [(Lanster27, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3nqjm/) (in reply to ID lt1gaop):\nSince Jackie Chan is pretty much all but retired, Ke is our next best thing especially seeing what he can do in Everything Everywhere.\n\n#### Comment ID lt7b5wy with +1 score by [(Impressive-Potato, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt7b5wy/) (in reply to ID lt3nqjm):\nJackie is still making movies. Just not Hollywood ones.\n\n### Comment ID lt5a7u7 with +1 score by [(ultimatequestion7, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt5a7u7/) (in reply to ID lt1gaop):\nThey must've gotten Bob Odenkirk to serve as a finger pointing consultant on this one\n\n## Comment ID lt1kzbz with +102 score by [(funkhero, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1kzbz/) (in reply to ID 1g8uzk5):\nKe Huy Quan as the leading man? Yes, please!\n\n## Comment ID lt1kwlu with +70 score by [(hankbaumbach, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1kwlu/) (in reply to ID 1g8uzk5):\nYou had me at Key Huy Quan\n\n## Comment ID lt2debr with +40 score by [(ElPunisher, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2debr/) (in reply to ID 1g8uzk5):\nAs a MKE filmmaker, it would have been sweet if they actually shot this in Milwaukee. We have no film tax incentives (unlike our surround neighbor States) and we rank 49th/50th in per capita spending for the arts. There's so many talented folks out here that  we lose to better funded industries.\n\n### Comment ID lt7em36 with +4 score by [(Impressive-Potato, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt7em36/) (in reply to ID lt2debr):\n\"We have no film tax incentives\" Yeah that'll be the nail in the coffin. \nMost of 87 North's small budget movies are shot in Winnipeg. Violent Night, Nobody, Love Hurts and Nobody 2 shot there.\n\n## Comment ID lt1o6ir with +29 score by [(pineapplesailfish, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1o6ir/) (in reply to ID 1g8uzk5):\nSign me up for anything starring Ke Huy Quan\n\n## Comment ID lt1hrsf with +18 score by [(Hashfyre, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1hrsf/) (in reply to ID 1g8uzk5):\nMan, someone needs to make a buddy-cop movie with him already.\n\n### Comment ID lt3n8pf with +1 score by [(SerDrinksAlot, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3n8pf/) (in reply to ID lt1hrsf):\nThat film will be called “Detective Bagabitch’s Murder Mystery”\n\n## Comment ID lt1hagm with +13 score by [(Havryl, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1hagm/) (in reply to ID 1g8uzk5):\nYup, yup, yup.\n\nKeeping my eye on this one.\n\n## Comment ID lt1wwp9 with +10 score by [(JPVsTheEvilDead, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1wwp9/) (in reply to ID 1g8uzk5):\ni am so happy to see Quan get more work, tbh\n\n## Comment ID lt1bhsg with +8 score by [(Sharktoothdecay, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1bhsg/) (in reply to ID 1g8uzk5):\nlooks fun\n\n## Comment ID lt3ktg4 with +6 score by [(ImpressionFeisty8359, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3ktg4/) (in reply to ID 1g8uzk5):\nKey Huy Quan is so hot right now.\n\n## Comment ID lt1ddkc with +31 score by [(Karurosun, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1ddkc/) (in reply to ID 1g8uzk5):\nFor a moment I though he was Jackie Chan.\n\n### Comment ID lt1f5jp with +45 score by [(doomrabbit, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1f5jp/) (in reply to ID lt1ddkc):\nHe's definitely channeling Jackie's \"I don't want trouble!\" vibe in a good way!\n\n#### Comment ID lt1r1x2 with +26 score by [(Hellknightx, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1r1x2/) (in reply to ID lt1f5jp):\nHe's definitely got that meek everyman look working in his favor. And then he goes Alpha Waymond on your ass.\n\n#### Comment ID lt1perg with +4 score by [(MuNansen, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1perg/) (in reply to ID lt1f5jp):\nUncle!\n\n### Comment ID lt1ob56 with +10 score by [(I_am_rectangular, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1ob56/) (in reply to ID lt1ddkc):\nThis generation's jackie chan. Far more wholesome that's for sure\n\n### Comment ID lt2ac10 with +5 score by [(ShustOne, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2ac10/) (in reply to ID lt1ddkc):\nThere were quite a few shots of him in EEAAO where I thought that too.\n\n### Comment ID lt3ld89 with +4 score by [(ImpressionFeisty8359, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3ld89/) (in reply to ID lt1ddkc):\nFunnily enough Jackie Chan was offered the lead role in EEAAO.\n\n## Comment ID lt221nd with +6 score by [(mxpayn1, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt221nd/) (in reply to ID 1g8uzk5):\nThe movie is actually called \"With Love\" per IMDB\n\n### Comment ID lt25qv7 with +5 score by [(FLORD1LUNA, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt25qv7/) (in reply to ID lt221nd):\nIt used to be, but they've changed the name. The name on IMDB still hasn't been changed for some reason. The Deadline and Entertainment Weekly articles are still very recent.\n\n## Comment ID lt1pbjb with +7 score by [(KingMario05, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1pbjb/) (in reply to ID 1g8uzk5):\nAfter all these years, ~~Short Round~~ Waymond Wang finally takes his place amongst action movie royalty!\n\n## Comment ID lt283sl with +3 score by [(BeingHuman30, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt283sl/) (in reply to ID 1g8uzk5):\nHe can play jackie chan in jackie chan biopic.\n\n## Comment ID lt1r9qo with +5 score by [(Rough_World_7063, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1r9qo/) (in reply to ID 1g8uzk5):\nLoving the Key Huy Quan renaissance after his role in Everything Everywhere All At Once!\n\n## Comment ID lt1f9an with +8 score by [(Fantom_Renegade, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1f9an/) (in reply to ID 1g8uzk5):\nIs that AOC?\n\n### Comment ID lt1fxux with +22 score by [(Antrikshy, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1fxux/) (in reply to ID lt1f9an):\nAriana DeBose.\n\n#### Comment ID lt1icxx with +21 score by [(The_Sugarfoot, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1icxx/) (in reply to ID lt1fxux):\nADB\n\n#### Comment ID lt44dvi with +4 score by [(Sisiwakanamaru, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt44dvi/) (in reply to ID lt1fxux):\nI just realized Ariana DeBose was the one who presented the Oscar for Ke Huy Quan.\n\n#### Comment ID lt1g0gs with +1 score by [(Fantom_Renegade, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1g0gs/) (in reply to ID lt1fxux):\nAaah\n\n## Comment ID lt1uwzx with +7 score by [(APiousCultist, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1uwzx/) (in reply to ID 1g8uzk5):\nThe Quanaissance continues.\n\n## Comment ID lt1itu4 with +4 score by [(Desperate_Hunter7947, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1itu4/) (in reply to ID 1g8uzk5):\nI have nothing but love and respect for Marshawn I just fear he’ll never be a seamless part of any cast, it will always take me out of the movie to see him on my screen. That’s Marshawn Lynch, not whoever you want me to think he is in this movie.\n\n### Comment ID lt24j8v with +6 score by [(DatKaz, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt24j8v/) (in reply to ID lt1itu4):\nwhat if they want you to think he's actually Marshawn Lynch\n\n#### Comment ID lt273e6 with +1 score by [(Desperate_Hunter7947, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt273e6/) (in reply to ID lt24j8v):\nThat could work!\n\n### Comment ID lt32mbl with +1 score by [(TheIllusiveGuy, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt32mbl/) (in reply to ID lt1itu4):\n\"I'm just in this movie so I don't get fined\"\n\n### Comment ID ltcvv0h with +1 score by [(kimchiMushrromBurger, Reddit, 2024-10-23)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/ltcvv0h/) (in reply to ID lt1itu4):\nI'll always remember him as a human version of Marshawn Pinch\n\n## Comment ID lt2ktzq with +2 score by [(Seraphilms, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2ktzq/) (in reply to ID 1g8uzk5):\n“I’m still here bitch. And I know everything” \n-A\n\n## Comment ID lt2vlmp with +2 score by [(jmfranklin515, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt2vlmp/) (in reply to ID 1g8uzk5):\nPlease tell me Ke is going to hook up with the baddie in the bottom-right panel.\n\n## Comment ID lt3eo7g with +2 score by [(golfingsince83, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3eo7g/) (in reply to ID 1g8uzk5):\nHis speech when he thanked spielberg was awesome\n\n## Comment ID lt3l9xi with +2 score by [(camposthetron, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3l9xi/) (in reply to ID 1g8uzk5):\nPlease tell me they cast one of the other Goonies as the former partner-in-crime🤞🏾\n\n## Comment ID lt3m3gj with +2 score by [(Oheyguyswassup, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3m3gj/) (in reply to ID 1g8uzk5):\nMarvin Gable?\n\n## Comment ID lt6d47n with +2 score by [(Ninjaflippin, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt6d47n/) (in reply to ID 1g8uzk5):\nSo like,  I've never heard of this guy before seeing this post... Based on these photos (which don't accurately show the actors face) it appears like they've managed to use AI to recreate a royalty free Jackie Chan.   I did a quick google,  and that's not true at all (also obligatory wtf Short Round!),  but bottom right is crazy!\n\n### Comment ID lt6tcwf with +2 score by [(MAGIGS, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt6tcwf/) (in reply to ID lt6d47n):\nKid from Goonies. Grown ass man in “Everything Everywhere All at once”\n\n#### Comment ID lt77mqb with +1 score by [(Illustrious-Yard-871, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt77mqb/) (in reply to ID lt6tcwf):\nOuroboros from Loki!\n\n## Comment ID lt22165 with +3 score by [(rafael-a, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt22165/) (in reply to ID 1g8uzk5):\nFor a second I thought he was Jackie Chan\n\n## Comment ID lt1dnv0 with +3 score by [(impulsekash, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1dnv0/) (in reply to ID 1g8uzk5):\nGive us a Short Round solo!\n\n### Comment ID lt1l5el with +1 score by [(snoogans8056, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt1l5el/) (in reply to ID lt1dnv0):\nHe is Indiana and Han's kid....\n\n## Comment ID lt257wm with +1 score by [(Bootytonus, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt257wm/) (in reply to ID 1g8uzk5):\nI'm a real estate agent and nothing exciting or mysterious happens to send upend my life in the suburbs.\n\n## Comment ID lt31ftp with +1 score by [(Tha_Watcher, Reddit, 2024-10-21)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt31ftp/) (in reply to ID 1g8uzk5):\nIt's now titled, \"With Love.\"\n\n[https://www.imdb.com/title/tt30788842/?ref\\_=nv\\_sr\\_srsg\\_0\\_tt\\_8\\_nm\\_0\\_in\\_0\\_q\\_Love%2520Hurts](https://www.imdb.com/title/tt30788842/?ref_=nv_sr_srsg_0_tt_8_nm_0_in_0_q_Love%2520Hurts)\n\n## Comment ID lt3hd4o with +1 score by [(snootyworms, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3hd4o/) (in reply to ID 1g8uzk5):\nDoes anyone know when this is expected to release? This sounds really fun :)\n\n## Comment ID lt3i6j3 with +1 score by [(One-Earth9294, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3i6j3/) (in reply to ID 1g8uzk5):\nAs someone from Milwaukee I just get giddy hearing anyone mention us so I'm in.\n\n### Comment ID lt4knfr with +1 score by [(georgecm12, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4knfr/) (in reply to ID lt3i6j3):\nSince it clearly wasn't filmed in or anywhere near Milwaukee, I can't wait to see how entirely unlike the real Milwaukee their version is.\n\n#### Comment ID lt4kvxr with +1 score by [(One-Earth9294, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4kvxr/) (in reply to ID lt4knfr):\nIt couldn't possibly be worse than 2004's Dawn of the Dead remake which was shot in, I believe, Vancouver lol.\n\nAt the end of that one they took a boat to an island which are pretty rare in Lake Michigan to begin with, and when they got there the island looked like a tropical volcano island.\n\n## Comment ID lt3mxcx with +1 score by [(PwnzillaGorilla, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3mxcx/) (in reply to ID 1g8uzk5):\nIs that Marshawn Lynch?!\n\n## Comment ID lt3xe4f with +1 score by [(blackhawkblake, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3xe4f/) (in reply to ID 1g8uzk5):\nWhy Milwaukee?\n\n## Comment ID lt3yvdx with +1 score by [(None, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt3yvdx/) (in reply to ID 1g8uzk5):\nYo is that marshawn lynch top left?\n\n## Comment ID lt4e4qz with +1 score by [(imortalpreacher, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4e4qz/) (in reply to ID 1g8uzk5):\nSilent hill 2 meets John Wick\n\n## Comment ID lt4lym6 with +1 score by [(None, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4lym6/) (in reply to ID 1g8uzk5):\nIs that…Marshawn Lynch..???\n\n## Comment ID lt4rkgy with +1 score by [(Nafeels, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4rkgy/) (in reply to ID 1g8uzk5):\nIf this doesn’t have the Nazareth song anywhere in the trailer or the entire movie I’m gonna riot. \n\nAlso Key Huy Quan! Hell yeah!\n\n## Comment ID lt4wl2g with +1 score by [(CrazyCanuckUncleBuck, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt4wl2g/) (in reply to ID 1g8uzk5):\nA fight scene with Marshawn Lynch? I'm going to guess there's some comedy in this which I'm all in for.\n\n## Comment ID lt53kax with +1 score by [(No_Tomatillo1125, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt53kax/) (in reply to ID 1g8uzk5):\nIs it racist if i think he looks like jackie chan\n\n## Comment ID lt5i5ip with +1 score by [(Bad_Hominid, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt5i5ip/) (in reply to ID 1g8uzk5):\nCouldn't find anything about this since there are an infinite number of movies and television episodes with that title.  Apparently it's called \"with love\" now ... anyway sounds fun.\n\n## Comment ID lt5qt1j with +1 score by [(None, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt5qt1j/) (in reply to ID 1g8uzk5):\nOh no. He’s going back straight outta movies doing shiz like this …\n\n## Comment ID lt5wjdy with +1 score by [(CuriousGeorgeBluth, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt5wjdy/) (in reply to ID 1g8uzk5):\nThe new Jackie\n\n## Comment ID lt5xfas with +1 score by [(metal_elk_, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt5xfas/) (in reply to ID 1g8uzk5):\nI'm here for Key Huy Quan. This movie could be about God damn anything, I'm just so happy to see this guy get the kind of opportunities he's getting right now.\n\n## Comment ID lt5ydqh with +1 score by [(sparkinthedark1, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt5ydqh/) (in reply to ID 1g8uzk5):\nThis guy seems like a no brainer. Next Indiana Jones.\n\n## Comment ID lt6zg36 with +1 score by [(SupervillainMustache, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt6zg36/) (in reply to ID 1g8uzk5):\nA little Goonies reunion with Sean Astin.\n\n## Comment ID lt7m4gf with +1 score by [(nappingtoday, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt7m4gf/) (in reply to ID 1g8uzk5):\nLooks fun\n\n## Comment ID lt89ojj with +1 score by [(GunsandDinosaurs, Reddit, 2024-10-22)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/lt89ojj/) (in reply to ID 1g8uzk5):\nIs that Marshawn Lynch?\n\n## Comment ID ltncdl6 with +1 score by [(Special-Willow8816, Reddit, 2024-10-25)](https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/ltncdl6/) (in reply to ID 1g8uzk5):\nMilwaukee suburbs definitely stallis",
      "# Post ID 9uulai: Nixon is in my head tonight. with +4212 score by [(None, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/)\n\n\n## Comment ID e97o7mr with +310 score by [(None, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e97o7mr/) (in reply to ID 9uulai):\nAnd once I'm swept into office, I'll sell our children's organs to zoos for meat! And I'll sneak into people's houses at night and wreck up the place!\n\n### Comment ID e9859rl with +133 score by [(Baconated-grapefruit, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e9859rl/) (in reply to ID e97o7mr):\nMy God? I really sound like that? I thought my voice had more of a Clark Gable quality.\n\n#### Comment ID e98gdpw with +33 score by [(Calculon3, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98gdpw/) (in reply to ID e9859rl):\nThe jig's up Nixon!  \nWe'll trade you the tape for the body\n\n### Comment ID e98rng2 with +5 score by [(_Trygon, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98rng2/) (in reply to ID e97o7mr):\nWhen you realize that Nixon is a r/Rimworld survivor.\n\n## Comment ID e978284 with +152 score by [(HipsterGalt, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e978284/) (in reply to ID 9uulai):\n**AA-ROOO!!!**\n\n### Comment ID e98f728 with +22 score by [(Nicechicken8032, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98f728/) (in reply to ID e978284):\nNIXON OUUUT\n\n#### Comment ID e98jq2z with +5 score by [(PresNixon, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98jq2z/) (in reply to ID e98f728):\nNo, Nixon's never out!!!!!\n\n### Comment ID e98fma1 with +2 score by [(None, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98fma1/) (in reply to ID e978284):\nVery well\n\n## Comment ID e989t8f with +89 score by [(JustAnotherTrickyDay, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e989t8f/) (in reply to ID 9uulai):\nNow, look here, you drugged-out Communist. I paid for this body and I'd no sooner return it than I would my little cocker-spaniel dog, Checkers. *\\[Checkers barks.\\]* Shut up, damnit!\n\n### Comment ID e98ta8g with +4 score by [(CheckersSpeech, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98ta8g/) (in reply to ID e989t8f):\nCan confirm.\n\n## Comment ID e979h1y with +45 score by [(mrsuns10, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e979h1y/) (in reply to ID 9uulai):\nAroooo!\n\n### Comment ID e98gflf with +9 score by [(Calculon3, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98gflf/) (in reply to ID e979h1y):\nExpletive deleted\n\n## Comment ID e97ijgc with +35 score by [(None, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e97ijgc/) (in reply to ID 9uulai):\nNixon always wins!\n\n### Comment ID e98gj7i with +26 score by [(Calculon3, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98gj7i/) (in reply to ID e97ijgc):\nMorbo congratulates our gargantuan, cyborg president.  \nMay death come quickly to his enemies 🙅‍♀️\n\n## Comment ID e97h2dz with +70 score by [(KaiserReaper, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e97h2dz/) (in reply to ID 9uulai):\nNixons head in a jar 2020, AAROOO\n\n### Comment ID e983b5b with +20 score by [(Practicing_Onanist, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e983b5b/) (in reply to ID e97h2dz):\nHe’s got a shiny new body!\n\n### Comment ID e987wao with +10 score by [(captain_flasch, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e987wao/) (in reply to ID e97h2dz):\nVote Real Holographic Simulated Evil Lincoln for president 2020!\n\n## Comment ID e98f8hy with +58 score by [(None, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98f8hy/) (in reply to ID 9uulai):\nOur planet has been through so much this past year--\n\nwars, droughts, impeachments--\n\nbut we've never lost our sense of what's truly important:\n\nThe great taste of Charleston Chew!\n\n## Comment ID e98j2pj with +28 score by [(Trek186, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98j2pj/) (in reply to ID 9uulai):\nMy god- Nixon with charisma?  I could rule the universe!\n\n## Comment ID e98kx3o with +18 score by [(None, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98kx3o/) (in reply to ID 9uulai):\n# Leave Reddit\n\n--------------------------------------------------------------------------------\n\nI urge anyone to leave Reddit immediately.\n\nOver the years Reddit has shown a clear and pervasive lack of respect for its  \nown users, its third party developers, other cultures, the truth, and common  \ndecency.\n\n--------------------------------------------------------------------------------\n\n## Lack of respect for its own users\n\nThe entire source of value for Reddit is twofold:\n1. Its users link content created elsewhere, effectively siphoning value from  \nother sources via its users.\n2. Its users create new content specifically for it, thus profiting of off the  \nfree labour and content made by its users\n\nThis means that Reddit creates no value but exploits its users to generate the  \nvalue that uses to sell advertisements, charge its users for meaningless tokens,  \nsell NFTs, and seek private investment. Reddit relies on volunteer moderation by  \npeople who receive no benefit, not thanks, and definitely no pay. Reddit is  \nprofiting entirely off all of its users doing all of the work from gathering  \nlinks, to making comments, to moderating everything, all for free. Reddit is\nalso going to sell your information, you data, your content to third party AI\ncompanies so that they can train their models on your work, your life, your\ncontent and Reddit can make money from it, all while you see nothing in return.\n\n## Lack of respect for its third party developers\n\nI'm sure everyone at this point is familiar with the API changes putting many  \nthird party application developers out of business. Reddit saw how much money  \nentities like OpenAI and other data scraping firms are making and wants a slice  \nof that pie, and doesn't care who it tramples on in the process. Third party  \ndevelopers have created tools that make the use of Reddit far more appealing and  \nfeasible for so many people, again freely creating value for the company, and  \nit doesn't care that it's killing off these initiatives in order to take some of  \nthe profits it thinks it's entitled to.\n\n## Lack of respect for other cultures\n\nReddit spreads and enforces right wing, libertarian, US values, morals, and  \nethics, forcing other cultures to abandon their own values and adopt American  \nones if they wish to provide free labour and content to a for profit American  \ncorporation. American cultural hegemony is ever present and only made worse by  \ncompanies like Reddit actively forcing their values and social mores upon  \nforeign cultures without any sensitivity or care for local values and customs.  \nMeanwhile they allow reprehensible ideologies to spread through their network  \nunchecked because, while other nations might make such hate and bigotry illegal,  \nReddit holds \"Free Speech\" in the highest regard, but only so long as it doesn't  \noffend their own American sensibilities.\n\n## Lack for respect for the truth\n\nReddit has long been associated with disinformation, conspiracy theories,  \nastroturfing, and many such targeted attacks against the truth. Again protected  \nunder a veil of \"Free Speech\", these harmful lies spread far and wide using  \nReddit as a base. Reddit allows whole deranged communities and power-mad  \nmoderators to enforce their own twisted world-views, allowing them to silence  \ndissenting voices who oppose the radical, and often bigoted, vitriol spewed by  \nthose who fear leaving their own bubbles of conformity and isolation.\n\n## Lack of respect for common decency\n\nReddit is full of hate and bigotry. Many subreddits contain casual exclusion,  \ndiscrimination, insults, homophobia, transphobia, racism, anti-semitism,  \ncolonialism, imperialism, American exceptionalism, and just general edgy hatred.  \nReddit is toxic, it creates, incentivises, and profits off of \"engagement\" and  \n\"high arousal emotions\" which is a polite way of saying \"shouting matches\" and  \n\"fear and hatred\".\n\n--------------------------------------------------------------------------------\n\nIf not for ideological reasons then at least leave Reddit for personal ones. Do  \nYou enjoy endlessly scrolling Reddit? Does constantly refreshing your feed bring  \nyou any joy or pleasure? Does getting into meaningless internet arguments with  \nstrangers on the internet improve your life? Quit Reddit, if only for a few  \nweeks, and see if it improves your life.\n\nI am leaving Reddit for good. I urge you to do so as well.\n\n### Comment ID e98lq6b with +18 score by [(coebruh, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98lq6b/) (in reply to ID e98kx3o):\nOh, you know we do!\n\n## Comment ID e9816yd with +38 score by [(DeadKittyPool, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e9816yd/) (in reply to ID 9uulai):\nFrankly, I've never felt voting to be all that essential to the process.\n\n### Comment ID e983dk9 with +31 score by [(giaaeron, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e983dk9/) (in reply to ID e9816yd):\nNo kidding, Ford.\n\n#### Comment ID e98rftb with +5 score by [(sumppumpslump, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98rftb/) (in reply to ID e983dk9):\nHi my name's Gerry and I like movies\n\n## Comment ID e98hwmc with +10 score by [(CannibalRed, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98hwmc/) (in reply to ID 9uulai):\nIs everyone enjoying their FREE BEER!\n\n## Comment ID e98s9kl with +7 score by [(GolemThe3rd, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98s9kl/) (in reply to ID 9uulai):\nAccourding to Moores law a computer in the year 3000 should be 2^684.66 times faster than one in 1973 (yes I know this is impossible, but its interesting)\n\n### Comment ID e98zr0z with +3 score by [(UnfetteredThoughts, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98zr0z/) (in reply to ID e98s9kl):\nShame Moore's Law is breaking down already.\n\n## Comment ID e98tkan with +6 score by [(CheckersSpeech, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98tkan/) (in reply to ID 9uulai):\nAt any rate, I *certainly* wouldn't harm the child.   \n\n*[Truthoscope goes nuts]*\n\n## Comment ID e98tmub with +6 score by [(CheckersSpeech, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98tmub/) (in reply to ID 9uulai):\nPuny Human #1, Puny Human #2 ... and Morbo's good friend Richard Nixon!\n\n## Comment ID e98tek8 with +4 score by [(CheckersSpeech, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98tek8/) (in reply to ID 9uulai):\nNixon's back!  Who's kicking who around NOW?!!\n\n## Comment ID e98q9bs with +2 score by [(PROFsmOAK, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e98q9bs/) (in reply to ID 9uulai):\nNixon knows Florida.\n\n## Comment ID e996hml with +1 score by [(None, Reddit, 2018-11-07)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e996hml/) (in reply to ID 9uulai):\nNixon always wins!!!!!!!!\n\n## Comment ID e99g4qe with +1 score by [(TeddyEatWorld, Reddit, 2018-11-08)](https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/e99g4qe/) (in reply to ID 9uulai):\nAaarrrooooo",
      "# Post ID 14dx53r: Any of you think AI is going to takeover the takeoff and estimating programs? 1 hell of a business idea with +13 score by [(Emooop, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/)\n\n\n## Comment ID jos9abd with +15 score by [(SykoFI-RE, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jos9abd/) (in reply to ID 14dx53r):\nBIM has had the capability to eliminate like 75% of the estimator workload for at least a decade now, but that data sharing almost never makes it over the fence. AI ability to read and comprehend drawings is such a complicated work around to a problem that shouldn’t even exist.\n\nI work for an owner that does our own EPCM in house and getting raw data from our engineers is like pulling teeth. It’s fucking wild.\n\n### Comment ID josmof9 with +13 score by [(None, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/josmof9/) (in reply to ID jos9abd):\nDude!  You hit the nail on the head. It's such a painfully obvious solution to quantify and price scope within the 3d model.  Ai takeoff on 2d drawings is downright retarded.  I work for one of the largest GCs in the world, and I can't believe how hard it is to make people understand this.  It's boggles me how quantity take of on 2d drawings hasn't mostly been replaced by now.  I can't believe how much effort is going into 2d Ai takeoff.  The same effort in the model would have paid off a decade ago.\n\n#### Comment ID jou6wjy with +2 score by [(NumbersGameOver, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jou6wjy/) (in reply to ID josmof9):\n100%. It's really crazy that it's taken this long. There are a handful of projects/decent betas out there, but it's such a simple concept that could replace so much needless effort. \n\nUntil then, keep clicking in those walls!! Click click click...\n\n### Comment ID jou80w9 with +1 score by [(russdr, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jou80w9/) (in reply to ID jos9abd):\nI always made the assumption that between the last of conforming specs & drawings along with the hundreds of CYA notes on the drawings was a purposeful obscurity.  They keep a certain degree of quality requirements and leave means and methods up to the contractor...\n\nI assume handing over additional BIM data to contractors puts more onus on the engineers if the design is incorrect or flawed, no?  The owner would buy the an engineering package which included a BIM design that would obviously be more expensive than today's average design, right?  And if the engineer messed that up, they'd have to own that as they failed to do their due diligence?\n\nI figured with current design document standards and what's typically made available during bid essentially gives the engineer more flexibility to outright deny, or at minimum, negotiate change orders.  A more exact design technically increases risk, does it not?\n\n#### Comment ID jow57hn with +1 score by [(SykoFI-RE, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jow57hn/) (in reply to ID jou80w9):\nI assumed that was the case when I worked for a contractor, purposeful obfuscation. Until I moved to an owner that does all our design work in house. I’m on the same bonus structure as the engineering team and my job is just to build construction budgets against their engineering packages, but it’s still a challenge to get them to give me the raw data we need to do fast estimates.\n\nIn my organization I think the biggest problem is that engineering is far bigger than the construction management group so their management has more pull to say no anytime it’s “more work for engineering”.\n\n## Comment ID josj0zr with +13 score by [(Crypto_craps, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/josj0zr/) (in reply to ID 14dx53r):\nI personally think the more immediate power in AI is going to be in database pricing models. I think if you can figure out good ways to categorize all of your historical bid / contract data AI will be able to produce pricing and give you a % confidence interval. Then you could base your markups off of the % confidence (risk). I think it will reach a point where the time is spent making sure you have clean, categorized data to feed your AI so it can generate the most accurate pricing for you.  It should also start to learn from itself and get better over time and knowing your particular business.\n\n## Comment ID josdywn with +8 score by [(First-Front-1165, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/josdywn/) (in reply to ID 14dx53r):\nNot for at least 10 years and even then it will be estimators using AI as a tool. But one person could do the job of whole departments probably. I agree with skyofire, for AI to truly understand construction it needs to be integrated into BIM and be used by architects to build the project in BIM.\n\n## Comment ID joskqft with +7 score by [(Adventurous_Light_85, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/joskqft/) (in reply to ID 14dx53r):\nI think the issue is going to be that the ai software is going to pass liability to the quality of the information I put, so if the plans suck that will be the architects fault. The architects will just push back with ai clauses.\n\n### Comment ID jotqpa9 with +5 score by [(OK_Opinions, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jotqpa9/) (in reply to ID joskqft):\narchitects and not taking responsibility for their work, name a more iconic duo\n\n## Comment ID jos2ist with +12 score by [(dillydily314, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jos2ist/) (in reply to ID 14dx53r):\nTogal AI is giving it a shot and it’s damn good. But I think replacing the estimator from the process completely is a decade or so away\n\n### Comment ID jos4jsq with +12 score by [(BrevitysLazyCousin, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jos4jsq/) (in reply to ID jos2ist):\nI happened to be randomly thinking about this earlier today and maybe I misunderstand AI’s capabilities but so much of what I do is identify things in the plans which are utterly unclear and make judgement calls as to how I take-off or count that unclear thing and qualify my proposal accordingly. Most of the time, I make no effort to qualify it, I just assume worst-case for me and assume I’ll hash it out in a scope review. \n\nWhen the value of the unclear thing is sufficient enough, maybe we generate an RFI but so often that can be determined by where a thin black line is showing up with relation to where I expect that line to be. \n\nHow does AI deal with some of these awful plan sets we see these days where so much is unclear. I can usually guess my way into a pretty close bid based on what I’m seeing but that comes after seeing a lot of weird things come together over many years and understanding why humans would want x over z - that can be much trickier for a computer to learn, even with lots of sample sets. \n\nIn its current form, it seems hard for me to imagine AI playing a meaningful role in this portion of the system. We may see it play a huge role in other aspects, and there may be trades where computers could be much more capable, but in my trade I’d be surprised to see it take hold soon.\n\n#### Comment ID jos52vk with +9 score by [(dillydily314, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jos52vk/) (in reply to ID jos4jsq):\nYou bring up a lot of good points. Essentially AI is still not able to do the critical thinking aspect of the process. But the mundane task of tracing lines (that are drawn properly) or getting a quick summary of different aspects of the projects is what AI is pretty good at.\n\n### Comment ID jos6iye with +3 score by [(dreamcometruesince82, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jos6iye/) (in reply to ID jos2ist):\nBut if all bidders are using AI for their bids, their bids should all be the same.... what happens then?\n\n#### Comment ID jos9mn2 with +12 score by [(aksalamander, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jos9mn2/) (in reply to ID jos6iye):\nThe race to the bottom continues. 6% markup to 4% markup to 2.5% markup until most of us end up going out of business.\n\n### Comment ID joz82kr with +1 score by [(friedabs, Reddit, 2023-06-21)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/joz82kr/) (in reply to ID jos2ist):\nHave you used it? I'm curious to try it out. Seems like it would be better suited for Commercial Construction which makes sense given who the founder is.\n\n## Comment ID josisn3 with +6 score by [(Ambitious-Delay5911, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/josisn3/) (in reply to ID 14dx53r):\nNo. This was discussed a few months ago. I don’t believe AI is going to help the average builder as it’ll become more of a confirmation tool for cashed builders who are willing to invest back into the business. An estimator is still going to have to code the AI functionality for sometime yet until it’s proficient enough. Long story short, I think it’ll only consolidate the staging requirements in general terms but plausibly become highly accurate for common take offs to eliminate or control wastage.\n\n## Comment ID jovfu3n with +2 score by [(wyopyro, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jovfu3n/) (in reply to ID 14dx53r):\nIf a computer can sort though and itemize the mess of plans I get on a regular basis I will happily give it my job. Just quoted a scope on a $8M heavy civil project with no quantities and was bid Lump Sum. I was just on the Asphalt and myself and the three competitors didn't even agree on quantities. ON ASPHALT, not the temporary river path or even the retaining walls. Additionally every company kept cranking their number due to it being a 1800s mining town with the only known being that all underground conditions are \"unreliable\". An AI will spit out a price half of everyone else number.\n\n## Comment ID jph3gqm with +2 score by [(DrywallBarron, Reddit, 2023-06-25)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jph3gqm/) (in reply to ID 14dx53r):\nPlans must have improved a lot since I was a full-time commercial drywall estimator. Almost all public bids were based on 100% drawings ao it might be possible that BIM and AI would work, but I would not stake my business on it. However, 90% of what we did was private work and we were pricing based on 60%-80% complete drawings at best. At least half that time we started budgeting design build work from preliminary floor plans, a couple of elevations, and a building section and that was it. As the plans progressed we revised the pricing accordingly. It could be a small one-story office building, a 15-story office building, a hotel, or anything else imaginable. At least early on the budgets were totally dependent on our ability to know what the life safety needs, engineering requirements, and often how we would make the framing system would fit the designs. If drawings are thorough enough for a BIM or AI-based estimate, a lot of the process for design-build will have to change.\n\n## Comment ID jy8xrc9 with +2 score by [(whatlaw-wasbroken, Reddit, 2023-08-29)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jy8xrc9/) (in reply to ID 14dx53r):\nHow about A.I for civil/ grading take-offs. Anybody running across or have any experience with it.\n\n### Comment ID k96xtj2 with +1 score by [(kedi007, Reddit, 2023-11-14)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/k96xtj2/) (in reply to ID jy8xrc9):\nCheck [this](http://truebuiltsoftware.com) They do the demo as well.\n\n## Comment ID l8q7q0b with +1 score by [(Decentralander, Reddit, 2024-06-15)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/l8q7q0b/) (in reply to ID 14dx53r):\nWe have been looking for a very specific system for doing 2D electrical takeoffs of single line drawings and converting them to a Materials list and a Utility Submittal Drawing - Any ideas would be most appreciated.\n\n## Comment ID lj9t1nr with +1 score by [(Practical_Buy6729, Reddit, 2024-08-21)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/lj9t1nr/) (in reply to ID 14dx53r):\nI am in process of starting at AI Based Takeoff Software.  I play in the HVAC filed so that's what I am focused on.  If i can get HVAC Set up the there are other trades that are much simpler.  It's definitely happening.  If anyone is interested get in touch maybe I can help.\n\n## Comment ID jotqu4o with +1 score by [(Hiltson87, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jotqu4o/) (in reply to ID 14dx53r):\nNot unless it can also replace shitty architects. Estimating purely off plans the way they are today would quickly bankrupt a company.\n\n### Comment ID l0kb1ky with +1 score by [(Sad-Classic3837, Reddit, 2024-04-21)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/l0kb1ky/) (in reply to ID jotqu4o):\nWhat do you mean by this?\n\n## Comment ID joughox with +1 score by [(russdr, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/joughox/) (in reply to ID 14dx53r):\nTake over?  Not for some time.  If anything, machine learning/AI tools might become more robust and trust-worthy for faster and more accurate take-offs, but an AI for take-off/estimating seems like a costly endeavor that would take years to create let alone implement into the industry.  Contractors just don't trust technology.\n\nWho knows, though?  I'm trying to keep up with AI related news as it interests me and I'm seeing huge jumps in such short periods of time.  We could have an AGI (artificial general intelligence) that's more than capable of being taught your companies standard methods and take-off routines/formats and put to work.  Sending emails, preparing proposal letters, so on and so forth.  Like a personal assistant but with access to your GMail, Office 365, Acrobat and Accubid suites.  Tell it to read every book it can on construction.  Give it some code books.  Show it old estimate data for projects you won and give it all of the related costs data.\n\nI think we'll have AI assistants that will change the way every person works and lives way before we have anything else.\n\n## Comment ID jouj3d3 with +1 score by [(mattskibasneck, Reddit, 2023-06-20)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jouj3d3/) (in reply to ID 14dx53r):\nMe and my 10th grade education can't understand how that would work for Electrical plans since we have to count things that don't actually exist on the drawings (power packs, power to Mech items not shown on the E pages, etc.)  I'd rather AI take over the Engineer's job - maybe then I'll have 10 less RFIs to write on every project.\n\n### Comment ID k5b6u9s with +2 score by [(QuantityTakeoffs, Reddit, 2023-10-17)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/k5b6u9s/) (in reply to ID jouj3d3):\nif the Ai takeoff tool could at least count everything that was there, giving you more time to focus on what isnt, does that help?     do you ever outsource just the takeoffs?\n\n#### Comment ID k96xmp0 with +1 score by [(kedi007, Reddit, 2023-11-14)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/k96xmp0/) (in reply to ID k5b6u9s):\nTake a look at truebuiltsoftware.com[truebuilt ](http://truebuiltsoftware.com) \nTheir demo is impressive.\n\n## Comment ID jpxuaxz with +1 score by [(asfcobra, Reddit, 2023-06-29)](https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/jpxuaxz/) (in reply to ID 14dx53r):\nIt's not the idea of perfectly replacing the human estimator it's really just about cutting down the time it takes. You'll always need a set of human eyes and a recap.",
      "# Post ID 1d7bqx2: How does one simply raise 50k in this current VC climate  with +49 score by [(APIsoup, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/)\nI have a product with way too many user requests than I initially thought I would need. Most of the features aren’t build yet and I will definitely need to delegate some stuff to a hire or two while I build alongside them. I am in no need to raise an absurd amount of money but I just want to know where and how can I raise 50k or more to address my micro-rapid growth trajectory atm.  \n\nEdit: if I must raise more money, then how does one simply raise 2-3 million in this current venture market lol \n\n## Comment ID l6yaaes with +81 score by [(Rathogawd, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6yaaes/) (in reply to ID 1d7bqx2):\n50k is a loan from family/friends, self, or bank.\n\n### Comment ID l6z52ha with +4 score by [(AtlasShrged, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6z52ha/) (in reply to ID l6yaaes):\nthis is the way\n\n### Comment ID l7b7ado with +3 score by [(Ironfour_ZeroLP, Reddit, 2024-06-06)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7b7ado/) (in reply to ID l6yaaes):\nAlso presales! \n\nIf OP has that much traction with users, they can ask users to put early money toward the product. It also helps validate the need - if some users are willing to pay and others are not, that is a strong signal on priority of features.\n\n### Comment ID l7hlr5s with +1 score by [(None, Reddit, 2024-06-07)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7hlr5s/) (in reply to ID l6yaaes):\n[removed]\n\n#### Comment ID l7igtqv with +1 score by [(Rathogawd, Reddit, 2024-06-07)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7igtqv/) (in reply to ID l7hlr5s):\nTrue. And not everyone can get VC backing and you won't for just 50k. The ways I listed are the best ways to fund your project if what you are looking for is only 50k. Kickstarter, GoFundMe, etc. are also available but not nearly as reliable as what I listed.\n\n## Comment ID l6y98bc with +41 score by [(207207, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6y98bc/) (in reply to ID 1d7bqx2):\nIf you need to raise money from VC, 50k isn’t enough. Believe it or not, you need to have a viable and believable plan to use 2-3M for someone to invest.\n\n“That seems counterintuitive! Why would someone want to give me MORE money?”\n\nHaving more cash on hand (in competent hands where there’s a plan to put that money to use) actually derisks the investment. 50k in a company means there’s zero margin for error. If you don’t deliver or make a mistake, that 50k is gone. With 2-3M, you have longer runway to deliver, make mistakes, etc. You also have a budget for marketing and acquiring users, hiring a team, etc, all of which is important. Without that, and only investing 50k, you might have a product but you have no path to finding anyone to use/buy your product, and someone has bet on just one persons ability for deliver it all.\n\n## Comment ID l6y7q7a with +41 score by [(None, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6y7q7a/) (in reply to ID 1d7bqx2):\n[removed]\n\n### Comment ID l6z6dos with +6 score by [(None, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6z6dos/) (in reply to ID l6y7q7a):\ni had angels offer 10-20 each. but only after many months of work\n\n#### Comment ID l6zqy8i with +8 score by [(TriggernometryPhD, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zqy8i/) (in reply to ID l6z6dos):\nThe juice is not worth the squeeze.\n\n## Comment ID l6z04ml with +10 score by [(DancinWithWolves, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6z04ml/) (in reply to ID 1d7bqx2):\nDepending on your area, you should be able to find a local network of angel investors. If you can get in front of them, you may be able to convince them to do a tiny pre seed round of $50k or $100k. \n\nVCs aren’t the only option here, everyone saying you can’t raise $50k aside from family has no hustle.\n\n## Comment ID l6y81e1 with +5 score by [(Late_Republic_7923, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6y81e1/) (in reply to ID 1d7bqx2):\nHey. I would prioritize those features that would lead to an increase in revenue. If you can build a case that your company would go from $x to $y after a cash injection, and the numbers make sense, you should still be bale to raise from any smart investor.\n\n## Comment ID l6y97qp with +3 score by [(abhi91, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6y97qp/) (in reply to ID 1d7bqx2):\nFind an angel in your network\n\n### Comment ID l7328ok with +1 score by [(techhouseliving, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7328ok/) (in reply to ID l6y97qp):\nStart now and butter those relationships and don't expect perfect money for a little while, in meantime get customers and show to understand your market and test sources of sales so you can tell them exactly what sources generate what return\n\n## Comment ID l6y8vzu with +5 score by [(zeptonaut20, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6y8vzu/) (in reply to ID 1d7bqx2):\nWhat's your revenue like? Are the users requesting these features sticking around, or are you thinking they'll start sticking around after you implement the feature? Are they paying customers and, if so, what's the annual customer value?\n\nTons of feature requests coming from users paying $2k/month and continuing to use the product is awesome. Tons of feature requests coming from free users looking at the app and saying \"I'd need X to use this\" is basically worthless: you can implement most of those features and there's a good chance those users likely still won't be willing to pay.\n\nIf you have paying customers and are making $5k-$10k/month, you can likely raise money from something like the Calm Fund or TinySeed even if you aren't seeking venture scale returns. Otherwise, your best bet is angel networks or friends + family.\n\n## Comment ID l6yihwz with +6 score by [(Various_Cabinet_5071, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6yihwz/) (in reply to ID 1d7bqx2):\nNvidia calls\n\n### Comment ID l6yk3nf with +1 score by [(APIsoup, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6yk3nf/) (in reply to ID l6yihwz):\nBest answer so far\n\n#### Comment ID l6zlwwi with +1 score by [(Various_Cabinet_5071, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zlwwi/) (in reply to ID l6yk3nf):\nUnironically, you'll prob raise the desired $3 mil by August with properly managed Nvidia options. I know some startups that raise a couple million and invested it in stocks over the last year that are up a couple mill. Must've gotten permission from their investors, not sure how else to square that.\n\n## Comment ID l6yvmo5 with +2 score by [(memory--, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6yvmo5/) (in reply to ID 1d7bqx2):\nRaise the money from your users. Revenue or crowdfunding. Don't give up equity unless you have to.\n\n## Comment ID l6z00r4 with +2 score by [(Middle_Loan731, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6z00r4/) (in reply to ID 1d7bqx2):\nThere’s a vc called Boost VC that specifically does 50k investments\n\n## Comment ID l6zti2z with +2 score by [(beohoff, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zti2z/) (in reply to ID 1d7bqx2):\nYou could try tinyseed, I think they specialize in this issue and type of funding https://tinyseed.com/\n\n### Comment ID l6zzefp with +2 score by [(rwalling, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zzefp/) (in reply to ID l6zti2z):\nIndeed we do! Funding from $120k-$300k. If you have at least $5k in MRR reach out to us, TinySeed.com. If less than that, you can apply during our next application period in September.\n\n## Comment ID l7iygri with +2 score by [(life-is-an-adventure, Reddit, 2024-06-07)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7iygri/) (in reply to ID 1d7bqx2):\nIf you can avoid taking VC money, do it. It comes with many, MANY strings attached. And it’s mostly a one-way door, you can’t (easily) undo it (context: speaking from personal experience - I raised $15M for my first startup, acquired in 2021).\n\nAside from the other possible funding sources that others have mentioned, if you do make the decision to raise from VCs, then asking for 50K is an order of magnitude (or two) off. Either raise a 500K SAFE, or go for a full priced round and ask for a few million.\n\nAgain, this all depends on what sort of traction you actually have.\n\n## Comment ID l6y9d7w with +1 score by [(there-you-run, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6y9d7w/) (in reply to ID 1d7bqx2):\nFriends and Family.\n\n## Comment ID l6zd07n with +1 score by [(lets-make-deals, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zd07n/) (in reply to ID 1d7bqx2):\nAngel Investors $10k - $750k ... Possibly multiple.\n\nThere are also crowdfunding solutions where multiple investors pool money and only a single entry on your cap table\n\n### Comment ID l6zdf9t with +1 score by [(APIsoup, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zdf9t/) (in reply to ID l6zd07n):\nWorst part about crowdfunding is it’s sort of corrupt. For example we were almost about to do wefunder, only to find out the friends of people at wefunder get their launches pushed way harder than everyone else’s as per someone internally who told us beforehand. Also you need to have a lead investor which is stupid imo. Overall I wouldn’t crowdfund this project, or any project for that matter.\n\n#### Comment ID l6zdyf8 with +2 score by [(lets-make-deals, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zdyf8/) (in reply to ID l6zdf9t):\nWe are going to crowdfund ours but through Kickstarter. We have a B2B2C solution and we want to build consumer awareness and interest in the product.  They should be able to access the consumer mobile in August right before holidays\n\n## Comment ID l6zfigq with +1 score by [(Audi52, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zfigq/) (in reply to ID 1d7bqx2):\nSend me some info.\n\n### Comment ID l6zhyo0 with +1 score by [(APIsoup, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zhyo0/) (in reply to ID l6zfigq):\nCheck dm\n\n## Comment ID l6zlmmx with +1 score by [(Radiant-Grass3665, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zlmmx/) (in reply to ID 1d7bqx2):\nwefunder\n\n## Comment ID l6zm9mj with +1 score by [(GucciDude0, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zm9mj/) (in reply to ID 1d7bqx2):\nBorrow from family. Cleanest way - gives a chance for them to believe in you\n\n## Comment ID l6zp67a with +1 score by [(on_the_mark_data, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6zp67a/) (in reply to ID 1d7bqx2):\nSimply put, a $50k investment doesn't make sense for the business model of VCs. Success of a VC fund is based on the \"power law\" where most companies in the portfolio will fail, but a couple will be a massive successes (e.g. the Facebooks) which will not only offset the other failed companies in the portfolio, but also return outsized gains for the investors of the fund (i.e. LPs). In other words, VCs need to make bets on companies where 1) the company has enough potential to be worth in the billions, and 2) the VC firm has enough invested where they won't be too diluted when (if) that exit event happens.\n\nFor perspective, the startup I joined as the first employee raised a $7M seed round. $50k checks would come from angel investors to fill out the round and bring on advisors.\n\nLike others said, potentially work with a bank or do a family and friends round. The fact that you have too many users should make this pitch easier.\n\n### Comment ID l73c7lj with +1 score by [(PM_ME_YOUR_ANUS_PIC, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l73c7lj/) (in reply to ID l6zp67a):\nHow did they go about raising 7M as a seed round? Really interested to hear, since I only know Accelerators who put up 150k-500k at most.\n\n#### Comment ID l73j080 with +1 score by [(on_the_mark_data, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l73j080/) (in reply to ID l73c7lj):\nWe didn't go through an accelerator. The founders built up demand through content to validate the problem, did 300+ user interviews with leaders in the industry, built the technology at a previous company, then turned that into a community with 8K+ people. In that community, they built up a list of first round design partners to help build out the solution. They did this for a year, just validating the problem and idea, which they were able to go to VCs and raise a round. This is why I was okay being employee one, and even quit my job to join before they officially raised. I saw they had the ingredients to build an amazing product in a market with a high TAM.\n\nHere is the company: https://venturebeat.com/ai/with-github-for-data-gable-ai-wants-to-connect-software-engineers-and-ml-developers/\n\n## Comment ID l70drke with +1 score by [(sugarnotnice, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l70drke/) (in reply to ID 1d7bqx2):\nAngels 😇😇😇😇\n\n## Comment ID l70l07g with +1 score by [(Moredream, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l70l07g/) (in reply to ID 1d7bqx2):\nraising money and spending money are totally different, no matter how much you raise if you spend too much you gonna die. so why do you need that much or how to spend it is more important. if you can, without funding  might be better haha. some idiots spend all to their salaries and died because they failed the next rounds. I personally see it.\n\nif \"too many user requests\" does not means increase your sales or revenues then you may have to think about that why you need that money PS there is no \"Simply raise\" way to do so as I believe.\n\n## Comment ID l70o7js with +1 score by [(None, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l70o7js/) (in reply to ID 1d7bqx2):\nYC, do me favor. :)\n\nHow to get VCs or angels for early seeding? We’re building a complex cybersecurity SaaS for enterprises B2B but it’s too much costly which I can’t afford anymore. And I put my tuition on it, thought it would be that much easier. But things turning into nightmare day by day.\n\nThank you 🙌\n\n### Comment ID l70oasq with +1 score by [(None, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l70oasq/) (in reply to ID l70o7js):\nIf anyone wants to hear what we’re building I would love to answer. DMs are open.\n\n## Comment ID l70r4kr with +1 score by [(Absorber_1, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l70r4kr/) (in reply to ID 1d7bqx2):\nDo crowdfunding.\n\nAs an e.g. minimum Ticket size 1k pp. Get that investment from friends, family, ex-colleagues, people who'd love to use your solution. You'll need 50 people maximum.\n\n## Comment ID l70x29p with +1 score by [(Petters39, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l70x29p/) (in reply to ID 1d7bqx2):\nSend me some more info, I’ve got access to an angels network\n\n### Comment ID l719u4b with +1 score by [(AggressiveEgg6554, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l719u4b/) (in reply to ID l70x29p):\nHey, how’s it going ? Can I dm mine too? Really looking for angel investors\n\n## Comment ID l72bgft with +1 score by [(Litlyx, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l72bgft/) (in reply to ID 1d7bqx2):\nInvestors invest in the team. Than they investe in the competence of the team. Then they check what master-plan you have to conquer the market. Than you need a business plan from a minimum of 150.000k for a pre-seed, to a 1M for a seed. This is what you should aim if you want a VC. \n\nAnother way is to find mentors/angels to give you the chip you need! (50K for example)\n\n  \nHope this can help!\n\nAntonio, CEO & Founder at [Litlyx.com](https://litlyx.com)\n\n## Comment ID l73hm1x with +1 score by [(immaheadout3000, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l73hm1x/) (in reply to ID 1d7bqx2):\nDepends on which country you're in\n\n### Comment ID l73jxi7 with +1 score by [(APIsoup, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l73jxi7/) (in reply to ID l73hm1x):\nI’m in the Bay Area, our own country basically\n\n## Comment ID l73ifb8 with +1 score by [(Rochesteract, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l73ifb8/) (in reply to ID 1d7bqx2):\nI work with a vc fund and provide free consulting: message me. I’ll try to help you out\n\n## Comment ID l73vran with +1 score by [(fat_fire_in_tech, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l73vran/) (in reply to ID 1d7bqx2):\nDM me\n\n## Comment ID l73zphd with +1 score by [(More-Trade-6502, Reddit, 2024-06-04)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l73zphd/) (in reply to ID 1d7bqx2):\nIf you have an early success, what you need is a super developer that believes in what you’re building and can work for very cheap + sweat equity\nI’m one such developer + I have 1 VC connection, + a few thousand to cold email in a list\nSend me an email, and let’s schedule a call: joao.10.pimenta@gmail.com 👌\n\n## Comment ID l7arvgk with +1 score by [(None, Reddit, 2024-06-05)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7arvgk/) (in reply to ID 1d7bqx2):\nWe raised 100k from a few angles at a good valuation pre revenue. Team is very important at that stage rather than idea from my experience\n\n## Comment ID l7g830s with +1 score by [(None, Reddit, 2024-06-06)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7g830s/) (in reply to ID 1d7bqx2):\nWhat VC is giving you 50k lol. You're thinking of friends/family or an angel investor.\n\n## Comment ID l7pc7y5 with +1 score by [(Schleppaaa, Reddit, 2024-06-08)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7pc7y5/) (in reply to ID 1d7bqx2):\nVC’s don’t really write checks that small, look into Angels if you only need 50k\n\n## Comment ID l7piuvg with +1 score by [(Dom-CannaTech, Reddit, 2024-06-08)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7piuvg/) (in reply to ID 1d7bqx2):\nIf you’re unable to raise $50k with a friends and family round, and assuming you’re prerevenue, there are a lot of lenders that will look at personal credit and (hopefully) income and assets for a loan.\n\n## Comment ID l7s5ymw with +1 score by [(Saas-builder, Reddit, 2024-06-09)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l7s5ymw/) (in reply to ID 1d7bqx2):\nyou could try a lifetime deal partnership, could bring in a couple of 10s of thousands, thats what im doing\n\n## Comment ID lagjqki with +1 score by [(ScooterPocket, Reddit, 2024-06-27)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/lagjqki/) (in reply to ID 1d7bqx2):\nSounds like a great fuckin problem to have.\n\n### Comment ID lalm92v with +1 score by [(APIsoup, Reddit, 2024-06-27)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/lalm92v/) (in reply to ID lagjqki):\nApplied to YC late app, they said no- but we want you to apply again “specifically you”. So I guess we will continue what we’re doing right now until October. Good problem but nerve wrecking since it’s only gotten more busy with a few crashes lol\n\n## Comment ID l6y86cb with +1 score by [(Longjumping-Ad8775, Reddit, 2024-06-03)](https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/l6y86cb/) (in reply to ID 1d7bqx2):\n$50k is going to be hard.  It’s a relatively small amount, so it will be hard to do with a full on angel, angel group, or VC.  The overhead of doing due diligence is going to eat into things.  This is going to be a job for 3Fs.  I suggest heavily that you go to friends, family, and fools.",
      "# Post ID 1067xq1: Automation and its effect with +9 score by [(Gon_jalt, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/)\nI am currently reading a new book called Rule of the Robots. It talks about how AI will transform everything. The good and the bad. What are your thoughts on how this will effect estimating and construction management in general?\n\n## Comment ID j3fow69 with +8 score by [(dilligaf4lyfe, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3fow69/) (in reply to ID 1067xq1):\nI think we like to pretend that construction will be impossible to automate because there are so many variables, but ultimately it's just a matter of accurately capturing and applying the data. When we get to the point that a machine learning process has processed and can reference data from tens or hundreds of thousands of projects, it seems to me it'd be pretty obvious that it'd be better than a human at 99% of estimation. Are we there yet? No. But we're not too far away mo.\n\n### Comment ID j3fpqve with +6 score by [(HereForGunTalk, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3fpqve/) (in reply to ID j3fow69):\nI’ve ran across way too many sets of drawings with unknown variables. Idk. Think boilerplate specs, missing specs, difference in specs and drawings, things actually not on the drawings at all but you know from experience they need to be added to your takeoff, etc. \n\nI’m sure it’ll occur at some point I’m just not sure it’s something that will be super reliable. Maybe I’m wrong though.\n\n#### Comment ID j3g56sz with +5 score by [(dilligaf4lyfe, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3g56sz/) (in reply to ID j3fpqve):\nSure, but the whole point is that computers are pretty much always better at complex problem solving than people if given the right information. Say you've got all the data from drawings *and* all the data from change orders and RFIs that resulted from them. A machine learning program could ostensibly identify similar projects and specifications and identify gaps better than a person.\n\nI think we're a long way off from estimation without human oversight, but automation will probably start replacing some estimating jobs in the next 10 years. There's not some unimaginable technology leap required. I think eventually you absolutely will have fully automated estimating, it's just a question of how long it takes.\n\n#### Comment ID j3jj2h6 with +1 score by [(Hamwag0n, Reddit, 2023-01-09)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3jj2h6/) (in reply to ID j3fpqve):\nI’m in agreement on this. Being able to determine any human error in assembling the bid package; overlapping specs, missing specs, scale issues, missing plans, etc. Anyone can count and measure, but also there is an art to estimating in the “factors” and how they impact the work. \n\nI think the technology will be there, and some divisions will get damn close to fully utilizing it before others, but let’s stop and think here… To be able to feed a set of plans or a model in to a program to get a complete cost, the entire job would need to be laid out by someone. It would need to be laid out prior to the competitive bid stage, to be specific. In my experience in the electrical division, the drawings have gotten less detailed and complete and the expectation is that the contractor assumes responsibility for delivering a complete and functioning system, regardless of every part and piece is called out. All to say, I don’t think the design firms and engineers will shell out the time and money to fully design some divisions. They don’t want the liability or the up front cost. \n\nYes, I do think someday it will get there, but I think it’s a long way off for some divisions. The trends go where the money flows!\n\n#### Comment ID julqeap with +1 score by [(Unlikely_Track_5154, Reddit, 2023-08-03)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/julqeap/) (in reply to ID j3fpqve):\nI think that ai will be more like an assistant in that way.\n\nIt will do the 99% of the work, and then the humans will check the estimate and add what needs to be added.\n\n### Comment ID j3hoozw with +3 score by [(martincline, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3hoozw/) (in reply to ID j3fow69):\nThis implies that plans/specs make sense and are complete and coordinated…. Which they never are. \n\nAI’s time would be better spent automating architecture.\n\n#### Comment ID j3huwnn with +2 score by [(dilligaf4lyfe, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3huwnn/) (in reply to ID j3hoozw):\nWell, A) if architecture is automated, that to some extent implies estimating is as well. It's the same data set more or less.\n\nB) Like I said in my other response, if an AI is learning off of change order and RFI data as well, there's no reason it couldn't compare drawings and specs from past projects and identify areas where specs are lacking. If anything, with the right data, an AI should be *better* than a person at identifying problems with the documents and predicting conflict.\n\nLet's say you've got an AI with thousands of projects each with hundreds or thousands of variables. All the minute details of a project. All it'd have to do is identify projects that share those variables, and notable variables that are out of place in the current project. \"Hey, 89% of projects that are 60% similar or more contain this missing spec. 76% of projects 60% similar or more without this spec in original drawings ultimately adopted it via change order.\"\n\nWe're obviously a long way out from perfect data capture, but as technology improves, incentives to improve data capture are higher, until eventually you get to a point where predictive models are better than people at this stuff.\n\nThis is the same refrain people have been saying since we first started using computers. \"X is too complicated a problem, only a person could do it.\" But time and time again, it turns out people on average aren't that great at solving complex problems, and given the right inputs, a computer absolutely is.\n\n## Comment ID j3fykw4 with +7 score by [(Traditional_Earth149, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3fykw4/) (in reply to ID 1067xq1):\nUntil clients are willing to spend the money upfront to\nProduce decent specs and drawings with minimal\nHoles to no holes I think this is a way off.\n\nI mean electrically we’re there now with auto\nTake offs and pricing and they are wrong most of the time with differences between specs / drawings and just plain crap drawings.\n\n## Comment ID j3gnyrc with +3 score by [(Floyd-fan, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3gnyrc/) (in reply to ID 1067xq1):\nMore and more engineers are sharing electronic documents that make takeoffs easier. AI in my opinion will never completely replace an intuitive analysis of AI generated information. \n\nI’m biding a job where pipe is getting installed at the bottom of a wet basin and the nearest intersection that is intended to be drained by this storm system will be constantly flooded due to fluid mechanics. Long story short standing water in wet basin is elevation 105. Top of curb at intersection is elevation 104.  Water seeks a uniform elevation. \n\nI doubt AI could pick that issue up.\n\n### Comment ID j3gp02p with +3 score by [(None, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3gp02p/) (in reply to ID j3gnyrc):\nAI would be able to pick up whatever issue it’s coded to pick up.\n\nEventually it will just be robots bidding to robots with a few humans there to review things make sense.\n\n#### Comment ID j3guo4p with +1 score by [(Floyd-fan, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3guo4p/) (in reply to ID j3gp02p):\nTherein lies the rub. Someone has to anticipate that. Point of the comment is every situation being anticipated is highly unlikely. At least not in my lifetime. My opinion.\n\n#### Comment ID j4871l4 with +1 score by [(RocktownLeather, Reddit, 2023-01-13)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j4871l4/) (in reply to ID j3gp02p):\nIf we all pay the same subscription to the estimating software...we'll have the same price.\n\nIf it ever gets to where you describe, we won't be bidding based off scope. We'll be bidding solely off of rates, fees, insurance. Potentially maybe bidding off of productivity rates that the AE firm plugs into this software with the Owner. But there will be no need to \"bid\" the material costs as you are describing anyway.\n\n## Comment ID j3gjs1p with +2 score by [(SlangFreak, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3gjs1p/) (in reply to ID 1067xq1):\nI think the first thing AI will assist with is interpreting data from schedules (equipment, door, windows, hardware, etc.) and formatting them into an excel compatible list. So much time is consumed by just doing data entry for schedules that it's a no brainer value proposition to have human supervised softwafe for it.\n\nThe hardest part to construction AI adoption is the crazy high inertia in nearly every construction firm I know. These guys are usually very resistant to any kind of change so persuading them to get new software is tricky.\n\n### Comment ID j3h4ci4 with +2 score by [(johnnyhopkins1515, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3h4ci4/) (in reply to ID j3gjs1p):\nFor door, equipment, room matrix schedules I’m able to export them directly from the PDF using Bluebeam to an excel sheet. It’s a huge time saver and works the majority of the time as long as the drawing are formatted correctly. Maybe you already knew that but wanted to throw it out because it helps me out a lot.\n\n#### Comment ID j3hdt8r with +3 score by [(SlangFreak, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3hdt8r/) (in reply to ID j3h4ci4):\nI'm still learning bluebeam, so I didn't. Thanks for the tip, I'll look into it!\n\n## Comment ID j3h6gch with +2 score by [(randazz18, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3h6gch/) (in reply to ID 1067xq1):\nI think it will effect vendors the most.  Start cutting out middlemen and sales people.  Why cant I just chose what I need from the manufacturer online for pricing.  I'm already seeing it start\n\n## Comment ID j3liulm with +2 score by [(OK_Opinions, Reddit, 2023-01-09)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3liulm/) (in reply to ID 1067xq1):\nAI will never decipher the nonsense architects send out, not concerned at all on the estimating front. Humans can't even figure out what an architect wants so I don't see how a human will design an AI that actually can.\n\nIt'll be big in manufacturing though. It's the next step after CNC automation\n\n## Comment ID j3h850v with +1 score by [(PancakesAlways, Reddit, 2023-01-08)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j3h850v/) (in reply to ID 1067xq1):\nI think for electrical it’s possible but won’t be soon. The current auto count software has improved over the last 10 years but it’s far from machine learning. I have to tell it what symbols to count, then verify it counted the correct symbols, and all of them. It only does quantity take off, it can’t do circuiting. And if the drawings are crowded, shaded weird, or not on a square plan the program isn’t reliable. It’s also just counts— I still have to input what materials we’re using per spec and code.\n\n## Comment ID j4c7eqs with +1 score by [(Learningontheclock, Reddit, 2023-01-14)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/j4c7eqs/) (in reply to ID 1067xq1):\nI think the effect of AI is generally overstated in the short term over next 5 years but understated over the next 25 years.  I see areas where automation can be added to my job as an estimator but it would more modify what I do rather than eliminate what I do.\n\n### Comment ID julqyz0 with +1 score by [(Unlikely_Track_5154, Reddit, 2023-08-03)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/julqyz0/) (in reply to ID j4c7eqs):\nThat is what I am thinking as well.\n\nI think it will end up being more like self checkout at Walmart, where the AI does the majority of the work and the humans are there for the exceptions and to review the estimates or at least sanity check the estimates.\n\n#### Comment ID jut1vpl with +1 score by [(Learningontheclock, Reddit, 2023-08-04)](https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/jut1vpl/) (in reply to ID julqyz0):\nOne of the problems with AI is that the drawings that we estimate from are so bad that as an estimator your job is as much to see what's not in the drawings as it is to see what is there. I don't think AI will be able to fill in those gaps in a meaningful way for the foreseeable future.",
      "# Post ID 16m4d46: any known AI/tools for estimating? with +5 score by [(None, Reddit, 2023-09-18)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/)\nthings I'd like to see:\n\n1. ability to combine individual PDF elevations into one continuous view, staying true to scale\n\n2. take individual 2D PDF and create 3D image\n\n3. count size and quantity of panels based on PDF scale\n\n4. the ability to interpret and correctly analyze a curved area on a 2D drawing (i.e. the drawing will scale 24\" but the program will know the true panel is 30\" because it's concave, etc)\n\nany info or direction is appreciated or anything that can get close to this or any tools or tricks at all are appreciated!\n\n## Comment ID k168ogx with +4 score by [(Stuntz-X, Reddit, 2023-09-18)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k168ogx/) (in reply to ID 16m4d46):\n3D image from plans is good. I always say the Isometric view is the best way to understand elevations and different levels.\n\nI personally would like to see AI be able to go through Specifications and just paraphrase the pertinent information. Seems very feasible right now and may already be out there.\n\n### Comment ID k177r9z with +1 score by [(JosefDerArbeiter, Reddit, 2023-09-18)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k177r9z/) (in reply to ID k168ogx):\nI would like to see some AI tools for reading the specs too. At the least maybe a tool to provide an executive summary and guidebook for preparing the estimate.\n\n“This job is a renovation of a 3 story 20,000 sf university building. In addition to the customary trades of metal studs, drywall, painting, MEPS, and roofing there’s some elevator and window repairs to be performed. The exterior of the building is to receive a full masonry restoration.\n\nParticular attention should be given to the exterior renovation portion of this project, as there are strict safety requirements found in the general conditions portion of the project manual.”\n\nSomething like that\n\n#### Comment ID k1e0t5x with +1 score by [(ooselfie, Reddit, 2023-09-20)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k1e0t5x/) (in reply to ID k177r9z):\nDamn you should check out www.downtobid.com I think they're doing exactly that\n\n## Comment ID k16s1q5 with +5 score by [(second-last-mohican, Reddit, 2023-09-18)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k16s1q5/) (in reply to ID 16m4d46):\nSo, you dont want to do any work?\n\nTogal and Kreo are the newest on the block.\n\n\nHowever, you have to rely on the drawings being accurate and consistent. \n\nEven 3d takeoff tools arent accurate as Architects dont normally know how to build and 3d plans arent engineered.\n\nIf you ask the Architect for the revit files, you can load them into Autodesk and pull the 3d components into groups which is great. However, they might not be accurate or drawn in a realistic manner.\n\n## Comment ID k16ra3a with +2 score by [(Remarkable-Okra6554, Reddit, 2023-09-18)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k16ra3a/) (in reply to ID 16m4d46):\nRe; first point \n\nThere’s not an AI that I’m aware of that can do this. I will screen shot plans, and load that to Sketchup, scale it, and then put the plans together in 3D. It’s helpful and free\n\n### Comment ID k6464je with +2 score by [(fosormic, Reddit, 2023-10-23)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k6464je/) (in reply to ID k16ra3a):\nThats what I've been doing for the past year or so lol. Works pretty well and really accurate if well done in fact.\n\n#### Comment ID k648kwv with +1 score by [(Remarkable-Okra6554, Reddit, 2023-10-23)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k648kwv/) (in reply to ID k6464je):\nHaha I love that. I knew there had to be someone out there doing it. It’s also really helpful for calculating area/volumes of weird shapes really fast.\n\n## Comment ID k17j0mw with +1 score by [(Ambitious-Delay5911, Reddit, 2023-09-19)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k17j0mw/) (in reply to ID 16m4d46):\nThis sort of information is actually available on some cad formats. The big IF is if architect/draftsperson will detail the cad to show this including a product ID that is recognisable. ArchiCad I understand has this capability for example.\n\n## Comment ID k19m4cs with +1 score by [(wamegojim, Reddit, 2023-09-19)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k19m4cs/) (in reply to ID 16m4d46):\n[Togal.AI](https://Togal.AI) is the only plan reading software I have seen. ChatGPT can do the spec summary. In fact almost any of the LLMs can do that summary. I have heard AutoCad is working on a tool but not 100% sure of the status. Again, as others have mentioned, the designers don't provide enough detail. In fact, I'm seeing EEs push fire alarm design on to the contractor more often now. Most small to medium sized electrical contractors don't have that capability.\n\n### Comment ID k1m5qcc with +1 score by [(slowsol, Reddit, 2023-09-21)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k1m5qcc/) (in reply to ID k19m4cs):\n100% of our fire alarms are delegated design and have been for 10 years.\n\n## Comment ID k645rmq with +1 score by [(fosormic, Reddit, 2023-10-23)](https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/k645rmq/) (in reply to ID 16m4d46):\nI have 15 yrs of estimating so kind of experienced on how things work. GC and masonry mostly. Before that, 20 or so years of software development, and never really stopped, so I'm kind of qualified to have an opinion. \n\nFor the past eight months I have been trying to see how I can do what you are mentioning. Both on the drawings and also on the specs part. I'm being supported by one of the very large AI companies since they believe it's an interesting use of their technologies.\n\nIn my opinion, at this point in time underlying technologies are not enough to accomplish what you mention. 2-3 years maybe, a commercial product probl 5 years away. \n\nEven thoguh costs are quickly dropping, it will also be very expensive still. AI models are extremely expensive to run and most (like almost all) of the time it must be run on big service providers and they charge per token (I'm not going to delve on that) and there would be *a lot* of those on a plan set. Point being, the service cost would be really high.",
      "# Post ID t9hrql: Is it time to replace Planswift? What has your experience been like if you have? with +7 score by [(European_or_Gay, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/)\nMy first estimating love, Planswift, is still my go to software for takeoff and it's hard to even rationalize how much time I've spent building assemblies on this program.  Even though it's essentially an outdated excel file with a UI for pulling scaleable measurements, I have enjoyed using the program.  It has taught me a lot about the different factors in construction estimating that need to be accounted for.  By trial and error I've worked through building assemblies that have given me very accurate takeoffs for my jobs.  Despite this love, I want to know if it's time to dump the old girl in favor for someone younger, who likes to take care of herself more...\n\nMy main issue with the old girl (Planswift) is it's \"plugins\" that are now essentially necessary for estimating purposes now are outdated, hard to use, and aren't being updated.  One function I really wish Planswift had, was updating material or labor costs and having that be updated with all prior jobs  so that old jobs are kept up to date cost wise and can be used again instead of having to re-takeoff the entire job with the assemblies that have updated costs.\n\nI know Planswift was recently acquired by ConstructConnect, and they offer a more cloud based takeoff software.  I was wondering if anyone has made the switch from Planswift to ConstructConnect or another similar more updated estimating software and what their experiences have been like?\n\nBeing able to port in my assemblies from Planswift would be a huge time saver.\n\nAny input on what your experience has been like moving on from Planswift would be greatly appreciated.\n\n## Comment ID hzvjlam with +7 score by [(None, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzvjlam/) (in reply to ID t9hrql):\nJust to be up front, I used to work in sales for a competing takeoff software until the first of the year and lurked this subreddit for years. I also know several people that work at or used to work at ConstructConnect. \n\nPlanswift is a dead software. They bought it for the customer list. They would have already sunset it if they could but there are too many companies holding onto it. They would would love to get recurring revenue for their cloud offering but it’s not very good and they’ve had too many people switch back to Planswift (and OST as well, which they also own) because it’s pretty lacking and crashes a lot. They are not supporting it or updating it.\n\n### Comment ID hzvuexs with +4 score by [(European_or_Gay, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzvuexs/) (in reply to ID hzvjlam):\nYeah, I guess this just confirms what we're all feeling.  What are most people going to then?\n\n#### Comment ID hzw7jhr with +3 score by [(None, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzw7jhr/) (in reply to ID hzvuexs):\nBlueBeam, STACK, Autodesk, OST (ConstructConnect actually has some service for that because they have some massive ENR contracts)\n\n### Comment ID juap10n with +1 score by [(anonymouswtPgQqesL2, Reddit, 2023-08-01)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/juap10n/) (in reply to ID hzvjlam):\nIt feels like they dont love their cloud offering...OST is getting all the cool shit like AI now. Whats your take?\n\n## Comment ID hzudhte with +2 score by [(JosefDerArbeiter, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzudhte/) (in reply to ID t9hrql):\nWell, I am still a new Planswift user but I find their quickness about updating poor.\n\nIt took a phone call with customer service for me to find out that the \"Export to PDF button\" for reports doesn't work and hasn't been fixed in an update. Like really? So the workaround solution is to print and save to PDF.\n\nAnd that's probably one of many issues.\n\n### Comment ID hzudowi with +3 score by [(European_or_Gay, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzudowi/) (in reply to ID hzudhte):\nThat's most of their functions... It's just slowly dying and with their acquisition they're pushing hard for people to switch to their subscription model cloud based takeoff software.\n\n## Comment ID hzw3x9o with +2 score by [(Constructestimator83, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzw3x9o/) (in reply to ID t9hrql):\nI thought it was going to be ConstructConnect but that thing is garbage so I guess it’s back to OST since it is the least painless way to work.  \n\nIt’s sad something like CCTO is so awful when the company literally owns the gold standard in takeoffs, OST.\n\n## Comment ID hzwfaim with +2 score by [(Hbhbob, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzwfaim/) (in reply to ID t9hrql):\nI'm still using planswift\n\n## Comment ID i072tvz with +2 score by [(Nearby_Lock9950, Reddit, 2022-03-11)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/i072tvz/) (in reply to ID t9hrql):\nBuildertrend\n\n### Comment ID lw6gv0o with +1 score by [(Informal-Maximum-240, Reddit, 2024-11-09)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/lw6gv0o/) (in reply to ID i072tvz):\nBuildertrend is just an amazing program all around.\n\n### Comment ID i0m9v6d with +1 score by [(vanuslob, Reddit, 2022-03-14)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/i0m9v6d/) (in reply to ID i072tvz):\nBuildertrend does estimation or takeoffs?\n\n#### Comment ID i0m9w7u with +1 score by [(alphabet_order_bot, Reddit, 2022-03-14)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/i0m9w7u/) (in reply to ID i0m9v6d):\nWould you look at that, all of the words in your comment are in alphabetical order.\n\nI have checked 641,102,137 comments, and only 130,579 of them were in alphabetical order.\n\n#### Comment ID i5ka56x with +1 score by [(Nearby_Lock9950, Reddit, 2022-04-21)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/i5ka56x/) (in reply to ID i0m9v6d):\nEverything in one, all your PM needs and partner with take offs that integrate with their software\n\n## Comment ID i0j2wj8 with +2 score by [(kaleb9999, Reddit, 2022-03-13)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/i0j2wj8/) (in reply to ID t9hrql):\nIn the same boat. Literally years of building custom templates that are extremely technical, but man does it get slow when you have to make changes. A very useful plugin for making changes to multiple properties at once is called “advanced item updater” which you can only get if you call and ask for it. Let’s say you have 20 wall assemblies with 2x6 framing, you could update the price of that 2x6 on all assemblies at once. Super useful\n\n## Comment ID kub775t with +1 score by [(None, Reddit, 2024-03-11)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/kub775t/) (in reply to ID t9hrql):\nI've been using PS for years and they over thought the whole process from set up to application. Tha data migration from start to finish is the most time consuming arguous process. In speaking with many, and I mean mant of their techs, they agreed. Even while 11 was in BETA, I was in touch with the main tech and i explained a few simple things that needed to be addressed. Did they address them or even try to implment them? NOT even close. It is not user friendly as they make it out to be for actual contractors. One Example: Setting up a project in PS at the start you enter the jobs tax rate, material profit, labor profit, burfen, overhead and so on. So why when you do your take off does it ask for that information on each step of the way? Why do you have to tell the program to unlock these items in each line? The program should migrate that data to where it should go automatically. It does not and then you have to a programmer to learn to operate all the stuff it says it does but doesn't. And then go to PS college to learn all the stuff to make it work. Too labourious. Stop overthinking this.\n\n## Comment ID lw5nge3 with +1 score by [(None, Reddit, 2024-11-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/lw5nge3/) (in reply to ID t9hrql):\n[removed]\n\n### Comment ID lw6h33j with +1 score by [(Informal-Maximum-240, Reddit, 2024-11-09)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/lw6h33j/) (in reply to ID lw5nge3):\nGiving your software a try right now brother man. I will get back to you with comments and suggestions if I have any.\n\n## Comment ID lziln8k with +1 score by [(Jag23707429, Reddit, 2024-11-29)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/lziln8k/) (in reply to ID t9hrql):\nSo is everyone here still using PLANSWIFT?\n\n## Comment ID hzuitam with +1 score by [(Mentor_Bob_Kazamakis, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzuitam/) (in reply to ID t9hrql):\n>My main issue with the old girl (Planswift) is it's \"plugins\" that are now essentially necessary for estimating purposes now are outdated, hard to use, and aren't being updated. One function I really wish Planswift had, was updating material or labor costs and having that be updated with all prior jobs so that old jobs are kept up to date cost wise and can be used again instead of having to re-takeoff the entire job with the assemblies that have updated costs.\n\nI mean, that's the crux of it, isn't it? I have thousands of takeoffs, but in order to update pricing it's hours upon hours of work. This may have been fine up until 2020, but it's not workable anymore. Price changes and supply issues are not going away anytime soon.  \n\n\nI've experimented with the pricing point to a database, but the issues I had with it is that the assemblies/formulas need to be redone with each pricing change, which negates the point. There may be things I'm missing, but it's gotten extremely convoluted.\n\n### Comment ID hzur3gq with +2 score by [(European_or_Gay, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzur3gq/) (in reply to ID hzuitam):\nExactly, there's so much there that it could do to make our lives easier but it seems like they're done with the product.  I'm at this point just looking for what the best replacement product is and hoping it's not too hard to move my assemblies over to it.\n\n### Comment ID hzvrhka with +2 score by [(NadlesKVs, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzvrhka/) (in reply to ID hzuitam):\nSame problem. I can't even get a Manufacturer to give me a Database anymore anyway and if they did, it would be outdated on Day 1.\n\nThey are now charging us the price it costs when it gets loaded onto the truck. Not when we order it. Pricing I get is good for, \"30 days\" but all of these items have lead times over 30 days. Essentially the pricing I get on Bid Day is already bad.\n\nI have to fix all my pricing in Excel just line by line.\n\n#### Comment ID hzvvsvd with +1 score by [(Mentor_Bob_Kazamakis, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzvvsvd/) (in reply to ID hzvrhka):\n100% in the same boat, my dude. I price something on Wednesday and it's out of date on Monday. And the job may not start for 6 months. So ... I'm out of ideas.\n\n## Comment ID hzwl9l9 with +1 score by [(russdr, Reddit, 2022-03-08)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzwl9l9/) (in reply to ID t9hrql):\nI'm not sure of your trade but I'm an EC that uses Accubid.  I believe accubid does MEP.  It's owned by Trimble so if Accubid doesn't cover you, they may have alternate solutions which may be applicable.  My point in commenting is that in Accubid you can \"re-extend\" using updated labor and cost databases (as long as your \"item\" or \"assembly\" matches the previous entry in the database).  Furthermore, you can link your database with Trade Service, which is also a Trimble company.  I only use it to update my material pricing but you can also link to the NECA labor manual to update labor units but again this is electrical only.  They also have an option to link the material to your local supplier's pricing which can save you some time with commodity sheets or emailed quote requests.  The unfortunate part, though is that all of these automatically updated items tend to be on the higher side of cost and labor.  Not very competitive.  \n\nTrimble may have a similar solution with their other offerings, if MEP is not your discipline, though.  Hope this helps.\n\n## Comment ID hzxlhq6 with +1 score by [(WalkApprehensive8040, Reddit, 2022-03-09)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/hzxlhq6/) (in reply to ID t9hrql):\nNot ready to leave Planswift yet, I know what you're referring to in regards to the Labor and Material Pricing updating issues. But I have searched and have not found any Takeoff software that is as customizable as Planswift.\n\n I have found solutions for Planswift for these pricing issues. One that I recommend, and I'm not a salesman for this company, is [\"DBLive Plugin for Planswift\"](https://www.tradetekplugins.com/planswift/dblive/)  it can keep your project pricing update. The other solution is a plugin that I build myself, is not very refine and still has some work to be done, but once I slowdown doing Takeoffs, I will polish it and put it out there for sale.\n\nIf you're not using the Planswift's ability to build Parts, Labor, Material with custom formulas, then any other software should be good for you. \n\nMy opinion about Revu Bluebeam, is that is as buggy and laggy as Planswift, sometimes even worse, since it works directly with PDF, and some PDF's are either too large or the way they were \"made\" causes Revu to Crash... for example, I use Revu to Organize and mange Project documentation, and yesterday I worked on a Project with 750 pages of 42\"x30\" drawings and it crashed the whole computer, had to do a hard reset.\n\n## Comment ID juj3hns with +1 score by [(ChampionshipOk2302, Reddit, 2023-08-02)](https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/juj3hns/) (in reply to ID t9hrql):\ni haven't used planswift, but i went from doing my estimates and takeoffs in excel and switched to buildxact a few years ago. really happy with buildxact and the takeoff tool is great, i find it easy to use. i did the demo before signing up and their support guys were really helpful. would recommend it.",
      "# Post ID 15tpp7l: Roof Data into Xactimate with +2 score by [(Toddvg, Reddit, 2023-08-17)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/)\nI am looking for a clean way to obtain and then import roof  measurements into Xactimate. Right now I am only aware of purchasing Eagleview  data that is imported into Xactimate. Is there any software that will allow me to measure from an aerial photo, maybe an app that will allow me to take a few pic's.\n\nI am sure with the large amount of Hail claims we have had this year someone has figured out a way. 25% or more of my roofs this year have been Steep with more different roof styles than i have seen in 30+ years in construction. The other day I had a roof that inorder to Sketch it even close I had to put a Gable on a hip with 4 flat roofs and have that all tie into a completly different style on the garage, and 8 dormers and 4 different pitches.\n\nI am am pretty good sketching but it took me 45 min,, to get it even close.\n\nANYONE OUT THERE HAVE SOMETHING THEY USE?\n\n## Comment ID jwl44uw with +11 score by [(MD_295, Reddit, 2023-08-17)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwl44uw/) (in reply to ID 15tpp7l):\nHover is what you want. Take photos around the house, upload and get your sketch in a few hours at the most.\n\n### Comment ID l3gadtw with +1 score by [(Purblebelly87, Reddit, 2024-05-10)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/l3gadtw/) (in reply to ID jwl44uw):\nI prefer using Loveland Innovations over Hover. You can directly import 3D and measurements into Xactimate. I use their AI for roof damage and it's quick and easy.\n\n### Comment ID lcpa21d with +1 score by [(None, Reddit, 2024-07-11)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/lcpa21d/) (in reply to ID jwl44uw):\n[removed]\n\n#### Comment ID lcpa234 with +1 score by [(AutoModerator, Reddit, 2024-07-11)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/lcpa234/) (in reply to ID lcpa21d):\nYour account is too new to post here. 15 day age account is required as well as a combined karma of 10.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/adjusters) if you have any questions or concerns.*\n\n## Comment ID jwlei3h with +3 score by [(mradjuster, Reddit, 2023-08-17)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwlei3h/) (in reply to ID 15tpp7l):\nYup hover\n\n## Comment ID jwlo7rw with +3 score by [(Danjinold, Reddit, 2023-08-17)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwlo7rw/) (in reply to ID 15tpp7l):\nThere’s like 4 companies you can pay 19-25 dollars for an esx.\n\n## Comment ID lcp9fqt with +1 score by [(None, Reddit, 2024-07-11)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/lcp9fqt/) (in reply to ID 15tpp7l):\n[removed]\n\n### Comment ID lcp9fsp with +1 score by [(AutoModerator, Reddit, 2024-07-11)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/lcp9fsp/) (in reply to ID lcp9fqt):\nYour account is too new to post here. 15 day age account is required as well as a combined karma of 10.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/adjusters) if you have any questions or concerns.*\n\n## Comment ID jwmx37k with +1 score by [(frvnco1, Reddit, 2023-08-17)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwmx37k/) (in reply to ID 15tpp7l):\nACTs are like $30 and have an esx\n\n### Comment ID lcpahln with +1 score by [(None, Reddit, 2024-07-11)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/lcpahln/) (in reply to ID jwmx37k):\n[removed]\n\n#### Comment ID lcpahnq with +1 score by [(AutoModerator, Reddit, 2024-07-11)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/lcpahnq/) (in reply to ID lcpahln):\nYour account is too new to post here. 15 day age account is required as well as a combined karma of 10.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/adjusters) if you have any questions or concerns.*\n\n### Comment ID jwmxq56 with +1 score by [(frvnco1, Reddit, 2023-08-17)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwmxq56/) (in reply to ID jwmx37k):\nI also use hover but only with the carriers that pay for it. I have a few carriers in my hover account so that I can directly send them bill to them.\n\n## Comment ID jwoc7lk with +1 score by [(LetterheadFair9521, Reddit, 2023-08-18)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwoc7lk/) (in reply to ID 15tpp7l):\nHover\n\n## Comment ID jwuwkjj with +1 score by [(VIOLENT_WIENER_STORM, Reddit, 2023-08-19)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwuwkjj/) (in reply to ID 15tpp7l):\nI got you, fam: https://youtu.be/TM4JKglS8g4\n\n## Comment ID jwv0jeu with +1 score by [(Competitive_Bat1293, Reddit, 2023-08-19)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwv0jeu/) (in reply to ID 15tpp7l):\nFiver\n\n## Comment ID jwye271 with +1 score by [(3puttnutt, Reddit, 2023-08-20)](https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/jwye271/) (in reply to ID 15tpp7l):\nLoveland Innovations. You can use their IMGING software and a compatible drone for the steep roof inspection. They can import the 3d sketch directly into Xactimate.",
      "# Post ID 1auh7ja: Is ChatGPT premium worth it?  with +5 score by [(Sandrummer2, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/)\nI'm pretty new to the AI world but I am looking to possibly pay for a subscription to an AI service. My question is, is it worth it? Are there better options than ChatGPT premium? \n\nAlso, let's say I want to upload an excel file with data to the tool and have it tell me patterns or unique findings it can gain from the file. Is there any premium AI tool that can do that? \n\nTIA\n\n\n\n## Comment ID kr3wvhn with +7 score by [(PhilosophyforOne, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr3wvhn/) (in reply to ID 1auh7ja):\nFor the latter one, you'd need Microsoft Copilot subscription. (Look into that.) \n\nI'd absolutely say that ChatGPT plus is worth the subscription. However, what value you get depends on your ability to use it. It's a tool like any other. However, it's the best tool currently out there (although Google's Gemini 1.5 Pro is likely to give it a run for the money), and if you were specifically looking for an AI tool, that's the one I'd both use and recommend to use.\n\n### Comment ID kr4xqt8 with +1 score by [(hpsims, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr4xqt8/) (in reply to ID kr3wvhn):\nDo you need copilot for this? I thought there was a ChatGPT addon. Can you also not upload the file directly to ChatGPT. Sorry if these are stupid questions as I’m not familiar with the programs.\n\n#### Comment ID kr69auj with +1 score by [(PhilosophyforOne, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr69auj/) (in reply to ID kr4xqt8):\nYou can, but I personally havent found the data analysis feature in ChatGPT to be that helpful, beyond fairly basic things.\n\n## Comment ID kr3xu73 with +2 score by [(DeviousDVS, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr3xu73/) (in reply to ID 1auh7ja):\nDon't forget that when you upload data, at the very least, you lose control of where it might turn up next. If your data is sensitive, maybe look for a more controlled solution. If you're happy to spread it to the four winds, go for it!\n\n### Comment ID kr3y358 with +2 score by [(Sandrummer2, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr3y358/) (in reply to ID kr3xu73):\nYes I'm aware of the risk. I would ofcourse put in fake data wherever PII was located in the file prior to upload.\n\n## Comment ID kr4o8v0 with +2 score by [(alkiealkie, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr4o8v0/) (in reply to ID 1auh7ja):\nI just subscribed this month after a few months of using the free service and yeah I would say it's worth it. That being said the only real game changers are advanced reasoning, speech mode, and image detection. The DALLE image generator is still pretty experimental and good luck getting exact results of any kind that aren't generic. GPTs are pretty good, I've made a few small ones to help with very specific tasks but overall I found the majority of them to be no better than just using plain old ChatGPT.\n\n## Comment ID kr92m8n with +2 score by [(Effective_Vanilla_32, Reddit, 2024-02-20)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr92m8n/) (in reply to ID 1auh7ja):\nit is\n\n## Comment ID l29o561 with +1 score by [(Basic-Pain-9730, Reddit, 2024-05-02)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/l29o561/) (in reply to ID 1auh7ja):\nThis video is a pretty neutral perspective on the matter, for me it's worth it because of the custom GPTs and the 40% increased probability of factual answers  \n[https://www.youtube.com/watch?v=hJAzSTeEYlM](https://www.youtube.com/watch?v=hJAzSTeEYlM)\n\n\n\n\n\n## Comment ID kr3v0wa with +1 score by [(AutoModerator, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr3v0wa/) (in reply to ID 1auh7ja):\n## r/ChatGPT is looking for mods — Apply here: https://redd.it/1arlv5s/\n\nHey /u/Sandrummer2!\n\nIf your post is a screenshot of a ChatGPT, conversation please reply to this message with the [conversation link](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq) or prompt.\n\nIf your post is a DALL-E 3 image post, please reply with the prompt used to make this image.\n\nConsider joining our [public discord server](https://discord.com/invite/r-chatgpt-1050422060352024636)! We have free bots with GPT-4 (with vision), image generators, and more!\n\n &#x1F916;\n\nNote: For any ChatGPT-related concerns, email support@openai.com\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPT) if you have any questions or concerns.*\n\n## Comment ID kr46teo with +1 score by [(late2theparty27, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr46teo/) (in reply to ID 1auh7ja):\nI don't know if I needed to upgrade or not as of yet,as i just got the upgrade two days ago but, I'm currently using it to help me build a pretty huge aviary/greenhouse and i have virtually zero construction experience. it's pretty handy and it quashes any doubts I may be having.\n\n### Comment ID kr4odcp with +2 score by [(alkiealkie, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr4odcp/) (in reply to ID kr46teo):\nHow are you using it for this purpose? Do you mean asking questions regarding aviaries and greenhouses or is it actually helping you in the design and construction?\n\n#### Comment ID kr76lb4 with +1 score by [(late2theparty27, Reddit, 2024-02-19)](https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/kr76lb4/) (in reply to ID kr4odcp):\nSo I'll imagine something in head (technique, approach, intention etc) and clearly give chat gpt all the details and goings on with my project and ask it what it would improve, how to make sure I'm re-enforcing everything correctly. Basically I'm using chat gpt a personal woodworking teacher on demand. I've discussed simple concepts with it like low slope gable roofs, or single slope roofs and I've also made it a point to mention to it that I'm not very good and that I don't know what Im doing and its guided me pretty well.",
      "# Post ID 11yjtyo: WWE 2k23 Tips & Awareness thread with +85 score by [(Cautious-Building-14, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/)\nBelow are tips for a few modes for people with FAQ in the sub. \n\nSliders: \n- please know this is subjective because a great match to me may be normal to you or vice versa, when you try out someone’s sliders keep that in mind. \n\nIMO: the best tip here is play around with it to your liking and what you enjoy for your game. What works for me may not work for you, & that’s fine \n\nDo not turn all the gameplay sliders to 0 though. Unless you do it for a character alone but don’t do it for the overall gameplay \n\nI’ve seen this done and it will only allow the AI to Irish whip each-other and that’s it. \n\nWhen editing sliders you’ll have to do them for the overall gameplay & for each character individually. \n\nThe one for the gameplay controls if the AI will do it at all. For example if you turn dodge to 0 in the overall gameplay it doesn’t matter what the superstar has it as they will not dodge ever. \n\nUniverse mode: \n\nIssues right now: \n- Custom move-sets & paybacks in Rival matches reverting to default during the match.\n- 3 man entrances & manager entrances \n- Run ins/ show Intro/ customs arenas. \n\nThere are no work arounds for these right now until a patch is issued. You aren’t the only one dealing with it I promise lol. \n\n\nIf you are doing a superstar mode: please do yourself a favor and edit then match table before you start. The AI books some really bad matches for you if you don’t. Just please for yourself edit the match table to have it have the type of matches you want then switch back. \n\nCreate a Arena: \nThe images are bugged some people aren’t seeing the issues but most are. Needs a patch \n\nCreate a entrance\nThe preview is bugged you can’t see your entrance and preview it like in games passed it pretty buggy but manageable if you have patience’s. Still needs a patch. \n\nShowcase My faction trophies: \nTrophy’s are staying but the progress is being wiped for some. Needs a patch. \n\nMY GM / My Rise: \nThe most stable modes of all modes right now really not to many issues that need a true fix. Besides minor things \n\nCody Rhodes & Ronda Rousey: \n- yes their music is copyright protected in game and you’ll lose their song making any changes to them, so be careful until (if) their is some type of music match for them. \n\nFeel free to add more tips and or awareness to the community down below:\n\n## Comment ID jd84vwp with +90 score by [(Anhcoholic, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd84vwp/) (in reply to ID 11yjtyo):\nBeing unable to select \"normal\" title entrance is another big issue\n\n### Comment ID jd88dnk with +12 score by [(MadEyeMood989, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd88dnk/) (in reply to ID jd84vwp):\nThis. Only this.\n\n#### Comment ID jd88izc with +14 score by [(Anhcoholic, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd88izc/) (in reply to ID jd88dnk):\nLol yeah this is my BIGGEST issue with the game as of now\n\n## Comment ID jd80pyw with +37 score by [(XZPUMAZX, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd80pyw/) (in reply to ID 11yjtyo):\nSave often in CC. It crashes often.\n\n### Comment ID jd81s91 with +18 score by [(Cautious-Building-14, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd81s91/) (in reply to ID jd80pyw):\nHad this issue in 2k22. 0 crashes in 2k23 at all for me for any reason. \n\nI’ve also not downloaded any of these new ALT. With hair changes and stuff either so idk if that has a bit to do with it, but no crashes for me I’ve scrolled a lot in CC with no issues\n\n#### Comment ID jda1ald with +3 score by [(KuruptionTing, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jda1ald/) (in reply to ID jd81s91):\nI think he means creation centre and not community creations. I have had the game crash if I’m creating a caw and do a lot of changes before I save. Probably what they’re talking about\n\n## Comment ID jd80hzv with +17 score by [(BrandonIsWhoIAm, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd80hzv/) (in reply to ID 11yjtyo):\nMyRISE is broken in one case - for me at least.\n\nAfter completing the side story, “A Good Inv-EST-ment,” my character was teleported to an area that doesn’t have Molly Holly in it. This doesn’t allow me to continue to the main storyline, which renders my second playthrough incomplete and unplayable.\n\n### Comment ID jd81ipl with +7 score by [(VirgilsCrew, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd81ipl/) (in reply to ID jd80hzv):\nIn my case, the first two times I tried to play it, I spent a good hour or so creating my character, and in both cases, the game crashed as I went to save. I decided to try a third time, and created a completely different character instead of trying to replicate my first two attempts, and that finally worked. I am assuming it had to do with one of the parts I selected for my original character…\n\n### Comment ID jd8jbvs with +3 score by [(ILoveIt19, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8jbvs/) (in reply to ID jd80hzv):\nI have the same problem here. Really sucks, as I've put a few hours in already.\n\n#### Comment ID jd8kab4 with +2 score by [(BrandonIsWhoIAm, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8kab4/) (in reply to ID jd8jbvs):\nSame! I have to do ANOTHER run because I missed the Lita storyline for a jacket! After this, I’ve gotten everything from that side!\n\n### Comment ID jd9pm9d with +3 score by [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9pm9d/) (in reply to ID jd80hzv):\nI've played thru Legacy story twice and didn't get the trophy for either choice. Anyone else have that problem?\n\n#### Comment ID jd9snez with +2 score by [(Aj-Adman, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9snez/) (in reply to ID jd9pm9d):\nI didn’t get the one for the second big choice. My theory is that they only work if you turn heel for the earlier choice.\n\n#### Comment ID jd9rn3c with +1 score by [(BrandonIsWhoIAm, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9rn3c/) (in reply to ID jd9pm9d):\nI got that glitch for my first run.\n\n## Comment ID jd8365b with +11 score by [(DustinoHeat, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8365b/) (in reply to ID 11yjtyo):\nEvery single year. Seriously. For the past two years I have lost everything via a corrupt save file or a bug or something of that nature. I have already completed MyRise and Showcase mode. I should’ve known better, I’m gonna be highly upset if it happens this year again.\n\n## Comment ID jd8hr5y with +10 score by [(Sergio808, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8hr5y/) (in reply to ID 11yjtyo):\nCustom championship doesn't appear on the wrestlers when they make their entrance in universe mode.\n\n### Comment ID jd9titm with +1 score by [(Puxple, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9titm/) (in reply to ID jd8hr5y):\nOk I thought this was just me\n\n## Comment ID jd8mnnc with +10 score by [(FireflyNitro, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8mnnc/) (in reply to ID 11yjtyo):\nAnother bug in Universe that literally nobody seems to be talking about is that setting a specific ref doesn’t work. I have WCW ref on one show and Smackdown ref on another, but I only see Standard Referee 1, on both shows.\n\n### Comment ID jda8ngi with +3 score by [(BananaSplit1209, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jda8ngi/) (in reply to ID jd8mnnc):\nI hate that ref because it just looks like Angelo Dawkins to me. Seeing him refereeing is just immersion breaking.\n\n#### Comment ID jdag69a with +3 score by [(J4S0NFTW, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdag69a/) (in reply to ID jda8ngi):\nI don’t understand why they couldn’t use a random 2k employees face for those refs.\n\n#### Comment ID jdauto8 with +1 score by [(Swimming-Chicken-424, Reddit, 2023-03-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdauto8/) (in reply to ID jda8ngi):\nI also hate the Chad Gable looking ref\n\n### Comment ID jdc2ntn with +1 score by [(ShadowKnight99, Reddit, 2023-03-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdc2ntn/) (in reply to ID jd8mnnc):\nI noticed that. I used the smackdown 2002 arena and logos, and set the ref to smackdown 2009 (blue shirt) ref and he isn't showing up in matches.\n\n## Comment ID jd8atb4 with +7 score by [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8atb4/) (in reply to ID 11yjtyo):\nFor the love of God, what do the pin sliders do.\n\n### Comment ID jd8esbg with +5 score by [(Cautious-Building-14, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8esbg/) (in reply to ID jd8atb4):\nIf you put them closer to 100 they will not kick out if you put them less than a 100 they will kick out more \nFor AI\n\nFor Human: \n\nIt’s just how easy or hard for you to kick out\n\n#### Comment ID jd8n9cm with +8 score by [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8n9cm/) (in reply to ID jd8esbg):\nThere's like 10 pin sliders. What is hard pin 1, or 2?\n\n#### Comment ID jd9qrrg with +3 score by [(AgentRickc137, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9qrrg/) (in reply to ID jd8esbg):\nWhat do you put the sliders on to make it easier for the player to kick out ?\n\n#### Comment ID jdc2zmr with +1 score by [(ShadowKnight99, Reddit, 2023-03-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdc2zmr/) (in reply to ID jd8esbg):\nWait really? So moving the slider closer to 100 makes the AI worse? I figured it was the other way around. Like if i wanted the AI to stop spamming counters i would move the reversal slider to 15 (or the closer to 0 the worse the AI is) or something, but you are saying that makes them use reversals more? This slider stuff is confusing.\n\n## Comment ID jd8dn15 with +8 score by [(Silly-Soil-9106, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8dn15/) (in reply to ID 11yjtyo):\nSo if I download an attire for Cody or Ronda and set it as an alternate outfit, does it eliminate entrance music?\n\n### Comment ID jd8eve5 with +7 score by [(Cautious-Building-14, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8eve5/) (in reply to ID jd8dn15):\nHighly likely\n\n### Comment ID jd8mik8 with +5 score by [(FireflyNitro, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8mik8/) (in reply to ID jd8dn15):\nCan confirm it does. I just downloaded a Ronda alt today and she comes out in silence 😔\n\n### Comment ID jd95lm7 with +5 score by [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd95lm7/) (in reply to ID jd8dn15):\nYou can't even change Cody's entrance to Cody Rhodes 2 to get his Wrestlemania entrance or even alter the colour of his gear.\n\n### Comment ID jd964rh with +2 score by [(pardyball, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd964rh/) (in reply to ID jd8dn15):\nEven on PC, you can’t even change Cody’s music at all. Because of this, I figured it just didn’t let you choose Kingdom, so I used sound editor to try and use that as a work around and no luck either.\n\n## Comment ID jd98ykk with +7 score by [(Man6287, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd98ykk/) (in reply to ID 11yjtyo):\nCan they please just let you pick the opponent in universe for rival actions\n\n### Comment ID jd9qtjo with +3 score by [(35antonio, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9qtjo/) (in reply to ID jd98ykk):\n👆\n\n## Comment ID jd87qey with +7 score by [(Yoruichi90, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd87qey/) (in reply to ID 11yjtyo):\nCreate a show: \n\n* Can't choose show intro movie nor music so it will always use the defaults (SD for intro and Sports 3 music).\n\nMyRise: \n\n* Had to literally wipe a save due to a gamebreaking bug. It wouldn't load the story any further and instead returned to the main menu of the game. For me it happened during a 24/7 story arc and I've seen other people reporting same issue at other points of the story.\n\n* Lip sync needs a fix if possible. It's way out of sync with audio.\n\nCreate an arena: \n\n* Various bugs, including sometimes rope colors showing up as the default white when in fact you have set other colors.\n\n* When choosing Bash at the Beach stage design you cannot add images on the \"side tron\" like you could in 22. This doesn't bother me much however as it can now play actual titantron videos.\n\nImages: \n\n* Weird behavior sometimes such as image being different size than it originally should be when you first pick one from the menus and later on you notice they've been automatically resized and that may break your designs. Noticed this when creating my WCW Bash at the Beach arena.\n\n### Comment ID jd9ldkz with +3 score by [(Rainmaker9m, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9ldkz/) (in reply to ID jd87qey):\nI am having all of these problems. In CAA, I'm having the white rope bug (or sometimes, the color of whatever the last arena I was working on had). I've also noticed that no matter what the lighting settings are, either on the lighting and movies menu or visual conditions, there are red and yellow lights behind the crowd in Small Studio cranked to 100% brightness. I also for some reason have the scoreboard from Indoor Sports Arena and Thunderdome hanging above the ring in Classic Indoor Sports Arena (which may be intentional, but what a bizarre addition to suddenly make after 8-9 years of these same fucking venues)\n\n## Comment ID jd8klbj with +6 score by [(Antique_Shower_3251, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8klbj/) (in reply to ID 11yjtyo):\nFor me it says Roman has the divas championship ?\n\n### Comment ID ji5ohs8 with +1 score by [(Money_thetruth, Reddit, 2023-04-29)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/ji5ohs8/) (in reply to ID jd8klbj):\nNothing wrong here. Roman wants to be the wwe undisputed world gender champion.\n\n## Comment ID jd8muy6 with +6 score by [(UnderstandingNo4867, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8muy6/) (in reply to ID 11yjtyo):\nFor the managers, a small desperate workaround to get them to show up properly is to make sure both sides have the same number of managers. So yea, if you want to have the faction leader and his 2 allies by his side vs one single guy, you can't, you'd need to give the 2nd guy 2 managers as well.\n\nThis doesn't fix the trio entrance issues though, sometimes with certain factions and wrestlers you might get the referee showing up instead of one of the members, and you still cannot customize trio entrances, so that sucks a lot.\n\n## Comment ID jd95zg7 with +6 score by [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd95zg7/) (in reply to ID 11yjtyo):\nNo ref in CAA\n\n## Comment ID jd97zm5 with +5 score by [(LightningV1, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd97zm5/) (in reply to ID 11yjtyo):\nMyGM:\n\nIf there is more than 1 human player, the person is in the 1st slot will always be awarded the Hall of Fame trophy at the end of the season for winning, even if they didn’t win.\n\nThey also only receive power cards used against them by the CPU while the second slot won’t face that.\n\n## Comment ID jd9mvc0 with +5 score by [(harrier1215, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9mvc0/) (in reply to ID 11yjtyo):\nWhy does it need to be copyrighted to the point of not letting you use it how you want if you are playing offline?!?!?!? That makes zero fucking sense.\n\n### Comment ID jd9of3p with +5 score by [(Cautious-Building-14, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9of3p/) (in reply to ID jd9mvc0):\nIt’s not 2k’s fault, WWE just doesn’t have the right to the song. It’s Cody’s Song so I’m sure they will work it out because Downstrait wants to help fix it \n\nBut I get it, it’s not ideal for this to be the case though\n\n## Comment ID jd7wjew with +3 score by [(JavaTehHut, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd7wjew/) (in reply to ID 11yjtyo):\nWDYM by “showcase MyFaction trophies”?\n\n### Comment ID jd7wq0z with +3 score by [(Cautious-Building-14, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd7wq0z/) (in reply to ID jd7wjew):\nIt’s a issue where some people are having their progress whipped away, but the trophies they earned will still be there. \n\nAs in they completed the entire John Cena showcase got all the trophies but then they lose all the in game progress.\n\n#### Comment ID jd800bn with +2 score by [(JonnyFour, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd800bn/) (in reply to ID jd7wq0z):\nI've had issues with this whereby I've done a couple of Showcase matches and then found the progress is gone when the game restarts. I initially had an issue with saved data being in the cloud and locally on the Xbox - I'm not sure if that was causing an issue between progess saves\n\n## Comment ID jd81nbz with +3 score by [(PingusDeathMachine, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd81nbz/) (in reply to ID 11yjtyo):\nCan you explain the universe issues a bit more please?\n\n### Comment ID jd823eq with +9 score by [(Cautious-Building-14, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd823eq/) (in reply to ID jd81nbz):\nIf you are using a custom moveset and you get into a rivalry match. The game will not use that moveset. You will use the in game default moveset. \n\nIt’s a issue with creating a faction (3 ppl) where the ref either comes out, the person is in the wrong team, or you can’t even edit the entrance at all. \n\nIt’s a issue with some for Roman reigns to come out with Paul Heyman. \n\nAlso create a arena in UM mode, you’ll have no referee in the match\n\n#### Comment ID jd82b8r with +2 score by [(PingusDeathMachine, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd82b8r/) (in reply to ID jd823eq):\nOk thanks. Hopefully its fixed soon\n\n## Comment ID jd8ea3f with +3 score by [(Direct_Swan2312, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8ea3f/) (in reply to ID 11yjtyo):\nThere seems to be a bug where searching or downloading (not sure which) anything from CC will cause the refs to disappear in custom shows.\n\nI found a workaround for exhibition but not sure if it works in Universe Mode. After exiting CC, go to shows, swap the ref selected for your show with another. (IE old school 1 with old school 2) After that re-select the original ref, then save again. It should work. Yes it is definitely a pain but it works. \n\nI'm at work at the moment but could someone tell me if this method works in Universe? Much appreciated.\n\n## Comment ID jd8ydo9 with +3 score by [(Regents-k-i-d26, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8ydo9/) (in reply to ID 11yjtyo):\nI’m on season 2 of MyGM and and for some reason on week 1 when I simulate to NXT match week the game just closes. When I load the GM save I simulate my week, RAW week and then NXT boom closes. Can’t get past it at all.\n\n### Comment ID jd94gfq with +1 score by [(csward53, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd94gfq/) (in reply to ID jd8ydo9):\nI haven't experienced that bug yet this year, but random crashes in MyGM were a big problem last year. To the point of making it unplayable. I could never figure out what caused it, just that it occured when beginning a sim in a PPV (PLE) week or at the end of a PPV week, usually. You may have to start over :/.\n\n#### Comment ID jd9655j with +1 score by [(Regents-k-i-d26, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9655j/) (in reply to ID jd94gfq):\nWhat a pain.. was recording it for a YouTube series and starting over as soon as you get to the second season is so frustrating.\n\n## Comment ID jd8gzqi with +5 score by [(ThisizLeon, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8gzqi/) (in reply to ID 11yjtyo):\nWhat is it with these games and game runing glitches. It feels like every year it never gets better. I used to buy every WWE game at launch since WWF No Mercy. That stopped after WWE 2K19.\n\nI'd rather wait for a price drop, some patches and an insane amount of CC available to download.\n\n## Comment ID jd8yr5c with +2 score by [(AreolaConnoisseur, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8yr5c/) (in reply to ID 11yjtyo):\nI don’t know if this has happened to anyone else but on tag matches I can only do the tag team finisher once, After that no matter how many finishers I have stored I won’t be able to get the prompt for a finisher. Really annoying specially after last year the tag team finishers never worked.\n\n## Comment ID jd91jsw with +2 score by [(Fazcoasters, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd91jsw/) (in reply to ID 11yjtyo):\nHopefully a patch comes out soon, we're approaching the one week mark for release, over a week for pre-orders\n\n## Comment ID jd96x3o with +2 score by [(TheMatfitz, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd96x3o/) (in reply to ID 11yjtyo):\nJust accessing CC has been an absolute nightmare for me, constant hanging and freezing and having to restart.\n\n## Comment ID jd9ywue with +2 score by [(BloodstoneWarrior, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9ywue/) (in reply to ID 11yjtyo):\nThe 90s and Bad VHS filters are also broken and show a buggy box effect on the screen and a bunch of lines on top of the actual effect. Turnbuckle logos in Create an Arena don't work and he ECW stage design disappears when you try and get rid of the green stuff ( fine in game)\n\n## Comment ID jfraql2 with +2 score by [(Competitive-Ad2334, Reddit, 2023-04-10)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jfraql2/) (in reply to ID 11yjtyo):\nIs there a way to reset Cody so his music comes back in Universe? I changed his alt attire back to default but it's not there still.\n\n### Comment ID jfrfjoe with +2 score by [(Cautious-Building-14, Reddit, 2023-04-10)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jfrfjoe/) (in reply to ID jfraql2):\nNot that I know of for WWE 2k23. Maybe if you hit revert on his entrance and custom victory it might come back\n\n## Comment ID jd8t1ba with +2 score by [(Expert-Singer4926, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8t1ba/) (in reply to ID 11yjtyo):\n- trophies aren’t unlocking. \n\n- create an arena is bugged to hell\n\n-  day, evening, night option is useless\n\n- game crashes almost as often as 2k20\n\n## Comment ID jd8x6wd with +1 score by [(Luis_Swagcia, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd8x6wd/) (in reply to ID 11yjtyo):\nNot sure if its a bug or anything but online entrances are disabled for anything that isn't 1v1, triple threat, or Royale Rumble. As someone who plays online with friends mostly this is very irritating\n\n## Comment ID jd9gf2o with +1 score by [(keijo02, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9gf2o/) (in reply to ID 11yjtyo):\nHow do you backup your save ? And can you backup downloaded content from cc ?\n\n## Comment ID jd9mept with +1 score by [(berick5, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9mept/) (in reply to ID 11yjtyo):\nIn Universe mode some of the matches on the match card disappear, when that happens one or 2 matches you play the pins and submissions are automatically turned off and you are unable to exit the ring. There is no way to win or lose\n\n## Comment ID jd9ofk5 with +1 score by [(SnowdriftK9, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9ofk5/) (in reply to ID 11yjtyo):\nI can kinda understand the copyright thing but I don't understand not being able to use their music for menus and stuff.\n\n## Comment ID jd9pgy8 with +1 score by [(35antonio, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9pgy8/) (in reply to ID 11yjtyo):\nMore for Universe\n\nThe game only let's you book custom 1 on 1 matches.\n\nEditing an entrance or Victory in Create an Entrance/Victory doesn't save to your Universe slot (actually it doesn't even ask you where to save it)\n\nWrestlers sometimes become invisible in cutscenes if they're using an alt\n\nDon't know if it's intentional or not but stipulation matches will revert to a regular match if you assign a cutscene. Doesn't matter if it's just a no DQ match or other smaller stipulations\n\nGame doesn't register the referees you pick. It ends up being the Angelo Dawkins lookalike.\n\n## Comment ID jd9unh3 with +1 score by [(WeaselWeaz, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jd9unh3/) (in reply to ID 11yjtyo):\nIs there a list of edits to make to superstars? Something like changing Dominick's enterance is obvious, but it looks like 2K mixed up the nWo and Outsider attires for Hall and Nash.\n\n## Comment ID jdadnbr with +1 score by [(None, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdadnbr/) (in reply to ID 11yjtyo):\nI just need help with showcase 😂 at the undertaker match and sucking\n\n## Comment ID jdaeftk with +1 score by [(Dragon_Knight1999, Reddit, 2023-03-22)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdaeftk/) (in reply to ID 11yjtyo):\nIve come across a bug in my universe mode where I saved and left a show midway through due to needing to go to work but when I return to out the following day, all the scheduled title matches were no longer for the title and were just plain old regular matches\n\n## Comment ID jdakv0a with +1 score by [(BkJayDee, Reddit, 2023-03-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdakv0a/) (in reply to ID 11yjtyo):\nI knew something was up. I’m big on having pyro in my entrances. I have the Goldberg entrance and I added pyro to the timeline section of ring and in the preview I can see it but for an actual match I don’t see it.\n\n## Comment ID jdbsdnb with +1 score by [(FireBlaze1, Reddit, 2023-03-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdbsdnb/) (in reply to ID 11yjtyo):\nWhen I make my arena, no matter where I put my titantron and save, the next time it loads up, the titantron has been moved upwards. Was that the default? I don't know, all I know is now my dudes are entering and the only trons they got are the wall ones!\n\n## Comment ID jdc8xyb with +1 score by [(dev-olution, Reddit, 2023-03-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jdc8xyb/) (in reply to ID 11yjtyo):\nHas any online game over 4 players been fixed yet? THAT was my biggest issue.\n\n## Comment ID ji7wqsp with +1 score by [(Mona_Payne, Reddit, 2023-04-29)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/ji7wqsp/) (in reply to ID 11yjtyo):\nI'm not an avid wrestling fan but got 2k23, does anyone know how the balancing sliders work? I keep getting stunned and it takes 20 minutes to stop being stunned, I'm sure the balancing sliders can help with this but there is no explanation as to how they work or what they do.\n\nAlso how do tag team matches work? I'm on universe atm and it says I can control the other dude but apparently I cant, only sometimes I can randomly it seems very inconsistent. There's no explanation as to why I'm switching characters and how to switch back. I dont want to play as this slow fat ass with crappy moves I made a custom wrestler for a reason\n\n## Comment ID jibdfvi with +1 score by [(Mona_Payne, Reddit, 2023-04-30)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jibdfvi/) (in reply to ID 11yjtyo):\nDoes anyone know how to intergrate a custom character naturally into universe mode?  I just want my custom dude to be a part of the universe naturally without having to remove another wrestler and replace him with my dude every time, it feels unimersive\n\n### Comment ID jibesmg with +3 score by [(Cautious-Building-14, Reddit, 2023-04-30)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jibesmg/) (in reply to ID jibdfvi):\nYou just add him to the roster in universe mode you don’t have to take anyone out if you don’t want to. It’s no limits to the rosters and how big you want them. Just has to be Atleast 10 ppl on the roster. \n\nYou can also do superstar mode if you only care about being yourself \n\nBut in classic mode you just go to the show and then the roster and add yourself\n\n#### Comment ID jibhnkr with +1 score by [(Mona_Payne, Reddit, 2023-04-30)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jibhnkr/) (in reply to ID jibesmg):\nCheers for the reply, I like superstar mode alot but it's missing the sandboxiness of classic mode but I guess i just wanna have my cake and eat it too. I've tried adding my dude the way you said, it says he's \"selected\" but he never actually appears on the card unless i replace another wrestler with him manually each card. I haven't played a wrestling game since 2010 and I'm not an avid wrestling fan in general so I'm not sure if what I'm saying even makes sence or if I'm just being an idiot (most likely scenario). I just want my dude to be included in the RAW fight cards like the other wrestlers. He's set to RAW btw. Thanks for the help bro\n\n## Comment ID jibwyh2 with +1 score by [(Mona_Payne, Reddit, 2023-04-30)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jibwyh2/) (in reply to ID 11yjtyo):\nDoes anyone know how to delete custom made tag teams from superstar mode? The game kept teaming me up with logan Paul against 2 clowns dressed in baseball outfits so I figured I'd make an official tag team with Logan.. well the game put me in 12 matches in a row with these clowns and I'm sick to death of fighting the same people and I'm sick of seeing Logans yellow trousers and headband.\n\nAlso why the hell is Logan Paul in this game?\n\n### Comment ID jic8cfs with +2 score by [(Cautious-Building-14, Reddit, 2023-04-30)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jic8cfs/) (in reply to ID jibwyh2):\nSwitch back to classic mode delete the team the go back\n\n## Comment ID jinjkyr with +1 score by [(Mona_Payne, Reddit, 2023-05-03)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jinjkyr/) (in reply to ID 11yjtyo):\nI have a question regarding the Lock campaign.\n\nDo the choices really matter? \n\nMy guy seems to be a whiney little asshole and im wondering if that's my fault for picking certain choices. I was kinda hoping he was gonna get kicked in the face tbh.\n\nI wont say too much incase of spoilers but my guy just had a full blown Anthony Joshua style meltdown, pushed a man over and majorly pissed off the top brass, Is this avoidable?\n\n## Comment ID jp7ubi8 with +1 score by [(Such_Friendship_5775, Reddit, 2023-06-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jp7ubi8/) (in reply to ID 11yjtyo):\nI recently bought the game 2k23 and I realised that they haven’t updated the game with the people who have the titles now like the tag team champs they are Sami and Kevin but in the game it’s jey and Jimmy has it not updated yet or do they not update it and wait until the next game to change it?\n\n### Comment ID jp7v0or with +1 score by [(Cautious-Building-14, Reddit, 2023-06-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jp7v0or/) (in reply to ID jp7ubi8):\nThat part of the game doesn’t update, it will be on you to update the champions for your universe mode or play now mode to reflect who you want to have what title. Sorry if that comes out as a bummer but it’s that way because some people don’t use the current set up and prefer the older one so it’s all about what you want your mode to be\n\nSo 2k never updates that stuff until the next game\n\n#### Comment ID jp7v5nd with +1 score by [(Such_Friendship_5775, Reddit, 2023-06-23)](https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/jp7v5nd/) (in reply to ID jp7v0or):\nOk thanks for letting me know have a good day"
    ],
    "sources": {
      "steam_url": null,
      "steam_reviews": null,
      "google_play_url": null,
      "google_play_reviews": null,
      "apple_store_url": null,
      "apple_reviews": null,
      "reddit_urls": [
        "https://www.reddit.com/r/movies/comments/1g8uzk5/first_images_from_love_hurts_key_huy_quan_stars/",
        "https://www.reddit.com/r/futurama/comments/9uulai/nixon_is_in_my_head_tonight/",
        "https://www.reddit.com/r/estimators/comments/14dx53r/any_of_you_think_ai_is_going_to_takeover_the/",
        "https://www.reddit.com/r/ycombinator/comments/1d7bqx2/how_does_one_simply_raise_50k_in_this_current_vc/",
        "https://www.reddit.com/r/estimators/comments/1067xq1/automation_and_its_effect/",
        "https://www.reddit.com/r/estimators/comments/16m4d46/any_known_aitools_for_estimating/",
        "https://www.reddit.com/r/estimators/comments/t9hrql/is_it_time_to_replace_planswift_what_has_your/",
        "https://www.reddit.com/r/adjusters/comments/15tpp7l/roof_data_into_xactimate/",
        "https://www.reddit.com/r/ChatGPT/comments/1auh7ja/is_chatgpt_premium_worth_it/",
        "https://www.reddit.com/r/WWEGames/comments/11yjtyo/wwe_2k23_tips_awareness_thread/"
      ],
      "reddit_search_url": "https://www.google.com/search?q=site%3Areddit.com+%22Gable%22+related%3Agable.ai+data"
    }
  },
  "glassdoor_result": null,
  "news_result": [
    [
      "Gable",
      "Gable",
      "gable.ai",
      [
        "data"
      ]
    ],
    [
      {
        "title": "Seattle startup Gable raising another round to help developers and ...",
        "link": "https://www.geekwire.com/2024/seattle-startup-gable-raising-another-round-to-help-developers-and-data-teams-work-together/",
        "snippet": "Jul 31, 2024 ... From left: Gable.ai co-founders Adrian Kreuziger (CTO), Chad Sanderson (CEO) and Daniel Dicker (Founding Engineer). Gable, a Seattle startup building.",
        "formattedUrl": "https://www.geekwire.com/.../seattle-startup-gable-raising-another-round-to..."
      },
      {
        "title": "Gable Blog - Top 5 Data Lineage Tools (+ How to Choose)",
        "link": "https://www.gable.ai/blog/data-lineage-tools",
        "snippet": "Oct 28, 2024 ... Data lineage tools: 5 worth considering · Gable.ai · Alation · Secoda · Collibra · Dbt (data build tool).",
        "formattedUrl": "https://www.gable.ai/blog/data-lineage-tools"
      },
      {
        "title": "Olympic champion wrestler Gable Steveson ends retirement, returns ...",
        "link": "https://apnews.com/article/gable-steveson-wrestling-minnesota-return-78e2e0e93e510578c2686eb4066562e4",
        "snippet": "Nov 12, 2024 ... Wrestler Gable Steveson, who won a gold medal at the Tokyo Olympics in 2021 ... The Associated Press is an independent global news organization dedicated to ...",
        "formattedUrl": "https://apnews.com/.../gable-steveson-wrestling-minnesota-return-78e2e0e9..."
      },
      {
        "title": "Gable Blog - 8 Common Data Engineering Best Practices",
        "link": "https://www.gable.ai/blog/data-engineering-best-practices",
        "snippet": "Jun 3, 2024 ... The good news? Getting started is easier than you might think. Learn more by signing up for our product waitlist at Gable.ai. Share this Post. Copy Link ...",
        "formattedUrl": "https://www.gable.ai/blog/data-engineering-best-practices"
      },
      {
        "title": "Staff Software Engineer - Data - Gable.ai | Built In Seattle",
        "link": "https://www.builtinseattle.com/job/staff-software-engineer-data/93730",
        "snippet": "Jul 17, 2024 ... Gable.ai is hiring for a Staff Software Engineer - Data in Seattle, WA, USA. Find more details about the job and how to apply at Built In Seattle.",
        "formattedUrl": "https://www.builtinseattle.com/job/staff-software-engineer-data/93730"
      },
      {
        "title": "Gable - Crunchbase Company Profile & Funding",
        "link": "https://www.crunchbase.com/organization/gable-f237",
        "snippet": "Jul 26, 2024 ... support@gable.ai; Phone Number (678) 446-2705. Gable is a B2B data infrastructure SaaS that offers a platform for collaboration to write and execute data ...",
        "formattedUrl": "https://www.crunchbase.com/organization/gable-f237"
      },
      {
        "title": "Cameron J. Gable | Lawyers | Jones Day",
        "link": "https://www.jonesday.com/en/lawyers/g/cameron-gable",
        "snippet": "Sep 24, 2024 ... Cameron Gable is a regulatory lawyer who counsels and represents clients in international trade, foreign investment, national security, environmental, energy,",
        "formattedUrl": "https://www.jonesday.com/en/lawyers/g/cameron-gable"
      },
      {
        "title": "ELI GABLE (@eli_gable_music) • Instagram photos and videos",
        "link": "https://www.instagram.com/eli_gable_music/",
        "snippet": "2 days ago ... 13K Followers, 1581 Following, 211 Posts - ELI GABLE (@eli_gable_music) on Instagram: \"Live every week like it's shark week Management: @3strandsmanagement ...",
        "formattedUrl": "https://www.instagram.com/eli_gable_music/"
      },
      {
        "title": "Goodman-Gable-Gould/Adjusters International - National ...",
        "link": "https://www.napia.com/find-a-public-adjuster/goodman-gable-gould-adjusters-international",
        "snippet": "Sep 19, 2024 ... Related Members. View Profile. Alex Goodman. View Profile. Andrew Macleay. View ... Goodman-Gable-Gould Company/AI ...",
        "formattedUrl": "https://www.napia.com/find.../goodman-gable-gould-adjusters-international"
      },
      {
        "title": "Susanna Gable | Bill & Melinda Gates Foundation",
        "link": "https://www.gatesfoundation.org/about/leadership/susanna-gable",
        "snippet": "Jan 31, 2024 ... Susanna Gable oversees international development finance efforts for the ... Read the latest stories, research, and news from across the foundation and subscribe ...",
        "formattedUrl": "https://www.gatesfoundation.org/about/leadership/susanna-gable"
      },
      {
        "title": "Cookie Policy | Goodman Gable Gould/Adjusters International",
        "link": "https://www.ggg-ai.com/cookie-policy/",
        "snippet": "Mar 8, 2024 ... Therefore, if the User chooses to block the use of Trackers, the Owner may be unable to provide related features. Owner and Data Controller. Goodman-Gable-Gould ...",
        "formattedUrl": "https://www.ggg-ai.com/cookie-policy/"
      },
      {
        "title": "CIRO Sanctions Donald Gable | Canadian Investment Regulatory ...",
        "link": "https://www.ciro.ca/news-room/publications/ciro-sanctions-donald-gable",
        "snippet": "Jan 29, 2024 ... ... Gable. Donald Gable admitted to the following violation(s):. engaged in securities related business that was not carried on for the account of the Dealer ...",
        "formattedUrl": "https://www.ciro.ca/news-room/publications/ciro-sanctions-donald-gable"
      },
      {
        "title": "Maldon High Street retirement flats' gable end collapses",
        "link": "https://www.bbc.com/news/articles/c0mz7e37xppo",
        "snippet": "Nov 24, 2024 ... A High Street was closed and residents evacuated after the gable end of a complex of retirement flats collapsed.",
        "formattedUrl": "https://www.bbc.com/news/articles/c0mz7e37xppo"
      },
      {
        "title": "Privacy Policy | Goodman Gable Gould/Adjusters International",
        "link": "https://www.ggg-ai.com/privacy-policy/",
        "snippet": "Mar 8, 2024 ... Goodman-Gable-Gould/Adjusters International 10110 Molecular Drive, Suite 300. Rockville, Maryland 20850. Owner contact email: info@gggai.com. Full policy. Owner ...",
        "formattedUrl": "https://www.ggg-ai.com/privacy-policy/"
      },
      {
        "title": "Lorri A Gable – BG Independent News",
        "link": "https://bgindependentmedia.org/lorri-a-gable/",
        "snippet": "Oct 10, 2024 ... Lorri Ann Gable, 65, of Cygnet, Ohio passed away at home on Wednesday October 9, 2024, surrounded by her loving family.",
        "formattedUrl": "https://bgindependentmedia.org/lorri-a-gable/"
      },
      {
        "title": "GABLE delivers all-time high income, ready to propel businesses ...",
        "link": "https://www.g-able.com/insights/g-able-enable-the-future",
        "snippet": "Feb 27, 2024 ... ... AI-ready data and AI-ready security, as higher demands for AI and cybersecurity will boost GABLE's growth. To expand the Group's capabilities through ...",
        "formattedUrl": "https://www.g-able.com/insights/g-able-enable-the-future"
      },
      {
        "title": "Ellen A. Adams - GableGotwals",
        "link": "https://www.gablelaw.com/attorneys/ellen-a-adams/",
        "snippet": "Apr 29, 2024 ... Ellen Adams is a shareholder at GableGotwals and Co-Chairs the Firm's Employment and Labor Practice Group. She enjoys counseling and advising clients.",
        "formattedUrl": "https://www.gablelaw.com/attorneys/ellen-a-adams/"
      },
      {
        "title": "Health Alerts – Albright College",
        "link": "https://www.albright.edu/health-alerts/",
        "snippet": "Sep 16, 2024 ... The Gable Health Center is well stocked to provide COVID-19 testing, free of charge. CDC Isolation Guidelines. Isolation guidelines have not changed since last ...",
        "formattedUrl": "https://www.albright.edu/health-alerts/"
      },
      {
        "title": "Gable Collings",
        "link": "https://www.facebook.com/gable.collings.9/",
        "snippet": "Feb 10, 2024 ... Gable Collings. 51 likes · 62 talking about this. I help busy people reach their goals and reclaim their energy with practical astrological coaching.",
        "formattedUrl": "https://www.facebook.com/gable.collings.9/"
      },
      {
        "title": "Top Envoy Alternatives: Why Gable Is the Best Choice for Hybrid ...",
        "link": "https://www.gable.to/blog/post/envoy-alternatives",
        "snippet": "Oct 7, 2024 ... Gable is a workspace management platform for hybrid and remote teams. Gable's HQ solution lets companies manage their leased offices, enable easy desk and room ...",
        "formattedUrl": "https://www.gable.to/blog/post/envoy-alternatives"
      }
    ],
    [
      "# [Top 5 Data Lineage Tools (+ How to Choose)](https://www.gable.ai/blog/data-lineage-tools)\nThe good news is that business leaders and stakeholders are increasingly seeing the value of data lineage in their organizations. The even better news is that the data lineage tool market offers more options for data teams every year.\n\nAs a whole, the global data catalog market is projected to grow from $878.8 million in 2023 to $4,680.9 million by 2032, with a compound annual growth rate (CAGR) of 17.7% during this period. That’s respectable.\n\nSo, as more data teams enter the market for lineage tools, it’s important to distinguish the apples from the oranges. Much like data lineage itself, knowledge is power when it comes to vetting potential lineage tools.\n\nThat's why we’re showcasing five potentially potent tools for data lineage here, noting the pros, cons, and pricing for each.\n\nData lineage tools: 5 worth considering\n\nGable.ai\n\nGable is a pioneering data contracts platform that's proactively bridging the gap between data producers and consumers. It focuses on proactive data quality management (i.e., shifting data quality left) by implementing data contracts early in the data lifecycle. In doing so, Gable allows teams to draft, define, and enforce data contracts, providing a collaborative environment for software developers, data engineers, and data scientists.\n\nWhile not a traditional data lineage tool, Gable's approach to data contracts offers a unique perspective on lineage. By defining and versioning data contracts, it provides visibility into data origins, transformations, and dependencies, effectively creating a proactive form of lineage tracking that starts at the source of data creation.\n\nPros:\n\nOffers a highly proactive approach to data quality\n\nUniquely able to integrate directly into development workflows\n\nCan also reduce costs and wasted effort by maintaining data integrity early in the process\n\nCons:\n\nAs a relative newcomer, Gable.ai may present a bit of a learning curve compared to other tools listed\n\nPricing: Interested parties should sign up to Gable’s product waitlist to learn more as details become available.\n\nAlation\n\nAlation is a comprehensive data intelligence platform that offers robust data lineage capabilities. It provides automatic table and column-level lineage, along with business lineage featuring metadata overlays. Alation's strength as a lineage tool lies in its advanced visualization capabilities—including end-to-end mini-map previews and data flow filtering.\n\nTogether, these features allow users to trace data from its origin through various transformations to its final use, providing crucial insights for data governance, impact analysis, and regulatory compliance. Alation's lineage capabilities are especially valuable for organizations dealing with complex data ecosystems, as they offer a clear, visual representation of data flows across multiple systems and processes.\n\nPros:\n\nA comprehensive data intelligence solution\n\nOffers advanced visualization capabilities\n\nIntegrates with many data sources\n\nCons:\n\nCan be complex to implement and use\n\nMay also be overkill for organizations with simpler needs\n\n‍\n\nPricing: Alation doesn't publicly disclose pricing. Those interested need to contact sales for a custom quote.\n\nSecoda\n\nSecoda bills itself as a data discovery and documentation platform that emphasizes user-friendliness and automation in its data lineage features. It offers automated data lineage capture and visualization, integrating with a variety of data sources and tools to provide a comprehensive view of data flows.\n\nAs a lineage tool, Secoda stands out for its ability to automatically generate and maintain up-to-date lineage information with a minimal amount of manual input. Its column-level lineage capabilities allow for granular tracking of data transformations, making it easier for organizations to understand data dependencies, troubleshoot issues, and assess the impact of changes across their data ecosystem.\n\nPros:\n\nProvides a user-friendly interface\n\nOffers strong integration capabilities\n\nLineage capture can be automated\n\nCons:\n\nAdvanced features may necessitate a learning curve for some\n\nLike Gable.ai, Scoda is a relatively new player in the market\n\nPricing: At this time Secoda doesn't publicly share pricing information. Curious parties will need to contact sales for a quote.\n\nCollibra\n\nCollibra is a solid data intelligence platform offering a suite of tools for data governance, cataloging, and lineage. Its data lineage capabilities, specifically, provide end-to-end lineage mapping with technical lineage at table, column, and transformation levels.\n\nViewed solely as a lineage tool, Collibra provides data teams with a comprehensive view of data flows across an organization. Its interactive lineage diagrams offer intuitive visual representations of complex data relationships, enabling users to easily trace data origins, understand transformations, and assess the impact of changes.\n\nThis makes Collibra particularly valuable for organizations that need to prioritize data governance, regulatory compliance, and maintain an in-depth understanding of their data landscape.\n\nPros:\n\nViewed as a comprehensive data governance solution\n\nOffers strong data lineage visualization capabilities\n\nVery robust metadata management\n\nCons:\n\nCan be expensive for smaller organizations\n\nComes with a comparatively complex implementation process\n\nPricing: Collibra offers yearly licensing subscriptions:\n\n12-month plan: $170,000\n\n24-month plan: $340,000\n\n36-month plan: $510,000\n\nDbt (data build tool)\n\nKnown primarily as a data transformation tool, dbt does data lineage capabilities. However, said capabilities are more limited compared to other tools featured above. It provides table-level lineage within dbt projects, with column-level lineage available in the dbt Cloud Enterprise tier.\n\nTherefore, when viewed as a potential lineage tool, dbt's strength lies in its native integration with data transformation processes.\n\nDbt does visualize dependencies between models, which helps data teams understand how changes in one part of a data pipeline might affect others.\n\nIts lineage features are more focused on assets managed within dbt projects—making this integration of particular value for organizations already using dbt, as it provides immediate insights into the lineage of transformed data without the need for additional tools.\n\nPros:\n\nNative integration with data transformation processes\n\nOpen-source core with active community\n\nVisualizes dependencies between models\n\nCons:\n\nLimited to dbt-managed assets\n\nFull column-level lineage only available in its Enterprise tier\n\nPricing: dbt offers three subscription tiers:\n\nCore: Free and open-source\n\nCloud Team: Starts at $50 per user per month\n\nCloud Enterprise: Custom pricing, make inquiries to dbt’s sales team\n\nWhy are data lineage tools important?\n\nAs a refresher, know that data lineage tools should increasingly be seen as table-stakes for modern organizations to establish (and reap the multitude of rewards from) robust data governance and management practices.\n\nIt’s these tools that provide the features and functionality that make fostering and maintaining pristine data quality possible.\n\nEnhanced data transparency and visibility\n\nData lineage tools provide a clear and real-time view of how data flows across an organization, enabling stakeholders to gain deeper insights into data usage, dependencies, and transformations.\n\nOft-overlooked, this transparency also contributes to a culture of impactful data-driven decision-making.\n\nImproved data quality and accuracy\n\nAutomated data lineage tools help identify data quality issues by highlighting anomalies, transformations, and potential errors in the lineage. This early detection allows data teams, stewards, and scientists to address issues promptly, ensuring data remains accurate and reliable.\n\nEfficient compliance and auditing\n\nData lineage is essential for regulatory compliance, especially in industries with strict and/or complex data regulations. These tools provide an audit trail demonstrating how data is used and processed, facilitating compliance reporting and audits.\n\nStreamlined data governance\n\nData lineage simplifies data governance by providing a clear understanding of data assets, their ownership, and the impact of made changes. As a result, lineage tools make it easier to enforce data policies and maintain optimal data quality.\n\nFaster troubleshooting and issue resolution\n\nWhen data issues arise, lineage tools enable faster troubleshooting by allowing data professionals to trace problems back to their source, identify root causes, and implement solutions as quickly as possible.\n\nEnhanced data security\n\nData lineage helps organizations identify vulnerabilities in their data pipelines and access controls, allowing for the implementation of robust security measures to safeguard sensitive information.\n\nEffective change management\n\nBy visualizing how data flows are impacted by changes, teams can assess potential risks and make informed decisions during system upgrades or process modifications.\n\nSupport for data-driven decision making\n\nData lineage empowers more people (both data professionals and their data-adjacent peers) to understand and leverage data assets, supporting true data democratization and enabling more informed decision-making throughout the organization.\n\nOperational efficiency\n\nBy automating data mapping and reducing the need for manual impact analysis, data lineage tools can save significant time and resources, enhancing overall operational efficiency.\n\nRisk management\n\nData lineage manages risks associated with data usage, transformations, and access by providing a comprehensive view of data flow and dependencies.\n\nHow to choose the right data lineage tool\n\nSituations, organizational needs, technical capabilities, and lineage tools themselves are all always in flux—so there will never be a one “best” way to go about choosing the right data lineage tool.\n\nThat said, by carefully considering the following factors and aligning them with your organization's specific requirements, you can streamline to process of learning about and comparing tools, ensuring the chosen tool provides the most value and the best fit possible:\n\nDetermine scope and depth of lineage tracking: Look for tools that provide comprehensive lineage at multiple levels—table, column, and row-level lineage. Ensure the tool captures lineage across your entire data ecosystem, not just from limited sources like BI tools.\n\nReview integration capabilities: The tool should integrate well with your existing data stack, including data warehouses, ETL/ELT tools, BI platforms, etc. Check the depth of integrations—some tools may claim to integrate with a platform but only offer surface-level connectivity.\n\nCompare visualization and analysis features: Clear, intuitive visualizations of data lineage are crucial for understanding complex data flows. Look for capabilities like impact analysis, data flow mapping, and the ability to trace data upstream and downstream.\n\nDetermine if automation and metadata collection is necessary: Automated lineage capture reduces manual effort and improves accuracy. The tool should be able to automatically collect and update metadata as your data environment changes.\n\nVet each tool’s ability to scale: Ensure the tool can handle your current data volume and complexity, as well as scale as your data ecosystem grows.\n\nConsider usability and accessibility: The tool should be user-friendly for both technical and non-technical team members. Features like search functionality and collaborative capabilities are valuable.\n\nInquire about compliance and governance support: If regulatory compliance is a concern, look for tools that offer features to support data governance and compliance efforts.\n\nAsses potential performance impact: Consider how the lineage tool might affect the performance of your data systems, especially for large-scale implementations.\n\nWeigh cost against potential ROI: Evaluate the pricing model and ensure it aligns with your budget and expected value from implementing data lineage.\n\nPrioritize future-proofing: Choose a tool that can adapt to evolving data architectures and technologies.\n\nGet a sense of each tool’s support and community: Consider the level of support provided by the vendor and the existence of an active user community for knowledge sharing.\n\nDetermine if complementary features are available: Some tools offer additional features like data quality monitoring or data cataloging that may provide added value.\n\nLooking to shift your lineage left?\n\nAgain, the right data lineage tools can dramatically enhance data governance, transparency, and quality within your organization. But it should now be crystal clear that choosing the right solution is crucial. Whether you're looking to streamline compliance, ensure data accuracy, or improve decision-making, having the right tool in your data stack is non-negotiable.\n\nGable.ai goes beyond traditional lineage solutions by introducing proactive data contracts, which tackle data quality at the source. By implementing Gable.ai's innovative approach, you’ll be setting your team up for long-term success, maintaining data integrity, and reducing costly errors early in the process.\n\nTo learn more about how Gable.ai can empower your organization with next-level data contracts and improve your overall data management strategy, sign up for our product waitlist today.\n\n‍",
      "# [Olympic champion wrestler Gable Steveson ends retirement, returns to University of Minnesota by CLIFF BRUNT, pro sports in Oklahoma, including the Thunder, Oklahoma Sooners, Oklahoma State Cowboys, apnews.com, cliff-brunt on 2024-11-12](https://apnews.com/article/gable-steveson-wrestling-minnesota-return-78e2e0e93e510578c2686eb4066562e4)\nGable Steveson, who won a gold medal at the Tokyo Olympics in 2021, said Tuesday he is coming out of retirement and will return to the University of Minnesota for a fifth and final season of college wrestling.\n\nSteveson won gold as a freestyle heavyweight in Tokyo at age 21, then won his second national title at Minnesota in 2022 before retiring.\n\nNow 24, the two-time Hodge Trophy winner as the nation’s top collegiate wrestler returns on a 52-match win streak.\n\n“Minnesota has given me everything, and now it’s my turn to give it right back to them: to put my feet back on the wrestling mat, to be the champ, one more time,” Steveson said in a video announcing his comeback.\n\nSteveson has an extra year of eligibility because of the COVID-19 pandemic. Minnesota said he is expected to make his season debut on Nov. 24 against Campbell.\n\n“Gable has the burning desire to compete for the Maroon and Gold one last time,” Eggum said. “We are thankful he has chosen the opportunity to add to his historic legacy with our program. He is one of the best to ever compete in the sport of wrestling, and we are grateful for the impact has had at our program.”\n\nSteveson tried professional wrestling with World Wrestling Entertainment and performed up mostly in NXT, the company’s developmental brand. After his release this year, he tried out for the NFL’s Buffalo Bills despite never having played organized football. He did not make the roster.",
      "# [8 Common Data Engineering Best Practices](https://www.gable.ai/blog/data-engineering-best-practices)\nWe’re told today’s world is data-driven. It’s hard to disagree. But, sometimes, it’s equally hard to comprehend how critical it is becoming for any given organization to ensure it can seamlessly integrate and manage high-quality data.\n\nFortunately, as the needs of modern organizations have evolved, so too have engineering best practices that encompass a wide array of processes and technologies—from ETL (extract, transform, load) data pipelines, data integration, and continuous integration to the management of big data, data validation, and real-time data processing.\n\nEffective data engineering is now table-stakes—not only supporting the needs of data scientists, analysts, and end users but also ensuring that data sources, whether from data lakes or data warehouses, are efficiently transformed from raw data into high-quality datasets. This transformation is facilitated by rigorous data validation and data quality checks.\n\nWhile these best practices need to be on point virtually all the time, it’s not always possible to keep up. So, increasingly, data contracts are demonstrating how they holistically make best practices even better.\n\nDon’t worry—we’ll explain how. First, let’s agree on exactly which best practices we’re referring to.\n\n8 Common data engineering best practices\n\nIt’s doubtful that any list of best practices—in any industry—is completely comprehensive. But it’s important to ensure said lists cover all common bases.\n\nFor our purposes here, we’ve referenced Joe Reis and Matt Housley’s excellent Fundamentals of Data Engineering to do exactly that. Here are eight data engineering best practices to keep in mind:\n\n1. Establish and maintain business alignment and value focus\n\nInvest in the long-term viability of data engineering in your organization by aligning all projects to business objectives. This ensures data teams can deliver measurable value and that leadership sees how projects contribute to the success of overall strategic goals.\n\n2. Insist on strict adherence to the data engineering lifecycle\n\nWhy wouldn’t a data engineer follow the data engineering lifecycle? Well, some sobering realities of working in enterprise organizations include resource constraints, time pressures, complexities in data environments, and even contradictory cultural norms.\n\nAny number of these factors can make it tempting to skip steps or cut corners. However, decreasing data quality while increasing the chance of breaches and running afoul of compliance regulations can never be justified. It’s also why strict adherence to the entire data engineering lifecycle (e.g., data generation, storage, ingestion, transformation, serving, etc.) forms the cornerstone of any data environment.\n\n3. Embrace data as a product\n\nData engineering teams should build on this cornerstone—encouraging organizations to manage and cultivate data quality with the same care and strategic focus afforded tangible products sold to customers.\n\nThe ensuing shift in the collective perspective of treating data as a product enables data management to shift from a supporting role to that of a central, integral function.\n\n4. Build for scalability and performance\n\nDelivering on the promise of data as a product requires data architecture that can scale up and/or out to handle increased loads as needed. At the same time, performance optimization ensures this operational flexibility occurs efficiently (and smoothly), keeping data consumers and users happy.\n\n5. Prioritize modularity and automation\n\nBy leveraging modular architecture, components can be independently developed, maintained, updated, or replaced. This simplifies maintenance and can mitigate risk, as failures are isolated to individual components.\n\nConversely, automation minimizes the risks of human-introduced errors and frees up valuable bandwidth among engineering team members. Overall, both increase agility and efficiency in data operations.\n\n6. Enable robust security and privacy measures\n\nAs waves of organizations implement digital transformation initiatives, data breaches are surging globally. With data becoming increasingly essential to modern business, data teams must enable and maintain aggressive safety postures to keep bad actors at bay while ensuring regulatory compliance.\n\n7. Foster comprehensive documentation and metadata management\n\nUnderstanding the origin, purpose, and characteristics of data flowing throughout an organization is essential for maintaining data quality over time.\n\nThis understanding, in turn, requires effective documentation and metadata management, which additionally contributes to data governance and compliance efforts.\n\n8. Sanctify data governance practices\n\nFinally, strong data governance practices should be essential, if not sacrosanct. As such, they should include clear and consistent definitions of roles, responsibilities, and data standards.\n\nEffective data governance is crucial for supporting data quality, compliance, and operational efficiency. It ensures data use is ethical, legal, and aligned with regulatory requirements.\n\nHow data contracts are changing the game\n\nData engineering teams must constantly fine-tune the specifics of these best practices to ensure they remain as practical as they are beneficial. This is especially true as data contracts are increasingly adopted and implemented by data-hungry enterprise organizations.\n\nHowever, before understanding how data contracts impact data engineering best practices, it’s essential to know how they function.\n\nData contracts: Common areas of impact\n\nPurpose and scope: At their most basic, data contracts define the purpose for which data is collected, processed, and shared. The established outline prevents data misuse by clearly establishing its scope usage limits.\n\nRoles and responsibilities: Data contracts will also clearly delineate roles and responsibilities between data providers and data producers, users, and any third parties involved in data processes.\n\nData quality and standards: Drafted contracts will specify the quality and format of organizational data, ensuring it will be consistent and usable across all relevant systems.\n\nData governance: Contracts will address all relevant data governance mechanisms—typically including data ownership, retention, and deletion policies.\n\nCompliance and auditing: In addition to collection, processing, and sharing, contracts will also outline how organizational data will remain compliant with relevant regulations—often including auditing rights to enforce compliance.\n\nSecurity and privacy: Data contracts will contain provisions for protecting the confidentiality, integrity, and availability of data, complying with laws such as GDPR, HIPAA, or CCPA.\n\nBreach and dispute resolution: Finally, data contracts increasingly outline provisions for handling breaches of contract, including penalties, dispute resolution mechanisms, and remedies.\n\nLesser-known aspects of data contracts\n\nFluidity: Not all data professionals understand that data contracts are rarely static. Like best practices, they often need to be updated and fine-tuned to meet changing business needs, technologies, and regulatory requirements.\n\nGlobal variations: Additionally, some data professionals underestimate the complexities introduced by international data transfers in increasingly global markets. By extension, these increase the complexity of data contract drafting and enforcement. But, ultimately, said contracts then better support organizations who navigate increasingly complex and nuanced data environments.\n\nTechnological implications: For some use cases, part of the data contract drafting process will outline specific technological requirements—potentially including encryption standards, interoperability protocols, and data formats that may impact existing or future IT systems and processes.\n\nCultural impacts: In some organizations, data contracts influence organizational culture by promoting data-centric approaches, such as treating data as a product. In these cases, data contracts may drive shifts in how teams and departments interface with each other.\n\nCost implications: On paper, complying with the standards and protocols data contracts outline can incur additional costs related to organizational data management. That said, these costs are often offset by enhanced data quality, risk reduction, operational efficiencies, and long-term savings.\n\nPerformance metrics: Data contracts can also incorporate performance metrics and service level agreements (SLAs). By doing so, contracts can help hold parties accountable for maintaining promised levels of service—impacting how data operations are managed and organized.\n\nEthical applications: Finally, contracts increasingly help govern the ethical use of data. For many organizations, this helps guide the governance of sensitive or personal information.\n\nHowever, as AI, large language models, and machine learning evolve into a component of business-as-usual, this specific guidance that data contracts can provide will prove exceedingly valuable.\n\nHow data contracts impact data engineering best practices\n\nBased on even the most basic functionality of data contracts, it’s clear they can dramatically improve both data quality and organizational data management.\n\nBut as they do so, data engineers should be mindful of how contracts can impact the practices they adhere to daily.\n\nStaying business-aligned and value-focused\n\nClarified expectations and stakeholder alignment are typical byproducts of the data contract drafting process. Structuring and documenting this alignment furthers the ability of data engineering teams to align efforts and projects with overall business goals.\n\nData contracts can also serve to bridge existing (or, perhaps, inevitable) communication gaps that grow between teams and stakeholders over time. As such, contracts not only promote valuable alignment with business goals but also help maintain them.\n\nAdhering to the data engineering lifecycle\n\nWhen a data contract defines quality standards, acceptance criteria, and data validation protocols, it also helps ensure that every phase of data generation adheres to standard protocols, reducing bottlenecks and ensuring efficient data handling.\n\nThis additional definitional fidelity can make them instrumental in helping enforce a holistic, dedicated approach to the entire data engineering lifecycle. A contract in place also serves as a bulwark against resource constraints and cultural pressures that may encourage team members to skip steps in certain situations.\n\nEmbracing data as a product\n\nData contracts enable the “data as a product” concept, formalizing the need to treat data with strategic import and elevating the status of data through an organization.\n\nIn addition to enhancing the perceived value of data, contracts help ensure ongoing maintenance and improvement projects get the time, attention, and resources that product upgrades typically enjoy within organizations.\n\nBuilding for scalability and performance\n\nOne critical aspect of data contracts involves defining all relevant SLAs. This ensures that designed architectures can meet organizational performance and scalability requirements, efficiently managing data volumes and dependencies.\n\nOnce in place, data contracts establish high standards and expectations for data handling and processing capabilities. As such, they can encourage data engineering terms to develop innovative new solutions for performance optimization techniques.\n\nEnabling robust security and privacy measures\n\nData contracts that include specific security and privacy measures help ensure that all data handling conforms to the highest data protection standards. This includes using DevOps frameworks and continuous integration practices to maintain robust security postures.\n\nIn addition to ensuring organizational data meets both regulatory and internal security requirements, these measures also build trust with customers and partners—essential for organizations working to position themselves well in the face of ever-increasing scrutiny regarding data privacy.\n\nFostering comprehensive documentation and metadata management\n\nData contracts require detailed documentation, effective metadata management, and regular data quality checks to maintain a clear understanding of data flows and transformations, which are essential for data quality and governance. This practice ensures that all dependencies are tracked and managed effectively.\n\nThe comprehensive approach this supports also helps with compliance, auditability, and operational transparency, which, in turn, makes it far easier for data teams to trace data lineage and manage the data lifecycle.\n\nSanctifying data governance practices\n\nContracts solidify data governance by codifying roles, standards, and responsibilities. This strengthens data governance by making data use across the organization more consistent and ethical, ensuring consistent, ethical data usage.\n\nAdditionally, strong governance supported by contractual obligations can reduce legal risks while enhancing the organization’s reputation in handling critical and/or sensitive data.\n\nMake sure your data engineering practices truly are the best\n\nIncorporating best practices in data engineering is essential for transforming raw data into high-quality datasets that drive informed decision-making. That’s what it takes for data to continue to function as the new oil.\n\nBut as big data grows into more and more of an understatement, data engineering best practices need to be as exceptional in practice as they are on paper. That will take a data contract at the tip of the spear, helping data engineering teams excel in providing a true end-to-end approach to data management that supports strategic goals and enhances overall performance, all in real time.",
      "# [Staff Software Engineer - Data - Gable.ai](https://www.builtinseattle.com/job/staff-software-engineer-data/93730)\nAbout Us: Gable.ai is a Seattle-based startup revolutionizing the data industry. Through our data communication, change management, and collaboration platform, we empower developers to build and manage data assets, bridging the gap between data producers and consumers to upscale data quality. Fresh out of stealth mode and backed by prominent venture partners, our mission is to reshape data management by fostering collaboration and innovation. Join us in transforming the landscape of the data industry!\n\nResponsibilities:\n\nAs a Staff Software Engineer specializing in data, your primary responsibilities will be to own end-to-end data projects. A key component of your work will be to scope out and build the best-possible data solutions (high performance, low cost, low latency) to green-field problems. This includes defining the use case, designing and curating appropriate datasets, shortlisting tools and technologies, implementing and validating production grade software, evaluation, and deployment.\n\nYou'll build robust solutions to improve data reliability and observability. You'll work closely with customers to understand their problems and requirements. You'll focus on generalizing your work and building abstractions that improve a variety of integration with common data stack oriented technologies.\n\nQualifications:\n\nYou have minimum 8 years of writing production grade software, ideally with experience at a B2B SaaS company\n\nYou have a minimum of 5 years of experience building data solutions in production settings. Your role involves not just research and experimentation to build state-of-the-art solutions but also shipping the product to a production environment.\n\nYou’re excited about being cross-functional and owning the lifecycle of building data solutions — from development to deployment.\n\nYou’re extremely comfortable with Typescript, Python and data processing frameworks such as Spark. You have experience with data management and integration tools like Kafka and Snowflake.\n\nYou stay up-to-date with the latest developments in your area of interest in data engineering. You’re comfortable reading technical papers and documentation, figuring out the key ideas, and reproducing the results in a production environment.\n\nYou’ve previously worked with various data systems, including relational databases like PostgreSQL and MySQL, NoSQL databases like MongoDB, and data transformation tools like dbt.\n\nYou’re really excited about solving the biggest challenges in the modern data stack and building applications that leverage these technologies for solving complex data problems.\n\nYou enjoy fast-paced environments and exhibit a high degree of ownership and self-sufficiency. Unstructured environments are exciting to you because they represent opportunities for growth and leadership.\n\nTech Stack:\n\nPython\n\nSpark\n\nKafka\n\nSnowflake\n\nPostgreSQL\n\nMySQL\n\nMongoDB\n\ndbt\n\nModern Data Stack\n\nData Quality\n\nData Observability\n\nWhy Join Us:\n\nBe part of a pioneering team that is redefining the data industry.\n\nWork on cutting-edge technology with the opportunity to make a significant impact.\n\nCollaborate with a talented and passionate team of engineers and industry experts.\n\nEnjoy a dynamic, fast-paced, and supportive work environment.\n\nCompetitive compensation package and benefits.\n\nIf you are passionate about the intersection of software engineering and data, and eager to contribute to the future of data management and collaboration, we would love to hear from you.",
      "# [Cameron J. Gable | Lawyers](https://www.jonesday.com/en/lawyers/g/cameron-gable)\nCameron Gable is a regulatory lawyer who counsels and represents clients in international trade, foreign investment, national security, environmental, energy, and other regulatory matters. He also advises on issues involving the regulation of emerging and strategic technologies, such as artificial intelligence and digital assets/blockchain.\n\nCameron represents clients in investment reviews conducted by the Committee on Foreign Investment in the United States (CFIUS) and assists clients in navigating and understanding economic sanctions, including sanctions regimes administered by the Office of Foreign Assets Control (OFAC). He also advises clients in evaluating the rules and incentives relevant to inbound investments, such as funding opportunities under the Creating Helpful Incentives to Produce Semiconductors Act (CHIPS Act). In addition, Cameron counsels clients in matters involving California's expansive environmental laws as well as federal laws, such as the National Environmental Policy Act (NEPA), the Clean Air Act (CAA), and the Clean Water Act (CWA).\n\nCameron's broad regulatory experience has involved counseling clients from a variety of industries, including technology, life sciences, semiconductors, energy, agriculture, real estate, medical devices, and consumer goods.",
      "# [Instagram](https://www.instagram.com/eli_gable_music/)\n",
      "# [National Association of Public Insurance Adjusters](https://www.napia.com/find-a-public-adjuster/goodman-gable-gould-adjusters-international)\nInterested in Membership?\n\nThe members of NAPIA invite and encourage you to join! By working together, we can achieve our mission to maintain and enhance our industry as a whole.\n\nAll membership applications for NAPIA must be approved by the Board of Directors.\n\nIf you are ready to join, click below to get started!",
      "# [Susanna Gable](https://www.gatesfoundation.org/about/leadership/susanna-gable)\nSusanna Gable oversees international development finance efforts for the Development Policy and Finance team and is based in the foundation’s Washington, D.C., office. She follows global economic trends and changes to the global financial architecture and international development cooperation, as well as the implications on financing flows, economic growth prospects, and inclusive sustainable economic transformation in developing countries.\n\nPreviously, Susanna served as chief economist at the Swedish International Development Cooperation Agency (Sida) for six years. She co-chaired the OECD-DAC Community of Practice on Poverty and Inequality, co-founded the global OECD-DAC Chief Economist Network, co-founded the Community of Practice on Country Diagnostics, and served on the Global Council on SDG 1, the Global Innovation Fund’s Development Committee, and the Advocates for the Reform of International Finance group at the Center for Global Development.\n\nBefore joining Sida, Susanna was at the World Bank, where she worked on issues including inclusive growth, growth diagnostics, economic transition, private-sector development and trade, investment climate, public expenditures and debt, poverty reduction, the Sustainable Development Goals, and financing for development.\n\nSusanna has a Ph.D. in economics from the University of Gothenburg, where her research focused on political freedom, economic reforms, economic growth and the environment.",
      "# [Goodman Gable Gould/Adjusters International](https://www.ggg-ai.com/cookie-policy/)\n",
      "# [Maldon High Street retirement flats' gable end collapses by Laura Devlin on 2024-11-24](https://www.bbc.com/news/articles/c0mz7e37xppo)\nA High Street was closed and residents evacuated after the gable end of a complex of retirement flats collapsed.\n\nEmergency services were called to Embassy Court in Maldon at 09:30 GMT after part of the top of the four-storey building gave way.\n\nNo-one was injured or trapped, the area was made safe and fire crews and police left the scene at 11:00, Essex County Fire & Rescue Service said.\n\nCrews also attended a Christmas Fayre in Wickford at about 12:15 where a marquee blew over in winds caused by Storm Bert, hitting three pedestrians leaving them with minor injuries.\n\nOne person on social media said her mother was caught up in the incident and left \"cut and bruised and very shaken up\", while another said they saw a man sitting with \"blood and a bash on the face\".\n\nThe fire service said its crew gave the people first aid and left them in the care of the ambulance service.\n\nIt is not known whether the collapse of part of the Maldon block was related to Storm Bert, which has led to strong winds across the East of England.\n\n\"Crews worked hard to remove sections of the roof and cleared the loft of any items so they were not blown away by the wind,\" said station manager Ryan Ainger.\n\n\"Initial crews put a cordon in place to maintain the safety of public as the bricks had fallen on to the neighbouring building and the alleyway below.\"\n\nFirefighters from Maldon had said they were joined on the High Street by crews from Chelmsford, Colchester, urban search and rescue, the hazardous area response team and police.\n\nMeanwhile, Essex County Fire & Rescue Service said its control room had received \"a large number of calls for fallen trees\".\n\nIn Great Baddow on the outskirts of Chelmsford, a tree came down blocking a road near the parish council offices and parish hall.\n\nA party was being held inside but no-one was injured.\n\nLive updates: Storm Bert hits the UK",
      "# [Goodman Gable Gould/Adjusters International](https://www.ggg-ai.com/privacy-policy/)\n",
      "# [Lorri A Gable – BG Independent News](https://bgindependentmedia.org/lorri-a-gable/)\n“Together Again”\n\nLorri Ann Gable, 65, of Cygnet, Ohio passed away at home on Wednesday October 9, 2024, surrounded by her loving family. She was born on March 25, 1959, to Lewis and Betty (Coler) Davis in Youngstown, Ohio.\n\nLorri was a 1977 graduate of Mahoning County Career and Technical Center. She then drove semitrucks coast to coast with her husband Dave until she became a stay-at-home mom in 1990.\n\nLorri is survived by her daughter Rhianna Gable of the home, son David (Brittany) Gable of Bowling Green, Ohio, grandchildren Gabriel, Leona, Kennedy, Caroline, Ezra, her mother Betty Davis of Columbiana, Ohio, Step-mother Georgia Davis of Washingtonville, Ohio, two sisters Terri Burt of Columbiana, Ohio, Merri Smith of Carrolton, Ohio, three brothers Lewis “Chip” Davis of Castaic, California, Ken Davis of Alliance, Ohio, Pete Davis of Leetonia, Ohio and numerous nieces and nephews.\n\nLorri was preceded in death by her husband of 32 years, David in 2012, her father Lewis Davis, grandparents Albert and Hellen Coler, John and Mary Davis.\n\nA memorial service will be held in Sebring at a later date for friends and family. Arrangements have been entrusted to Dunn Funeral Home located in the Historical District of Bowling, Green Ohio at 408 W. Wooster St.\n\nTo leave an online condolence or fond memory with the Gable family please visit www.dunnfuneralhome.com.",
      "# [GABLE delivers all-time high income, ready to propel businesses towards the AI FIRST era with the strategy of “Sustain = Smart + Secure.”](https://www.g-able.com/insights/g-able-enable-the-future)\nG-Able Public Company Limited, a leading \"Tech Enabler\" that helps businesses embrace every aspect of the digital era, has revealed its 2024 business strategy, focusing on developing digital solutions and capabilities while enhancing businesses' readiness to address various challenges on the path to becoming AI-ready organizations. GABLE plans to expand its Business Application segment through global HCM partnerships, offering full-suite digital solutions across five portfolios to meet business needs. This expansion aligns with the core strategy of \"Sustain = Smart + Secure,\" enabling clients’ businesses to navigate the AI-First era towards sustainable success.\n\nDr. Chaiyuth Chunnahacha, CEO of G-Able Public Company Limited, stated, “As a SET-listed digital tech giant equipped with technologies and capital, our main aim is to tap into our modern and smart technologies and digital solutions to serve future business needs, secure organizational data, increase profitability, and ensure sustainable growth of our clients in the AI-First era, in alignment with the strategy of 'Sustain = Smart + Secure.'”\n\nIn 2023, GABLE achieved huge success in its initial public offering and SET-listing as G-Able Public Company Limited. This has enhanced its readiness in terms of its capital for investment in its capacity and capabilities in line with its plan to drive strong and sustainable growth. GABLE’s own software platform has served as a key growth engine propelling the Group’s solid business expansion across many segments. The five affiliated companies have been key in generating the Group’s income, using its Value-Added Distribution to further its growth. The Group’s recurring income exceeded one half of the total income, and its backlog portion climbed up to an unprecedented level of over Baht 4.5 billion.\n\nWith its extensive experience of over 35 years in helping businesses gain a competitive edge through technologies, GABLE has seen opportunities to steer its growth by capitalizing on the AI trend that plays an increasingly important role in organizations. All businesses need to develop their systems to become AI-ready organizations. In doing so, Cloud-based IT infrastructures, data analytics systems through big data platforms, and 24-hour cybersecurity systems should be established to ensure that front-office and back-office systems are ready to work synchronously with AI in the future.\n\nApart from the AI trend that is bringing more growth opportunities for GABLE, building ‘Smart Organizations’ through business applications such as human capital management software is another key growth driver because one crucial asset of an organization is “human.” According to Gartner, the HCM market is expected to see an average growth rate over the next three years at 18%. As organizations need to improve their competitiveness through building up a pool of talents, software platforms can help them do so through the use of big data and AI in talent analytics, skill management, and productivity and efficiency enhancement of employees across sections.\n\nGABLE’s 2024 strategy is originated from the adoption of the concept of “Smart + Secure” to ensure clients’ business sustainability. This consists of the following 3 main guidelines: To integrate GABLE’s Enterprise Solutions and Services core business comprising 5 portfolios, namely Data Analytics, Cloud, Cybersecurity, Application Development, and Managed Tech Services, with its IP platforms to support the preparation of AI-ready data and AI-ready security, as higher demands\n\nfor AI and cybersecurity will boost GABLE’s growth.\n\nTo expand the Group’s capabilities through potential business applications in HCM and ERP through partnering with global entities with expertise across various fields and selecting other interesting smart business applications to provide continued support for its clients. To focus on investment in businesses that are aligned with GABLE’s business concept to secure\n\nmore opportunities and satisfying rates of return; and to gain competitive edge by using its funds from its IPO worth around Baht 600 million to propel business growth under the investment framework covering three main areas: Right Product, Right Technology; Win-Win business Synergy; and Right Price, Right Value.\n\nMs. Raveeratana Satchavarodom, Chief Finance & Strategy Officer of G-Able Public Company Limited stated that in 2023, GABLE’s operating income reached Baht 5,338 million, 13% up from 2022. Despite external factors and fluctuations at macro and industrial levels leading to stronger competition, GABLE was able to navigate these challenges, achieving steadfast expansion and double-digit growth rates in income across all segments, including Enterprise Solution, Valued Added Distribution, and Software Platform, from its clients.\n\nMoreover, after its IPO, GABLE was able to generate a gross profit of Baht 1,099 million in 2023, growing 10% year-on-year, or a gross profit margin of 21%, about the same level as last year. GABLE’s net profit for 2023 stayed at Baht 253 million, and the backlog portion reached an all-time high at Baht 4,544 million, up 16% from Q3 of 2023, ready to support future income recognition. The backlog level is set to support future income generation in 2024 of over Baht 2,753 million, accounting for nearly one-half of the target income in 2024. Furthermore, the Company’s opportunities to further grow its business come from\n\nthe accelerated demand for the creation of AI-ready organizations, the need to set up data analytics and cybersecurity, its partnerships in developing business applications, and inorganic investment through M&As.\n\nBy adopting the strategy of “Sustain = Smart + Secure,” in 2024 GABLE will continue to operate its business based on the 3 guidelines, namely Smart Finance, Secure Finance, and Sustain Finance. Smart Finance is to create more financial returns from organic investment and inorganic investment. Secure Finance is to maintain financial discipline through secure operations and secure investment, focusing on sustainable investment within the so-called Investment Framework to ensure secure and sustainable business growth in the long term. And Sustain Finance is to establish sustainable financial growth, including mitigating risks to be within acceptable levels.\n\nThe above strategy will lead to GABLE’s growing backlog and its move towards reaching another all-time high this year at around Baht 4.5-5.5 billion. GABLE will expectedly continue to maintain its gross profit margin at 20-22% with its recurring income of more than 50% of the total income, to support risk management for investors. With its sound financial discipline and available capital of more than Baht 600 million from the IPO along with its capacity and capabilities, GABLE is ready to grow further in line with the upcoming trend in 2024.",
      "# [Ellen A. Adams on 2021-12-01](https://www.gablelaw.com/attorneys/ellen-a-adams/)\nEllen Adams is a shareholder at GableGotwals and Co-Chairs the Firm’s Employment and Labor Practice Group. She enjoys counseling and advising clients on employment law compliance to mitigate risk. Ellen regularly develops policies, procedures, and training to align her client’s business goals with human resources best practices. Working across a variety of industries, including energy, construction, manufacturing, healthcare, retail, and banking, she is familiar with the unique challenges that vary across work environments and employee populations.\n\nEllen regularly conducts internal investigations, both in the context of responding to internal complaints and outside claims. While Ellen aims to keep her clients from incurring the expense of litigation, her practice also focuses on defending employers before government agencies, arbiters, and state and federal courts.",
      "# [Top Envoy Alternatives: Why Gable Is the Best Choice for Hybrid Workspaces](https://www.gable.to/blog/post/envoy-alternatives)\nChoosing the right workspace management tool is crucial in a hybrid work environment. Selecting the wrong tool can lead to inefficiencies that drag down productivity and inflate costs.\n\nYour teams could be struggling to find available meeting spaces or double-booking rooms because of outdated or complicated software. These issues disrupt your daily operations, hinder long-term process improvements, and lead to budget overruns.\n\nBy making an informed choice, you can avoid these costly setbacks and create a seamless employee experience.\n\nWhen choosing your next office management tool, look for features like ease of use, customization options, and high customer satisfaction. You will also want to ensure flexibility, pricing, and features for managing visitor check-ins and desk bookings.\n\nWe'll discuss several alternatives to Envoy that deliver these capabilities, including Gable. Gable surpasses Envoy in user-friendliness, flexibility, and customer satisfaction, making it a strong contender for businesses looking to optimize their hybrid workspaces.\n\nThis article will explore the best Envoy alternatives, compare functionality, and explain why Gable is the best choice for modern, agile workplaces.\n\nWhether you want to improve office processes or cut costs, this article will help. Keep reading to discover the best solution for you.\n\nWhat is Gable?\n\nGable is a workspace management platform that aims to simplify the oversight of hybrid setups with its four core products:\n\nGable On-Demand, which gives your employees access to over 10,000 premium workspaces worldwide, including coworking spaces, conference rooms, and private offices\n\nGable HQ, which lets companies manage their leased offices and ensure desk booking and room scheduling run smoothly, and space utilization is optimized\n\nGable Visitor Management, which ensures your office visitors have a delightful, welcoming, and safe experience\n\nGable Event Orchestration, which enables you to organize and manage company events smoothly and efficiently and focus on fostering connections in your teams\n\nOur full suite of tools aims to provide employees with a top-notch workplace experience. It’s an excellent alternative to Envoy and other workspace management solutions. Gable helps businesses boost productivity by optimizing workflows through a flexible and customizable user interface.\n\nWhat is Envoy?\n\nEnvoy is a workplace management platform. It seamlessly connects people, spaces, and data and has many features that improve efficiency, safety, and user experience.\n\nKey Features of Envoy:\n\nDesk and Room Booking: Employees can use the room booking system to reserve desks, conference rooms, and other workspaces in advance or on the spot.\n\nVisitor Management: Streamlines the visitor check-in process with a secure interface. The system lets employees pre-register and sign in digitally.\n\nOccupancy and Space Utilization Analytics: The platform provides real-time insights into space usage. It tracks employee attendance and visitor traffic.\n\nEmergency Notifications and Safety Features: Envoy can send emergency alerts. This lets organizations quickly communicate with employees and visitors during crises.\n\nIntegrations and Automation: Envoy connects with various workplace tools, including Slack, Microsoft Teams, and access control systems.\n\nWhile Envoy works well for some, it's not a one-size-fits-all solution. Gable is a great choice for companies with hybrid teams. Many businesses find that alternative platforms better meet their specific needs, whether due to more advanced customization options, greater ease of use, or stronger customer support. Exploring these alternatives ensures companies find the perfect fit for their unique hybrid work environment.\n\nKey competitors to Envoy: A quick overview\n\nEnvoy is a popular choice for managing workspaces, but it’s far from the only one.\n\nWhen considering alternatives to Envoy, four tools for managing workspaces stand out: Gable, Robin, SpaceIQ, and OfficeSpace. These platforms each offer reliable solutions for companies looking to optimize their hybrid work environments.\n\nBelow is a brief overview of these tools and a comparison of their key features and pricing.\n\nGable\n\nGable is a workspace management platform for hybrid and remote teams. Gable’s HQ solution lets companies manage their leased offices, enable easy desk and room booking, and get insights into space utilization, employee engagement, and more.\n\nGable is an excellent choice for companies that need adaptable tools that offer flexibility, real-time data, and smooth integrations with everyday tools.\n\nKey features\n\nDesk and Room Booking: Empowers employees to easily book desks, reserve rooms, and meet their coworkers in your offices.\n\nVisitor Management Solution: Streamlines the check-in process for visitor registration to ensure a secure and welcoming experience.\n\nData and Insights: Offers detailed analytics on office space usage, employee engagement, and real estate costs.\n\nIntegration Capabilities: Integrates seamlessly with everyday tools like Slack, Microsoft Teams, and Google Calendar for smoother workflow management.\n\nEvent Orchestration: Simplifies the planning and management of onsite and offsite events from a single platform.\n\nWorkspace Budget Management: Enables companies to track and manage workspace expenses, optimizing costs across locations.\n\nPricing\n\nPricing starts at $3 per seat per month for HQ desk booking and room reservation, all inclusive. For visitor management, it is $150 per month per location. Custom pricing and discounts are available for enterprise clients.\n\nWhy choose Gable over Envoy?\n\nGable provides more extensive real-time data on workspace usage and integrates with tools like HRIS, SSO, Slack, and Microsoft Teams. It also offers advanced budget management, helping companies control costs while providing flexible options for employees. Envoy, on the other hand, is better suited for businesses focused solely on managing in-office resources.\n\nRobin\n\nRobin is a workspace management platform that simplifies desk and room bookings, provides real-time office maps and workplace analytics, and integrates with popular calendar tools like Outlook and Google Calendar.\n\nRobin offers flexible booking to avoid overbooked rooms. Users appreciate Robin for its easy-to-use interface and quick support.\n\nKey features\n\nDesk Booking: Simplifies the process of reserving desks and managing space availability.\n\nMeeting Room Booking: Ensures that rooms are available when needed, preventing scheduling conflicts.\n\nInteractive Maps: Provides real-time visual representations of the office layout and available spaces.\n\nVisitor Management Solution: Ensures a smooth and secure check-in experience for visitors.\n\nIntegration Capabilities: Syncs bookings and space usage with tools like Slack, Microsoft Teams, and Google Calendar for improved collaboration.\n\nReal-Time Usage Analytics: Offers insights into space utilization and occupancy trends to optimize workspace efficiency.\n\nPricing\n\nPricing details are available upon request. They are mid-range for similar tools.\n\nWhy choose Robin over Envoy?\n\nRobin offers more robust desk and room booking features, making it an excellent choice for companies needing a solution that prioritizes space management over visitor control. Robin’s interactive maps provide a visual overview of workspace availability, something Envoy lacks. Additionally, Robin is often praised for its user-friendly interface and fast customer support, making it a better option for teams seeking a more seamless user experience.\n\nWhy choose Gable over Robin?\n\nWith real-time booking, management tools, and integrations with HRIS, SSO, Slack, Microsoft Teams, Google Calendar, and access control apps like Brivo and Verkada, Gable helps you manage offices easily and smoothly.\n\nIt also offers valuable data insights on space usage and employee engagement. In contrast, Robin focuses on desk and room bookings, with features like interactive maps and calendar integrations, but it’s less suited for remote or hybrid teams.\n\nSpaceIQ\n\nSpaceIQ, a part of Eptura, offers many space management tools, including occupancy planning, move management, and real estate forecasting. It aims to help facilities managers by providing tools to optimize space, arrange seating, and plan scenarios.\n\nSpaceIQ also has strong integrations with various IT and access management systems, ensuring smooth and secure workplace operations.\n\nKey features\n\nOccupancy Management: Tracks and optimizes how space is used across different areas of the workplace.\n\nMove Management: Simplifies the process of relocating teams or departments within the office space.\n\nScenario Planning: Helps plan for future office needs, including layout changes and space utilization improvements.\n\nSpace Utilization Analytics: Provides detailed insights into how workspace is being used to maximize efficiency.\n\nUser-Friendly Drag-and-Drop Space Planning: Enables quick and easy adjustments to office layouts with a simple drag-and-drop interface.\n\nComprehensive Reporting: Delivers detailed reports on space utilization, occupancy, and forecasting to support data-driven decisions.\n\nPricing\n\nPricing is available upon request, with options tailored for both small and large enterprises.\n\nWhy choose SpaceIQ over Envoy?\n\nFor companies looking to optimize real estate usage and handle complex occupancy and scenario planning, SpaceIQ offers tools that Envoy does not. SpaceIQ’s integrations with IT and access management systems provide an added layer of workplace security and operational efficiency, whereas Envoy focuses on managing visitors and office check-ins. Facilities managers benefit from SpaceIQ’s advanced planning features, which make it easier to manage large-scale office spaces and move personnel when needed.\n\nWhy choose Gable over SpaceIQ?\n\nGable offers flexible workspace options for both remote and in-office teams, making it ideal for businesses that need to scale across multiple locations. In contrast, SpaceIQ focuses on in-office management with tools for space planning, occupancy management, and move management, making it a better fit for larger organizations optimizing their fixed office spaces.\n\nGable also provides a scalable solution with clear pricing and budget management tools, helping companies control costs as they grow. SpaceIQ has strong space utilization features, but its complex cost structure and focus on traditional offices may not suit companies needing more flexibility.\n\nOfficeSpace\n\nOfficeSpace is an integrated workplace management system (IWMS). An IWMS takes workspace management further by providing a holistic solution that incorporates desk and room booking and real estate management, facility maintenance, and energy efficiency. Unlike a traditional Workspace Management System (WMS), which primarily focuses on managing physical spaces like desks, rooms, and meeting areas, an IWMS integrates multiple workplace functions into a single platform.\n\nOfficeSpace uses AI assistants and real-time data to optimize the workplace offering tools for desk booking, floor plan management, and scenario planning to support dynamic work environments.\n\nKey Features\n\nDesk Booking: Allows employees to easily book and manage desks, optimizing workspace allocation for hybrid teams.\n\nFloor Plan Management: Provides a visual representation of office layouts, enabling better space utilization and planning.\n\nScenario Planning: Helps businesses anticipate future office space needs and plan for changes in real time.\n\nSpace Utilization Analytics: Offers detailed data on how office spaces are being used, helping companies maximize efficiency.\n\nMove Management: Simplifies the process of moving employees within the office, making it easy to rearrange layouts as needed.\n\nIntegration Capabilities: Seamlessly integrates with popular tools like Slack and Microsoft Teams for better workflow management.\n\nPricing\n\nLike its competitors, pricing is available upon request. There are flexible options for organizations of different sizes.\n\nWhy choose OfficeSpace over Envoy?\n\nOfficeSpace excels in floor plan management and scenario planning, which are not key features of Envoy. It also offers more robust desk booking and space planning capabilities, allowing companies to visualize and adapt their office layouts easily. While Envoy may be more suited for visitor management and security, OfficeSpace provides a more complete solution for companies focused on optimizing their workspace for hybrid and dynamic work models.\n\nWhy choose Gable over OfficeSpace?\n\nGable offers a simple, user-friendly interface that makes booking desks and rooms easy, with minimal training required. This speeds up adoption and is ideal for organizations with global teams. OfficeSpace, while feature-rich, has a steeper learning curve, especially for advanced tools like AI assistants and move management, which may take more time to master.\n\nOfficeSpace offers customizable floor plans and integrations, but it doesn’t match Gable’s level of flexibility, especially for businesses with unique branding needs or hybrid workspaces.\n\nOverall, Gable’s ease of use and customization make it a top choice for businesses looking for a flexible, user-friendly solution, while OfficeSpace’s powerful tools may require more time to become proficient.\n\nGable vs. Envoy: A detailed comparison\n\nWhile both Gable and Envoy provide strong workspace management tools, Gable stands out as the best alternative for hybrid office management. It is more adaptable, budget-friendly, and all-encompassing.\n\nLet's explore how Gable excels over Envoy in key areas.\n\nWhat users are saying\n\nUsers praise Gable for its user-friendly interface, adaptability, and ease of use. Gable's integration with tools like Slack, Outlook, and Teams is a big plus.\n\nReviewers also emphasize the platform's attentive customer support and affordability. Gable's clear pricing and customer-centric approach significantly benefit companies that want scalable, customizable workspace management options.\n\nEnvoy has received mostly positive feedback. Its visitor management, ease of use, and adaptability to corporate settings are praised. Users on Capterra and G2 appreciate Envoy's visitor check-in and badge features. They help streamline reception and improve security. The platform's features, like pre-registration and e-signatures, have been vital during COVID-19. They reduce contact and support health protocols.\n\nOn the other hand, there are some mixed opinions about customer service and pricing. Some users find the onboarding and setup easy. Some issues include app navigation, limited weekend support, and mobile compatibility. Additionally, users noted that Envoy's annual premium subscription is too high for small organizations.\n\nEase of use: User interface and experience\n\nGable and Envoy have user-friendly interfaces, but Gable has been reported to be simpler and easier to navigate.\n\nGable has a simple, intuitive interface. It makes booking desks, rooms, and workspaces easy and ensures a smooth experience for all users, regardless of their tech skills. User reviews note Gable's low learning curve, which cuts training time and speeds up team adoption.\n\nWhile also praised for its usability, Envoy has a steeper learning curve for certain features. For example, users appreciate Envoy’s customizable maps and interactive tools, but users have reported Envoy lacking a user-friendly interface.\n\nOne user in Biotechnology reported, “Changing desks is not the most straightforward, user-friendly task to accomplish within the app.”\n\nVerdict:\n\nGable's simple interface is better for groups that want a quick, easy setup.\n\nFlexibility: Adapting to business needs\n\nGable stands out for its exceptional flexibility in hybrid and remote work settings, while Envoy is more tailored to managing in-office operations.\n\nIn addition to the HQ product which lets companies handle desk and room bookings, Gable's On-Demand product with access to 10,000 flex workspaces worldwide makes the product adaptable. It's perfect for organizations with both in-office teams and hybrid employees using flex spaces. Its tools support remote and in-office work, helping businesses scale and adapt to changing needs.\n\nEnvoy helps manage in-office work with its hybrid scheduling and desk reservation features, making it a solid choice for companies with a central office structure. However, when compared to Gable, Envoy’s reach is more limited. Gable offers access to over 10,000 workspaces across 50+ cities worldwide, whereas Envoy focuses primarily on in-office management without providing the same global flexibility.\n\nVerdict:\n\nGable is the better choice for companies with flexible locations and hybrid work.\n\nIntegration capabilities: Seamless connections with everyday tools\n\nBoth platforms offer integrations, but Gable's approach is broader.\n\nGable connects with over 30 workplace tools, including Slack, Microsoft Teams, HRIS, and access control systems like Brivo and Verkada. This versatility allows businesses to streamline workflows and boost productivity, particularly in remote and hybrid work environments. By offering such a wide range of integrations, Gable helps teams work seamlessly across multiple platforms and locations.\n\nEnvoy integrates with more than 15 essential tools, such as Slack, Microsoft Teams, and various access control systems. However, it primarily focuses on in-office management tools, making it a better fit for companies with centralized office setups and less flexibility for remote-first organizations.\n\nVerdict:\n\nGable's many integration options make it a better choice for organizations that need tools for both in-office and hybrid work.\n\nPricing: Transparent comparison with cost-savings\n\nGable offers a clearer and more affordable pricing structure.\n\nGable starts at $3 per seat per month for HQ desk booking and room reservation, offering comprehensive features, including integrations with HRIS, Slack, Teams, and access control systems. You also get full access to a detailed data and analytics dashboard that provides insights into space utilization, meeting room occupancy, and booking patterns, allowing you to make informed real estate decisions. This all-inclusive package helps optimize office usage, foster collaboration, and streamline operations in hybrid workplaces.\n\nFor Gable visitor management, it is $150 per month per location. Custom pricing and discounts are available for enterprise clients. It's a smart choice for businesses that need flexibility and branding options.\n\nEnvoy’s Workplace pricing for desk and room booking starts at $5 per seat per month, which includes key features like desk hoteling, permanent desk assignments, and room booking through their mobile app. The system integrates with popular workplace tools like Slack, Teams, and access control systems. In addition, businesses get access to detailed space usage analytics that help optimize layouts and reduce real estate costs.\n\nEnvoy Visitor Management offers packages starting at $329 per location per month for comparable features to Gable’s Visitor Management package, which can be costly for businesses with many locations and those needing advanced visitor management features.\n\nVerdict:\n\nGable's simple pricing model makes it the cheaper option for the same (and even more) features. This is true for companies with multiple locations or that need extensive customization.\n\nCustomer support: Review-based comparison\n\nBoth platforms are known for their customer support. But Gable's personalized approach adds extra value.\n\nGable is recognized for its responsive 24/7 support team, which assists with email, live chat, and phone. Customers often praise the fast response times and tailored support. This is especially true during onboarding and for urgent issues.\n\nEnvoy offers 24/7 customer support through various phone, chat, and email channels. However, some users have noted occasional delays in support response times, particularly for more complex issues or outside of regular business hours. One user reported having to wait until Monday for assistance when support wasn't available over the weekend, which can be inconvenient for urgent tasks.\n\nOne user shared this experience on Capterra: “Ok. Let's try their support, right? Not available, as it is Saturday. Everybody in the company must be taking weekends off, there is no support. I must wait for Monday. But Monday is exactly what I am trying to reserve at the office, as the company policy is to use Envoy to be able to work at the office.” - Fara M., Head of Data\n\nVerdict:\n\nGable's quick, personal support ensures users have a great experience and get help when needed.\n\nFeatures: Side-by-side comparison of key features\n\nDesk Booking: Both Gable and Envoy offer desk booking functionality, but the flexibility differs. Gable allows users to book desks with real-time availability and easy cancellations, which is especially useful for hybrid or fully remote teams. Envoy provides advanced desk booking with interactive maps, making it easier to visualize available spaces, though it's more suited for companies with centralized office needs.\n\nRoom Booking: Gable offers room booking, allowing users to manage availability and track usage across multiple locations. This is ideal for companies with distributed teams. Envoy focuses more on simplifying in-office room booking and managing free or unused rooms, making it more appropriate for businesses with a single or centralized office.\n\nVisitor Management: Both platforms feature visitor management capabilities, but their focuses differ. Gable provides streamlined check-in and visitor tracking, while Envoy excels in pre-registration, badge access, and notification features, giving it an edge in office security and visitor logistics.\n\nSpace Utilization: Gable offers real-time analytics on workspace usage, employee engagement, and cost optimization, helping businesses get a complete picture of how their spaces are used. Envoy provides a unified view of space usage data but focuses more on centralized space utilization rather than optimizing for remote or global operations.\n\nEvent Orchestration: One of the biggest differences is that Gable allows companies to plan and manage both on-site and off-site events from a single platform. Envoy lacks this feature entirely, making Gable a more comprehensive solution for companies needing robust event management tools.\n\nIntegration Capabilities: Both platforms integrate with popular tools like Slack and Microsoft Teams, but Gable goes further by also integrating with Google Calendar and offering more advanced budget management tools. Envoy, on the other hand, focuses more on access control system integrations, which may be better for businesses prioritizing office security.\n\nAnalytics and Insights: Gable offers comprehensive data on bookings, space utilization, and budget management, providing businesses with the tools to optimize both space and cost. Envoy offers occupancy and space utilization analytics but without the deeper financial tracking that Gable provides.\n\nVerdict:\n\nGable offers more features, including unique tools like event orchestration. It is a better, all-in-one solution for diverse business needs.\n\nHow Ironclad successfully transitioned from Envoy to Gable\n\nIronclad, a top digital contracting platform, switched from Envoy to Gable when aiming to improve their hybrid work and boost data-driven decisions. Here’s how Gable changed Ironclad's workplace strategy and helped them optimize their office and coworking space use.\n\nThe challenge\n\nIronclad used Envoy for workplace and visitor management. But, its many features were too much for their needs. They didn't fully use most of the tools. As Josh Bukstein, Director of Workplace at Ironclad, said, \"Envoy’s all-in-one product is now costly and has unused features, like pandemic-era questionnaires.\"\n\nIronclad wanted a more user-friendly platform to improve visibility into workspace bookings and meet their hybrid needs.\n\nThe switch to Gable\n\nWhen Ironclad chose to switch to Gable, Josh Bukstein noted that Gable was designed to meet all their employee needs, from office desk and room booking to coworking space access around the world.\n\nGable's layout lets Ironclad employees easily track their colleagues' bookings, improving collaboration and team interaction. Gable’s pricing better suited Ironclad's needs, helping them avoid wasted costs on unnecessary features.\n\nThe Results\n\nSince moving to Gable, Ironclad has improved work flexibility and employee independence. The platform allows team members to book spaces independently, promoting a feeling of ownership and trust among the staff. “The employee experience has improved dramatically with Gable. It’s far superior to our previous systems,\" Bukstein said, praising Gable's interface.\n\nSince adopting Gable, one of the most significant changes has been the ability to utilize data effectively. Ironclad now relies on Gable to obtain real-time insights into the usage of both coworking and office spaces. \"With Gable, we can track usage in our offices and coworking areas. We now understand how many people plan to come in, how many show up, and we base our decisions on that,\" Bukstein explained.\n\nIronclad's work with Gable has transformed its hybrid work strategy. It has greatly improved employee experience, data access, and cost efficiency. \"We have all three of these essential components with Gable. Everyone understands how to reserve spaces, we obtained all the data we required, and the employee experience is fantastic,\" Bukstein remarked.\n\nTransform your workspace management with Gable\n\nHybrid work is changing fast. You need a workspace management tool that is flexible, scalable, and easy to use. Many organizations like Envoy, but Gable is a strong alternative, meeting the needs of modern, dynamic workplaces.\n\nGable's design is user-friendly, it provides real-time data insights, and has 40+ seamless integrations. This versatile solution boosts employee autonomy and optimizes both in-office and remote work. For companies like Ironclad, switching from Envoy to Gable improves decision-making, optimizes employee experience, and cuts costs.\n\nTry Gable, a tool built for today’s hybrid and remote work, to help your business succeed. Don’t settle for a one-size-fits-all solution."
    ],
    "# Gable: Comprehensive Analyst Report\n\n## Company Overview\n\nGable.ai is a Seattle-based startup that aims to revolutionize the data industry through its innovative data communication, change management, and collaboration platform. The company focuses on bridging the gap between data producers and consumers, enhancing data quality management by implementing proactive data contracts early in the data lifecycle [(Top 5 Data Lineage Tools, Gable.ai, Date Unknown)](https://www.gable.ai/blog/data-lineage-tools). Gable recently emerged from stealth mode and is backed by prominent venture partners, indicating strong investor confidence in its potential to reshape data management practices [(Staff Software Engineer - Data - Gable.ai, Built In Seattle, Date Unknown)](https://www.builtinseattle.com/job/staff-software-engineer-data/93730).\n\n## Product Overview\n\nGable offers a suite of products designed to optimize workspace management, particularly in hybrid work environments. Its core offerings include:\n\n- **Gable On-Demand**: Provides access to over 10,000 premium workspaces worldwide, including coworking spaces and conference rooms.\n- **Gable HQ**: Allows companies to manage their leased offices, ensuring efficient desk booking and room scheduling.\n- **Gable Visitor Management**: Streamlines the visitor check-in process, enhancing security and user experience.\n- **Gable Event Orchestration**: Facilitates the organization and management of company events [(Top Envoy Alternatives: Why Gable Is the Best Choice for Hybrid Workspaces, Gable, Date Unknown)](https://www.gable.to/blog/post/envoy-alternatives).\n\nGable's approach to workspace management emphasizes flexibility, user-friendliness, and integration capabilities, making it a strong alternative to competitors like Envoy [(Top Envoy Alternatives: Why Gable Is the Best Choice for Hybrid Workspaces, Gable, Date Unknown)](https://www.gable.to/blog/post/envoy-alternatives).\n\n## Market Position and Growth Potential\n\nThe global data catalog market is projected to grow significantly, from $878.8 million in 2023 to $4,680.9 million by 2032, with a compound annual growth rate (CAGR) of 17.7% [(Top 5 Data Lineage Tools, Gable.ai, Date Unknown)](https://www.gable.ai/blog/data-lineage-tools). Gable's unique positioning as a data contracts platform allows it to tap into this growing market by offering a proactive approach to data quality management, which is increasingly recognized as essential for modern organizations.\n\n## Financial Performance\n\nGable's financial performance has shown promising growth. In 2023, the company achieved an operating income of Baht 5,338 million, a 13% increase from the previous year. The gross profit margin remained stable at around 21%, with a net profit of Baht 253 million [(GABLE delivers all-time high income, G-Able Public Company Limited, Date Unknown)](https://www.g-able.com/insights/g-able-enable-the-future). The company’s backlog reached an all-time high of over Baht 4.5 billion, indicating strong future income potential [(GABLE delivers all-time high income, G-Able Public Company Limited, Date Unknown)](https://www.g-able.com/insights/g-able-enable-the-future).\n\n## Executive Leadership\n\nGable is led by a team of experienced executives, including Dr. Chaiyuth Chunnahacha, the CEO, who emphasizes the company's commitment to leveraging modern technologies to meet future business needs. He stated, “Our main aim is to tap into our modern and smart technologies and digital solutions to serve future business needs, secure organizational data, increase profitability, and ensure sustainable growth” [(GABLE delivers all-time high income, G-Able Public Company Limited, Date Unknown)](https://www.g-able.com/insights/g-able-enable-the-future).\n\n## Competitive Landscape\n\nGable competes with several established players in the workspace management and data lineage markets. Its primary competitors include Envoy, Robin, SpaceIQ, and OfficeSpace. Gable differentiates itself through its user-friendly interface, extensive integration capabilities, and flexible pricing model, which starts at $3 per seat per month for its HQ product [(Top Envoy Alternatives: Why Gable Is the Best Choice for Hybrid Workspaces, Gable, Date Unknown)](https://www.gable.to/blog/post/envoy-alternatives).\n\n## User Feedback and Market Sentiment\n\nUser feedback on Gable has been largely positive, with many praising its intuitive interface and responsive customer support. One user noted, “The employee experience has improved dramatically with Gable. It’s far superior to our previous systems” [(Top Envoy Alternatives: Why Gable Is the Best Choice for Hybrid Workspaces, Gable, Date Unknown)](https://www.gable.to/blog/post/envoy-alternatives). This sentiment reflects Gable's commitment to enhancing user experience and operational efficiency in hybrid work environments.\n\n## Conclusion\n\nGable is well-positioned to capitalize on the growing demand for data management and workspace optimization solutions. With its innovative approach to data contracts and a comprehensive suite of products tailored for hybrid work environments, Gable is poised for significant growth. The company's strong financial performance, backed by a capable leadership team and positive user feedback, makes it an attractive option for prospective candidates and investors looking to engage with a forward-thinking organization in the data industry. \n\nFor more information about Gable and its offerings, interested parties can sign up for their product waitlist or explore their website."
  ],
  "lineage": {
    "run_at": "2024-12-20T16:51:58.037301",
    "git_sha": "b66763b"
  }
}