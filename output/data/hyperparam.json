{
  "summary_markdown": "# About hyperparam\n\nHyperparam is a company focused on enhancing the data science process by providing tools that allow users to explore and curate large datasets directly in their browsers. The company addresses the challenges data scientists face in understanding and cleaning data, especially as datasets grow in scale within the AI landscape.\n\n- **Founded**: The specific founding date of Hyperparam is not provided in the available content.\n- **Employees**: Information about the number of employees is not available.\n- **Products and Services**:\n  \n  - **Hyperparam Tool**: A browser-based application that allows users to interactively explore parquet files by dropping them into the tool.\n  - **Hyparquet**: A JavaScript parquet parser that facilitates efficient querying of parquet files stored in the cloud, enabling a client-side only data viewer.\n  \n  These products are designed to improve data quality for better model training by allowing users to load and explore datasets with billions of rows using modern data formats like Apache Parquet. The tools operate as local-first applications, meaning users can work entirely within their browser without needing complex services.\n\n- **Business Model**: Hyperparam targets a broad range of users, from mega-scale AI companies to small enterprise teams, all of whom require improved data quality to build advanced AI models. This suggests a B2B business model, although specific revenue figures are not provided.\n- **Distribution**: The products are likely distributed online, given their browser-based nature, but specific distribution channels are not detailed.\n- **Company Evolution**: The company is positioned as a modern data tool provider, emphasizing innovation in data science and the importance of data quality and user-friendly interfaces.\n\nThird parties and the company itself describe Hyperparam as a transformative force in data science, aiming to make data exploration more intuitive and efficient by leveraging modern technologies and AI.\n\n# Key personnel\n\nDetails about the leadership team or key personnel at Hyperparam are not provided in the available content.\n\n# News\n\nThere are no specific news articles or events related to Hyperparam provided in the available content. For more information, one might consider visiting their website or blog for updates: [Look At Your Data üëÄ](https://hyperparam.app/) and [Hyperparam Blog](https://blog.hyperparam.app/).",
  "target": [
    "hyperparam",
    "hyperparam",
    "hyperparam.app",
    [
      "dataset"
    ],
    true,
    true
  ],
  "webpage_result": {
    "summary_markdown": "# Hyperparam Company Overview\n\n## Company History\nHyperparam is a modern data tool designed to enhance the data science process by enabling users to explore and curate large datasets directly in the browser. The company recognizes the challenges faced by data scientists in understanding and cleaning data, particularly with the increasing scale of datasets in the AI landscape.\n\n## Services\nHyperparam offers a highly scalable dataset tool that allows users to:\n- Load and explore datasets with billions of rows using modern data formats like Apache Parquet.\n- Utilize model-assisted data curation to improve data quality for better model training.\n- Operate as a local-first application, enabling users to work entirely within their browser without complex services.\n\n## Products\n- **Hyperparam Tool**: A browser-based application that allows users to drop parquet files and explore them interactively.\n- **Hyparquet**: A JavaScript parquet parser that enables efficient querying of parquet files stored in the cloud, facilitating a client-side only data viewer.\n\n## Customers\nHyperparam targets a wide range of users, from mega-scale AI companies to small enterprise teams, all of whom require better data quality to build advanced AI models.\n\n## Leadership Team\nDetails about the leadership team are not provided in the available content.\n\n## Culture\nHyperparam promotes a culture of innovation in data science, emphasizing the importance of data quality and user-friendly interfaces. The company aims to blend human expertise with AI-assisted insights to streamline the data cleaning process.\n\n## Conclusion\nHyperparam is at the forefront of transforming how data scientists interact with their datasets, making data exploration more intuitive and efficient. By leveraging modern technologies and AI, Hyperparam is set to redefine the standards for data quality in AI model development. \n\nFor more information, visit their website: [Look At Your Data üëÄ](https://hyperparam.app/) and their blog: [Hyperparam Blog](https://blog.hyperparam.app/).",
    "page_markdowns": [
      "# [Look At Your Data üëÄ](https://hyperparam.app/)\nHighly scalable dataset tool\n\nThe first step in data science is to be deeply familiar with your training data.\n\nBut where do you even start? Most data tools cannot handle the scale of modern data interactively. Using modern data formats like parquet, Hyperparam can load and explore datasets with billions of rows directly in the browser.\n\nModel assisted data curation\n\nWelcome to the era of model-assisted data exploration and curation.\n\nUsing models to reflect back on their own training data can help you find the best quality data, in order to build the best quality models.\n\nLocal-first\n\nA new type of app that moves everything to the browser.\n\nHyperparam is a local-first app that can run entirely in the browser.\n\nDrop a parquet file on this page, or install the Hyperparam CLI tool:\n\nnpx hyperparam",
      "# [Hyperparam Blog by Hyperparam Blog](https://blog.hyperparam.app/)\nHyperparam: How Browser-Based Tools Will Re-Shape AI\n\nWhat is the key to building the most advanced AI models? Data quality.\n\nEveryone wants better AI models: smarter, cheaper, and with style. How does one achieve that? Whether you‚Äôre a mega-scale AI company, or a small enterprise team, the only real lever for making better models is to construct a better training set.\n\nHow do you build a better training set? This is a question that has always been one of the most challenging, and labor-intensive parts of the data science process.\n\nWhy is data cleaning and data understanding so time-consuming? Because current tools often miss three key capabilities: 1) should enable very fast free-form data exploration by the user, which is key to finding insights in your data, 2) use AI models to assist looking at huge volumes of data that would be impractical for a person, and 3) should be simple to run locally in the browser and not depend on complex services and data pipelines. Instead, most tools are built around Python, arguably the worst language for creating modern, compelling UIs and tools. This might seem controversial, but think about what is the most common interface for python? Jupyter Notebooks. Notebooks are great for iteration and experimentation, but they are extremely weak when it comes to interactive data exploration. If you‚Äôve ever tried to open a parquet file (the most common format for modern ML datasets) in a notebook it looks like this:\n\nThis table is practically useless. You can‚Äôt paginate to the next set of rows. You can‚Äôt even see the entire data in a cell (which in this case is an entire github source file). So how are you supposed to get an intuitive sense of your data if you can‚Äôt even see it?\n\nCan we do better? If you want to build a highly performant user interface, there is only one choice: JavaScript. The browser is the only place for building modern UIs.\n\nThe problem is that ML datasets are massive (often multiple gigabytes of compressed text data), so it‚Äôs not obvious if it‚Äôs even possible to work with large scale datasets in the browser. However, by using modern data formats like Apache Parquet, and clever frontend engineering, it is in fact possible to work with massive datasets directly in the browser.\n\nAside: Apache Parquet files are a column-oriented data structure that contains a built-in index. This allows tools like hadoop and duckdb to efficiently query parquet datasets without having to retrieve all the data. Furthermore it allows doing these queries without a server, simply by putting the parquet files in a storage service like S3. What if you could do this same trick in the browser, and pull in just the data needed to render the current view. Hello Hyparquet.\n\nHyparquet is a new JavaScript parquet parser which can efficiently query against parquet files stored in the cloud. This enables the creation of a new type of client-side only parquet data viewer which is significantly faster than anything that could be done with a server.\n\nThe goal here is to get data engineers to look at their data üëÄ Anyone who has worked with data for a model before knows that looking at your data is the key to understanding the domain you‚Äôre trying to model, and it is virtually impossible to do good data science without looking at your data. Looking at your data is the easiest way to find data and model issues, and is a constant source of ideas of how to improve them.\n\nThis is one of the core workflows in data science: build a model, see what data was correctly or incorrectly modeled, fix the data and/or the model, and repeat. This is a repeatable, teachable process! And if it can be taught to a human data scientist, why can‚Äôt it be taught to a model to assist?\n\nCan you use a model to assist with dataset curation? The challenges are two-fold: 1) How do you leverage human expertise to express what you want from the model? 2) These datasets are huge, so the cost of running a model across all the data is expensive.\n\nYou need the human in the loop to express their intent for the data. There is not just one definition of ‚Äúgood‚Äù versus ‚Äúbad‚Äù data. What matters is the question ‚Äúis this data useful for the model I‚Äôm trying to build?‚Äù This is where the UI comes in as a way to allow the user to look at the data, and use the data to express their intent.\n\nAs for the cost, we are entering a new era of LLMs where for the first time it is affordable to do dataset-scale inference in which you run an entire dataset through a model to help filter and label data. In 2023 it cost $5,000,000 USD to process 1 trillion input tokens with a sota model (gpt-4-turbo). In 2024 it cost $75,000 USD to process 1 trillion input tokens with a similar model (gpt-4o-mini). This trend will continue to make dataset-scale inference accessible to model builders. Model-based quality filtering has already been used by Meta to filter the training set for llama3 using labels generated by llama2 [1].\n\nWe‚Äôre entering a new era in which dataset-scale inference and interactive, browser-based data exploration will define how AI models are built and refined. By combining efficient data formats, high-performance JavaScript interfaces, and affordable AI-based annotations, teams can finally put data quality front and center without prohibitively high costs or clunky workflows.\n\nThe future belongs to those who seamlessly blend human expertise with AI-assisted insights‚Äîan approach that makes data cleaning faster, more intuitive, and ultimately, far more effective in powering the next generation of advanced AI models."
    ],
    "search_results": [
      {
        "title": "Hyperparam - Look At Your Data",
        "link": "https://hyperparam.app/",
        "snippet": "hyperparam is the missing UI for machine learning.",
        "formattedUrl": "https://hyperparam.app/"
      },
      {
        "title": "Hyperparam Blog | The Missing UI for AI Data",
        "link": "https://blog.hyperparam.app/",
        "snippet": "7 days ago ... What is the key to building the most advanced AI models? Data quality. Everyone wants better AI models: smarter, cheaper, and with style. How¬†...",
        "formattedUrl": "https://blog.hyperparam.app/"
      }
    ]
  },
  "general_search_markdown": "# Official social media\n- [Hyperparam on LinkedIn](https://www.linkedin.com/company/hyperparam)  \n- [Hyperparam Blog](https://blog.hyperparam.app)  \n\n# Job boards\n- [Senior Javascript Engineer at Hyperparam ‚Ä¢ Seattle | Wellfound](https://wellfound.com/jobs/3185363-senior-javascript-engineer)  \n\n# App stores\n- [Hyperparam - Look At Your Data](https://hyperparam.app/)  \n\n# Product reviews\n- No relevant product reviews found.\n\n# News articles (most recent first, grouped by event)\n- No significant news articles found.\n\n# Key employees (grouped by employee)\n- **Kenny Daniel**  \n  [Kenny Daniel - Hyperparam | LinkedIn](https://www.linkedin.com/in/kennydaniel)  \n\n# Other pages on the company website\n- [Hyperparam Blog | The Missing UI for AI Data](https://blog.hyperparam.app/)  \n\n# Other\n- [Learning Diffusion using Hyperparameters](http://proceedings.mlr.press/v80/kalimeris18a/kalimeris18a.pdf)  \n- [A Hyperparameter Optimization Toolkit for Neural Machine ...](https://aclanthology.org/2023.acl-demo.15.pdf)  \n- [Improving Unsupervised Video Object Segmentation with Motion ...](https://arxiv.org/abs/2212.08816)  \n- [Hyperparameter tuning on Google Cloud Platform is now faster and ...](https://cloud.google.com/blog/products/gcp/hyperparameter-tuning-on-google-cloud-platform-is-now-faster-and-smarter)  \n- [Vertex AI: Hyperparameter Tuning](https://codelabs.developers.google.com/vertex_hyperparameter_tuning)  \n- [Hyperparameter tuning using Bayesian optimization - PyTorch Forums](https://discuss.pytorch.org/t/hyperparameter-tuning-using-bayesian-optimization/36145)  \n- [Hyperopt best practices and troubleshooting | Databricks on AWS](https://docs.databricks.com/en/machine-learning/automl-hyperparam-tuning/hyperopt-best-practices.html)  \n- [Hyperparameter optimization with Dask ‚Äî Dask Examples ...](https://examples.dask.org/machine-learning/hyperparam-opt.html)  \n- [KerasTuner](https://keras.io/keras_tuner/)  \n- [Hyperparameter Tuning for Machine and Deep Learning with R](https://library.oapen.org/bitstream/id/240dc394-c1a4-414e-8465-d9dc8824c7e5/978-981-19-5170-1.pdf)  \n- [An Efficient Approach for Assessing Hyperparameter Importance](https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/14-ICML-HyperparameterAssessment-longversion.pdf)  \n- [Meta Hyperparameter Optimization with Adversarial Proxy Subsets ...](https://mn.cs.tsinghua.edu.cn/xinwang/PDF/papers/2021_Meta%20Hyperparameter%20Optimization%20with%20Adversarial%20Proxy%20Subsets%20Sampling.pdf)  \n- [Privacy Policy ‚Äì PostgresML](https://postgresml.org/privacy)  \n- [MLflow Hyperparameter Tuning Guide ‚Äî Restack](https://www.restack.io/docs/mlflow-knowledge-mlflow-hyperparameter-tuning)  \n- [Bayesian Hyperparameter Optimization: Basics & Quick Tutorial](https://www.run.ai/guides/hyperparameter-tuning/bayesian-hyperparameter-optimization)  \n- [Convolutional Neural Networks Hyperparameter Tunning for ...](https://www.tandfonline.com/doi/full/10.1080/08839514.2022.2058165)",
  "crunchbase_markdown": null,
  "customer_experience_result": null,
  "glassdoor_result": null,
  "news_result": null,
  "lineage": {
    "run_at": "2025-01-27T20:12:24.516403",
    "git_sha": "b3fa075"
  }
}